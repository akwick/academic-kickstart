
@article{parnas_criteria_1972,
	title = {On the criteria to be used in decomposing systems into modules},
	volume = {15},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=361598.361623},
	doi = {10.1145/361598.361623},
	number = {12},
	urldate = {2017-11-20},
	journal = {Communications of the ACM},
	author = {Parnas, David Lorge},
	month = dec,
	year = {1972},
	keywords = {software engineering, KWIC index, modularity, modules, software, software design},
	pages = {1053--1058},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\K39JZTC3\\Parnas - 1972 - On the Criteria to Be Used in Decomposing Systems .pdf:application/pdf;Parnas - 1972 - On the Criteria to Be Used in Decomposing Systems .pdf:C\:\\Users\\Anna\\Zotero\\storage\\UI5SEBZ5\\Parnas - 1972 - On the Criteria to Be Used in Decomposing Systems .pdf:application/pdf}
}

@inproceedings{halfond_using_2006,
	title = {Using positive tainting and syntax-aware evaluation to counter {SQL} injection attacks},
	abstract = {SQL injection attacks pose a serious threat to the security of Web applications because they can give attackers unrestricted access to databases that contain sensitive information. In this paper, we propose a new, highly automated approach for protecting existing Web applications against SQL injection. Our approach has both conceptual and practical advantages over most existing techniques. From the conceptual standpoint, the approach is based on the novel idea of positive tainting and the concept of syntax-aware evaluation. From the practical standpoint, our technique is at the same time precise and efficient and has minimal deployment requirements. The paper also describes WASP, a tool that implements our technique, and a set of studies performed to evaluate our approach. In the studies, we used our tool to protect several Web applications and then subjected them to a large and varied set of attacks and legitimate accesses. The evaluation was a complete success: WASP successfully and efficiently stopped all of the attacks without generating any false positives.},
	booktitle = {{IN} {SIGSOFT} {FSE}},
	publisher = {ACM Press},
	author = {Halfond, William G. J. and Orso, Alessandro and Manolios, Panagiotis},
	year = {2006},
	pages = {175--185},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\M3XHB8SU\\Halfond et al. - 2006 - Using positive tainting and syntax-aware evaluatio.pdf:application/pdf;Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\3S4D8NE8\\Halfond et al. - 2006 - Using positive tainting and syntax-aware evaluatio.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7Q4D85RH\\summary.html:text/html;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NQIWSWQU\\summary.html:text/html}
}

@inproceedings{haldar_dynamic_2005,
	title = {Dynamic {Taint} {Propagation} for {Java}},
	abstract = {Improperly validated user input is the underlying root cause for a wide variety of attacks on web-based applications. Static approaches for detecting this problem help at the time of development, but require source code and report a number of false positives. Hence, they are of little use for securing fully deployed and rapidly evolving applications. We propose a dynamic solution that tags and tracks user input at runtime and prevents its improper use to maliciously affect the execution of the program. Our implementation can be transparently applied to Java classfiles, and does not require source code. Benchmarks show that the overhead of this runtime enforcement is negligible and can prevent a number of attacks. 1.},
	booktitle = {In {Proceedings} of the 21st {Annual} {Computer} {Security} {Applications} {Conference}},
	author = {Haldar, Vivek and Chandra, Deepak and Franz, Michael},
	year = {2005},
	pages = {303--311},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ZPXQ8MSZ\\Haldar et al. - 2005 - Dynamic Taint Propagation for Java.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\A6CC782D\\summary.html:text/html}
}

@inproceedings{nguyen-tuong_automatically_2005,
	title = {Automatically hardening web applications using precise tainting},
	abstract = {Most web applications contain security vulnerabilities. The simple and natural ways of creating a web application are prone to SQL injection attacks and cross-site scripting attacks (among other less common vulnerabilities). In response, many tools have been developed for detecting or mitigating common web application vulnerabilities. Existing techniques either require effort from the site developer or are prone to false positives. This paper presents a fully automated approach to securely hardening web applications. It is based on precisely tracking taintedness of data and checking specifically for dangerous content in only in parts of commands and output that came from untrustworthy sources. Unlike previous work in which everything that is derived from tainted input is tainted, our approach precisely tracks taintedness within data values. We describe our results and prototype implementation on the predominant LAMP (Linux, Apache, MySQL, PHP) platform. 1.},
	booktitle = {In 20th {IFIP} {International} {Information} {Security} {Conference}},
	author = {Nguyen-tuong, Anh and Guarnieri, Salvatore and Greene, Doug and Evans, David},
	year = {2005},
	pages = {372--382},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\93UP4FXW\\Nguyen-tuong et al. - 2005 - Automatically hardening web applications using pre.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\XWRCQAWE\\summary.html:text/html}
}

@inproceedings{newsome_dynamic_2005,
	title = {Dynamic {Taint} {Analysis} for {Automatic} {Detection}, {Analysis}, and {Signature} {Generation} of {Exploits} on {Commodity} {Software}},
	abstract = {Software vulnerabilities have had a devastating effect on the Internet. Worms such as CodeRed and Slammer can compromise hundreds of thousands of hosts within hours or even minutes, and cause millions of dollars of damage [25, 42]. To successfully combat these fast automatic Internet attacks, we need fast automatic attack detection and filtering mechanisms. In this paper we propose dynamic taint analysis for automatic detection of overwrite attacks, which include most types of exploits. This approach does not need source code or special compilation for the monitored program, and hence works on commodity software. To demonstrate this idea, we have implemented TaintCheck, a mechanism that can perform dynamic taint analysis by performing binary rewriting at run time. We show that TaintCheck reliably detects most types of exploits. We found that TaintCheck produced no false positives for any of the many different programs that we tested. Further, we describe how Taint-Check could improve automatic signature generation in several ways. 1.},
	author = {Newsome, James},
	year = {2005},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\H8AEGSNZ\\Newsome - 2005 - Dynamic Taint Analysis for Automatic Detection, An.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EPRZJ893\\summary.html:text/html}
}

@inproceedings{clause_dytan:_2007,
	title = {Dytan: {A} {Generic} {Dynamic} {Taint} {Analysis} {Framework}},
	shorttitle = {Dytan},
	abstract = {Dynamic taint analysis is gaining momentum. Techniques based on dynamic tainting have been successfully used in the context of application security, and now their use is also being explored in different areas, such as program understanding, software testing, and debugging. Unfortunately, most existing approaches for dynamic tainting are defined in an ad-hoc manner, which makes it difficult to extend them, experiment with them, and adapt them to new contexts. Moreover, most existing approaches are focused on data-flow based tainting only and do not consider tainting due to control flow, which limits their applicability outside the security domain. To address these limitations and foster experimentation with dynamic tainting techniques, we defined and developed a general framework for dynamic tainting that (1) is highly flexible and customizable, (2) allows for performing both data-flow and control-flow based tainting conservatively, and (3) does not rely on any customized runtime system. We also present DYTAN, an implementation of our framework that works on x86 executables, and a set of preliminary studies that show how DYTAN can be used to implement different tainting-based approaches with limited effort. In the studies, we also show that DYTAN can be used on real software, by using FIRE-FOX as one of our subjects, and illustrate how the specific characteristics of the tainting approach used can affect efficiency and accuracy of the taint analysis, which further justifies the use of our framework to experiment with different variants of an approach.},
	booktitle = {in {Proceedings} of the {International} {Symposium} on {Software} {Testing} and {Analysis}},
	author = {Clause, James and Li, Wanchun and Orso, Ro},
	year = {2007},
	pages = {196--206},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ZFMU87RQ\\Clause et al. - 2007 - Dytan A Generic Dynamic Taint Analysis Framework.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\Q8W3U498\\summary.html:text/html}
}

@book{denning_lattice_1976,
	title = {A {Lattice} {Model} of {Secure} {Information} {Flow}},
	abstract = {This paper investigates mechanisms that guarantee secure information flow in a computer system. These mechanisms are examined within a mathematical framework suitable for formulating the requirements of secure information flow among security classes. The central component of the model is a lattice structure derived from the security classes and justified by the semantics of information flow. The lattice properties permit concise formulations of the security requirements of different existing systems and facilitate the construction of mechanisms that enforce security. The model provides a unifying view of all systems that restrict information flow, enables a classification of them according to security objectives, and suggests some new approaches. It also leads to the construction of automatic program certification mechanisms for verifying the secure flow of information through a program.},
	author = {Denning, Dorothy E.},
	year = {1976},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\V8NRHIAS\\Denning - 1976 - A Lattice Model of Secure Information Flow.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\U6CTPSHK\\summary.html:text/html}
}

@misc{noauthor_berkeley-correctness-group/jalangi-berkeley_nodate,
	title = {Berkeley-{Correctness}-{Group}/{Jalangi}-{Berkeley}},
	url = {https://github.com/Berkeley-Correctness-Group/Jalangi-Berkeley},
	abstract = {Jalangi-Berkeley - Doing research on top of Jalangi},
	urldate = {2016-02-05},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\B2JZ5R8E\\Jalangi-Berkeley.html:text/html}
}

@article{james_scrum_2010,
	title = {Scrum reference card},
	url = {http://www.martinschuurman.nl/AgileScrum_bestanden/Naslag/TheScrumReferenceCard.pdf},
	urldate = {2016-01-22},
	journal = {CollabNet Inc},
	author = {James, Michael},
	year = {2010},
	file = {ScrumReferenceCard.pdf:C\:\\Users\\Anna\\Zotero\\storage\\H5QJ6VVG\\ScrumReferenceCard.pdf:application/pdf}
}

@misc{noauthor_yasserg/crawler4j_nodate,
	title = {yasserg/crawler4j},
	url = {https://github.com/yasserg/crawler4j},
	abstract = {crawler4j - Open Source Web Crawler for Java},
	urldate = {2016-01-19},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IBTKWVQH\\crawler4j.html:text/html}
}

@misc{noauthor_top_nodate,
	title = {Top {Sites}: {The} 500 {Most} {Important} {Websites} on the {Internet} - {Moz}},
	url = {https://moz.com/top500},
	urldate = {2016-01-19},
	file = {Top Sites\: The 500 Most Important Websites on the Internet - Moz:C\:\\Users\\Anna\\Zotero\\storage\\5D8FGTQM\\top500.html:text/html}
}

@misc{noauthor_mikecann/chrome-crawler_nodate,
	title = {mikecann/{Chrome}-{Crawler}},
	url = {https://github.com/mikecann/Chrome-Crawler},
	abstract = {Chrome-Crawler - An extension for google chrome that lets a use crawl a webpage for files and links},
	urldate = {2016-01-19},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2FM64C76\\Chrome-Crawler.html:text/html}
}

@misc{noauthor_jalangi_nodate,
	title = {Jalangi {Online} {Demo}},
	url = {https://www.eecs.berkeley.edu/~gongliang13/jalangi_ff/demo_integrated.htm},
	urldate = {2016-01-16},
	file = {Jalangi Online Demo:C\:\\Users\\Anna\\Zotero\\storage\\DRQTPWXA\\demo_integrated.html:text/html;Jalangi Online Demo:C\:\\Users\\Anna\\Zotero\\storage\\FPNSAPB4\\demo_integrated.html:text/html;Jalangi Online Demo:C\:\\Users\\Anna\\Zotero\\storage\\HK5FU3IE\\demo_integrated.html:text/html}
}

@misc{noauthor_jalangi_nodate-1,
	title = {Jalangi - {A} {Dynamic} {Analysis} {Framework} for {Frontend} and {Backend} {JavaScript}},
	url = {https://www.eecs.berkeley.edu/~gongliang13/jalangi_ff/},
	urldate = {2016-01-16},
	file = {Jalangi - A Dynamic Analysis Framework for Frontend and Backend JavaScript:C\:\\Users\\Anna\\Zotero\\storage\\68E5T92R\\jalangi_ff.html:text/html}
}

@article{theodore_d._hellmann_rule-based_2011,
	title = {Rule-{Based} {Exploratory} {Testing} of {Graphical} {User} {Interfaces}},
	doi = {10.1109/AGILE.2011.23},
	journal = {Proceedings - 2011 Agile Conference, Agile 2011},
	author = {Theodore D. Hellmann, Frank Maurer},
	year = {2011},
	pages = {107 -- 116},
	file = {Rule-Based Exploratory Testing of Graphical User Interfaces (PDF Download Available):C\:\\Users\\Anna\\Zotero\\storage\\PPV59KQ3\\224256377_Rule-Based_Exploratory_Testing_of_Graphical_User_Interfaces.html:text/html}
}

@misc{noauthor_moqups_nodate,
	title = {Moqups · online mockups made simple},
	url = {https://moqups.com},
	abstract = {The most stunning HTML5 app for creating resolution-independent SVG mockups, wireframes \& interactive prototypes for your next project},
	urldate = {2016-01-10},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\D77WBM2I\\moqups.com.html:text/html}
}

@article{rivest_inference_1993,
	title = {Inference of {Finite} {Automata} {Using} {Homing} {Sequences}},
	volume = {103},
	issn = {08905401},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540183710217},
	doi = {10.1006/inco.1993.1021},
	language = {en},
	number = {2},
	urldate = {2016-01-09},
	journal = {Information and Computation},
	author = {Rivest, R.L. and Schapire, R.E.},
	month = apr,
	year = {1993},
	pages = {299--347}
}

@article{angluin_learning_1987,
	title = {Learning regular sets from queries and counterexamples},
	volume = {75},
	issn = {08905401},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0890540187900526},
	doi = {10.1016/0890-5401(87)90052-6},
	language = {en},
	number = {2},
	urldate = {2016-01-09},
	journal = {Information and Computation},
	author = {Angluin, Dana},
	month = nov,
	year = {1987},
	pages = {87--106}
}

@inproceedings{saxena_symbolic_2010,
	title = {A {Symbolic} {Execution} {Framework} for {JavaScript}},
	isbn = {978-1-4244-6894-2},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5504700},
	doi = {10.1109/SP.2010.38},
	urldate = {2016-01-09},
	publisher = {IEEE},
	author = {Saxena, Prateek and Akhawe, Devdatta and Hanna, Steve and Mao, Feng and McCamant, Stephen and Song, Dawn},
	year = {2010},
	pages = {513--528}
}

@inproceedings{mesbah_invariant-based_2009,
	title = {Invariant-based automatic testing of {AJAX} user interfaces},
	isbn = {978-1-4244-3453-4},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5070522},
	doi = {10.1109/ICSE.2009.5070522},
	urldate = {2016-01-09},
	publisher = {IEEE},
	author = {Mesbah, Ali and van Deursen, Arie},
	year = {2009},
	pages = {210--220}
}

@inproceedings{mesbah_crawling_2008,
	title = {Crawling {AJAX} by {Inferring} {User} {Interface} {State} {Changes}},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4577876},
	doi = {10.1109/ICWE.2008.24},
	urldate = {2016-01-09},
	publisher = {IEEE},
	author = {Mesbah, Ali and Bozdag, Engin and Deursen, Arie van},
	month = jul,
	year = {2008},
	pages = {122--134}
}

@misc{noauthor_ui/application_nodate,
	title = {{UI}/{Application} {Exerciser} {Monkey} {\textbar} {Android} {Developers}},
	url = {https://developer.android.com/tools/help/monkey.html},
	urldate = {2016-01-08},
	file = {UI/Application Exerciser Monkey | Android Developers:C\:\\Users\\Anna\\Zotero\\storage\\R5RGBDMV\\monkey.html:text/html}
}

@misc{noauthor_monkeyrunner_nodate,
	title = {monkeyrunner {\textbar} {Android} {Developers}},
	url = {https://developer.android.com/tools/help/monkeyrunner_concepts.html},
	urldate = {2016-01-08},
	file = {monkeyrunner | Android Developers:C\:\\Users\\Anna\\Zotero\\storage\\4WF82MK3\\monkeyrunner_concepts.html:text/html}
}

@inproceedings{choi_guided_2013,
	title = {Guided {GUI} testing of android apps with minimal restart and approximate learning},
	isbn = {978-1-4503-2374-1},
	url = {http://dl.acm.org/citation.cfm?doid=2509136.2509552},
	doi = {10.1145/2509136.2509552},
	language = {en},
	urldate = {2016-01-06},
	publisher = {ACM Press},
	author = {Choi, Wontae and Necula, George and Sen, Koushik},
	year = {2013},
	pages = {623--640}
}

@inproceedings{artzi_framework_2011,
	title = {A framework for automated testing of javascript web applications},
	isbn = {978-1-4503-0445-0},
	url = {http://portal.acm.org/citation.cfm?doid=1985793.1985871},
	doi = {10.1145/1985793.1985871},
	language = {en},
	urldate = {2016-01-06},
	publisher = {ACM Press},
	author = {Artzi, Shay and Dolby, Julian and Jensen, Simon Holm and Møller, Anders and Tip, Frank},
	year = {2011},
	pages = {571}
}

@inproceedings{pradel_eventbreak:_2014,
	title = {{EventBreak}: analyzing the responsiveness of user interfaces through performance-guided test generation},
	isbn = {978-1-4503-2585-1},
	shorttitle = {{EventBreak}},
	url = {http://dl.acm.org/citation.cfm?doid=2660193.2660233},
	doi = {10.1145/2660193.2660233},
	language = {en},
	urldate = {2016-01-06},
	publisher = {ACM Press},
	author = {Pradel, Michael and Schuh, Parker and Necula, George and Sen, Koushik},
	year = {2014},
	pages = {33--47}
}

@inproceedings{pan_digtool:_2017,
	address = {Vancouver, BC},
	title = {Digtool: {A} {Virtualization}-{Based} {Framework} for {Detecting} {Kernel} {Vulnerabilities}},
	volume = {26th \{USENIX\} Security Symposium (\{USENIX\} Security 17},
	shorttitle = {Digtool},
	url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/pan},
	publisher = {\{USENIX\} Association},
	author = {Pan, Jianfeng and Yan, Guanglu and Fan, Xiaocao},
	year = {2017},
	pages = {149--165},
	file = {Digtool\: A Virtualization-Based Framework for Detecting Kernel Vulnerabilities | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\PQTT2KMS\\biblio-170.html:text/html}
}

@inproceedings{li_steelix:_2017,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2017},
	title = {Steelix: {Program}-state {Based} {Binary} {Fuzzing}},
	isbn = {978-1-4503-5105-8},
	shorttitle = {Steelix},
	url = {http://doi.acm.org/10.1145/3106237.3106295},
	doi = {10.1145/3106237.3106295},
	abstract = {Coverage-based fuzzing is one of the most effective techniques to find vulnerabilities, bugs or crashes. However, existing techniques suffer from the difficulty in exercising the paths that are protected by magic bytes comparisons (e.g., string equality comparisons). Several approaches have been proposed to use heavy-weight program analysis to break through magic bytes comparisons, and hence are less scalable. In this paper, we propose a program-state based binary fuzzing approach, named Steelix, which improves the penetration power of a fuzzer at the cost of an acceptable slow down of the execution speed. In particular, we use light-weight static analysis and binary instrumentation to provide not only coverage information but also comparison progress information to a fuzzer. Such program state information informs a fuzzer about where the magic bytes are located in the test input and how to perform mutations to match the magic bytes efficiently. We have implemented Steelix and evaluated it on three datasets: LAVA-M dataset, DARPA CGC sample binaries and five real-life programs. The results show that Steelix has better code coverage and bug detection capability than the state-of-the-art fuzzers. Moreover, we found one CVE and nine new bugs.},
	urldate = {2017-10-30},
	booktitle = {Proceedings of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Li, Yuekang and Chen, Bihuan and Chandramohan, Mahinthan and Lin, Shang-Wei and Liu, Yang and Tiu, Alwen},
	year = {2017},
	keywords = {binary fuzzing, binary instrumentation, coverage-based fuzzing},
	pages = {627--637},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\FCX7U3C7\\Li et al. - 2017 - Steelix Program-state Based Binary Fuzzing.pdf:application/pdf}
}

@inproceedings{gao_bovinspector:_2016,
	title = {{BovInspector}: {Automatic} inspection and repair of buffer overflow vulnerabilities},
	shorttitle = {{BovInspector}},
	abstract = {Buffer overflow is one of the most common types of software vulnerabilities. Various static analysis and dynamic testing techniques have been proposed to detect buffer overflow vulnerabilities. With automatic tool support, static buffer overflow detection technique has been widely used in academia and industry. However, it tends to report too many false positives fundamentally due to the lack of software execution information. Currently, static warnings can only be validated by manual inspection, which significantly limits the practicality of the static analysis. In this paper, we present BovInspector, a tool framework for automatic static buffer overflow warnings inspection and validated bugs repair. Given the program source code and static buffer overflow vulnerability warnings, BovInspector first performs warning reachability analysis. Then, BovInspector executes the source code symbolically under the guidance of reachable warnings. Each reachable warning is validated and classified by checking whether all the path conditions and the buffer overflow constraints can be satisfied simultaneously. For each validated true warning, BovInspector fix it with three predefined strategies. BovInspector is complementary to prior static buffer overflow discovery schemes. Experimental results on real open source programs show that BovInspector can automatically inspect on average of 74.9\% of total warnings, and false warnings account for about 25\% to 100\% (on average of 59.9\%) of the total inspected warnings. In addition, the automatically generated patches fix all target vulnerabilities. Further information regarding the implementation and experimental results of BovInspector is available at http://bovinspectortool.github.io/project/. And a short video for demonstrating the capabilities of BovInspector is now available at https://youtu.be/IMdcksROJDg.},
	booktitle = {2016 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Gao, F. and Wang, L. and Li, X.},
	month = sep,
	year = {2016},
	keywords = {Automatic Repair, automatic static buffer overflow warnings inspection, BovInspector, Buffer Overflow, buffer overflow constraints, buffer overflow vulnerabilities repair, bugs repair, dynamic testing techniques, Engines, Explosions, inspection, Inspection, Maintenance engineering, open source programs, path conditions, program debugging, program diagnostics, program source code, program testing, public domain software, Reachability analysis, Software, software vulnerabilities, source code (software), static analysis, static buffer overflow detection technique, static buffer overflow discovery schemes, Symbolic Execution, Testing, tool framework, Validation, warning reachability analysis},
	pages = {786--791},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\3DEJ2H4C\\7582816.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\9FYXUDBT\\Gao et al. - 2016 - BovInspector Automatic inspection and repair of b.pdf:application/pdf}
}

@inproceedings{ognawala_macke:_2016,
	title = {{MACKE}: {Compositional} analysis of low-level vulnerabilities with symbolic execution},
	shorttitle = {{MACKE}},
	abstract = {Concolic (concrete+symbolic) execution has recently gained popularity as an effective means to uncover non-trivial vulnerabilities in software, such as subtle buffer overflows. However, symbolic execution tools that are designed to optimize statement coverage often fail to cover potentially vulnerable code because of complex system interactions and scalability issues of constraint solvers. In this paper, we present a tool (MACKE) that is based on the modular interactions inferred by static code analysis, which is combined with symbolic execution and directed inter-procedural path exploration. This provides an advantage in terms of statement coverage and ability to uncover more vulnerabilities. Our tool includes a novel feature in the form of interactive vulnerability report generation that helps developers prioritize bug fixing based on severity scores. A demo of our tool is available at https://youtu.be/icC3jc3mHEU.},
	booktitle = {2016 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Ognawala, S. and Ochoa, M. and Pretschner, A. and Limmer, T.},
	month = sep,
	year = {2016},
	keywords = {Engines, program debugging, program diagnostics, program testing, Software, buffer overflows, bug fixing, complex system interactions, Complex systems, compositional analysis, Compositional analysis, Computer bugs, concolic execution, concrete+symbolic execution, constraint solvers, directed interprocedural path exploration, interactive vulnerability report generation, low-level vulnerabilities, MACKE tool, Memory management, modular interactions, nontrivial software vulnerabilities, Scalability, scalability issues, Security, severity scores, software tools, static code analysis, Symbolic execution},
	pages = {780--785},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\9TTL5GE8\\7582815.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\RDU6MBWS\\Ognawala et al. - 2016 - MACKE Compositional analysis of low-level vulnera.pdf:application/pdf}
}

@inproceedings{pham_model-based_2016,
	title = {Model-based whitebox fuzzing for program binaries},
	abstract = {Many real-world programs take highly structured and complex files as inputs. The automated testing of such programs is non-trivial. If the test does not adhere to a specific file format, the program returns a parser error. For symbolic execution-based whitebox fuzzing the corresponding error handling code becomes a significant time sink. Too much time is spent in the parser exploring too many paths leading to trivial parser errors. Naturally, the time is better spent exploring the functional part of the program where failure with valid input exposes deep and real bugs in the program. In this paper, we suggest to leverage information about the file format and data chunks of existing, valid files to swiftly carry the exploration beyond the parser code. We call our approach Modelbased Whitebox Fuzzing (MoWF) because the file format input model of blackbox fuzzers can be exploited as a constraint on the vast input space to rule out most invalid inputs during path exploration in symbolic execution. We evaluate on 13 vulnerabilities in 8 large program binaries with 6 separate file formats and found that MoWF exposes all vulnerabilities while both, traditional whitebox fuzzing and model-based blackbox fuzzing, expose only less than half, respectively. Our experiments also demonstrate that MoWF exposes 70\% vulnerabilities without any seed inputs.},
	booktitle = {2016 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Pham, V. T. and Böhme, M. and Roychoudhury, A.},
	month = sep,
	year = {2016},
	keywords = {program debugging, program testing, Symbolic Execution, Testing, Computer bugs, automated program testing, Browsers, bugs, Data models, error handling, error handling code, Grammar, Libraries, Media, model-based blackbox fuzzing, model-based whitebox fuzzing, MoWF, parser error, path exploration, program binaries, Program Binaries, program compilers, program vulnerabilities, security of data, symbolic execution-based whitebox fuzzing},
	pages = {543--553},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\P5LP9RAV\\7582789.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\M5GFBFNV\\Pham et al. - 2016 - Model-based whitebox fuzzing for program binaries.pdf:application/pdf}
}

@inproceedings{bohme_partition-based_2013,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '13},
	title = {Partition-based {Regression} {Verification}},
	isbn = {978-1-4673-3076-3},
	url = {http://dl.acm.org/citation.cfm?id=2486788.2486829},
	abstract = {Regression verification (RV) seeks to guarantee the absence of regression errors in a changed program version. This paper presents Partition-based Regression Verification (PRV): an approach to RV based on the gradual exploration of differential input partitions. A differential input partition is a subset of the common input space of two program versions that serves as a unit of verification. Instead of proving the absence of regression for the complete input space at once, PRV verifies differential partitions in a gradual manner. If the exploration is interrupted, PRV retains partial verification guarantees at least for the explored differential partitions. This is crucial in practice as verifying the complete input space can be prohibitively expensive.   Experiments show that PRV provides a useful alternative to state-of-the-art regression test generation techniques. During the exploration, PRV generates test cases which can expose different behaviour across two program versions. However, while test cases are generally single points in the common input space, PRV can verify entire partitions and moreover give feedback that allows programmers to relate a behavioral difference to those syntactic changes that contribute to this difference.},
	urldate = {2017-10-30},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Böhme, Marcel and Oliveira, Bruno C. d. S. and Roychoudhury, Abhik},
	year = {2013},
	pages = {302--311},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\YZX337KL\\Böhme et al. - 2013 - Partition-based Regression Verification.pdf:application/pdf}
}

@inproceedings{reaves_mobile_2015,
	address = {Berkeley, CA, USA},
	series = {{SEC}'15},
	title = {Mo({Bile}) {Money}, {Mo}({Bile}) {Problems}: {Analysis} of {Branchless} {Banking} {Applications} in the {Developing} {World}},
	isbn = {978-1-931971-23-2},
	shorttitle = {Mo({Bile}) {Money}, {Mo}({Bile}) {Problems}},
	url = {http://dl.acm.org/citation.cfm?id=2831143.2831145},
	abstract = {Mobile money, also known as branchless banking, brings much-needed financial services to the unbanked in the developing world. Leveraging ubiquitous cellular networks, these services are now being deployed as smart phone apps, providing an electronic payment infrastructure where alternatives such as credit cards generally do not exist. Although widely marketed as a more secure option to cash, these applications are often not subject to the traditional regulations applied in the financial sector, leaving doubt as to the veracity of such claims. In this paper, we evaluate these claims and perform the first in-depth measurement analysis of branchless banking applications. We first perform an automated analysis of all 46 known Android mobile money apps across the 246 known mobile money providers and demonstrate that automated analysis fails to provide reliable insights. We subsequently perform comprehensive manual teardown of the registration, login, and transaction procedures of a diverse 15\% of these apps. We uncover pervasive and systemic vulnerabilities spanning botched certification validation, do-it-yourself cryptography, and myriad other forms of information leakage that allow an attacker to impersonate legitimate users, modify transactions in flight, and steal financial records. These findings confirm that the majority of these apps fail to provide the protections needed by financial services. Finally, through inspection of providers' terms of service, we also discover that liability for these problems unfairly rests on the shoulders of the customer, threatening to erode trust in branchless banking and hinder efforts for global financial inclusion.},
	urldate = {2017-10-28},
	booktitle = {Proceedings of the 24th {USENIX} {Conference} on {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Reaves, Bradley and Scaife, Nolen and Bates, Adam and Traynor, Patrick and Butler, Kevin R. B.},
	year = {2015},
	pages = {17--32}
}

@inproceedings{marinescu_ivd:_2017,
	title = {{IVD}: {Automatic} {Learning} and {Enforcement} of {Authorization} {Rules} in {Online} {Social} {Networks}},
	shorttitle = {{IVD}},
	doi = {10.1109/SP.2017.33},
	abstract = {Authorization bugs, when present in online social networks, are usually caused by missing or incorrect authorization checks and can allow attackers to bypass the online social network's protections. Unfortunately, there is no practical way to fully guarantee that an authorization bug will never be introduced-even with good engineering practices-as a web application and its data model become more complex. Unlike other web application vulnerabilities such as XSS and CSRF, there is no practical general solution to prevent missing or incorrect authorization checks. In this paper we propose Invariant Detector (IVD), a defense-in-depth system that automatically learns authorization rules from normal data manipulation patterns and distills them into likely invariants. These invariants, usually learned during the testing or pre-release stages of new features, are then used to block any requests that may attempt to exploit bugs in the social network's authorization logic. IVD acts as an additional layer of defense, working behind the scenes, complementary to privacy frameworks and testing. We have designed and implemented IVD to handle the unique challenges posed by modern online social networks. IVD is currently running at Facebook, where it infers and evaluates daily more than 200,000 invariants from a sample of roughly 500 million client requests, and checks the resulting invariants every second against millions of writes made to a graph database containing trillions of entities. Thus far IVD has detected several high impact authorization bugs and has successfully blocked attempts to exploit them before code fixes were deployed.},
	booktitle = {2017 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Marinescu, P. and Parry, C. and Pomarole, M. and Tian, Y. and Tague, P. and Papagiannis, I.},
	month = may,
	year = {2017},
	keywords = {program testing, Computer bugs, Data models, application security, authorisation, authorization, Authorization, authorization bugs, authorization rules, automatic learning, Business, data manipulation patterns, data privacy, Databases, defense-in-depth system, dynamic invariant detection, Facebook, Internet, intrusion detection and prevention, invariant detector, IVD, learning (artificial intelligence), online social networks, OSN, Privacy, privacy frameworks, privacy testing, Social network services, social networking (online), Web application},
	pages = {1094--1109},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\FZV6QHJD\\7958627.html:text/html;Marinescu et al. - 2017 - IVD Automatic Learning and Enforcement of Authori.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UWCH5D5I\\Marinescu et al. - 2017 - IVD Automatic Learning and Enforcement of Authori.pdf:application/pdf}
}

@inproceedings{holzinger_hardening_2017,
	title = {Hardening {Java} \#x2019;s {Access} {Control} by {Abolishing} {Implicit} {Privilege} {Elevation}},
	doi = {10.1109/SP.2017.16},
	abstract = {While the Java runtime is installed on billions of devices and servers worldwide, it remains a primary attack vector for online criminals. As recent studies show, the majority of all exploited Java vulnerabilities comprise incorrect or insufficient implementations of access-control checks. This paper for the first time studies the problem in depth. As we find, attacks are enabled by shortcuts that short-circuit Java's general principle of stack-based access control. These shortcuts, originally introduced for ease of use and to improve performance, cause Java to elevate the privileges of code implicitly. As we show, this creates many pitfalls for software maintenance, making it all too easy for maintainers of the runtime to introduce blatant confused-deputy vulnerabilities even by just applying normally semantics-preserving refactorings. How can this problem be solved? Can one implement Java's access control without shortcuts, and if so, does this implementation remain usable and efficient? To answer those questions, we conducted a tool-assisted adaptation of the Java Class Library (JCL), avoiding (most) shortcuts and therefore moving to a fully explicit model of privilege elevation. As we show, the proposed changes significantly harden the JCL against attacks: they effectively hinder the introduction of new confused-deputy vulnerabilities in future library versions, and successfully restrict the capabilities of attackers when exploiting certain existing vulnerabilities. We discuss usability considerations, and through a set of large-scale experiments show that with current JVM technology such a faithful implementation of stack-based access control induces no observable performance loss.},
	booktitle = {2017 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Holzinger, P. and Hermann, B. and Lerch, J. and Bodden, E. and Mezini, M.},
	month = may,
	year = {2017},
	keywords = {Libraries, application security, authorisation, Access control, Access control and authorization, access-control checks, attacks and defenses, blatant confused-deputy vulnerabilities, Electronic mail, implicit privilege elevation, Java, Java access control, Java Class Library, Java runtime, Java vulnerabilities, JCL, JVM technology, online criminals, primary attack vector, Runtime, semantics-preserving refactoring, Servers, software libraries, software maintenance, stack-based access control, usability considerations},
	pages = {1027--1040},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\53228FYI\\7958623.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\3Q3N89AW\\Holzinger et al. - 2017 - Hardening Java #x2019\;s Access Control by Abolishi.pdf:application/pdf}
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Downloads}},
	url = {https://www.zotero.org/download/},
	urldate = {2017-10-27},
	file = {Zotero | Downloads:C\:\\Users\\Anna\\Zotero\\storage\\4NLK4PM6\\download.html:text/html}
}

@inproceedings{bocic_finding_2016,
	title = {Finding access control bugs in web applications with {CanCheck}},
	isbn = {978-1-4503-3845-5},
	url = {http://dl.acm.org/citation.cfm?doid=2970276.2970350},
	doi = {10.1145/2970276.2970350},
	language = {en},
	urldate = {2017-10-27},
	publisher = {ACM Press},
	author = {Bocić, Ivan and Bultan, Tevfik},
	year = {2016},
	pages = {155--166}
}

@misc{noauthor_cellular_2016,
	title = {Cellular network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Cellular_network&oldid=753451227},
	abstract = {A cellular network or mobile network is a communication network where the last link is wireless. The network is distributed over land areas called cells, each served by at least one fixed-location transceiver, known as a cell site or base station. This base station provides the cell with the network coverage which can be used for transmission of voice, data and others. A cell might use a different set of frequencies from neighboring cells, to avoid interference and provide guaranteed service quality within each cell.
When joined together these cells provide radio coverage over a wide geographic area. This enables a large number of portable transceivers (e.g., mobile phones, pagers, etc.) to communicate with each other and with fixed transceivers and telephones anywhere in the network, via base stations, even if some of the transceivers are moving through more than one cell during transmission.
Cellular networks offer a number of desirable features:
More capacity than a single large transmitter, since the same frequency can be used for multiple links as long as they are in different cells
Mobile devices use less power than with a single transmitter or satellite since the cell towers are closer
Larger coverage area than a single terrestrial transmitter, since additional cell towers can be added indefinitely and are not limited by the horizon
Major telecommunications providers have deployed voice and data cellular networks over most of the inhabited land area of the Earth. This allows mobile phones and mobile computing devices to be connected to the public switched telephone network and public Internet. Private cellular networks can be used for research or for large organizations and fleets, such as dispatch for local public safety agencies or a taxicab company.},
	language = {en},
	urldate = {2016-12-29},
	journal = {Wikipedia},
	month = dec,
	year = {2016},
	note = {Page Version ID: 753451227},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\V8G6CNX7\\index.html:text/html}
}

@misc{broadfoot_go_2016,
	title = {Go 1.7 is released},
	url = {https://blog.golang.org/go1.7},
	urldate = {2016-12-19},
	journal = {The Go Blog},
	author = {Broadfoot, Chris},
	month = aug,
	year = {2016},
	note = {bibtex: broadfoot\_go\_2016},
	file = {Go 1.7 is released - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\DQ8UAJAP\\go1.html:text/html}
}

@misc{kisiel_errcheck_2016,
	title = {errcheck},
	url = {https://github.com/kisielk/errcheck},
	abstract = {errcheck checks that you checked errors.},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Kisiel, Kamil},
	month = nov,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JPRTSPKJ\\errcheck.html:text/html}
}

@misc{hormann_go-sql-driver/mysql_2016,
	title = {go-sql-driver/mysql},
	url = {https://github.com/go-sql-driver/mysql},
	abstract = {mysql - Go MySQL Driver is a MySQL driver for Go's (golang) database/sql package},
	urldate = {2016-12-07},
	journal = {GitHub},
	author = {Hormann, Arne and Schmidt, Julien},
	month = dec,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\72ENT7WQ\\mysql.html:text/html}
}

@misc{honnef_dominikh/go-staticcheck_2016,
	title = {dominikh/go-staticcheck},
	url = {https://github.com/dominikh/go-staticcheck},
	abstract = {go-staticcheck - Staticcheck is go vet on steroids, applying a ton of static analysis checks you might be used to from tools like ReSharper for C\#},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Honnef, Dominik},
	month = dec,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MMKVIG5X\\go-staticcheck.html:text/html}
}

@article{hoare_communicating_1978,
	title = {Communicating {Sequential} {Processes}},
	volume = {21},
	issn = {0001-0782},
	doi = {10.1145/359576.359585},
	abstract = {This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions of a variety of a familiar programming exercises.},
	number = {8},
	urldate = {2016-08-25},
	journal = {Commun. ACM},
	author = {Hoare, C. A. R.},
	month = aug,
	year = {1978},
	keywords = {classes, concurrency, conditional critical regions, coroutines, data representations, guarded commands, input, iterative arrays, monitors, multiple entries, multiple exits, nondeterminacy, output, parallel programming, procedures, program structures, programming, programming languages, programming primitives, recursion},
	pages = {666--677},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\3UMQZHBR\\Hoare - 1978 - Communicating Sequential Processes.pdf:application/pdf}
}

@inproceedings{hind_pointer_2001,
	address = {New York, NY, USA},
	series = {{PASTE} '01},
	title = {Pointer {Analysis}: {Haven}'t {We} {Solved} {This} {Problem} {Yet}?},
	isbn = {978-1-58113-413-1},
	shorttitle = {Pointer {Analysis}},
	doi = {10.1145/379605.379665},
	abstract = {During the past twenty-one years, over seventy-five papers and nine Ph.D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder, “Haven'trdquo; we solved this problem yet?''  With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.},
	urldate = {2016-10-28},
	booktitle = {Proceedings of the 2001 {ACM} {SIGPLAN}-{SIGSOFT} {Workshop} on {Program} {Analysis} for {Software} {Tools} and {Engineering}},
	publisher = {ACM},
	author = {Hind, Michael},
	year = {2001},
	pages = {54--61},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\EU58HT5N\\Hind - 2001 - Pointer Analysis Haven'T We Solved This Problem Y.pdf:application/pdf}
}

@misc{gautheron_static_2016,
	title = {Static {Analysis} {Tools} for {Go}},
	url = {https://medium.com/@jgautheron/static-analysis-tools-for-go-47e2071aeef7},
	abstract = {Detecting potential issues automatically can spare software engineers many problems that would be spotted later, and possibly too late.},
	urldate = {2016-12-06},
	journal = {Medium},
	author = {Gautheron, Jonathan},
	month = mar,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\3EXPDGCI\\static-analysis-tools-for-go-47e2071aeef7.html:text/html}
}

@misc{gautheron_quality_2015,
	title = {Quality pipeline for {Go} projects},
	url = {https://medium.com/@jgautheron/quality-pipeline-for-go-projects-497e34d6567#.hafv88mfm},
	abstract = {For relatively large projects, it’s never simple to keep a certain level of quality in the code.},
	urldate = {2016-12-06},
	journal = {Medium},
	author = {Gautheron, Jonathan},
	month = sep,
	year = {2015},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CHBE2M32\\quality-pipeline-for-go-projects-497e34d6567.html:text/html}
}

@misc{bohuslavek_mibk/dupl_nodate,
	title = {mibk/dupl},
	url = {https://github.com/mibk/dupl},
	abstract = {dupl - a tool for code clone detection},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Bohusl{\textbackslash}'avek, Michal},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\5QDSQMMT\\dupl.html:text/html}
}

@misc{astaxie_how_2016,
	title = {How to use {PostgreSQL}  {Build} web application with {Golang}},
	url = {https://astaxie.gitbooks.io/build-web-application-with-golang/content/en/05.4.html},
	urldate = {2016-12-13},
	author = {astaxie},
	month = nov,
	year = {2016},
	file = {How to use PostgreSQL · Build web application with Golang:C\:\\Users\\Anna\\Zotero\\storage\\J5WB58F4\\05.4.html:text/html}
}

@misc{gautheron_jgautheron/goconst_2016,
	title = {jgautheron/goconst},
	url = {https://github.com/jgautheron/goconst},
	abstract = {goconst - Find in Go repeated strings that could be replaced by a constant},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Gautheron, Jonathan},
	month = may,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MDRGITSB\\goconst.html:text/html}
}

@misc{klaus_gordonklaus/ineffassign_2016,
	title = {gordonklaus/ineffassign},
	url = {https://github.com/gordonklaus/ineffassign},
	abstract = {ineffassign - Detect ineffectual assignments in Go code.},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Klaus, Gordon},
	month = sep,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7EQQ3SZH\\ineffassign.html:text/html}
}

@misc{fzipp_fzipp/gocyclo_2015,
	title = {fzipp/gocyclo},
	url = {https://github.com/fzipp/gocyclo},
	abstract = {gocyclo - Calculate cyclomatic complexities of functions in Go source code.},
	urldate = {2016-12-04},
	journal = {GitHub},
	author = {fzipp},
	month = jun,
	year = {2015},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\J5GJHT8J\\gocyclo.html:text/html}
}

@misc{pike_cover_2013,
	title = {The cover story - {The} {Go} {Blog}},
	url = {https://blog.golang.org/cover},
	urldate = {2016-04-29},
	author = {Pike, Rob},
	month = dec,
	year = {2013},
	file = {The cover story - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\WMI83ITJ\\cover.html:text/html}
}

@misc{edward_state_2016,
	title = {State of {Go} 2016},
	url = {http://go-talks.appspot.com/github.com/freeformz/talks/20160712_gophercon/talk.slide#26},
	urldate = {2016-12-17},
	author = {Edward, Müller},
	year = {2016},
	file = {State of Go 2016:C\:\\Users\\Anna\\Zotero\\storage\\GKHTNBAJ\\talk.html:text/html}
}

@techreport{owasp_foundation_owasp_2013,
	title = {{OWASP} {Top} 10 - 2013},
	author = {\{OWASP Foundation\}},
	year = {2013}
}

@misc{wassermann_vulnerability_2016,
	title = {Vulnerability {Note} {VU}\#245327 - {McAfee} {VirusScan} for {Linux} contains multiple vulnerabilities},
	url = {http://www.kb.cert.org/vuls/id/245327},
	abstract = {Sql injection},
	urldate = {2016-12-17},
	author = {Wassermann, Garret},
	month = dec,
	year = {2016},
	file = {Vulnerability Note VU#245327 - McAfee VirusScan for Linux contains multiple vulnerabilities:C\:\\Users\\Anna\\Zotero\\storage\\3FBIEHD4\\245327.html:text/html}
}

@misc{barysevich_russian-speaking_2016,
	title = {Russian-{Speaking} {Hacker} {Selling} {Access} to the {US} {Election} {Assistance} {Commission}},
	url = {https://www.recordedfuture.com/rasputin-eac-breach/},
	abstract = {Recorded Future has successfully attributed a breach of the U.S. Election Assistance Commission (EAC) to a Russian-speaking hacker.},
	urldate = {2016-12-17},
	journal = {Recorded Future},
	author = {Barysevich},
	month = dec,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\HA23CAJA\\rasputin-eac-breach.html:text/html}
}

@misc{cisco_cisco_2016,
	title = {Cisco {Firepower} {Management} {Center} {SQL} {Injection} {Vulnerability}},
	url = {https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-20160928-fpmc},
	urldate = {2016-12-17},
	author = {Cisco},
	month = sep,
	year = {2016},
	file = {Cisco Firepower Management Center SQL Injection Vulnerability:C\:\\Users\\Anna\\Zotero\\storage\\K4TXRSBW\\cisco-sa-20160928-fpmc.html:text/html}
}

@misc{noauthor_2004_nodate,
	title = {2004 {Updates} {OWASP} {Top} {Ten} {Project} - {OWASP}},
	url = {https://www.owasp.org/index.php/2004_Updates_OWASP_Top_Ten_Project},
	urldate = {2016-12-17},
	file = {2004 Updates OWASP Top Ten Project - OWASP:C\:\\Users\\Anna\\Zotero\\storage\\KBEVBDSD\\2004_Updates_OWASP_Top_Ten_Project.html:text/html}
}

@misc{boyer_saga_2016,
	title = {The {Saga} of {Go} {Dependency} {Management}},
	url = {https://blog.gopheracademy.com/advent-2016/saga-go-dependency-management/},
	urldate = {2016-12-13},
	author = {Boyer, Sam},
	month = dec,
	year = {2016},
	file = {The Saga of Go Dependency Management:C\:\\Users\\Anna\\Zotero\\storage\\3RSCN5Z5\\saga-go-dependency-management.html:text/html}
}

@misc{noauthor_saga_nodate,
	title = {The {Saga} of {Go} {Dependency} {Management}},
	url = {https://blog.gopheracademy.com/advent-2016/saga-go-dependency-management/},
	urldate = {2016-12-13},
	file = {The Saga of Go Dependency Management:C\:\\Users\\Anna\\Zotero\\storage\\MWWKUC95\\saga-go-dependency-management.html:text/html}
}

@misc{vividcortex_go_nodate,
	title = {Go database/sql tutorial},
	url = {http://go-database-sql.org/index.html},
	urldate = {2016-12-07},
	author = {VividCortex},
	file = {Go database/sql tutorial:C\:\\Users\\Anna\\Zotero\\storage\\MR58PEAZ\\index.html:text/html}
}

@misc{go_authors_ast_nodate,
	title = {ast - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/pkg/go/ast/},
	urldate = {2016-12-07},
	author = {Go Authors},
	file = {ast - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\WHSHW2PC\\ast.html:text/html}
}

@misc{hewlett_packard_enterprise_development_lp_gas_2016,
	title = {{GAS} - {Go} {AST} {Scanner}},
	url = {https://github.com/HewlettPackard/gas},
	abstract = {gas - Go AST Scanner},
	urldate = {2016-09-12},
	journal = {GitHub},
	author = {\{\vphantom{\}}Hewlett Packard Enterprise Development LP},
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WS8AX7ID\\gas.html:text/html}
}

@misc{go_authors_sql_nodate,
	title = {sql - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/pkg/database/sql/},
	urldate = {2016-12-07},
	author = {Go Authors},
	file = {sql - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\WH6JQD56\\sql.html:text/html}
}

@misc{stripe_inc._stripe/safesql_nodate,
	title = {stripe/safesql},
	url = {https://github.com/stripe/safesql},
	abstract = {safesql - Static analysis tool for Golang that protects against SQL injections},
	urldate = {2016-12-07},
	journal = {GitHub},
	author = {Stripe Inc.},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BU87ZT7M\\safesql.html:text/html}
}

@misc{galbreath_client9/misspell_nodate,
	title = {client9/misspell},
	url = {https://github.com/client9/misspell},
	abstract = {Correct commonly misspelled words in source files},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Galbreath, Nick},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\P8RXJZWN\\misspell.html:text/html}
}

@misc{wallgren_walle/lll_nodate,
	title = {walle/lll},
	url = {https://github.com/walle/lll},
	abstract = {lll - Line length linter},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Wallgren, Fredrik},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\4FNMR3KU\\lll.html:text/html}
}

@misc{go_authors_command_nodate,
	title = {Command goimports},
	url = {https://godoc.org/golang.org/x/tools/cmd/goimports},
	abstract = {Command goimports updates your Go import lines, adding missing ones and removing unreferenced ones.},
	urldate = {2016-12-06},
	author = {Go Authors},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\E84VTQJM\\goimports.html:text/html}
}

@misc{honnef_dominikh/go-simple_nodate,
	title = {dominikh/go-simple},
	url = {https://github.com/dominikh/go-simple},
	abstract = {go-simple - Gosimple is a linter for Go source code that specialises on simplifying code},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Honnef, Dominik},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\W6GCF48U\\go-simple.html:text/html}
}

@misc{dempsky_mdempsky/unconvert_nodate,
	title = {mdempsky/unconvert},
	url = {https://github.com/mdempsky/unconvert},
	abstract = {unconvert - Remove unnecessary type conversions from Go source},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Dempsky, Dempsky},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\Z6MM8863\\unconvert.html:text/html}
}

@misc{marti_mvdan/interfacer_nodate,
	title = {mvdan/interfacer},
	url = {https://github.com/mvdan/interfacer},
	abstract = {interfacer - A linter that suggests interface types},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Martí, Daniel},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\W6MQT7H6\\interfacer.html:text/html}
}

@misc{noauthor_golang/lint_nodate,
	title = {golang/lint},
	url = {https://github.com/golang/lint},
	abstract = {This is a linter for Go source code.},
	urldate = {2016-12-06},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\362ZRXIC\\lint.html:text/html}
}

@misc{opennota_opennota/check_nodate,
	title = {opennota/check},
	url = {https://github.com/opennota/check},
	abstract = {A set of utilities for checking Go sources},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {opennota},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EGIG4DBD\\check.html:text/html}
}

@misc{go_authors_golang/lint_nodate,
	title = {golang/lint},
	url = {https://github.com/golang/lint},
	abstract = {This is a linter for Go source code.},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Go Authors},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\GZZUHA5S\\lint.html:text/html}
}

@misc{noauthor_fzipp/gocyclo_nodate,
	title = {fzipp/gocyclo},
	url = {https://github.com/fzipp/gocyclo},
	abstract = {gocyclo - Calculate cyclomatic complexities of functions in Go source code.},
	urldate = {2016-12-06},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6T84WQG2\\gocyclo.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\TP4DZ76G\\gocyclo.html:text/html}
}

@misc{senart_tsenart/deadcode_nodate,
	title = {tsenart/deadcode},
	url = {https://github.com/tsenart/deadcode},
	abstract = {Standalone repo of deadcode package from http://github.com/remyoudompheng/go-misc},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Senart, Tomás},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\KGCQJVP6\\deadcode.html:text/html}
}

@misc{noauthor_tsenart/deadcode_nodate,
	title = {tsenart/deadcode},
	url = {https://github.com/tsenart/deadcode},
	abstract = {Standalone repo of deadcode package from http://github.com/remyoudompheng/go-misc},
	urldate = {2016-12-06},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RI8SUVMT\\deadcode.html:text/html}
}

@misc{go_authors_command_nodate-1,
	title = {Command gotype},
	url = {https://godoc.org/golang.org/x/tools/cmd/gotype},
	abstract = {The gotype command does syntactic and semantic analysis of Go files and packages like the front-end of a Go compiler.},
	urldate = {2016-12-06},
	author = {Go Authors},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6JZUF8EK\\gotype.html:text/html}
}

@misc{donovan_static_2014,
	title = {Static analysis tools for {Go} code comprehension and refactoring},
	url = {https://talks.golang.org/2014/static-analysis.slide#1},
	urldate = {2016-12-06},
	author = {Donovan, Alan},
	month = nov,
	year = {2014},
	file = {Static analysis tools:C\:\\Users\\Anna\\Zotero\\storage\\EU5MXERI\\static-analysis.html:text/html}
}

@misc{noauthor_static_nodate,
	title = {Static analysis tools},
	url = {https://talks.golang.org/2014/static-analysis.slide#1},
	urldate = {2016-12-06},
	file = {Static analysis tools:C\:\\Users\\Anna\\Zotero\\storage\\P7ZGCM2A\\static-analysis.html:text/html}
}

@misc{ralchev_golang_2015,
	title = {Golang code inspection tools : blog.ralch.com},
	shorttitle = {Golang code inspection tools},
	url = {http://blog.ralch.com/tutorial/golang-tools-inspection/},
	urldate = {2016-12-06},
	journal = {Svett Ralchev},
	author = {Ralchev, Svett},
	month = sep,
	year = {2015},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\X56DG269\\golang-tools-inspection.html:text/html}
}

@misc{noauthor_golang_2015,
	title = {Golang code inspection tools : blog.ralch.com},
	shorttitle = {Golang code inspection tools},
	url = {http://blog.ralch.com/tutorial/golang-tools-inspection/},
	urldate = {2016-12-06},
	journal = {Svett Ralchev},
	month = sep,
	year = {2015},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7TIGVIUR\\golang-tools-inspection.html:text/html}
}

@misc{go_authors_vet_nodate,
	title = {vet - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/cmd/vet/},
	urldate = {2016-12-06},
	author = {Go Authors},
	file = {vet - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\XTJANDPI\\vet.html:text/html}
}

@misc{noauthor_opennota/check_nodate,
	title = {opennota/check},
	url = {https://github.com/opennota/check},
	abstract = {A set of utilities for checking Go sources},
	urldate = {2016-12-06},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\R3G6TQC5\\check.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\XDFB25SD\\check.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6QCXTMQK\\check.html:text/html}
}

@misc{gerrand_go_2013,
	title = {go fmt your code - {The} {Go} {Blog}},
	url = {https://blog.golang.org/go-fmt-your-code},
	urldate = {2016-12-06},
	author = {Gerrand, Andrew},
	month = jan,
	year = {2013},
	file = {go fmt your code - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\MJEU4QAH\\go-fmt-your-code.html:text/html}
}

@misc{noauthor_gofmt_nodate,
	title = {gofmt - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/cmd/gofmt/},
	urldate = {2016-12-06},
	file = {gofmt - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\9AE8NVQK\\gofmt.html:text/html}
}

@misc{thomas_alecthomas/gometalinter_nodate,
	title = {alecthomas/gometalinter},
	url = {https://github.com/alecthomas/gometalinter},
	abstract = {gometalinter - Concurrently run Go lint tools and normalise their output},
	urldate = {2016-12-06},
	journal = {GitHub},
	author = {Thomas, Alec},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\5RXAQIPS\\gometalinter.html:text/html}
}

@inproceedings{johnson_lint_1978,
	title = {Lint, a {C} {Program} {Checker}},
	abstract = {Lint is a command which examines C source programs, detecting a number of bugs and obscurities. It enforces the type rules of C more strictly than the C compilers. It may also be used to enforce a number of portability restrictions involved in moving programs between different machines and/or operating systems. Another option detects a number of wasteful, or error prone, constructions which nevertheless are, strictly speaking, legal.  Lint accepts multiple input files and library specifications, and checks them for consistency. The separation of function between lint and the C compilers has both historical and practical rationale. The compilers turn C programs into executable files rapidly and efficiently. This is possible in part because the compilers do not do sophisticated type checking, especially between separately compiled programs. Lint takes a more global, leisurely view of the program, looking much more carefully at the compatibilities.  This document discusses the use of lint...},
	booktitle = {Comp. {Sci}. {Tech}. {Rep}},
	author = {Johnson, S. C.},
	year = {1978},
	pages = {78--1273},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\2QUQ8HA3\\Johnson - 1978 - Lint, a C Program Checker.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\KZR2PQJ3\\summary.html:text/html}
}

@misc{piper_0xdabbad00_2015,
	title = {0xdabbad00 - {Looking} for security trouble spots in {Go} code},
	url = {http://0xdabbad00.com/2015/04/12/looking_for_security_trouble_spots_in_go_code/},
	urldate = {2016-12-04},
	author = {Piper, Scott},
	month = apr,
	year = {2015},
	file = {0xdabbad00 - Looking for security trouble spots in Go code:C\:\\Users\\Anna\\Zotero\\storage\\4R393J9S\\looking_for_security_trouble_spots_in_go_code.html:text/html}
}

@misc{piper_0xdabbad00_2015-1,
	title = {0xdabbad00 - {Go} code auditing},
	url = {http://0xdabbad00.com/2015/04/18/go_code_auditing/},
	urldate = {2016-12-04},
	author = {Piper, Scott},
	month = apr,
	year = {2015},
	file = {0xdabbad00 - Go code auditing:C\:\\Users\\Anna\\Zotero\\storage\\7G9SAJQR\\go_code_auditing.html:text/html}
}

@misc{noauthor_mre/awesome-static-analysis_nodate,
	title = {mre/awesome-static-analysis},
	url = {https://github.com/mre/awesome-static-analysis},
	abstract = {awesome-static-analysis - A curated list of static analysis tools, linters and code quality checkers for various programming languages},
	urldate = {2016-12-04},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\384T3FB9\\awesome-static-analysis.html:text/html}
}

@misc{whatcott_goconvey_nodate,
	title = {{GoConvey} - {Go} testing in the browser},
	url = {http://goconvey.co/},
	urldate = {2016-11-29},
	author = {Whatcott, Mike and Holt, Matt},
	file = {GoConvey - Go testing in the browser:C\:\\Users\\Anna\\Zotero\\storage\\DZNTX9RJ\\goconvey.co.html:text/html}
}

@misc{go_authors_testing_nodate,
	title = {testing - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/pkg/testing/},
	urldate = {2016-11-29},
	author = {Go Authors},
	file = {testing - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\MWJDVESP\\testing.html:text/html}
}

@article{midtgaard_control-flow_2012,
	title = {Control-flow {Analysis} of {Functional} {Programs}},
	volume = {44},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2187671.2187672},
	doi = {10.1145/2187671.2187672},
	abstract = {We present a survey of control-flow analysis of functional programs, which has been the subject of extensive investigation throughout the past 30 years. Analyses of the control flow of functional programs have been formulated in multiple settings and have led to many different approximations, starting with the seminal works of Jones, Shivers, and Sestoft. In this article, we survey control-flow analysis of functional programs by structuring the multitude of formulations and approximations and comparing them.},
	number = {3},
	urldate = {2016-11-27},
	journal = {ACM Comput. Surv.},
	author = {Midtgaard, Jan},
	month = jun,
	year = {2012},
	keywords = {Control-flow analysis, higher-order functions},
	pages = {10:1--10:33},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\7D8R29RS\\Midtgaard - 2012 - Control-flow Analysis of Functional Programs.pdf:application/pdf}
}

@inproceedings{agarwal_may-happen--parallel_2007,
	address = {New York, NY, USA},
	series = {{PPoPP} '07},
	title = {May-happen-in-parallel {Analysis} of {X}10 {Programs}},
	isbn = {978-1-59593-602-8},
	url = {http://doi.acm.org/10.1145/1229428.1229471},
	doi = {10.1145/1229428.1229471},
	abstract = {X10 is a modern object-oriented programming language designed for high performance, high productivity programming of parallel and multi-core computer systems. Compared to the lower-level thread-based concurrency model in the JavaTM language, X10 has higher-level concurrency constructs such as async, atomic and finish built into the language to simplify creation, analysis and optimization of parallel programs. In this paper, we introduce a new algorithm for May-Happen-in-Parallel (MHP) analysis of X10 programs. The analysis algorithm is based on simple path traversals in the Program Structure Tree, and does not rely on pointer alias analysis of thread objects as in MHP analysis for Java programs. We introduce a more precise definition of the MHP relation than in past work by adding condition vectors that identify execution instances for which the MHP relation holds, instead of just returning a single true/false value for all pairs of executing instances. Further, MHP analysis is refined in our approach by using the observation that two statement instances which occur in atomic sections that execute at the same X10 place must have MHP = false. We expect that our MHP analysis algorithm will be applicable to any language that adopts the core concepts of places, async, finish, and atomic sections from the X10 programming model. We also believe that this approach offers the best of two worlds to programmers and parallel programming tools ---higher-level abstractions of concurrency coupled with simple and efficient analysis algorithms.},
	urldate = {2016-11-27},
	booktitle = {Proceedings of the 12th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming}},
	publisher = {ACM},
	author = {Agarwal, Shivali and Barik, Rajkishore and Sarkar, Vivek and Shyamasundar, Rudrapatna K.},
	year = {2007},
	keywords = {activity, atomic, concurrent, may-happen-in-parallel, parallel program analysis, place, X10},
	pages = {183--193},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\SHWG6QKJ\\Agarwal et al. - 2007 - May-happen-in-parallel Analysis of X10 Programs.pdf:application/pdf}
}

@incollection{might_family_2011,
	title = {A {Family} of {Abstract} {Interpretations} for {Static} {Analysis} of {Concurrent} {Higher}-{Order} {Programs}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-23702-7_16},
	abstract = {We develop a framework for computing two foundational analyses for concurrent higher-order programs: (control-)flow analysis (CFA) and may-happen-in-parallel analysis (MHP). We pay special attention to the unique challenges posed by the unrestricted mixture of first-class continuations and dynamically spawned threads. To set the stage, we formulate a concrete model of concurrent higher-order programs: the P(CEK*)S machine. We find that the systematic abstract interpretation of this machine is capable of computing both flow and MHP analyses. Yet, a closer examination finds that the precision for MHP is poor. As a remedy, we adapt a shape analytic technique—singleton abstraction—to dynamically spawned threads (as opposed to objects in the heap). We then show that if MHP analysis is not of interest, we can substantially accelerate the computation of flow analysis alone by collapsing thread interleavings with a second layer of abstraction.},
	language = {en},
	urldate = {2016-11-27},
	booktitle = {Static {Analysis}},
	publisher = {Springer Berlin Heidelberg},
	author = {Might, Matthew and Horn, David Van},
	month = sep,
	year = {2011},
	doi = {10.1007/978-3-642-23702-7_16},
	pages = {180--197},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ENQ3JHEH\\Might und Horn - 2011 - A Family of Abstract Interpretations for Static An.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\N57QSAGE\\10.html:text/html}
}

@misc{noauthor_go_nodate,
	title = {Go {Concurrency} {Patterns}: {Pipelines} and cancellation - {The} {Go} {Blog}},
	url = {https://blog.golang.org/pipelines},
	urldate = {2016-11-26},
	file = {Go Concurrency Patterns\: Pipelines and cancellation - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\V4MJEUJU\\pipelines.html:text/html}
}

@misc{pike_go_2012,
	title = {Go {Concurrency} {Patterns}},
	url = {https://talks.golang.org/2012/concurrency.slide},
	abstract = {Talk from Rob Pike about golang concurrency Patterns},
	urldate = {2016-10-27},
	author = {Pike, Rob},
	month = jun,
	year = {2012},
	file = {Go Concurrency Patterns:C\:\\Users\\Anna\\Zotero\\storage\\ZK6AJQ5F\\concurrency.html:text/html}
}

@misc{pike_go_2012-1,
	title = {Go at {Google}: {Language} {Design} in the {Service} of {Software} {Engineering}},
	url = {https://talks.golang.org/2012/splash.article},
	urldate = {2016-11-22},
	author = {Pike, Rob},
	month = oct,
	year = {2012},
	file = {Go at Google\: Language Design in the Service of Software Engineering:C\:\\Users\\Anna\\Zotero\\storage\\87PJCFXA\\splash.html:text/html}
}

@misc{norvaisa_go_nodate,
	title = {{GO} {LANG} – {A} {Next} {Gen} language – easier to learn than you think! {Some} great resources to get you started.},
	url = {https://www.zenedge.com/blog/go-lang-a-next-gen-language-easier-to-learn-than-you-think-some-great-resources-to-get-you-started},
	abstract = {GO LANG – A Next Gen language – easier to learn than you think! Some great resources to get you started.},
	urldate = {2016-11-22},
	author = {Norvaisa, Mantas},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2X7MM4FV\\go-lang-a-next-gen-language-easier-to-learn-than-you-think-some-great-resources-to-get-you-star.html:text/html}
}

@misc{gouy_go_nodate,
	title = {Go vs {Java} (64-bit {Ubuntu} quad core) {\textbar} {Computer} {Language} {Benchmarks} {Game}},
	url = {http://benchmarksgame.alioth.debian.org/u64q/go.html},
	urldate = {2016-11-22},
	journal = {The Computer Language Benchmarks Game},
	author = {Gouy, Isaac},
	file = {Go vs Java (64-bit Ubuntu quad core) | Computer Language Benchmarks Game:C\:\\Users\\Anna\\Zotero\\storage\\E4EQIDUN\\go.html:text/html}
}

@book{davey_introduction_1990,
	address = {Cambridge},
	edition = {1},
	title = {Introduction to {Lattices} and {Order}},
	publisher = {Cambridge University Press},
	author = {Davey, B.A. and Priestley, H.A},
	year = {1990}
}

@misc{davey_introduction_nodate,
	title = {Introduction to {Lattices} and {Order} - {Cambridge} {University} {Press}},
	url = {http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521784511},
	urldate = {2016-11-21},
	author = {Davey, B.A. and Priestley, H.A},
	file = {Introduction to Lattices and Order - Cambridge University Press:C\:\\Users\\Anna\\Zotero\\storage\\ESUECKWS\\catalogue.html:text/html}
}

@incollection{cavalcante_architecture-based_nodate,
	title = {Architecture-{Based} {Code} {Generation}: {From} π-{ADL} {Architecture} {Descriptions} to {Implementations} in the {Go} {Language}},
	shorttitle = {Architecture-{Based} {Code} {Generation}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-09970-5_13},
	abstract = {Architecture description languages (ADLs) should consider both structural and runtime perspectives of software architectures, an important requirement for current software systems. However, most existing ADLs are disconnected from the runtime level, thus entailing architectural mismatches and inconsistencies between architecture and implementation. With the emergence of the new generation programming languages for large-scale, dynamic, and distributed systems, this problem becomes worse since most existing ADLs do not capture the features of this type of language. In this context, we investigate the generation of source code in the Go programming language from architecture descriptions in the π-ADL language as they are both based on the π-calculus process algebra. We define the correspondences between π-ADL and Go elements and present how architecture descriptions in π-ADL can be automatically translated to their respective implementations in Go through a real-world flood monitoring system.},
	language = {en},
	urldate = {2016-11-11},
	booktitle = {{SpringerLink}},
	publisher = {Springer International Publishing},
	author = {Cavalcante, Everton and Oquendo, Flavio and Batista, Thais},
	doi = {10.1007/978-3-319-09970-5_13},
	pages = {130--145},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\P82RJNZ6\\Cavalcante et al. - Architecture-Based Code Generation From π-ADL Arc.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\DKPB4SQQ\\978-3-319-09970-5_13.html:text/html}
}

@article{pascual_native_2012,
	title = {Native {Handling} of {Message}-{Passing} {Communication} in {Data}-{Flow} {Analysis}},
	volume = {87},
	issn = {1439-7358},
	url = {https://www.researchgate.net/publication/265201351_Native_Handling_of_Message-Passing_Communication_in_Data-Flow_Analysis},
	doi = {10.1007/978-3-642-30023-3_8},
	abstract = {Automatic Differentiation by program transformation uses static data-flow analysis to produce efficient code. This data-flow analysis must be adapted for parallel programs with Message-Passing...},
	urldate = {2016-11-11},
	journal = {ResearchGate},
	author = {Pascual, Valérie and Hascoët, Laurent},
	month = jan,
	year = {2012},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\V4XE6ZKR\\265201351_Native_Handling_of_Message-Passing_Communication_in_Data-Flow_Analysis.html:text/html}
}

@book{balbaert_way_2012,
	title = {The {Way} to {Go}: {A} {Thorough} {Introduction} to the {Go} {Programming} {Language}},
	isbn = {978-1-4697-6916-5},
	shorttitle = {The {Way} to {Go}},
	abstract = {This book provides the reader with a comprehensive overview of the new open source programming language Go (in its first stable and maintained release Go 1) from Google. The language is devised with Java / C\#-like syntax so as to feel familiar to the bulk of programmers today, but Go code is much cleaner and simpler to read, thus increasing the productivity of developers. You will see how Go:  simplifies programming with slices, maps, structs and interfaces incorporates functional programming makes error-handling easy and secure simplifies concurrent and parallel programming with goroutines and channels  And you will learn how to:  make use of Go's excellent standard library program Go the idiomatic way using patterns and best practices in over 225 working examples and 135 exercises  This book focuses on the aspects that the reader needs to take part in the coming software revolution using Go.},
	language = {en},
	publisher = {iUniverse},
	author = {Balbaert, Ivo},
	year = {2012},
	note = {Google-Books-ID: Sxss1kQxfP0C},
	keywords = {Computers / Programming / General, Computers / Reference, Reference / General}
}

@incollection{ferreira_optimizing_2012,
	address = {Berlin, Heidelberg},
	title = {Optimizing a {Geomodeling} {Domain} {Specific} {Language}},
	isbn = {978-3-642-33182-4},
	url = {http://dx.doi.org/10.1007/978-3-642-33182-4_8},
	booktitle = {Programming {Languages}: 16th {Brazilian} {Symposium}, {SBLP} 2012, {Natal}, {Brazil}, {September} 23-28, 2012. {Proceedings}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ferreira, Bruno Morais and Pereira, Fernando Magno Quintão and Rodrigues, Hermann and Soares-Filho, Britaldo Silveira},
	editor = {de Carvalho Junior, Francisco Heron and Barbosa, Luis Soares},
	year = {2012},
	pages = {87--101}
}

@misc{rainald_programmiersprachen-ranking:_2016,
	title = {Programmiersprachen-{Ranking}: {Assembler} stabil, {Go} im {Aufwind}},
	shorttitle = {Programmiersprachen-{Ranking}},
	url = {http://www.heise.de/newsticker/meldung/Programmiersprachen-Ranking-Assembler-stabil-Go-im-Aufwind-3458803.html},
	abstract = {In TIOBEs Top 10 haben sich die Assemblersprachen inzwischen einen festen Platz gesichert. Das im vorigen Jahr herausgefallene Objective-C steht kurz vor dem Wiedereinzug, dicht gefolgt von Swift und Googles Go.},
	urldate = {2016-11-10},
	journal = {heise online},
	author = {Rainald, Menge-Sonnentag},
	month = nov,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZBUGQ86N\\Programmiersprachen-Ranking-Assembler-stabil-Go-im-Aufwind-3458803.html:text/html}
}

@misc{online_programmiersprachen-ranking:_nodate,
	title = {Programmiersprachen-{Ranking}: {Assembler} stabil, {Go} im {Aufwind}},
	shorttitle = {Programmiersprachen-{Ranking}},
	url = {http://www.heise.de/newsticker/meldung/Programmiersprachen-Ranking-Assembler-stabil-Go-im-Aufwind-3458803.html},
	abstract = {In TIOBEs Top 10 haben sich die Assemblersprachen inzwischen einen festen Platz gesichert. Das im vorigen Jahr herausgefallene Objective-C steht kurz vor dem Wiedereinzug, dicht gefolgt von Swift und Googles Go.},
	urldate = {2016-11-10},
	journal = {heise online},
	author = {online, heise},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\V3HS6NRC\\Programmiersprachen-Ranking-Assembler-stabil-Go-im-Aufwind-3458803.html:text/html}
}

@book{nielson_principles_2005,
	address = {Secaucus, NJ, USA},
	title = {Principles of {Program} {Analysis}},
	isbn = {978-3-540-65410-0},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Nielson, Flemming and Nielson, Hanne R. and Hankin, Chris},
	year = {2005}
}

@misc{pike_concurrency_2012,
	title = {Concurrency is not {Parallelism}},
	url = {https://talks.golang.org/2012/waza.slide#1},
	urldate = {2016-11-07},
	author = {Pike, Rob},
	month = jan,
	year = {2012},
	file = {Concurrency is not Parallelism:C\:\\Users\\Anna\\Zotero\\storage\\QHWS6ZTC\\waza.html:text/html}
}

@misc{gerrand_concurrency_2013,
	title = {Concurrency is not parallelism - {The} {Go} {Blog}},
	url = {https://blog.golang.org/concurrency-is-not-parallelism},
	urldate = {2016-11-07},
	author = {Gerrand, Andrew},
	month = jan,
	year = {2013},
	file = {Concurrency is not parallelism - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\8PF2CGIK\\concurrency-is-not-parallelism.html:text/html}
}

@misc{pike_gos_2010,
	title = {Go's {Declaration} {Syntax} - {The} {Go} {Blog}},
	url = {https://blog.golang.org/gos-declaration-syntax},
	urldate = {2016-11-04},
	author = {Pike, Rob},
	month = jul,
	year = {2010},
	file = {Go's Declaration Syntax - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\4X7GI2I2\\gos-declaration-syntax.html:text/html}
}

@misc{donovan_github.com_nodate,
	title = {Github.com tools/go/pointer/gen.go},
	url = {https://github.com/golang/tools},
	abstract = {tools - [mirror] Go Tools},
	urldate = {2016-11-03},
	journal = {GitHub},
	author = {Donovan, Alan and Griesemer, Rob and Gerrand, Andrew and pcc},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\AF3W58KB\\gen.html:text/html}
}

@misc{noauthor_golang/tools_nodate,
	title = {golang/tools},
	url = {https://github.com/golang/tools},
	abstract = {tools - [mirror] Go Tools},
	urldate = {2016-11-03},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BPX5SFQU\\golangtools.html:text/html}
}

@misc{go_authors_pointer_nodate,
	title = {pointer - {GoDoc}},
	url = {https://godoc.org/golang.org/x/tools/go/pointer},
	urldate = {2016-10-28},
	author = {\{Go Authors\}},
	file = {pointer - GoDoc:C\:\\Users\\Anna\\Zotero\\storage\\UM2277BT\\pointer.html:text/html}
}

@inproceedings{hardekopf_ant_2007,
	title = {The ant and the grasshopper: fast and accurate pointer analysis for millions of lines of code},
	isbn = {978-1-59593-633-2},
	shorttitle = {The ant and the grasshopper},
	url = {http://portal.acm.org/citation.cfm?doid=1250734.1250767},
	doi = {10.1145/1250734.1250767},
	language = {en},
	urldate = {2016-10-28},
	publisher = {ACM Press},
	author = {Hardekopf, Ben and Lin, Calvin},
	year = {2007},
	pages = {290}
}

@article{grove_framework_2001,
	title = {A framework for call graph construction algorithms},
	volume = {23},
	issn = {01640925},
	url = {http://portal.acm.org/citation.cfm?doid=506315.506316},
	doi = {10.1145/506315.506316},
	number = {6},
	urldate = {2016-10-28},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Grove, David and Chambers, Craig},
	month = nov,
	year = {2001},
	pages = {685--746}
}

@inproceedings{rountev_off-line_2000,
	title = {Off-line variable substitution for scaling points-to analysis},
	isbn = {978-1-58113-199-4},
	url = {http://portal.acm.org/citation.cfm?doid=349299.349310},
	doi = {10.1145/349299.349310},
	language = {en},
	urldate = {2016-10-28},
	publisher = {ACM Press},
	author = {Rountev, Atanas and Chandra, Satish},
	year = {2000},
	pages = {47--56}
}

@article{pearce_online_2004,
	title = {Online {Cycle} {Detection} and {Difference} {Propagation}: {Applications} to {Pointer} {Analysis}},
	volume = {12},
	issn = {0963-9314},
	shorttitle = {Online {Cycle} {Detection} and {Difference} {Propagation}},
	url = {http://link.springer.com/10.1023/B:SQJO.0000039791.93071.a2},
	doi = {10.1023/B:SQJO.0000039791.93071.a2},
	language = {en},
	number = {4},
	urldate = {2016-10-28},
	journal = {Software Quality Journal},
	author = {Pearce, David J. and Kelly, Paul H.J. and Hankin, Chris},
	month = dec,
	year = {2004},
	pages = {311--337}
}

@inproceedings{pearce_efficient_2004,
	title = {Efficient field-sensitive pointer analysis for {C}},
	isbn = {978-1-58113-910-5},
	url = {http://portal.acm.org/citation.cfm?doid=996821.996835},
	doi = {10.1145/996821.996835},
	language = {en},
	urldate = {2016-10-28},
	publisher = {ACM Press},
	author = {Pearce, David J. and Kelly, Paul H. J. and Hankin, Chris},
	year = {2004},
	pages = {37}
}

@article{landi_undecidability_1992,
	title = {Undecidability of {Static} {Analysis}},
	volume = {1},
	issn = {1057-4514},
	url = {http://doi.acm.org/10.1145/161494.161501},
	doi = {10.1145/161494.161501},
	abstract = {Static analysis of programs is indispensable to any software tool, environment, or system that requires compile-time information about the semantics of programs. With the emergence of languages like C and LISP, static analysis of programs with dynamic storage and recursive data structures has become a field of active research. Such analysis is difficult, and the static-analysis community has recognized the need for simplifying assumptions and approximate solutions. However, even under the common simplifying assumptions, such analyses are harder than previously recognized. Two fundamental static-analysis problems are may alias and must alias. The former is not recursive (is undecidable), and the latter is not recursively enumerable (is uncomputable), even when all paths are executable in the program being analyzed for languages with if statements, loops, dynamic storage, and recursive data structures.},
	number = {4},
	urldate = {2016-10-28},
	journal = {ACM Lett. Program. Lang. Syst.},
	author = {Landi, William},
	month = dec,
	year = {1992},
	keywords = {static analysis, abstract interpretation, Alias analysis, data flow analysis, halting problem},
	pages = {323--337},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\GVVENZ7W\\Landi - 1992 - Undecidability of Static Analysis.pdf:application/pdf}
}

@inproceedings{landi_safe_1992,
	address = {New York, NY, USA},
	series = {{PLDI} '92},
	title = {A {Safe} {Approximate} {Algorithm} for {Interprocedural} {Aliasing}},
	isbn = {978-0-89791-475-8},
	url = {http://doi.acm.org/10.1145/143095.143137},
	doi = {10.1145/143095.143137},
	abstract = {During execution, when two or more names exist for the same location at some program point, we call them aliases. In a language which allows arbitrary pointers, the problem of determining aliases at a program point is \&rgr;-space-hard [Lan92]. We present an algorithm for the Conditional May Alias problem, which can be used to safely approximate Interprocedural May Alias in the presence of pointers. This algorithm is as precise as possible in the worst case and has been implemented in a prototype analysis tool for C programs. Preliminary speed and precision results are presented.},
	urldate = {2016-10-28},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1992 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Landi, William and Ryder, Barbara G.},
	year = {1992},
	pages = {235--248},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\KMK49GNN\\Landi und Ryder - 1992 - A Safe Approximate Algorithm for Interprocedural A.pdf:application/pdf}
}

@inproceedings{paisante_symbolic_2016,
	address = {New York, NY, USA},
	series = {{CGO} '16},
	title = {Symbolic {Range} {Analysis} of {Pointers}},
	isbn = {978-1-4503-3778-6},
	url = {http://doi.acm.org/10.1145/2854038.2854050},
	doi = {10.1145/2854038.2854050},
	abstract = {Alias analysis is one of the most fundamental techniques that compilers use to optimize languages with pointers. However, in spite of all the attention that this topic has received, the current state-of-the-art approaches inside compilers still face challenges regarding precision and speed. In particular, pointer arithmetic, a key feature in C and C++, is yet to be handled satisfactorily. This paper presents a new alias analysis algorithm to solve this problem. The key insight of our approach is to combine alias analysis with symbolic range analysis. This combination lets us disambiguate fields within arrays and structs, effectively achieving more precision than traditional algorithms. To validate our technique, we have implemented it on top of the LLVM compiler. Tests on a vast suite of benchmarks show that we can disambiguate several kinds of C idioms that current state-of-the-art analyses cannot deal with. In particular, we can disambiguate 1.35x more queries than the alias analysis currently available in LLVM. Furthermore, our analysis is very fast: we can go over one million assembly instructions in 10 seconds.},
	urldate = {2016-10-28},
	booktitle = {Proceedings of the 2016 {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {ACM},
	author = {Paisante, Vitor and Maalej, Maroua and Barbosa, Leonardo and Gonnord, Laure and Quintão Pereira, Fernando Magno},
	year = {2016},
	keywords = {Alias analysis, precision, range analysis, speed},
	pages = {171--181},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\HC7A3D97\\Paisante et al. - 2016 - Symbolic Range Analysis of Pointers.pdf:application/pdf}
}

@misc{noauthor_tiobe_nodate,
	title = {{TIOBE} {Index} {\textbar} {TIOBE} - {The} {Software} {Quality} {Company}},
	url = {http://www.tiobe.com/tiobe-index/},
	urldate = {2016-10-24},
	file = {TIOBE Index | TIOBE - The Software Quality Company:C\:\\Users\\Anna\\Zotero\\storage\\HTUUSAPF\\tiobe-index.html:text/html}
}

@misc{pike_gophers:_2016,
	type = {microblog},
	title = {Gophers: {Pointer} receivers in \#golang aren't unusual, it's value receivers that are. {Pointer} receivers are just like in {Java}, only honest.},
	shorttitle = {Gophers},
	url = {https://twitter.com/},
	urldate = {2016-10-21},
	author = {Pike, Rob},
	month = oct,
	year = {2016},
	file = {Tweet Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NEQZ9KK2\\twitter.com.html:text/html;Tweet Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\559HQ454\\twitter.com.html:text/html;Tweet Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RKJHBSCU\\Pike - 2016 - Gophers Pointer receivers in #golang aren't unusu.html:text/html}
}

@misc{google_frequently_nodate,
	title = {Frequently {Asked} {Questions} ({FAQ}) - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/doc/faq},
	urldate = {2016-10-20},
	author = {Google},
	file = {Frequently Asked Questions (FAQ) - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\BMM9S3MM\\faq.html:text/html}
}

@misc{go_authors_effective_nodate,
	title = {Effective {Go} - {The} {Go} {Programming} {Language}},
	shorttitle = {Effective {Go}},
	url = {https://golang.org/doc/effective_go.html},
	urldate = {2016-08-25},
	author = {\{Go Authors\}},
	file = {Effective Go - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\PIW4CMNF\\effective_go.html:text/html}
}

@misc{cheney_five_2014,
	title = {Five things that make {Go} fast {\textbar} {Dave} {Cheney}},
	url = {http://dave.cheney.net/2014/06/07/five-things-that-make-go-fast},
	urldate = {2016-08-25},
	author = {Cheney, Dave},
	month = jun,
	year = {2014},
	file = {Five things that make Go fast | Dave Cheney:C\:\\Users\\Anna\\Zotero\\storage\\ZV376S74\\five-things-that-make-go-fast.html:text/html}
}

@techreport{european_commission_directive_1995,
	title = {\{{Directive} 95/46/{EC} of the {European} {Parliament} and of the {Council} of 24 {October} 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data\}},
	url = {http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31995L0046:en:HTML},
	abstract = {Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data},
	language = {EN},
	number = {Volume 38},
	urldate = {2016-09-01},
	institution = {European Union},
	author = {\{European Commission\} and \{European Parliament\}},
	month = nov,
	year = {1995},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ERC444RC\\LexUriServ.html:text/html}
}

@book{go_authors_mobile_2016,
	title = {Mobile · golang/go {Wiki} · {GitHub}},
	url = {https://github.com/golang/go/wiki/Mobile},
	urldate = {2016-08-17},
	author = {{Go Authors}},
	month = feb,
	year = {2016}
}

@phdthesis{denning_secure_1976,
	title = {Secure {Information} {Flow} in {Computer} {Systems}},
	school = {Purdue University},
	author = {Denning, D.},
	year = {1976}
}

@phdthesis{andersen_program_1994,
	title = {Program {Analysis} and {Specialization} for the {C} {Programming} {Language}},
	school = {DIKU, University of Copenhagen},
	author = {Andersen, Lars Ole},
	year = {1994},
	note = {Available as DIKU report 94/19}
}

@misc{noauthor_secure_nodate,
	title = {Secure {Application} {Development} with {Go} {\textbar} {USA} 2015 {\textbar} {RSA} {Conference}},
	url = {https://www.rsaconference.com/events/us15/agenda/sessions/1587/secure-application-development-with-go},
	urldate = {2016-10-12},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WWZB5739\\secure-application-development-with-go.html:text/html}
}

@misc{scott_0xdabbad00_nodate,
	title = {0xdabbad00 - {Looking} for security trouble spots in {Go} code},
	url = {http://0xdabbad00.com/2015/04/12/looking_for_security_trouble_spots_in_go_code/},
	urldate = {2016-10-12},
	author = {Scott},
	file = {0xdabbad00 - Looking for security trouble spots in Go code:C\:\\Users\\Anna\\Zotero\\storage\\RBDZ8S2I\\looking_for_security_trouble_spots_in_go_code.html:text/html}
}

@misc{noauthor_golang_2016,
	title = {{GOLANG} - {Trojan} {That} {Uses} {Twitter} as a {C}\&{C} server},
	url = {http://www.sectechno.com/golang-trojan-uses-twitter-cc-server/},
	abstract = {GoAT (Golang Advanced Trojan) is a trojan made in Go, using Twitter as a the C\&C server. GoAT has some very unique and impressive capabilities},
	urldate = {2016-10-12},
	journal = {SecTechno},
	month = jul,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\58AT8XS4\\golang-trojan-uses-twitter-cc-server.html:text/html}
}

@misc{noauthor_stripe/safesql_nodate,
	title = {stripe/safesql},
	url = {https://github.com/stripe/safesql},
	abstract = {safesql - Static analysis tool for Golang that protects against SQL injections},
	urldate = {2016-10-12},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WV8JGPSF\\safesql.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\56NUIRQH\\safesql.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\UMIHC9H8\\stripesafesql.html:text/html}
}

@misc{center_for_history_and_new_media_schnelleinstieg_nodate,
	title = {Schnelleinstieg},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@article{kam_monotone_1977,
	title = {Monotone data flow analysis frameworks},
	volume = {7},
	issn = {0001-5903, 1432-0525},
	url = {http://link.springer.com/article/10.1007/BF00290339},
	doi = {10.1007/BF00290339},
	abstract = {We consider a generalization of Kildall's lattice theoretic approach to data flow analysis, which we call monotone data flow analysis frameworks. Many flow analysis problems which appear in practice meet the monotonicity condition but not Kildall's condition called distributivity. We show that the maximal fixed point solution exists for every instance of every monotone framework, and that it can be obtained by Kildall's algorithm. However, whenever the framework is monotone but not distributive, there are instances in which the desired solution—the “meet over all paths solution” — differs from the maximal fixed point. Finally, we show the nonexistence of an algorithm to compute the meet over all paths solution for monotone frameworks.},
	language = {en},
	number = {3},
	urldate = {2016-09-12},
	journal = {Acta Informatica},
	author = {Kam, John B. and Ullman, Jeffrey D.},
	month = sep,
	year = {1977},
	pages = {305--317},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\RKTQMRZ6\\Kam und Ullman - Monotone data flow analysis frameworks.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\TGVAERJZ\\BF00290339.html:text/html}
}

@inproceedings{kildall_unified_1973,
	address = {New York, NY, USA},
	series = {{POPL} '73},
	title = {A {Unified} {Approach} to {Global} {Program} {Optimization}},
	url = {http://doi.acm.org/10.1145/512927.512945},
	doi = {10.1145/512927.512945},
	abstract = {A technique is presented for global analysis of program structure in order to perform compile time optimization of object code generated for expressions. The global expression optimization presented includes constant propagation, common subexpression elimination, elimination of redundant register load operations, and live expression analysis. A general purpose program flow analysis algorithm is developed which depends upon the existence of an "optimizing function." The algorithm is defined formally using a directed graph model of program flow structure, and is shown to be correct. Several optimizing functions are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily be defined for other forms of global code optimization.},
	urldate = {2016-09-12},
	booktitle = {Proceedings of the 1st {Annual} {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kildall, Gary A.},
	year = {1973},
	pages = {194--206},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DFRQ5DE7\\Kildall - 1973 - A Unified Approach to Global Program Optimization.pdf:application/pdf}
}

@misc{noauthor_economic_nodate,
	title = {The economic value of personal data for online platforms, firms and consumers {\textbar} {Bruegel}},
	url = {http://bruegel.org/2016/01/the-economic-value-of-personal-data-for-online-platforms-firms-and-consumers/},
	abstract = {Data is often referred to as the ‘oil of the twenty-first century'. This article reviews how personal data generate economic value for the three major parties of the digital market: online platforms (such as search engines, social networking sites, online videos, content sites) and their clients, companies and consumers.},
	urldate = {2016-09-01},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JR2FJEW8\\the-economic-value-of-personal-data-for-online-platforms-firms-and-consumers.html:text/html}
}

@article{lampson_note_1973,
	title = {A {Note} on the {Confinement} {Problem}},
	volume = {16},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/362375.362389},
	doi = {10.1145/362375.362389},
	abstract = {onfining a program during its execution so that it cannot transmit information to any other program except its caller. A set of examples attempts to stake out the boundaries of the problem. Necessary conditions for a solution are stated and informally justified.},
	number = {10},
	urldate = {2016-08-30},
	journal = {Commun. ACM},
	author = {Lampson, Butler W.},
	month = oct,
	year = {1973},
	keywords = {confinement, leakage of data, privacy, proprietary program, protection, security},
	pages = {613--615},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\6V8Q7D85\\Lampson - 1973 - A Note on the Confinement Problem.pdf:application/pdf}
}

@misc{morsing_go_2013,
	title = {The {Go} scheduler - {Morsing}'s blog},
	shorttitle = {The {Go} scheduler},
	url = {https://morsmachine.dk/go-scheduler},
	urldate = {2016-08-25},
	author = {Morsing, Daniel},
	month = jun,
	year = {2013},
	file = {The Go scheduler - Morsing's blog:C\:\\Users\\Anna\\Zotero\\storage\\2QMVCVNK\\go-scheduler.html:text/html}
}

@misc{vyukov_scalable_2012,
	title = {Scalable {Go} {Scheduler} {Design} {Doc}},
	shorttitle = {Scalable {Go} {Scheduler}},
	url = {https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit?usp=embed_facebook},
	abstract = {Scalable Go Scheduler Design Doc Dmitry Vyukov dvyukov@google.com May 2, 2012 The document assumes some prior knowledge of the Go language and current goroutine scheduler implementation. Problems with current scheduler Current goroutine scheduler limits scalability of concurrent programs written...},
	urldate = {2016-08-25},
	journal = {Google Docs},
	author = {Vyukov, Dmitry},
	month = may,
	year = {2012},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\FRWVK74D\\edit.html:text/html}
}

@misc{noauthor_how_2014,
	title = {How {Goroutines} {Work}},
	url = {http://blog.nindalf.com/how-goroutines-work/},
	abstract = {Introduction to Go If you are new to the Go programming language, or if the sentence "Concurrency is not parallelism" means nothing to you, then check out Rob Pike's excellent talk on the subject. Its 30 minutes long, and I...},
	urldate = {2016-08-25},
	journal = {Krishna's blog},
	month = feb,
	year = {2014},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MKPR5EAG\\how-goroutines-work.html:text/html}
}

@misc{gerrand_share_2010,
	title = {Share {Memory} {By} {Communicating} - {The} {Go} {Blog}},
	shorttitle = {Share {Memory} {By} {Communicating}},
	url = {https://blog.golang.org/share-memory-by-communicating},
	urldate = {2016-08-25},
	author = {Gerrand, Andrew},
	month = jul,
	year = {2010},
	file = {Share Memory By Communicating - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\2RUKGIVP\\share-memory-by-communicating.html:text/html}
}

@misc{noauthor_share_nodate,
	title = {Share {Memory} {By} {Communicating} - {The} {Go} {Blog}},
	url = {https://blog.golang.org/share-memory-by-communicating},
	urldate = {2016-08-25},
	file = {Share Memory By Communicating - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\D23CK2UD\\share-memory-by-communicating.html:text/html}
}

@misc{griesemer_hey!_2009,
	title = {Hey! {Ho}! {Let}'s {Go}!},
	url = {http://google-opensource.blogspot.com/2009/11/hey-ho-lets-go.html},
	urldate = {2016-08-25},
	journal = {Google Open Source Blog},
	author = {Griesemer, Rob and Pike, Rob and Thompson, Ken and Taylor, Ian and Cox, Russ and Kim, Jini and Langley, Adam},
	month = oct,
	year = {2009},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\E3P3EDAT\\hey-ho-lets-go.html:text/html}
}

@misc{gerrand_go_2012,
	title = {Go version 1 is released - {The} {Go} {Blog}},
	url = {https://blog.golang.org/go-version-1-is-released},
	urldate = {2016-08-25},
	author = {Gerrand, Andrew},
	month = mar,
	year = {2012},
	file = {Go version 1 is released - The Go Blog:C\:\\Users\\Anna\\Zotero\\storage\\WEBGE89I\\go-version-1-is-released.html:text/html}
}

@inproceedings{schmager_gohotdraw:_2010,
	address = {New York, NY, USA},
	series = {{PLATEAU} '10},
	title = {{GoHotDraw}: {Evaluating} the {Go} {Programming} {Language} with {Design} {Patterns}},
	isbn = {978-1-4503-0547-1},
	shorttitle = {{GoHotDraw}},
	url = {http://doi.acm.org/10.1145/1937117.1937127},
	doi = {10.1145/1937117.1937127},
	abstract = {Go, a new programming language backed by Google, has the potential for widespread use: it deserves an evaluation. Design patterns are records of idiomatic programming practice and inform programmers about good program design. In this study, we evaluate Go by implementing design patterns, and porting the "pattern-dense" drawing framework HotDraw into Go, producing GoHotDraw. We show how Go's language features affect the implementation of Design Patterns, identify some potential Go programming patterns, and demonstrate how studying design patterns can contribute to the evaluation of a programming language.},
	urldate = {2016-08-25},
	booktitle = {Evaluation and {Usability} of {Programming} {Languages} and {Tools}},
	publisher = {ACM},
	author = {Schmager, Frank and Cameron, Nicholas and Noble, James},
	year = {2010},
	keywords = {design patterns, evaluation, go, programming language},
	pages = {10:1--10:6},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\JVZZHDZZ\\Schmager et al. - 2010 - GoHotDraw Evaluating the Go Programming Language .pdf:application/pdf}
}

@misc{go_authors_mobile_2016-1,
	title = {Mobile · golang/go {Wiki} · {GitHub}},
	url = {https://github.com/golang/go/wiki/Mobile},
	urldate = {2016-08-17},
	author = {\{Go Authors\}, \{\}},
	month = feb,
	year = {2016},
	file = {Mobile · golang/go Wiki · GitHub:C\:\\Users\\Anna\\Zotero\\storage\\NFNUD5IN\\Mobile.html:text/html}
}

@inproceedings{bodden_information_2016,
	series = {lncs},
	title = {Information {Flow} {Analysis} for {Go}},
	copyright = {All rights reserved},
	booktitle = {Proceedings of the 7th {International} {Symposium} on {Leveraging} {Application}},
	publisher = {sv},
	author = {Bodden, Eric and Pun, Ka I. and Stolz, Volker and Steffen, Martin and Wickert, Anna-Katharina},
	month = may,
	year = {2016},
	note = {Accepted for inclusion in the Symposium's proceedings},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\72CI73D9\\Bodden et al. - 2016 - Information Flow Analysis for Go.pdf:application/pdf;Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\A29M6Y7J\\Bodden et al. - 2016 - Information Flow Analysis for Go.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\E594D6ZL\\978-3-319-47166-2_30.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IU2QSD29\\978-3-319-47166-2_30.html:text/html}
}

@inproceedings{livshits_towards_2013,
	address = {New York, NY, USA},
	series = {{POPL} '13},
	title = {Towards {Fully} {Automatic} {Placement} of {Security} {Sanitizers} and {Declassifiers}},
	isbn = {978-1-4503-1832-7},
	url = {http://doi.acm.org/10.1145/2429069.2429115},
	doi = {10.1145/2429069.2429115},
	abstract = {A great deal of research on sanitizer placement, sanitizer correctness, checking path validity, and policy inference, has been done in the last five to ten years, involving type systems, static analysis and runtime monitoring and enforcement. However, in pretty much all work thus far, the burden of sanitizer placement has fallen on the developer. However, sanitizer placement in large-scale applications is difficult, and developers are likely to make errors, and thus create security vulnerabilities. This paper advocates a radically different approach: we aim to fully automate the placement of sanitizers by analyzing the ow of tainted data in the program. We argue that developers are better off leaving out sanitizers entirely instead of trying to place them. This paper proposes a fully automatic technique for sanitizer placement. Placement is static whenever possible, switching to run time when necessary. Run-time taint tracking techniques can be used to track the source of a value, and thus apply appropriate sanitization. However, due to the runtime overhead of run-time taint tracking, our technique avoids it wherever possible.},
	urldate = {2016-08-17},
	booktitle = {Proceedings of the 40th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Livshits, Benjamin and Chong, Stephen},
	year = {2013},
	keywords = {security analysis, vulnerability prevention, to read},
	pages = {385--398},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\AUQCFPXC\\Livshits und Chong - 2013 - Towards Fully Automatic Placement of Security Sani.pdf:application/pdf;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DKAIVP9D\\Livshits und Chong - 2013 - Towards Fully Automatic Placement of Security Sani.pdf:application/pdf}
}

@inproceedings{livshits_tracking_2003,
	title = {Tracking {Pointers} with {Path} and {Context} {Sensitivity} for {Bug} {Detection} in {C} {Programs}},
	abstract = {This paper proposes a pointer alias analysis for automatic error detection. State-of-the-art pointer alias analyses are either too slow or too imprecise for finding errors in real-life programs. We propose a hybrid pointer analysis that tracks actively manipulated pointers held in local variables and parameters accurately with path and context sensitivity and handles pointers stored in recursive data structures less precisely but efficiently. We make the unsound assumption that pointers passed into a procedure, in parameters, global variables, and locations reached by applying simple access paths to parameters and global variables, are all distinct from each other and from any other locations. This assumption matches the semantics of many functions, reduces spurious aliases and speeds up the analysis. We present a program representation...},
	booktitle = {in {ACM} {SIGSOFT} {Symposium} on the {Foundations} of {Software} {Engineering}},
	author = {Livshits, V. Benjamin and Lam, Monica S.},
	year = {2003},
	pages = {317--326},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\6XI5QFQ7\\Livshits und Lam - 2003 - Tracking Pointers with Path and Context Sensitivit.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\8KEMAX3T\\summary.html:text/html}
}

@book{livshits_finding_2005,
	title = {Finding {Security} {Vulnerabilities} in {Java} {Applications} with {Static} {Analysis}},
	abstract = {This paper proposes a static analysis technique for detecting many recently discovered application vulnerabilities such as SQL injections, cross-site scripting, and HTTP splitting attacks. These vulnerabilities stem from unchecked input, which is widely recognized as the most common source of security vulnerabilities in Web applications. We propose a static analysis approach based on a scalable and precise points-to analysis. In our system, user-provided specifications of vulnerabilities are automatically translated into static analyzers. Our approach finds all vulnerabilities matching a specification in the statically analyzed code. Results of our static analysis are presented to the user for assessment in an auditing interface integrated within Eclipse, a popular Java development environment. Our static analysis found 29 security vulnerabilities in nine large, popular open-source applications, with two of the vulnerabilities residing in widely-used Java libraries. In fact, all but one application in our benchmark suite had at least one vulnerability.Context sensitivity, combined with improved object naming, proved instrumental in keeping the number of false positives low. Our approach yielded very few false positives in our experiments: in fact, only one of our benchmarks suffered from false alarms.},
	author = {Livshits, V. Benjamin and Lam, Monica S.},
	year = {2005},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\U95ENK5J\\Livshits und Lam - 2005 - Finding Security Vulnerabilities in Java Applicati.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NSCKGA8W\\summary.html:text/html}
}

@inproceedings{arzt_flowdroid:_2013,
	title = {{FlowDroid}: precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for {Android} apps},
	isbn = {978-1-4503-2784-8},
	shorttitle = {{FlowDroid}},
	url = {http://dl.acm.org/citation.cfm?doid=2594291.2594299},
	doi = {10.1145/2594291.2594299},
	language = {en},
	urldate = {2016-08-17},
	publisher = {ACM Press},
	author = {Arzt, Steven and Rasthofer, Siegfried and Fritz, Christian and Bodden, Eric and Bartel, Alexandre and Klein, Jacques and Le Traon, Yves and Octeau, Damien and McDaniel, Patrick},
	year = {2013},
	pages = {259--269}
}

@inproceedings{padhye_interprocedural_2013,
	address = {New York, NY, USA},
	series = {{SOAP} '13},
	title = {Interprocedural {Data} {Flow} {Analysis} in {Soot} {Using} {Value} {Contexts}},
	isbn = {978-1-4503-2201-0},
	url = {http://doi.acm.org/10.1145/2487568.2487569},
	doi = {10.1145/2487568.2487569},
	abstract = {An interprocedural analysis is precise if it is flow sensitive and fully context-sensitive even in the presence of recursion. Many methods of interprocedural analysis sacrifice precision for scalability while some are precise but limited to only a certain class of problems. Soot currently supports interprocedural analysis of Java programs using graph reachability. However, this approach is restricted to IFDS/IDE problems, and is not suitable for general data flow frameworks such as heap reference analysis and points-to analysis which have non-distributive flow functions. We describe a general-purpose interprocedural analysis framework for Soot using data flow values for context-sensitivity. This framework is not restricted to problems with distributive flow functions, although the lattice must be finite. It combines the key ideas of the tabulation method of the functional approach and the technique of value-based termination of call string construction. The efficiency and precision of interprocedural analyses is heavily affected by the precision of the underlying call graph. This is especially important for object-oriented languages like Java where virtual method invocations cause an explosion of spurious call edges if the call graph is constructed naively. We have instantiated our framework with a flow and context-sensitive points-to analysis in Soot, which enables the construction of call graphs that are far more precise than those constructed by Soot's spark engine.},
	urldate = {2016-08-17},
	booktitle = {Proceedings of the 2Nd {ACM} {SIGPLAN} {International} {Workshop} on {State} {Of} the {Art} in {Java} {Program} {Analysis}},
	publisher = {ACM},
	author = {Padhye, Rohan and Khedker, Uday P.},
	year = {2013},
	keywords = {call graph, context-sensitive analysis, interprocedural analysis, points-to analysis},
	pages = {31--36},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\S3EHUQ9S\\Padhye und Khedker - 2013 - Interprocedural Data Flow Analysis in Soot Using V.pdf:application/pdf}
}

@misc{noauthor_go_nodate-1,
	title = {The {Go} language is a},
	url = {https://app.grammarly.com/docs/102257819},
	urldate = {2016-08-17},
	file = {The Go language is a:C\:\\Users\\Anna\\Zotero\\storage\\EHQ9B588\\102257819.html:text/html}
}

@misc{cheney_dont_nodate,
	title = {Don’t just check errors, handle them gracefully {\textbar} {Dave} {Cheney}},
	url = {http://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully},
	urldate = {2016-06-29},
	author = {Cheney, Dave},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZKWEJCUI\\dont-just-check-errors-handle-them-gracefully.html:text/html}
}

@misc{cheney_introducing_nodate,
	title = {Introducing profile, super simple profiling for {Go} programs {\textbar} {Dave} {Cheney}},
	url = {http://dave.cheney.net/2013/07/07/introducing-profile-super-simple-profiling-for-go-programs},
	urldate = {2016-06-29},
	author = {Cheney, Dave},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NSWPA4NV\\introducing-profile-super-simple-profiling-for-go-programs.html:text/html}
}

@misc{cheney_introducing_nodate-1,
	title = {Introducing gmx, runtime instrumentation for {Go} applications {\textbar} {Dave} {Cheney}},
	url = {http://dave.cheney.net/2012/02/05/introducing-gmx-runtime-instrumentation-for-go-applications},
	urldate = {2016-06-29},
	author = {Cheney, Dave},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\GQ6PHGIR\\introducing-gmx-runtime-instrumentation-for-go-applications.html:text/html}
}

@misc{noauthor_go_nodate-2,
	title = {The {Go} {Memory} {Model} - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/ref/mem},
	urldate = {2016-06-28},
	file = {The Go Memory Model - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\4DPJ4ME2\\mem.html:text/html}
}

@misc{mina_concurrency_2015,
	title = {Concurrency in {Golang}},
	url = {http://www.minaandrawos.com/2015/12/06/concurrency-in-golang/},
	abstract = {Concurrency in Golang is one of the most powerful features in the language. Numerous folks covered the topic, today is my turn.},
	urldate = {2016-05-18},
	journal = {Mina Andrawos},
	author = {Mina, Author},
	month = dec,
	year = {2015},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\QPVKN9Q4\\concurrency-in-golang.html:text/html}
}

@misc{noauthor_go_nodate-3,
	title = {Go {Concurrency} {Patterns}},
	url = {https://talks.golang.org/2012/concurrency.slide#37},
	urldate = {2016-05-18},
	file = {Go Concurrency Patterns:C\:\\Users\\Anna\\Zotero\\storage\\KDNBVW9S\\concurrency.html:text/html}
}

@misc{noauthor_effective_nodate,
	title = {Effective {Go} - {The} {Go} {Programming} {Language}},
	url = {https://golang.org/doc/effective_go.html#concurrency},
	urldate = {2016-04-29},
	file = {Effective Go - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\Q2SRHAG3\\effective_go.html:text/html;Effective Go - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\C29D754B\\effective_go.html:text/html}
}

@inproceedings{brumley_bap:_2011,
	title = {{BAP}: {A} binary analysis platform},
	shorttitle = {{BAP}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-22110-1_37},
	urldate = {2016-03-29},
	booktitle = {Computer aided verification},
	publisher = {Springer},
	author = {Brumley, David and Jager, Ivan and Avgerinos, Thanassis and Schwartz, Edward J.},
	year = {2011},
	pages = {463--469},
	file = {paper.dvi - cav11.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KC76M4BN\\cav11.pdf:application/pdf}
}

@inproceedings{luk_pin:_2005,
	title = {Pin: building customized program analysis tools with dynamic instrumentation},
	shorttitle = {Pin},
	abstract = {Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called Pin. Our goals are to provide easy-to-use, portable, transparent, and efficient instrumentation. Instrumentation tools (called Pintools) are written in C/C++ using Pin’s rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be architecture independent whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly transparent as the application and Pintool observe the application’s original, uninstrumented behavior. Pin uses dynamic compilation to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin’s versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium R ○ , and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website. Categories and Subject Descriptors D.2.5 [Software Engineering]: Testing and Debugging-code inspections and walk-throughs,},
	booktitle = {In {PLDI} ’05: {Proceedings} of the 2005 {ACM} {SIGPLAN} conference on {Programming} language design and implementation},
	publisher = {ACM Press},
	author = {Luk, Chi-keung and Cohn, Robert and Muth, Robert and Patil, Harish and Klauser, Artur and Lowney, Geoff and Wallace, Steven and Janapa, Vijay and Hazelwood, Reddi Kim},
	year = {2005},
	pages = {190--200},
	file = {Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\V3Q9CPRN\\summary.html:text/html}
}

@inproceedings{ming_taintpipe:_nodate,
	title = {{TaintPipe}: {Pipelined} symbolic taint analysis},
	shorttitle = {{TaintPipe}},
	abstract = {Taint analysis has a wide variety of compelling applica-tions in security tasks, from software attack detection to data lifetime analysis. Static taint analysis propagates taint values following all possible paths with no need for concrete execution, but is generally less accurate than dynamic analysis. Unfortunately, the high performance penalty incurred by dynamic taint analyses makes its de-ployment impractical in production systems. To amelio-rate this performance bottleneck, recent research efforts aim to decouple data flow tracking logic from program execution. We continue this line of research in this paper and propose pipelined symbolic taint analysis, a novel technique for parallelizing and pipelining taint analy-sis to take advantage of ubiquitous multi-core platforms. We have developed a prototype system called TaintPipe. TaintPipe performs very lightweight runtime logging to produce compact control flow profiles, and spawns mul-tiple threads as different stages of a pipeline to carry out symbolic taint analysis in parallel. Our experiments show that TaintPipe imposes low overhead on applica-tion runtime performance and accelerates taint analysis significantly. Compared to a state-of-the-art inlined dy-namic data flow tracking tool, TaintPipe achieves 2.38 times speedup for taint analysis on SPEC 2006 and 2.43 times for a set of common utilities, respectively. In ad-dition, we demonstrate the strength of TaintPipe such as natural support of multi-tag taint analysis with several security applications. 1},
	booktitle = {In {Proceedings} of the 24th {USENIX} {Security} {Symposium} (2015), {USENIX} {Association}},
	author = {Ming, Jiang and Wu, Dinghao and Xiao, Gaoyao and Wang, Jun and Liu, Peng},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\FGWQZNM6\\Ming et al. - TaintPipe Pipelined symbolic taint analysis.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\4WRTDIQ4\\summary.html:text/html}
}

@book{kiriansky_secure_2002,
	title = {Secure {Execution} {Via} {Program} {Shepherding}},
	abstract = {We introduce program shepherding, a method for monitoring control flow transfers during program execution to enforce a security policy. Program shepherding provides three techniques as building blocks for security policies. First, shepherding can restrict execution privileges on the basis of code origins. This distinction can ensure that malicious code masquerading as data is never executed, thwarting a large class of security attacks. Second, shepherding can restrict control transfers based on instruction class, source, and target. For example, shepherding can forbid execution of shared library code except through declared entry points, and can ensure that a return instruction only targets the instruction after a call. Finally, shepherding guarantees that sandboxing checks placed around any type of program operation will never be bypassed. We have implemented these capabilities efficiently in a runtime system with minimal or no performance penalties. This system operates on unmodified native binaries, requires no special hardware or operating system support, and runs on existing IA-32 machines under both Linux and Windows.},
	author = {Kiriansky, Vladimir and Bruening, Derek and Amarasinghe, Saman},
	year = {2002},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\8IZKMFS4\\Kiriansky et al. - 2002 - Secure Execution Via Program Shepherding.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EMWDS5BX\\summary.html:text/html}
}

@inproceedings{nethercote_valgrind:_2007,
	title = {Valgrind: {A} framework for heavyweight dynamic binary instrumentation},
	shorttitle = {Valgrind},
	abstract = {Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited. In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values—a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO. Categories and Subject Descriptors D.2.5 [Software Engineering]: Testing and Debugging—debugging aids, monitors; D.3.4},
	booktitle = {In {Proceedings} of the 2007 {Programming} {Language} {Design} and {Implementation} {Conference}},
	author = {Nethercote, Nicholas and Seward, Julian},
	year = {2007},
	file = {Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\W2V6W4PT\\summary.html:text/html}
}

@article{pottier_information_nodate,
	title = {Information flow inference for {ML}},
	abstract = {This paper presents a type-based information flow analysis for a call-by-value λ-calculus equipped with references, exceptions and let-polymorphism, which we refer to as Core ML. The type system is constraint-based and has decidable type inference. Its noninterference proof is reasonably light-weight, thanks to the use of a number of orthogonal techniques. First, a syntactic segregation between values and expressions allows a lighter formulation of the type system. Second, noninterference is reduced to subject reduction for a nonstandard language extension. Lastly, a semi-syntactic approach to type soundness allows dealing with constraint-based polymorphism separately.},
	journal = {ACM Trans. Program. Lang. Syst},
	author = {Pottier, François and Simonet, Vincent},
	pages = {2003},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\CFR6JZ2D\\Pottier und Simonet - Information flow inference for ML.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\UGNBCDPH\\summary.html:text/html}
}

@inproceedings{myers_jflow:_1999,
	title = {{JFlow}: {Practical} {Mostly}-{Static} {Information} {Flow} {Control}},
	shorttitle = {{JFlow}},
	abstract = {A promising technique for protecting privacy and integrity of sensitive data is to statically check information flow within programs that manipulate the data. While previous work has proposed programming language extensions to allow this static checking, the resulting languages are too restrictive for practical use and have not been implemented. In this paper, we describe the new language JFlow, an extension to the Java language that adds statically-checked information flow annotations. JFlow provides several new features that make information flow checking more flexible and convenient than in previous models: a decentralized label model, label polymorphism, run-time label checking, and automatic label inference. JFlow also supports many language features that have never been integrated successfully with static information flow control, including objects, subclassing, dynamic type tests, access control, and exceptions. This paper defines the JFlow language and presents formal rules tha...},
	booktitle = {In {Proc}. 26th {ACM} {Symp}. on {Principles} of {Programming} {Languages} ({POPL}},
	author = {Myers, Andrew C.},
	year = {1999},
	pages = {228--241},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\W98KRID8\\Myers - 1999 - JFlow Practical Mostly-Static Information Flow Co.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7C2JBHFU\\summary.html:text/html}
}

@inproceedings{masri_detecting_2004,
	title = {Detecting and {Debugging} {Insecure} {Information} {Flows}},
	abstract = {A new approach to dynamic information flow analysis is presented that can be used to detect and debug insecure flows in programs. It can be applied offline to validate and debug a program against an information flow policy, or, when fast response is not critical, it can be applied online to prevent illegal flows in deployed programs. Since dynamic analysis alone is inherently unable to detect implicit information flows, our approach incorporates a static preprocessing phase that permits detection of most implicit flows at runtime, in addition to explicit ones. To support interactive debugging of insecure flows, it also incorporates a new forward computing algorithm for dynamic slicing, which is more precise than previous forward computing algorithms and is not restricted to programs with structured control flow. A prototype tool implementing the proposed approach has been developed for Java byte code programs. Case studies in which this tool was applied to several subject programs are described. 1.},
	booktitle = {In {ISSRE}’04: the 15th {International} {Symposium} on {Software} {Reliability} {Engineering}},
	author = {Masri, Wes and Podgurski, Andy and Leon, David},
	year = {2004},
	pages = {198--209},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\Q8PMMR42\\Masri et al. - 2004 - Detecting and Debugging Insecure Information Flows.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\AD2ZP3U5\\summary.html:text/html}
}

@techreport{leek_coverage_2007,
	title = {Coverage maximization using dynamic taint tracing},
	abstract = {Approved for public release; distribution is unlimited.},
	author = {Leek, T. R. and Brown, R. E. and Zhivich, M. A. and Leek, T. R. and Brown, R. E.},
	year = {2007},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\U4FTA7VB\\Leek et al. - 2007 - Coverage maximization using dynamic taint tracing.pdf:application/pdf;Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\TX7RBFJJ\\Leek et al. - 2007 - Coverage maximization using dynamic taint tracing.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZNRHJHDG\\summary.html:text/html;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\VFHB4Q5H\\summary.html:text/html}
}

@inproceedings{pietraszek_defending_2005,
	title = {Defending against {Injection} {Attacks} through {Context}-{Sensitive} {String} {Evaluation}},
	abstract = {Injection vulnerabilities pose a major threat to application-level security. Some of the more common types are SQL injection, cross-site scripting and shell injection vulnerabilities. Existing methods for defending against injection attacks, that is, attacks exploiting these vulnerabilities, rely heavily on the application developers and are therefore error-prone. In this paper we introduce CSSE, a method to detect and prevent injection attacks. CSSE works by addressing the root cause why such attacks can succeed, namely the ad-hoc serialization of user-provided input. It provides a platform-enforced separation of channels, using a combination of assignment of metadata to user-provided input, metadata-preserving string operations and context-sensitive string evaluation. CSSE requires neither application developer interaction nor application source code modifications. Since only changes to the underlying platform are needed, it effectively shifts the burden of implementing countermeasures against injection attacks from the many application developers to the small team of security-savvy platform developers. Our method is effective against most types of injection attacks, and we show that it is also less error-prone than other solutions proposed so far. We have developed a prototype CSSE implementation for PHP, a platform that is particularly prone to these vulnerabilities. We used our prototype with phpBB, a well-known bulletin-board application, to validate our method. CSSE detected and prevented all the SQL injection attacks we could reproduce and incurred only reasonable run-time overhead.},
	booktitle = {In {Recent} {Advances} in {Intrusion} {Detection} ({RAID}},
	author = {Pietraszek, Tadeusz and Berghe, Chris Vanden and V, Chris and Berghe, En},
	year = {2005},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ZEG2XQBF\\Pietraszek et al. - 2005 - Defending against Injection Attacks through Contex.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\FCWFUIRS\\summary.html:text/html}
}

@inproceedings{buchmann_xmss_2011,
	address = {Berlin, Heidelberg},
	series = {{PQCrypto}'11},
	title = {{XMSS} - a {Practical} {Forward} {Secure} {Signature} {Scheme} {Based} on {Minimal} {Security} {Assumptions}},
	isbn = {978-3-642-25404-8},
	url = {http://dx.doi.org/10.1007/978-3-642-25405-5_8},
	doi = {10.1007/978-3-642-25405-5_8},
	abstract = {We present the hash-based signature scheme XMSS. It is the first provably (forward) secure and practical signature scheme with minimal security requirements: a pseudorandom and a second preimage resistant (hash) function family. Its signature size is reduced to less than 25\% compared to the best provably secure hash based signature scheme.},
	urldate = {2017-11-20},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Post}-{Quantum} {Cryptography}},
	publisher = {Springer-Verlag},
	author = {Buchmann, Johannes and Dahmen, Erik and Hülsing, Andreas},
	year = {2011},
	keywords = {digital signature, forward security, hash-based signatures, minimal security assumptions, practical, provable security},
	pages = {117--129}
}

@inproceedings{schurr_specification_1995,
	address = {London, UK, UK},
	series = {{WG} '94},
	title = {Specification of {Graph} {Translators} with {Triple} {Graph} {Grammars}},
	isbn = {978-3-540-59071-2},
	url = {http://dl.acm.org/citation.cfm?id=647675.731658},
	urldate = {2017-11-20},
	booktitle = {Proceedings of the 20th {International} {Workshop} on {Graph}-{Theoretic} {Concepts} in {Computer} {Science}},
	publisher = {Springer-Verlag},
	author = {Schürr, Andy},
	year = {1995},
	pages = {151--163}
}

@inproceedings{keivanloo_spotting_2014,
	address = {New York, NY, USA},
	series = {{ICSE} 2014},
	title = {Spotting {Working} {Code} {Examples}},
	isbn = {978-1-4503-2756-5},
	url = {http://doi.acm.org/10.1145/2568225.2568292},
	doi = {10.1145/2568225.2568292},
	abstract = {Working code examples are useful resources for pragmatic reuse in software development. A working code example provides a solution to a specific programming problem. Earlier studies have shown that existing code search engines are not successful in finding working code examples. They fail in ranking high quality code examples at the top of the result set. To address this shortcoming, a variety of pattern-based solutions are proposed in the literature. However, these solutions cannot be integrated seamlessly in Internet-scale source code engines due to their high time complexity or query language restrictions. In this paper, we propose an approach for spotting working code examples which can be adopted by Internet-scale source code search engines. The time complexity of our approach is as low as the complexity of existing code search engines on the Internet and considerably lower than the pattern-based approaches supporting free-form queries. We study the performance of our approach using a representative corpus of 25,000 open source Java projects. Our findings support the feasibility of our approach for Internet-scale code search. We also found that our approach outperforms Ohloh Code search engine, previously known as Koders, in spotting working code examples.},
	urldate = {2017-11-20},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Keivanloo, Iman and Rilling, Juergen and Zou, Ying},
	year = {2014},
	keywords = {clone detection, Source code search, working code example, E1ext},
	pages = {664--675},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\X6YBQTYT\\Keivanloo et al. - 2014 - Spotting Working Code Examples.pdf:application/pdf}
}

@inproceedings{fischer_stack_2017,
	title = {Stack {Overflow} {Considered} {Harmful}? {The} {Impact} of {Copy} {Paste} on {Android} {Application} {Security}},
	shorttitle = {Stack {Overflow} {Considered} {Harmful}?},
	doi = {10.1109/SP.2017.31},
	abstract = {Online programming discussion platforms such as Stack Overflow serve as a rich source of information for software developers. Available information include vibrant discussions and oftentimes ready-to-use code snippets. Previous research identified Stack Overflow as one of the most important information sources developers rely on. Anecdotes report that software developers copy and paste code snippets from those information sources for convenience reasons. Such behavior results in a constant flow of community-provided code snippets into production software. To date, the impact of this behaviour on code security is unknown. We answer this highly important question by quantifying the proliferation of security-related code snippets from Stack Overflow in Android applications available on Google Play. Access to the rich source of information available on Stack Overflow including ready-to-use code snippets provides huge benefits for software developers. However, when it comes to code security there are some caveats to bear in mind: Due to the complex nature of code security, it is very difficult to provide ready-to-use and secure solutions for every problem. Hence, integrating a security-related code snippet from Stack Overflow into production software requires caution and expertise. Unsurprisingly, we observed insecure code snippets being copied into Android applications millions of users install from Google Play every day. To quantitatively evaluate the extent of this observation, we scanned Stack Overflow for code snippets and evaluated their security score using a stochastic gradient descent classifier. In order to identify code reuse in Android applications, we applied state-of-the-art static analysis. Our results are alarming: 15.4\% of the 1.3 million Android applications we analyzed, contained security-related code snippets from Stack Overflow. Out of these 97.9\% contain at least one insecure code snippet.},
	booktitle = {2017 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Fischer, Felix and Böttinger, Konstantin and Xiao, Huang and Stransky, Christian and Acar, Yasemin and Backes, Michael and Fahl, Sascha},
	month = may,
	year = {2017},
	keywords = {program diagnostics, Software, static analysis, Libraries, security of data, Android (operating system), Android application security, Android Application Security, Androids, code security, code snippets, copy \& paste behavior, Cryptography, Google, Google Play, gradient methods, Humanoid robots, information source, online programming discussion platforms, pattern classification, production software, software developers, Software Development, software engineering, stack overflow, Stack Overflow, stochastic gradient descent classifier, stochastic processes},
	pages = {121--136},
	file = {Fischer et al. - 2017 - Stack Overflow Considered Harmful The Impact of C.pdf:C\:\\Users\\Anna\\Zotero\\storage\\6XUCWTT4\\Fischer et al. - 2017 - Stack Overflow Considered Harmful The Impact of C.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\RT3R68SD\\7958574.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\CPBC6E56\\Fischer et al. - 2017 - Stack Overflow Considered Harmful The Impact of C.pdf:application/pdf}
}

@article{spath_ideal:_2017,
	title = {{IDEal}: {Efficient} and {Precise} {Alias}-aware {Dataflow} {Analysis}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {{IDEal}},
	url = {http://doi.acm.org/10.1145/3133923},
	doi = {10.1145/3133923},
	abstract = {Program analyses frequently track objects throughout a program, which requires reasoning about aliases. Most dataflow analysis frameworks, however, delegate the task of handling aliases to the analysis clients, which causes a number of problems. For instance, custom-made extensions for alias analysis are complex and cannot easily be reused. On the other hand, due to the complex interfaces involved, off-the-shelf alias analyses are hard to integrate precisely into clients. Lastly, for precision many clients require strong updates, and alias abstractions supporting strong updates are often relatively inefficient.   In this paper, we present IDEal, an alias-aware extension to the framework for Interprocedural Distributive Environment (IDE) problems. IDEal relieves static-analysis authors completely of the burden of handling aliases by automatically resolving alias queries on-demand, both efficiently and precisely. IDEal supports a highly precise analysis using strong updates by resorting to an on-demand, flow-sensitive, and context-sensitive all-alias analysis. Yet, it achieves previously unseen efficiency by propagating aliases individually, creating highly reusable per-pointer summaries.   We empirically evaluate IDEal by comparing TSf, a state-of-the-art typestate analysis, to TSal, an IDEal-based typestate analysis. Our experiments show that the individual propagation of aliases within IDEal enables TSal to propagate 10.4x fewer dataflow facts and analyze 10.3x fewer methods when compared to TSf. On the DaCapo benchmark suite, TSal is able to efficiently compute precise results.},
	number = {OOPSLA},
	urldate = {2017-11-21},
	journal = {Proc. ACM Program. Lang.},
	author = {Späth, Johannes and Ali, Karim and Bodden, Eric},
	month = oct,
	year = {2017},
	keywords = {static analysis, aliasing, dataflow, crypto misuses},
	pages = {99:1--99:27},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\N5QEGYMH\\Späth et al. - 2017 - IDEal Efficient and Precise Alias-aware Dataflow .pdf:application/pdf;Späth et al. - 2017 - IDEal Efficient and Precise Alias-aware Dataflow .pdf:C\:\\Users\\Anna\\Zotero\\storage\\TDILVACU\\Späth et al. - 2017 - IDEal Efficient and Precise Alias-aware Dataflow .pdf:application/pdf}
}

@inproceedings{shuai_modelling_2014,
	title = {Modelling {Analysis} and {Auto}-detection of {Cryptographic} {Misuse} in {Android} {Applications}},
	doi = {10.1109/DASC.2014.22},
	abstract = {Cryptographic misuse affects a sizeable portion of Android applications. However, there is only an empirical study that has been made about this problem. In this paper, we perform a systematic analysis on the cryptographic misuse, build the cryptographic misuse vulnerability model and implement a prototype tool Crypto Misuse Analyser (CMA). The CMA can perform static analysis on Android apps and select the branches that invoke the cryptographic API. Then it runs the app following the target branch and records the cryptographic API calls. At last, the CMA identifies the cryptographic API misuse vulnerabilities from the records based on the pre-defined model. We also analyze dozens of Android apps with the help of CMA and find that more than a half of apps are affected by such vulnerabilities.},
	author = {Shuai, Shao and Guowei, Dong and Tao, Guo and Tianchang, Yang and Chenjie, Shi},
	month = aug,
	year = {2014},
	pages = {75--80}
}

@inproceedings{jonsson_framework_2011,
	title = {A framework for security metrics based on operational system attributes},
	doi = {10.1109/Metrisec.2011.19},
	abstract = {There exists a large number of suggestions for how to measure security, with different goals and objectives. The application areas range from business management and organizational systems to large software systems. The approaches may be theoretical, technical, administrative or practical. In many cases the goal is to find a single overall metric of security. Given that security is a complex and multi-faceted property, we believe that there are fundamental problems to find such an overall metric. Thus, we suggest a framework for security metrics that is based on a number of system attributes taken from the security and the dependability disciplines. We start out from the traditional decomposition of security into three main aspects ("CIA") and include a set of dependability attributes. The reason for this is that security and dependability largely reflect the same basic system feature and are partly overlapping. We then regroup those attributes according to an existing conceptual system model and propose metrication methods in accordance. We suggest that there should be metrics related to protective attributes, to behavioural attributes and to system correctness. We also discuss the relation between these types of metrics. We are convinced that this approach will facilitate making quantitative assessment of the concept of combined security and dependability and that it would also improve our understanding of these important system properties.},
	booktitle = {2011 {Third} {International} {Workshop} on {Security} {Measurements} and {Metrics}},
	author = {Jonsson, E. and Pirzadeh, L.},
	month = sep,
	year = {2011},
	keywords = {Security, security of data, Availability, behavioural attributes, behavioural metrics, business management, conceptual system model, Conferences, dependability attributes, effort-based metrics, Measurement, metrication methods, modelling, NIST, operational security, operational system attributes, organisational aspects, organizational systems, quantitative assessment, Safety, security metrics, software metrics, software systems},
	pages = {58--65},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\FEAVRQ4H\\6165764.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\J4WN4B7R\\Jonsson und Pirzadeh - 2011 - A framework for security metrics based on operatio.pdf:application/pdf}
}

@inproceedings{egele_empirical_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {An {Empirical} {Study} of {Cryptographic} {Misuse} in {Android} {Applications}},
	isbn = {978-1-4503-2477-9},
	url = {http://doi.acm.org/10.1145/2508859.2516693},
	doi = {10.1145/2508859.2516693},
	abstract = {Developers use cryptographic APIs in Android with the intent of securing data such as passwords and personal information on mobile devices. In this paper, we ask whether developers use the cryptographic APIs in a fashion that provides typical cryptographic notions of security, e.g., IND-CPA security. We develop program analysis techniques to automatically check programs on the Google Play marketplace, and find that 10.327 out of 11,748 applications that use cryptographic APIs -- 88\% overall -- make at least one mistake. These numbers show that applications do not use cryptographic APIs in a fashion that maximizes overall security. We then suggest specific remediations based on our analysis towards improving overall cryptographic security in Android applications.},
	urldate = {2017-12-07},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \& {Communications} {Security}},
	publisher = {ACM},
	author = {Egele, Manuel and Brumley, David and Fratantonio, Yanick and Kruegel, Christopher},
	year = {2013},
	keywords = {program analysis, software security, cryptolint, API misuse, Cryptographic misuse, important},
	pages = {73--84},
	file = {Egele et al. - 2013 - An Empirical Study of Cryptographic Misuse in Andr.pdf:C\:\\Users\\Anna\\Zotero\\storage\\2SYWDHMR\\Egele et al. - 2013 - An Empirical Study of Cryptographic Misuse in Andr.pdf:application/pdf}
}

@misc{noauthor_sonarjava_nodate,
	title = {{SonarJava} {Rules} {\textbar} {SonarSource}},
	url = {https://www.sonarsource.com/products/codeanalyzers/sonarjava/rules.html#Vulnerability_Detection},
	urldate = {2017-12-07},
	file = {SonarJava Rules | SonarSource:C\:\\Users\\Anna\\Zotero\\storage\\LXMDDMBH\\rules.html:text/html}
}

@misc{noauthor_bug_nodate,
	title = {Bug {Patterns} - {Find} {Security} {Bugs}},
	url = {http://find-sec-bugs.github.io/bugs.htm},
	urldate = {2017-12-07},
	file = {Bug Patterns - Find Security Bugs:C\:\\Users\\Anna\\Zotero\\storage\\435ASYMP\\bugs.html:text/html}
}

@inproceedings{lazar_why_2014,
	address = {New York, NY, USA},
	series = {{APSys} '14},
	title = {Why {Does} {Cryptographic} {Software} {Fail}?: {A} {Case} {Study} and {Open} {Problems}},
	isbn = {978-1-4503-3024-4},
	shorttitle = {Why {Does} {Cryptographic} {Software} {Fail}?},
	url = {http://doi.acm.org/10.1145/2637166.2637237},
	doi = {10.1145/2637166.2637237},
	abstract = {Mistakes in cryptographic software implementations often undermine the strong security guarantees offered by cryptography. This paper presents a systematic study of cryptographic vulnerabilities in practice, an examination of state-of-the-art techniques to prevent such vulnerabilities, and a discussion of open problems and possible future research directions. Our study covers 269 cryptographic vulnerabilities reported in the CVE database from January 2011 to May 2014. The results show that just 17\% of the bugs are in cryptographic libraries (which often have devastating consequences), and the remaining 83\% are misuses of cryptographic libraries by individual applications. We observe that preventing bugs in different parts of a system requires different techniques, and that no effective techniques exist to deal with certain classes of mistakes, such as weak key generation.},
	urldate = {2017-12-20},
	booktitle = {Proceedings of 5th {Asia}-{Pacific} {Workshop} on {Systems}},
	publisher = {ACM},
	author = {Lazar, David and Chen, Haogang and Wang, Xi and Zeldovich, Nickolai},
	year = {2014},
	keywords = {important},
	pages = {7:1--7:7},
	file = {Lazar et al. - 2014 - Why Does Cryptographic Software Fail A Case Stud.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Lazar et al. - 2014 - Why Does Cryptographic Software Fail A Case Stud.pdf:application/pdf;Lazar et al. - 2014 - Why Does Cryptographic Software Fail A Case Stud.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MHP6VWAY\\Lazar et al. - 2014 - Why Does Cryptographic Software Fail A Case Stud.pdf:application/pdf}
}

@misc{kammerer_mubench-jce_2017,
	title = {{MuBench}-{JCE} - {A} {Misuse}-{Detection} {Benchmakr} for the {Java} {Cryptography} {Extensions} {API}},
	language = {Englisch},
	author = {Kämmerer, Mattis Manfred},
	month = may,
	year = {2017},
	file = {Thesis-Kämmerer-Final.pdf:C\:\\Users\\Anna\\Documents\\55_Paper\\Thesis-Kämmerer-Final.pdf:application/pdf}
}

@inproceedings{ghafari_security_2017,
	title = {Security {Smells} in {Android}},
	doi = {10.1109/SCAM.2017.24},
	abstract = {The ubiquity of smartphones, and their very broad capabilities and usage, make the security of these devices tremendously important. Unfortunately, despite all progress in security and privacy mechanisms, vulnerabilities continue to proliferate.,,Research has shown that many vulnerabilities are due to insecure programming practices. However, each study has often dealt with a specific issue, making the results less actionable for practitioners. To promote secure programming practices, we have reviewed related research, and identified avoidable vulnerabilities in Android-run devices and the security code smells that indicate their presence. In particular, we explain the vulnerabilities, their corresponding smells, and we discuss how they could be eliminated or mitigated during development. Moreover, we develop a lightweight static analysis tool and discuss the extent to which it successfully detects several vulnerabilities in about 46 000 apps hosted by the official Android market.},
	booktitle = {2017 {IEEE} 17th {International} {Working} {Conference} on {Source} {Code} {Analysis} and {Manipulation} ({SCAM})},
	author = {Ghafari, M. and Gadient, P. and Nierstrasz, O.},
	month = sep,
	year = {2017},
	keywords = {program diagnostics, source code (software), Security, Libraries, data privacy, programming, Programming, Android (operating system), Androids, Cryptography, Humanoid robots, Android, invasive software, mobile computing, privacy mechanisms, secure programming practices, security code, security code smells, security mechanisms, smart phones, Smart phones, smartphones, Smell, static analysis tool, Tools},
	pages = {121--130},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\PLIZGRXC\\8090145.html:text/html}
}

@misc{keck_analysing_2017,
	title = {Analysing and improving the crypto ecosystem of {Rust}},
	author = {Keck, Philipp},
	month = apr,
	year = {2017},
	file = {analysingAndImprovingTheCryptoEcosystemOfRust_PhilippKeck_Masterthesis.pdf:C\:\\Users\\Anna\\Documents\\Paper\\analysingAndImprovingTheCryptoEcosystemOfRust_PhilippKeck_Masterthesis.pdf:application/pdf}
}

@misc{katz_thinking_2016,
	address = {Boston, MA},
	title = {Thinking about {Cryptography}: {Crypto} {Flaws} and {How} to {Avoid} {Them}},
	url = {http://cybersec-prod.s3.amazonaws.com/secdev/wp-content/uploads/2016/12/05201108/CryptoFlaws-IEEESecDev2016.pdf},
	urldate = {2017-12-28},
	author = {Katz, Jonathan},
	month = nov,
	year = {2016},
	file = {Jonathan - 2016 - Thinking about Cryptography Crypto Flaws and How .pdf:C\:\\Users\\Anna\\Zotero\\storage\\N3FCX7YK\\Jonathan - 2016 - Thinking about Cryptography Crypto Flaws and How .pdf:application/pdf}
}

@inproceedings{rahaman_program_2017,
	title = {Program {Analysis} of {Cryptographic} {Implementations} for {Security}},
	doi = {10.1109/SecDev.2017.23},
	booktitle = {2017 {IEEE} {Cybersecurity} {Development} ({SecDev})},
	author = {Rahaman, S. and Yao, D.},
	month = sep,
	year = {2017},
	keywords = {program diagnostics, public domain software, source code (software), Security, Libraries, program compilers, Cryptography, Tools, Ciphers, code compilation, compile-time security checking, CPA, cryptographic implementations, cryptographic primitives, cryptographic program analysis, Cryptographic Program Analysis, cryptography, Encryption, open source libraries, Program Analysis, Side-channel attacks, static taint analysis},
	pages = {61--68},
	file = {Rahaman und Yao - 2017 - Program Analysis of Cryptographic Implementations .pdf:C\:\\Users\\Anna\\Documents\\Paper\\Rahaman und Yao - 2017 - Program Analysis of Cryptographic Implementations .pdf:application/pdf;Rahaman und Yao - 2017 - Program Analysis of Cryptographic Implementations_slides.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Rahaman und Yao - 2017 - Program Analysis of Cryptographic Implementations_slides.pdf:application/pdf}
}

@inproceedings{nadi_jumping_2016,
	title = {Jumping through hoops: why do {Java} developers struggle with cryptography {APIs}?},
	booktitle = {International {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Nadi, Sarah and Krüger, Stefan and Mezini, Mira and Bodden, Eric},
	year = {2016},
	keywords = {Libraries, Java, Cryptography, cryptography, Encryption, E1peer, API misuse, application program interface, application program interfaces, Complexity theory, cryptography algorithms, cryptography API, empirical software engineering, Face, GitHub repositories, Java developers, Public key, sensitive data protection, StackOverflow, important},
	pages = {935--946},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\8X7QPBLJ\\7886969.html:text/html;Nadi et al. - 2016 - #x0022\;Jumping Through Hoops #x0022\; Why do Java .pdf:C\:\\Users\\Anna\\Zotero\\storage\\7EVWN99Y\\Nadi et al. - 2016 - #x0022\;Jumping Through Hoops #x0022\; Why do Java .pdf:application/pdf}
}

@inproceedings{nadi_variability_2016,
	title = {Variability {Modeling} of {Cryptographic} {Components}: {Clafer} {Experience} {Report}},
	booktitle = {International {Workshop} on {Variability} {Modelling} of {Software}-intensive {Systems} ({VaMoS})},
	author = {Nadi, Sarah and Krüger, Stefan},
	year = {2016},
	keywords = {E1peer},
	pages = {105--112}
}

@book{amann_systematic_2017,
	title = {A {Systematic} {Evaluation} of {API}-{Misuse} {Detectors}},
	author = {Amann, Sven and Nguyen, Hoan Anh and Nadi, Sarah and Nguyen, Tien N. and Mezini, Mira},
	year = {2017},
	keywords = {E1other, Under Submission}
}

@inproceedings{kruger_cognicrypt_2017,
	title = {{CogniCrypt} - {Supporting} {Developers} in using {Cryptography}},
	booktitle = {International {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Krüger, Stefan and Nadi, Sarah and Reif, Michael and Ali, Karim and Bodden, Eric and Mezini, Mira and Göpfert, Florian and Günther, Felix and Weinert, Christian and Demmler, Daniel and Kamath, Ram},
	year = {2017},
	keywords = {E1peer},
	file = {Krüger et al. - CogniCrypt Supporting Developers in using Cryptog.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9YAWUPBC\\Krüger et al. - CogniCrypt Supporting Developers in using Cryptog.pdf:application/pdf}
}

@inproceedings{bodden_ts4j:_2014,
	title = {{TS}4J: a fluent interface for defining and computing typestate analyses},
	booktitle = {International {Workshop} on {State} of the {Art} in {Java} {Program} analysis ({SOAP})},
	author = {Bodden, Eric},
	year = {2014},
	keywords = {E1peer},
	pages = {1:1--1:6}
}

@inproceedings{arzt_towards_2015,
	title = {Towards {Secure} {Integration} of {Cryptographic} {Software}},
	booktitle = {International {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software} ({Onward}!)},
	author = {Arzt, Steven and Nadi, Sarah and Ali, Karim and Bodden, Eric and Erdweg, Sebastian and Mezini, Mira},
	year = {2015},
	keywords = {cryptography, E1peer, API protocols, Software product lines, typestate analysis},
	file = {Arzt et al. - 2015 - Towards Secure Integration of Cryptographic Softwa.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CVZW4Y44\\Arzt et al. - 2015 - Towards Secure Integration of Cryptographic Softwa.pdf:application/pdf}
}

@inproceedings{spath_boomerang:_2016,
	title = {Boomerang: {Demand}-{Driven} {Flow}- and {Context}-{Sensitive} {Pointer} {Analysis} for {Java}},
	booktitle = {European {Conference} on {Object}-{Oriented} {Programming} ({ECOOP})},
	author = {Späth, Johannes and Nguyen, Lisa and Ali, Karim and Bodden, Eric},
	year = {2016},
	keywords = {E1peer}
}

@inproceedings{amann_mubench:_2016,
	address = {Austin, TX, USA},
	title = {{MUBench}: a benchmark for {API}-misuse detectors},
	url = {http://2016.msrconf.org/},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Amann, Sven and Nadi, Sarah and Nguyen, Hoan Anh and Nguyen, Tien N. and Mezini, Mira},
	month = may,
	year = {2016},
	keywords = {E1peer, important},
	pages = {464--467},
	file = {Amann et al. - 2016 - MUBench a benchmark for API-misuse detectors.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TAPBQ852\\Amann et al. - 2016 - MUBench a benchmark for API-misuse detectors.pdf:application/pdf}
}

@inproceedings{bodden_reducing_2013,
	title = {Reducing human factors in software security architectures},
	url = {http://www.bodden.de/pubs/blh+13reducing.pdf},
	booktitle = {Future {Security} {Conference} 2013},
	author = {Bodden, Eric and Hermann, Ben and Lerch, Johannes and Mezini, Mira},
	month = sep,
	year = {2013},
	keywords = {E1peer}
}

@inproceedings{inostroza_join_2011,
	title = {Join {Point} {Interfaces} for {Modular} {Reasoning} in {Aspect}-{Oriented} {Programs}},
	url = {http://www.bodden.de/pubs/itb11jpi.pdf},
	booktitle = {{FSE}},
	publisher = {ACM},
	author = {Inostroza, Milton and Tanter, Éric and Bodden, Eric},
	year = {2011},
	keywords = {E1peer},
	pages = {508--511}
}

@incollection{eichberg_component_2010,
	series = {{LNCS}},
	title = {Component {Composition} {Using} {Feature} {Models}},
	volume = {6092},
	booktitle = {{CBSE}},
	publisher = {Springer},
	author = {Eichberg, Michael and Klose, Karl and Mitschke, Ralf and Mezini, Mira},
	year = {2010},
	keywords = {E1peer},
	pages = {200--215}
}

@inproceedings{mezini_variability_2004,
	title = {Variability management with feature-oriented programming and aspects},
	booktitle = {{FSE}},
	publisher = {ACM},
	author = {Mezini, Mira and Ostermann, Klaus},
	year = {2004},
	keywords = {E1peer, aspect-oriented, feature-oriented, product lines, variability management},
	pages = {127--136}
}

@inproceedings{bodden_efficient_2010,
	title = {Efficient {Hybrid} {Typestate} {Analysis} by {Determining} {Continuation}-{Equivalent} {States}},
	booktitle = {{ICSE}},
	publisher = {ACM},
	author = {Bodden, Eric},
	year = {2010},
	keywords = {E1peer, clara},
	pages = {5--14}
}

@inproceedings{charfi_using_2005,
	title = {Using {Aspects} for {Security} {Engineering} of {Web} {Service} {Compositions}},
	booktitle = {{ICWS}},
	publisher = {IEEE},
	author = {Charfi, Anis and Mezini, Mira},
	year = {2005},
	keywords = {E1peer},
	pages = {59--66}
}

@article{bodden_aspect-oriented_2010,
	title = {Aspect-oriented {Race} {Detection} in {Java}},
	volume = {36},
	journal = {TSE},
	author = {Bodden, Eric and Havelund, Klaus},
	year = {2010},
	keywords = {E1peer},
	pages = {509--527}
}

@inproceedings{eichberg_integrating_2006,
	title = {Integrating and {Scheduling} an {Open} {Set} of {Static} {Analyses}},
	booktitle = {{ASE}},
	publisher = {IEEE},
	author = {Eichberg, Michael and Mezini, Mira and Kloppenburg, Sven and Ostermann, Klaus and Rank, Benjamin},
	year = {2006},
	keywords = {E1peer},
	pages = {113--122}
}

@inproceedings{thies_refaflex:_2012,
	title = {{RefaFlex}: {Safer} refactorings for reflective {Java} programs},
	booktitle = {{ISSTA}},
	publisher = {ACM},
	author = {Thies, Andreas and Bodden, Eric},
	year = {2012},
	keywords = {E1peer},
	pages = {1--11}
}

@inproceedings{bodden_static_2012,
	title = {Static flow-sensitive \& context-sensitive information-flow analysis for software product lines: position paper},
	booktitle = {{PLAS}},
	publisher = {ACM},
	author = {Bodden, Eric},
	year = {2012},
	keywords = {E1peer},
	pages = {6:1--6:6}
}

@inproceedings{arzt_how_2013,
	series = {{GI} {Lecture} {Notes} in {Informatics}},
	title = {How useful are existing monitoring languages for securing {Android} apps?},
	volume = {P-215},
	booktitle = {{ATPS}},
	publisher = {Gesellschaft für Informatik},
	author = {Arzt, Steven and Falzon, Kevin and Follner, Andreas and Rasthofer, Siegfried and Bodden, Eric and Stolz, Volker},
	year = {2013},
	keywords = {E1peer},
	pages = {107--122}
}

@inproceedings{bodden_spllift:_2013,
	address = {New York, NY, USA},
	title = {{SPLLIFT}: statically analyzing software product lines in minutes instead of years},
	isbn = {978-1-4503-2014-6},
	url = {http://doi.acm.org/10.1145/2491956.2491976},
	doi = {10.1145/2491956.2491976},
	booktitle = {{PLDI} '13},
	publisher = {ACM},
	author = {Bodden, Eric and Tolêdo, Társis and Ribeiro, Márcio and Brabrand, Claus and Borba, Paulo and Mezini, Mira},
	year = {2013},
	keywords = {E1peer},
	pages = {355--364}
}

@inproceedings{bruch_learning_2009,
	title = {Learning from examples to improve code completion systems},
	booktitle = {{FSE}},
	publisher = {ACM},
	author = {Bruch, Marcel and Monperrus, Martin and Mezini, Mira},
	year = {2009},
	keywords = {E1ext, code completion, code recommender, content assist, integrated development environment},
	pages = {213--222}
}

@inproceedings{schafer_mining_2008,
	title = {Mining framework usage changes from instantiation code},
	booktitle = {{ICSE}},
	publisher = {ACM},
	author = {Schäfer, T. and Jonas, J. and Mezini, Mira},
	year = {2008},
	keywords = {E1ext, evolution, framework comprehension, migration},
	pages = {471--480},
	file = {Schäfer et al. - 2008 - Mining Framework Usage Changes from Instantiation .pdf:C\:\\Users\\Anna\\Zotero\\storage\\P7LFVYB2\\Schäfer et al. - 2008 - Mining Framework Usage Changes from Instantiation .pdf:application/pdf}
}

@inproceedings{gasiunas_dependent_2007,
	address = {New York, NY, USA},
	title = {Dependent classes},
	isbn = {978-1-59593-786-5},
	url = {http://doi.acm.org/10.1145/1297027.1297038},
	doi = {10.1145/1297027.1297038},
	booktitle = {{OOPSLA} '07},
	publisher = {ACM},
	author = {Gasiunas, Vaidas and Mezini, Mira and Ostermann, Klaus},
	year = {2007},
	keywords = {E1peer},
	pages = {133--152}
}

@inproceedings{spath_ide$:_2017,
	title = {{IDE}$^{\textrm{al\$}}$: {Efficient} and {Precise} {Alias}-aware {Dataflow} {Analysis}},
	booktitle = {2017 {International} {Conference} on {Object}-{Oriented} {Programming}, {Languages} and {Applications} ({OOPSLA}/{SPLASH})},
	publisher = {ACM Press},
	author = {Späth, Johannes and Ali, Karim and Bodden, Eric},
	month = oct,
	year = {2017},
	keywords = {E1peer}
}

@inproceedings{eichberg_defining_2008,
	title = {Defining and continuous checking of structural program dependencies},
	booktitle = {{ICSE}},
	author = {Eichberg, Michael and Kloppenburg, Sven and Klose, Karl and Mezini, Mira},
	year = {2008},
	keywords = {E1peer},
	pages = {391--400}
}

@inproceedings{kim_towards_2010,
	title = {Towards an {Intelligent} {Code} {Search} {Engine}},
	booktitle = {Conference on {Artificial} {Intelligence} ({AAAI})},
	author = {Kim, Jinhan and Lee, Sanghoon and Hwang, Seung-won and Kim, Sunghun},
	year = {2010},
	keywords = {E1ext}
}

@inproceedings{buse_synthesizing_2012,
	title = {Synthesizing {API} usage examples},
	booktitle = {International {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Buse, Raymond P. L. and Weimer, Westley},
	year = {2012},
	keywords = {E1ext},
	pages = {782--792}
}

@inproceedings{moreno_how_2015,
	title = {How {Can} {I} {Use} {This} {Method}?},
	booktitle = {International {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Moreno, Laura and Bavota, Gabriele and Penta, Massimiliano Di and Oliveto, Rocco and Marcus, Andrian},
	year = {2015},
	keywords = {E1ext},
	pages = {880--890}
}

@inproceedings{reif_call_2016,
	title = {Call graph construction for {Java} libraries},
	url = {http://doi.acm.org/10.1145/2950290.2950312},
	doi = {10.1145/2950290.2950312},
	booktitle = {Proceedings of the 24th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}, {FSE} 2016},
	author = {Reif, Michael and Eichberg, Michael and Hermann, Ben and Lerch, Johannes and Mezini, Mira},
	year = {2016},
	keywords = {E1peer},
	pages = {474--486}
}

@article{proksch_intelligent_2015,
	title = {Intelligent {Code} {Completion} with {Bayesian} {Networks}},
	volume = {25},
	url = {http://doi.acm.org/10.1145/2744200},
	doi = {10.1145/2744200},
	number = {1},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Proksch, Sebastian and Lerch, Johannes and Mezini, Mira},
	year = {2015},
	keywords = {evaluation, E1peer, to read, machine learning, code completion, code recommender, Content assist, integrated development environments, productivity},
	pages = {3:1--3:31},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\79953ZZV\\Proksch et al. - 2015 - Intelligent Code Completion with Bayesian Networks.pdf:application/pdf;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\I8M4BJCI\\Proksch et al. - 2015 - Intelligent Code Completion with Bayesian Networks.pdf:application/pdf}
}

@book{amman_mudetect:_nodate,
	title = {{MuDetect}: {The} {Next} {Step} in {API}-{Misuse} {Detection}},
	author = {Amman, Sven and Nguyen, H. A. and Nadi, Sarah and Nguyen, T. and Mezini, Mira},
	keywords = {E1other}
}

@phdthesis{kruger_product-line_2014,
	title = {Product-{Line} {Verification} with {Abstract} {Contracts}},
	school = {University of Magdeburg},
	author = {Krüger, Stefan},
	year = {2014},
	keywords = {E1other}
}

@inproceedings{buscher_compiling_2016,
	series = {{LNCS}},
	title = {Compiling {Low} {Depth} {Circuits} for {Practical} {Secure} {Computation}},
	volume = {9879},
	booktitle = {21. {European} {Symposium} on {Research} in {Computer} {Security} ({ESORICS}'16)},
	publisher = {Springer},
	author = {Büscher, Niklas and Holzer, Andreas and Weber, Alina and Katzenbeisser, Stefan},
	year = {2016},
	keywords = {E4peer},
	pages = {80--98}
}

@inproceedings{buscher_faster_2015,
	title = {Faster {Secure} {Computation} through {Automatic} {Parallelization}},
	booktitle = {24. {USENIX} {Security} {Symposium} ({USENIX} {Security}'15)},
	publisher = {USENIX},
	author = {Büscher, Niklas and Katzenbeisser, Stefan},
	year = {2015},
	keywords = {E4peer},
	pages = {531--546}
}

@article{asharov_privacy-preserving_2017,
	title = {Privacy-{Preserving} {Interdomain} {Routing} at {Internet} {Scale}},
	volume = {2017},
	url = {http://thomaschneider.de/papers/ADSSSSZ17.pdf},
	abstract = {The Border Gateway Protocol (BGP) computes routes between the organizational networks that make up today’s Internet. Unfortunately, BGP suffers from deficiencies, including slow convergence, security problems, a lack of innovation, and the leakage of sensitive information about domains’ routing preferences. To overcome some of these problems, we revisit the idea of centralizing and using secure multi-party computation (MPC) for interdomain routing which was proposed by Gupta et al. (ACM HotNets’12). We implement two algorithms for interdomain routing with state-of-the-art MPC protocols. On an empirically derived dataset that approximates the topology of today’s Internet (55809 nodes), our protocols take as little as 6s of topology-independent precomputation and only 3 s of online time. We show, moreover, that when our MPC approach is applied at country/region-level scale, runtimes can be as low as 0.17 s online time and 0.20 s pre-computation time. Our results motivate the MPC approach for interdomain routing and furthermore demonstrate that current MPC techniques are capable of efficiently tackling real-world problems at a large scale.},
	number = {3},
	journal = {Proceedings on Privacy Enhancing Technologies (PoPETs)},
	author = {Asharov, Gilad and Demmler, Daniel and Schapira, Michael and Schneider, Thomas and Segev, Gil and Shenker, Scott and Zohner, Michael},
	year = {2017},
	keywords = {E4peer},
	pages = {143--163}
}

@inproceedings{albrecht_ciphers_2015,
	series = {{LNCS}},
	title = {Ciphers for {MPC} and {FHE}},
	volume = {9056},
	url = {http://thomaschneider.de/papers/ARSTZ15.pdf},
	doi = {10.1007/978-3-662-46800-5_17},
	abstract = {Designing an efficient cipher was always a delicate balance between linear and non-linear operations. This goes back to the design of DES, and in fact all the way back to the seminal work of Shannon. Here we focus, for the first time, on an extreme corner of the design space and initiate a study of symmetric-key primitives that minimize the multiplicative size and depth of their descriptions. This is motivated by recent progress in practical instantiations of secure multi-party computation (MPC), fully homomorphic encryption (FHE), and zero-knowledge proofs (ZK) where linear computations are, compared to non-linear operations, essentially “free”. We focus on the case of a block cipher, and propose the family of block ciphers “LowMC”, beating all existing proposals with respect to these metrics by far. We sketch several applications for such ciphers and give implementation comparisons suggesting that when encrypting larger amounts of data the new design strategy translates into improvements in computation and communication complexity by up to a factor of 5 compared to AES-128, which incidentally is one of the most competitive classical designs. Furthermore, we identify cases where “free XORs” can no longer be regarded as such but represent a bottleneck, hence refuting this commonly held belief with a practical example.},
	booktitle = {34. {Annual} {International} {Conference} on the {Theory} and {Applications} of {Cryptographic} {Techniques} ({EUROCRYPT}'15)},
	publisher = {Springer},
	author = {Albrecht, Martin and Rechberger, Christian and Schneider, Thomas and Tiessen, Tyge and Zohner, Michael},
	year = {2015},
	keywords = {E4peer},
	pages = {430--454}
}

@inproceedings{demmler_automated_2015,
	title = {Automated {Synthesis} of {Optimized} {Circuits} for {Secure} {Computation}},
	url = {http://thomaschneider.de/papers/DDKSSZ15.pdf},
	doi = {10.1145/2810103.2813678},
	abstract = {In the recent years, secure computation has been the subject of intensive research, emerging from theory to practice. In order to make secure computation usable by non-experts, Fairplay (USENIX Security 2004) initiated a line of research in compilers that allow to automatically generate circuits from high-level descriptions of the functionality that is to be computed securely. Most recently, TinyGarble (IEEE S\&P 2015) demonstrated that it is natural to use existing hardware synthesis tools for this task.{\textbackslash} In this work, we present how to use industrial-grade hardware synthesis tools to generate circuits that are not only optimized for size, but also for depth. These are required for secure computation protocols with non-constant round complexity. We compare a large variety of circuits generated by our toolchain with hand-optimized circuits and show reduction of depth by up to 14\%.{\textbackslash} The main advantages of our approach are developing customized libraries of depth-optimized circuit constructions which we map to high-level functions and operators, and using existing libraries available in the industrial-grade logic synthesis tools which are heavily tested. In particular, we show how to easily obtain circuits for IEEE 754 compliant floating-point operations. We extend the open source ABY framework (NDSS 2015) to securely evaluate circuits generated with our toolchain and show between 0.5 to 21.4 times faster floating-point operations than previous protocols of Aliasgari et al. (NDSS 2013), even though our protocols work for two parties instead of three or more. As application we consider privacy-preserving proximity testing on Earth.},
	booktitle = {22. {ACM} {Computer} and {Communications} {Security} ({CCS}'15)},
	publisher = {ACM},
	author = {Demmler, Daniel and Dessouky, Ghada and Koushanfar, Farinaz and Sadeghi, Ahmad-Reza and Schneider, Thomas and Zeitouni, Shaza},
	year = {2015},
	keywords = {E4peer},
	pages = {1504--1517}
}

@inproceedings{songhori_tinygarble:_2015,
	title = {{TinyGarble}: {Highly} {Compressed} and {Scalable} {Sequential} {Garbled} {Circuits}},
	url = {http://esonghori.github.io/file/TinyGarble.pdf},
	doi = {10.1109/SP.2015.32},
	abstract = {We introduce TinyGarble, a novel automated methodology based on powerful logic synthesis techniques for generating and optimizing compressed Boolean circuits used in secure computation, such as Yao's Garbled Circuit (GC) protocol. TinyGarble achieves an unprecedented level of compactness and scalability by using a sequential circuit description for GC. We introduce new libraries and transformations, such that our sequential circuits can be optimized and securely evaluated by interfacing with available garbling frameworks. The circuit compactness makes the memory footprint of the garbling operation fit in the processor cache, resulting in fewer cache misses and thereby less CPU cycles. Our proof-of-concept implementation of benchmark functions using TinyGarble demonstrates a high degree of compactness and scalability. We improve the results of existing automated tools for GC generation by orders of magnitude; for example, TinyGarble can compress the memory footprint required for 1024-bit multiplication by a factor of 4,172, while decreasing the number of non-XOR gates by 67\%. Moreover, with TinyGarble we are able to implement functions that have never been reported before, such as SHA-3. Finally, our sequential description enables us to design and realize a garbled processor, using the MIPS I instruction set, for private function evaluation. To the best of our knowledge, this is the first scalable emulation of a general purpose processor.},
	booktitle = {36. {IEEE} {Symposium} on {Security} and {Privacy} ({S}\&{P}'15)},
	publisher = {IEEE},
	author = {Songhori, Ebrahim M. and Hussain, Siam U. and Sadeghi, Ahmad-Reza and Schneider, Thomas and Koushanfar, Farinaz},
	year = {2015},
	keywords = {E4peer},
	pages = {411--428}
}

@inproceedings{dessouky_pushing_2017,
	title = {Pushing the {Communication} {Barrier} in {Secure} {Computation} using {Lookup} {Tables}},
	url = {http://thomaschneider.de/papers/DKSSZZ17.pdf},
	abstract = {Secure two-party computation has witnessed significant efficiency improvements in the recent years. Current implementations of protocols with security against passive adversaries generate and process data much faster than it can be sent over the network, even with a single thread. This paper introduces novel methods to further reduce the communication bottleneck and round complexity of semi-honest secure two-party computation. Our new methodology creates a trade-off between communication and computation, and we show that the added computing cost for each party is still feasible and practicable in light of the new communication savings. We first improve communication for Boolean circuits with 2-input gates by factor 1.9x when evaluated with the protocol of Goldreich-Micali-Wigderson (GMW). As a further step, we change the conventional Boolean circuit representation from 2-input gates to multi-input/multi-output lookup tables (LUTs) which can be programmed to realize arbitrary functions. We construct two protocols for evaluating LUTs offering a trade-off between online communication and total communication. Our most efficient LUT-based protocol reduces the communication and round complexity by a factor 2-4x for several basic and complex operations. Our proposed scheme results in a significant overall runtime decrease of up to a factor of 3x on several benchmark functions.},
	booktitle = {24. {Network} and {Distributed} {System} {Security} {Symposium} ({NDSS}'17)},
	publisher = {Internet Society},
	author = {Dessouky, Ghada and Koushanfar, Farinaz and Sadeghi, Ahmad-Reza and Schneider, Thomas and Zeitouni, Shaza and Zohner, Michael},
	year = {2017},
	keywords = {E4peer}
}

@inproceedings{pinkas_phasing:_2015,
	title = {Phasing: {Private} {Set} {Intersection} using {Permutation}-{Based} {Hashing}},
	url = {http://thomaschneider.de/papers/PSSZ15.pdf},
	abstract = {Private Set Intersection (PSI) allows two parties to compute the intersection of private sets while revealing nothing more than the intersection itself. PSI needs to be applied to large data sets in scenarios such as measurement of ad conversion rates, data sharing, or contact discovery. Existing PSI protocols do not scale up well, and therefore some applications use insecure solutions instead.{\textbackslash} We describe a new approach for designing PSI protocols based on permutation-based hashing, which enables to reduce the length of items mapped to bins while ensuring that no collisions occur. We denote this approach as Phasing, for Permutation-based Hashing Set Intersection. Phasing can dramatically improve the performance of PSI protocols whose overhead depends on the length of the representations of input items.{\textbackslash} We apply Phasing to design a new approach for circuit-based PSI protocols. The resulting protocol is up to 5 times faster than the previously best Sort-Compare-Shuffle circuit of Huang et al. (NDSS 2012). We also apply Phasing to the OT-based PSI protocol of Pinkas et al. (USENIX Security 2014), which is the fastest PSI protocol to date. Together with additional improvements that reduce the computation complexity by a logarithmic factor, the resulting protocol improves run-time by a factor of up to 20 and can also have better communication overhead than the previously best PSI protocol in that respect. The new protocol is only moderately less efficient than an {\textbackslash}em insecure PSI protocol that is currently used by real-world applications, and is therefore the first secure PSI protocol that is scalable to the demands and the constraints of current real-world settings.},
	booktitle = {24. {USENIX} {Security} {Symposium} ({USENIX} {Security}'15)},
	publisher = {USENIX},
	author = {Pinkas, Benny and Schneider, Thomas and Segev, Gil and Zohner, Michael},
	year = {2015},
	keywords = {E4peer},
	pages = {515--530}
}

@inproceedings{demmler_aby_2015,
	title = {{ABY} – {A} {Framework} for {Efficient} {Mixed}-{Protocol} {Secure} {Two}-{Party} {Computation}},
	url = {http://thomaschneider.de/papers/DSZ15.pdf},
	abstract = {Secure computation enables mutually distrusting parties to jointly evaluate a function on their private inputs without revealing anything but the function's output. Generic secure computation protocols in the semi-honest model have been studied extensively and several best practices have evolved.{\textbackslash} In this work, we design and implement a mixed-protocol framework, called {\textbackslash}emphABY, that efficiently combines secure computation schemes based on {\textbackslash}underlineArithmetic sharing, {\textbackslash}underlineBoolean sharing, and {\textbackslash}underlineYao's garbled circuits and that makes available best practice solutions in secure two-party computation. Our framework allows to pre-compute almost all cryptographic operations and provides novel, highly efficient conversions between secure computation schemes based on pre-computed oblivious transfer extensions. ABY supports several standard operations and we perform benchmarks on a local network and in a public intercontinental cloud. From our benchmarks we deduce new insights on the efficient design of secure computation protocols, most prominently that oblivious transfer-based multiplications are much more efficient than multiplications based on homomorphic encryption. We use ABY to construct mixed-protocols for three example applications – private set intersection, biometric matching, and modular exponentiation – and show that they are more efficient than using a single protocol.},
	booktitle = {22. {Network} and {Distributed} {System} {Security} {Symposium} ({NDSS}'15)},
	publisher = {Internet Society},
	author = {Demmler, Daniel and Schneider, Thomas and Zohner, Michael},
	year = {2015},
	keywords = {E4peer}
}

@inproceedings{chiesa_towards_2016,
	title = {Towards {Securing} {Internet} {eXchange} {Points} {Against} {Curious} {onlooKers} ({Short} {Paper})},
	url = {http://thomaschneider.de/papers/CDCSS16.pdf},
	doi = {10.1145/2959424.2959427},
	abstract = {The growing relevance of Internet eXchange Points (IXPs), where an increasing number of networks exchange routing information, poses fundamental questions regarding the privacy guarantees of confidential business information. To facilitate the exchange of routes among their members, IXPs provide Route Server (RS) services to dispatch the routes according to each member’s export policies. Nowadays, to make use of RSes, these policies must be disclosed to the IXP. This state of affairs raises privacy concerns among network administrators and even deters some networks from subscribing to RS services. We design SIXPACK (which stands for “Securing Internet eXchange Points Against Curious onlooKers”), a RS service that leverages Secure Multi-Party Computation (SMPC) techniques to keep export policies confidential, while maintaining the same functionalities as today’s RSes. We assess the effectiveness and scalability of our system by evaluating our prototype implementation and using traces of data from one of the largest IXPs in the world.},
	booktitle = {{ACM}, {IRTF} \& {ISOC} {Applied} {Networking} {Research} {Workshop} ({ANRW}'16)},
	publisher = {ACM},
	author = {Chiesa, Marco and Demmler, Daniel and Canini, Marco and Schapira, Michael and Schneider, Thomas},
	year = {2016},
	keywords = {E4peer},
	pages = {32--34}
}

@article{riazi_toward_2017,
	title = {Toward {Practical} {Secure} {Stable} {Matching}},
	volume = {2017},
	url = {http://thomaschneider.de/papers/RSSSK17.pdf},
	doi = {10.1515/popets-2017-0005},
	abstract = {The Stable Matching (SM) algorithm has been deployed in many real-world scenarios including the National Residency Matching Program (NRMP) and financial applications such as matching of suppliers and consumers in capital markets. Since these applications typically involve highly sensitive information such as the underlying preference lists, their current implementations rely on trusted third parties. This paper introduces the first provably secure and scalable implementation of SM based on Yao's garbled circuit protocol and Oblivious RAM (ORAM). Our scheme can securely compute a stable match for 8k pairs four orders of magnitude faster than the previously best known method. We achieve this by introducing a compact and efficient sub-linear size circuit. We even further decrease the computation cost by three orders of magnitude by proposing a novel technique to avoid unnecessary iterations in the SM algorithm. We evaluate our implementation for several problem sizes and plan to publish it as open-source.},
	number = {1},
	journal = {Proceedings on Privacy Enhancing Technologies (PoPETs)},
	author = {Riazi, M. Sadegh and Songhori, Ebrahim M. and Sadeghi, Ahmad-Reza and Schneider, Thomas and Koushanfar, Farinaz},
	year = {2017},
	keywords = {E4peer},
	pages = {62--78}
}

@article{kiss_private_2017,
	title = {Private {Set} {Intersection} for {Unequal} {Set} {Sizes} with {Mobile} {Applications}},
	volume = {2017},
	url = {http://thomaschneider.de/papers/KLSAP17.pdf},
	abstract = {Private set intersection (PSI) is a cryptographic technique that is applicable to many privacy-sensitive scenarios. For decades, researchers have been focusing on improving its efficiency in both communication and computation. However, most of the existing solutions are inefficient for an unequal number of inputs, which is common in conventional client-server settings.{\textbackslash} In this paper, we analyze and optimize the efficiency of existing PSI protocols to support precomputation so that they can efficiently deal with such input sets. We transform four existing PSI protocols into the precomputation form such that in the setup phase the communication is linear only in the size of the larger input set, while in the online phase the communication is linear in the size of the smaller input set. We implement all four protocols and run experiments between two PCs and between a PC and a smartphone and give a systematic comparison of their performance. Our experiments show that a protocol based on securely evaluating a garbled AES circuit achieves the fastest setup time by several orders of magnitudes, and the fastest online time in the PC setting where AES-NI acceleration is available. In the mobile setting, the fastest online time is achieved by a protocol based on the Diffie-Hellman assumption.},
	number = {4},
	journal = {Proceedings on Privacy Enhancing Technologies (PoPETs)},
	author = {Kiss, Ágnes and Liu, Jian and Schneider, Thomas and Asokan, N. and Pinkas, Benny},
	year = {2017},
	keywords = {E4peer},
	pages = {97--117}
}

@inproceedings{kiss_valiants_2016,
	series = {{LNCS}},
	title = {Valiant's {Universal} {Circuit} is {Practical}},
	volume = {9665},
	url = {http://thomaschneider.de/papers/KS16.pdf},
	doi = {10.1007/978-3-662-49890-3_27},
	abstract = {Universal circuits (UCs) can be programmed to evaluate any circuit of a given size \$k\$. They provide elegant solutions in various application scenarios, e.g. for private function evaluation (PFE) and for improving the flexibility of attribute-based encryption (ABE) schemes. The optimal size of a universal circuit is proven to be \$Ømega(k{\textbackslash}log k)\$. Valiant (STOC'76) proposed a size-optimized UC construction, which has not been put in practice ever since. The only implementation of universal circuits was provided by Kolesnikov and Schneider (FC'08), with size \${\textbackslash}mathcalO(k{\textbackslash}log{\textasciicircum}2 k)\$.{\textbackslash} In this paper, we refine the size of Valiant's UC and further improve the construction by (at least) \$2k\$. We show that due to recent optimizations and our improvements, it is the best solution to apply in the case for circuits with a constant number of inputs and outputs. When the number of inputs or outputs is linear in the number of gates, we propose a more efficient hybrid solution based on the two existing constructions. We validate the practicality of Valiant's UC, by giving an example implementation for PFE using these size-optimized UCs.},
	booktitle = {35th {Annual} {International} {Conference} on the {Theory} and {Applications} of {Cryptographic} {Techniques} ({EUROCRYPT}'16)},
	publisher = {Springer},
	author = {Kiss, Ágnes and Schneider, Thomas},
	year = {2016},
	keywords = {E4peer},
	pages = {699--728}
}

@article{asharov_more_2017,
	title = {More {Efficient} {Oblivious} {Transfer} {Extensions}},
	volume = {30},
	url = {http://thomaschneider.de/papers/ALSZ17.pdf},
	doi = {10.1007/s00145-016-9236-6},
	abstract = {Oblivious transfer (OT) is one of the most fundamental primitives in cryptography and is widely used in protocols for secure two-party and multi-party computation. As secure computation becomes more practical, the need for practical large scale oblivious transfer protocols is becoming more evident. Oblivious transfer extensions are protocols that enable a relatively small number of “base-OTs” to be utilized to compute a very large number of OTs at low cost. In the semi-honest setting, Ishai et al. (CRYPTO 2003) presented an OT extension protocol for which the cost of each OT (beyond the base-OTs) is just a few hash function operations. In the malicious setting, Nielsen et al. (CRYPTO 2012) presented an efficient OT extension protocol for the setting of malicious adversaries, that is secure in a random oracle model.{\textbackslash} In this work we improve OT extensions with respect to communication complexity, computation complexity, and scalability in the semi-honest, covert, and malicious model. Furthermore, we show how to modify our maliciously secure OT extension protocol to achieve security with respect to a version of correlation robustness instead of the random oracle. We also provide specific optimizations of OT extensions that are tailored to the use of OT in various secure computation protocols such as Yao's garbled circuits and the protocol of Goldreich-Micali-Wigderson, which reduce the communication complexity even further. We experimentally verify the efficiency gains of our protocols and optimizations.},
	number = {3},
	journal = {Journal of Cryptology (JoC)},
	author = {Asharov, Gilad and Lindell, Yehuda and Schneider, Thomas and Zohner, Michael},
	month = jul,
	year = {2017},
	keywords = {E4peer},
	pages = {805--858}
}

@inproceedings{asharov_more_2015,
	series = {{LNCS}},
	title = {More {Efficient} {Oblivious} {Transfer} {Extensions} with {Security} for {Malicious} {Adversaries}},
	volume = {9056},
	url = {http://thomaschneider.de/papers/ALSZ15.pdf},
	doi = {10.1007/978-3-662-46800-5_26},
	abstract = {Oblivious transfer (OT) is one of the most fundamental primitives in cryptography and is widely used in protocols for secure two-party and multi-party computation. As secure computation becomes more practical, the need for practical large scale oblivious transfer protocols is becoming more evident. Oblivious transfer extensions are protocols that enable a relatively small number of “base-OTs” to be utilized to compute a very large number of OTs at low cost. In the semi-honest setting, Ishai et al. (CRYPTO 2003) presented an OT extension protocol for which the cost of each OT (beyond the base-OTs) is just a few hash function operations. In the malicious setting, Nielsen et al. (CRYPTO 2012) presented an efficient OT extension protocol for the setting of active adversaries, that is secure in the random oracle model. In this work, we present an OT extension protocol for the setting of malicious adversaries that is more efficient and uses less communication than previous works. In addition, our protocol can be proven secure in both the random oracle model, and in the standard model with a type of correlation robustness. Given the importance of OT in many secure computation protocols, increasing the efficiency of OT extensions is another important step forward to making secure computation practical.},
	booktitle = {34. {Annual} {International} {Conference} on the {Theory} and {Applications} of {Cryptographic} {Techniques} ({EUROCRYPT}'15)},
	publisher = {Springer},
	author = {Asharov, Gilad and Lindell, Yehuda and Schneider, Thomas and Zohner, Michael},
	year = {2015},
	keywords = {E4peer},
	pages = {673--701}
}

@book{pinkas_scalable_2016,
	title = {Scalable {Private} {Set} {Intersection} {Based} on {OT} {Extension}},
	abstract = {Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing any information about items that are not in the intersection. It is one of the best studied applications of secure computation and many PSI protocols have been proposed. However, the variety of existing PSI protocols makes it difficult to identify the solution that performs best in a respective scenario, especially since they were not compared in the same setting. In addition, existing PSI protocols are several orders of magnitude slower than an insecure naive hashing solution which is used in practice.{\textbackslash} In this work, we review the progress made on PSI protocols and give an overview of existing protocols in various security models. We then focus on PSI protocols that are secure against semi-honest adversaries and take advantage of the most recent efficiency improvements in OT extension and propose significant optimizations to previous PSI protocols and to suggest a new PSI protocol whose run-time is superior to that of existing protocols. We compare the performance of the protocols both theoretically and experimentally, by implementing all protocols on the same platform, give recommendations on which protocol to use in a particular setting, and evaluate the progress on PSI protocols by comparing them to the currently employed insecure naive hashing protocol. We demonstrate the feasibility of our new PSI protocol by processing two sets with a billion elements each.},
	author = {Pinkas, Benny and Schneider, Thomas and Zohner, Michael},
	year = {2016},
	note = {Published: Cryptology ePrint Archive, Report 2016/930},
	keywords = {E4peer}
}

@inproceedings{songhori_garbledcpu:_2016,
	title = {{GarbledCPU}: {A} {MIPS} {Processor} for {Secure} {Computation} in {Hardware}},
	url = {http://thomaschneider.de/papers/SZDSSK16.pdf},
	doi = {10.1145/2897937.2898027},
	abstract = {We present GarbledCPU, the first framework that realizes a hardware-based general purpose sequential processor for secure computation. Our MIPS-based implementation enables development of applications (functions) in a high-level language while performing secure function evaluation (SFE) using Yao's garbled circuit protocol in hardware. GarbledCPU provides three degrees of freedom for SFE which allow leveraging the trade-off between privacy and performance: public functions, private functions, and semi-private functions. We synthesize GarbledCPU on a Virtex-7 FPGA as a proof-of-concept implementation and evaluate it on various benchmarks including Hamming distance, private set intersection and AES. Our results indicate that our pipelined hardware framework outperforms the fastest available software implementation.},
	booktitle = {53. {Annual} {Design} {Automation} {Conference} ({DAC}'16)},
	publisher = {ACM},
	author = {Songhori, Ebrahim M. and Zeitouni, Shaza and Dessouky, Ghada and Schneider, Thomas and Sadeghi, Ahmad-Reza and Koushanfar, Farinaz},
	year = {2016},
	keywords = {E4peer},
	pages = {73:1--73:6}
}

@misc{noauthor_jumping_nodate,
	title = {"{Jumping} {Through} {Hoops}": {Why} do {Java} {Developers} {Struggle} with {Cryptography} {APIs}? - {IEEE} {Conference} {Publication}},
	url = {http://ieeexplore.ieee.org/document/7886969/},
	urldate = {2018-01-02},
	file = {"Jumping Through Hoops"\: Why do Java Developers Struggle with Cryptography APIs? - IEEE Conference Publication:C\:\\Users\\Anna\\Zotero\\storage\\8ILN9967\\7886969.html:text/html}
}

@inproceedings{glanz_codematch:_2017,
	address = {Paderborn, Germany},
	title = {{CodeMatch}: {Obfuscation} {Won}’t {Conceal} {Your} {Repackaged} {App}},
	isbn = {978-1-4503-5105-8},
	doi = {10.1145/3106237.3106305},
	booktitle = {{ESEC}/{FSE} 2017 {Proceedings} of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM New York, NY, USA ©2017},
	author = {Glanz, Leonid and Amann, Sven and Eichberg, Michael and Reif, Michael and Hermann, Ben and Lerch, Johannes and Mezini, Mira},
	month = sep,
	year = {2017},
	pages = {638--648}
}

@inproceedings{medeiros_love/hate_2015,
	address = {Prague, Czech Republic},
	title = {The {Love}/{Hate} {Relationship} with the {C} {Preprocessor}: {An} {Interview} {Study}},
	booktitle = {European {Conference} on {Object}-{Oriented} {Programming}},
	author = {Medeiros, Flávio and Kästner, Christian and Ribeiro, Márcio and Nadi, Sarah and Gheyi, Rohit},
	month = jul,
	year = {2015},
	pages = {999--1022}
}

@inproceedings{zhou_extracting_2015,
	address = {Florence, Italy},
	title = {Extracting {Configuration} {Knowledge} from {Build} {Files} with {Symbolic} {Analysis}},
	booktitle = {3rd {International} {Workshop} on {Release} {Engineering}},
	author = {Zhou, Shurui and Al-Kofahi, Jafar and Nguyen, Tien and Kaestner, Christian and Nadi, Sarah},
	month = may,
	year = {2015},
	pages = {4}
}

@inproceedings{hauck_securescala:_2016,
	title = {{SecureScala}: {Scala} embedding of secure computations},
	booktitle = {Proceedings of the 2016 7th {ACM} {SIGPLAN} {Symposium} on {Scala}},
	publisher = {ACM},
	author = {Hauck, Markus and Savvides, Savvas and Eugster, Patrick and Mezini, Mira and Salvaneschi, Guido},
	month = oct,
	year = {2016}
}

@inproceedings{mariano_parallel_2017,
	title = {A {Parallel} {Variant} of {LDSieve} for the {SVP} on {Lattices}},
	doi = {10.1109/PDP.2017.60},
	booktitle = {2017 25th {Euromicro} {International} {Conference} on {Parallel}, {Distributed} and {Network}-based {Processing} ({PDP})},
	author = {Mariano, A. and Laarhoven, T. and Bischof, C.},
	month = mar,
	year = {2017},
	keywords = {P1peer},
	pages = {23--30}
}

@incollection{mariano_vectorized_2017,
	address = {Cham},
	title = {A {Vectorized}, {Cache} {Efficient} {LLL} {Implementation}},
	isbn = {978-3-319-61982-8},
	url = {https://doi.org/10.1007/978-3-319-61982-8_16},
	abstract = {This paper proposes a vectorized, cache efficient implementation of a floating-point version of the Lenstra-Lenstra-Lovász (LLL) algorithm, which is a key algorithm in many fields of computer science. We propose a re-arrangement of the data structures in LLL, which exposes parallelism and enables vectorization. We show that in one kernel, 128-bit SIMD vectorization works better than 256-bit, while in another kernel it is the other way around. In high lattice dimensions, this re-arrangement renders the implementation more cache friendly, thereby further increasing performance. Our floating-point LLL implementation is slightly slower than the implementation in the Number Theory Library (NTL) without vectorization, but 10\% faster when vectorized, for lattices that require exhaustive computation with multi-precision. For larger lattices, we obtain a speedup factor of 35\% over a non-vectorized implementation.},
	booktitle = {High {Performance} {Computing} for {Computational} {Science} – {VECPAR} 2016: 12th {International} {Conference}, {Porto}, {Portugal}, {June} 28-30, 2016, {Revised} {Selected} {Papers}},
	publisher = {Springer International Publishing},
	author = {Mariano, A. and Correia, F. and Bischof, C.},
	editor = {Dutra, I. and Camacho, R. and Barbosa, J. and Marques, O.},
	year = {2017},
	doi = {10.1007/978-3-319-61982-8_16},
	keywords = {P1peer},
	pages = {162--173}
}

@inproceedings{correia_parallel_2016,
	title = {Parallel {Improved} {Schnorr}-{Euchner} {Enumeration} {SE}++ for the {CVP} and {SVP}},
	doi = {10.1109/PDP.2016.95},
	booktitle = {2016 24th {Euromicro} {International} {Conference} on {Parallel}, {Distributed}, and {Network}-{Based} {Processing} ({PDP})},
	author = {Correia, F. and Mariano, A. and Proença, A. and Bischof, C. and Agrell, E.},
	month = feb,
	year = {2016},
	keywords = {P1peer},
	pages = {596--603}
}

@inproceedings{mariano_enhancing_2016,
	title = {Enhancing the {Scalability} and {Memory} {Usage} of {Hashsieve} on {Multi}-core {CPUs}},
	doi = {10.1109/PDP.2016.31},
	booktitle = {2016 24th {Euromicro} {International} {Conference} on {Parallel}, {Distributed}, and {Network}-{Based} {Processing} ({PDP})},
	author = {Mariano, A. and Bischof, C.},
	month = feb,
	year = {2016},
	keywords = {P1peer},
	pages = {545--552}
}

@inproceedings{mariano_parallel_2015,
	title = {Parallel ({Probable}) {Lock}-{Free} {Hash} {Sieve}: {A} {Practical} {Sieving} {Algorithm} for the {SVP}},
	doi = {10.1109/ICPP.2015.68},
	booktitle = {2015 44th {International} {Conference} on {Parallel} {Processing}},
	author = {Mariano, A. and Bischof, C. and Laarhoven, T.},
	month = sep,
	year = {2015},
	keywords = {P1peer},
	pages = {590--599}
}

@inproceedings{mariano_lock-free_2014,
	title = {Lock-{Free} {GaussSieve} for {Linear} {Speedups} in {Parallel} {High} {Performance} {SVP} {Calculation}},
	doi = {10.1109/SBAC-PAD.2014.18},
	booktitle = {2014 {IEEE} 26th {International} {Symposium} on {Computer} {Architecture} and {High} {Performance} {Computing}},
	author = {Mariano, A. and Timnat, S. and Bischof, C.},
	month = oct,
	year = {2014},
	keywords = {P1peer},
	pages = {278--285}
}

@inproceedings{akleylek_efficient_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An {Efficient} {Lattice}-{Based} {Signature} {Scheme} with {Provably} {Secure} {Instantiation}},
	volume = {9646},
	booktitle = {Progress in {Cryptology} - {AFRICACRYPT} 2016 - 8th {International} {Conference} on {Cryptology} in {Africa}, {Fes}, {Morocco}, {April} 13-15, 2016, {Proceedings}},
	publisher = {Springer},
	author = {Akleylek, Sedat and Bindel, Nina and Buchmann, Johannes A. and Krämer, Juliane and Marson, Giorgia Azzurra},
	year = {2016},
	keywords = {P2peer},
	pages = {44--60}
}

@book{backes_operational_2014,
	title = {Operational {Signature} {Schemes}},
	volume = {820},
	url = {http://eprint.iacr.org/2014/820},
	author = {Backes, Michael and Dagdelen, Özgür and Fischlin, Marc and Gajek, Sebastian and Meiser, Sebastian and Schröder, Dominique},
	year = {2014},
	keywords = {P2other}
}

@inproceedings{bernhard_hardness_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On the {Hardness} of {Proving} {CCA}-{Security} of {Signed} {ElGamal}},
	volume = {9614},
	booktitle = {Public-{Key} {Cryptography} - {PKC} 2016 - 19th {IACR} {International} {Conference} on {Practice} and {Theory} in {Public}-{Key} {Cryptography}, {Taipei}, {Taiwan}, {March} 6-9, 2016, {Proceedings}, {Part} {I}},
	publisher = {Springer},
	author = {Bernhard, David and Fischlin, Marc and Warinschi, Bogdan},
	year = {2016},
	pages = {47--69}
}

@inproceedings{erwig_redactable_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Redactable {Graph} {Hashing}, {Revisited} - ({Extended} {Abstract})},
	volume = {10343},
	booktitle = {Information {Security} and {Privacy} - 22nd {Australasian} {Conference}, {ACISP} 2017, {Auckland}, {New} {Zealand}, {July} 3-5, 2017, {Proceedings}, {Part} {II}},
	publisher = {Springer},
	author = {Erwig, Andreas and Fischlin, Marc and Hald, Martin and Helm, Dominik and Kiel, Robert and Kübler, Florian and Kümmerlin, Michael and Laenge, Jakob and Rohrbach, Felix},
	year = {2017},
	keywords = {P2peer},
	pages = {398--405}
}

@mastersthesis{fehr_sanitizable_2015,
	title = {Sanitizable {Signcryption} - {Sanitizable} {Signatures} on {Encrypted} {Data}},
	school = {Darmstadt University of Technology},
	author = {Fehr, Victoria},
	year = {2015}
}

@book{fehr_sanitizable_2015-1,
	title = {Sanitizable {Signcryption}: {Sanitization} over {Encrypted} {Data} ({Full} {Version})},
	volume = {765},
	url = {http://eprint.iacr.org/2015/765},
	author = {Fehr, Victoria and Fischlin, Marc},
	year = {2015},
	keywords = {P2other}
}

@inproceedings{fischlin_data_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Data {Is} a {Stream}: {Security} of {Stream}-{Based} {Channels}},
	volume = {9216},
	booktitle = {Advances in {Cryptology} - {CRYPTO} 2015 - 35th {Annual} {Cryptology} {Conference}, {Santa} {Barbara}, {CA}, {USA}, {August} 16-20, 2015, {Proceedings}, {Part} {II}},
	publisher = {Springer},
	author = {Fischlin, Marc and Günther, Felix and Marson, Giorgia Azzurra and Paterson, Kenneth G.},
	year = {2015},
	keywords = {P2peer},
	pages = {545--564}
}

@book{fischlin_data_2017,
	title = {Data {Is} a {Stream}: {Security} of {Stream}-{Based} {Channels}},
	volume = {1191},
	url = {https://eprint.iacr.org/2017/1191},
	author = {Fischlin, Marc and Günther, Felix and Marson, Giorgia Azzurra and Paterson, Kenneth G.},
	year = {2017}
}

@unpublished{fischlin_invisible_nodate,
	title = {Invisible {Sanitizable} {Signatures} and {Public}-{Key} {Encryption} are {Equivalent}},
	author = {Fischlin, Marc and Harasser, Patrick}
}

@inproceedings{fischlin_obfuscation_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Obfuscation {Combiners}},
	volume = {9815},
	booktitle = {Advances in {Cryptology} - {CRYPTO} 2016 - 36th {Annual} {International} {Cryptology} {Conference}, {Santa} {Barbara}, {CA}, {USA}, {August} 14-18, 2016, {Proceedings}, {Part} {II}},
	publisher = {Springer},
	author = {Fischlin, Marc and Herzberg, Amir and Noon, Hod Bin and Shulman, Haya},
	year = {2016},
	keywords = {P2peer},
	pages = {521--550}
}

@inproceedings{gunther_formal_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Formal} {Treatment} of {Multi}-key {Channels}},
	volume = {10403},
	booktitle = {Advances in {Cryptology} - {CRYPTO} 2017 - 37th {Annual} {Cryptology} {Conference}, {Santa} {Barbara}, {CA}, {USA}, {August} 16-20, 2015, {Proceedings}, {Part} {III}},
	publisher = {Springer},
	author = {Günther, Felix and Mazaheri, Sogol},
	year = {2017},
	keywords = {P2peer},
	pages = {587--618}
}

@article{marson_security_2017,
	title = {Security {Notions} for {Bidirectional} {Channels}},
	volume = {2017},
	number = {1},
	journal = {IACR Trans. Symmetric Cryptol.},
	author = {Marson, Giorgia Azzurra and Poettering, Bertram},
	year = {2017},
	keywords = {P2peer},
	pages = {405--426}
}

@inproceedings{classen_opportunities_2016,
	title = {Opportunities and pitfalls in securing visible light communication on the physical layer},
	booktitle = {Proceedings of the 3rd {Workshop} on {Visible} {Light} {Communication} {Systems}},
	publisher = {ACM},
	author = {Classen, Jiska and Steinmetzer, Daniel and Hollick, Matthias},
	year = {2016},
	keywords = {S1peer},
	pages = {19--24}
}

@inproceedings{christin_friend_2012,
	title = {Friend is {Calling}: {Exploiting} {Mobile} {Phone} {Data} to {Help} {Users} in {Setting} their {Privacy} {Preferences}},
	booktitle = {Proceedings of the 4th {Intl}.{\textbackslash} {Workshop} on {Security} and {Privacy} in {Spontaneous} {Interaction} and {Mobile} {Phone} {Use} ({IWSSI}/{SPMU})},
	author = {Christin, D. and Bentolila, A. and Hollick, M.},
	year = {2012},
	keywords = {S1peer},
	pages = {1--7}
}

@inproceedings{christin_picture_2011,
	title = {A {Picture} is {Worth} a {Thousand} {Words}: {Privacy}-aware and {Intuitive} {Relationship} {Establishment} in {Online} {Social} {Networks}},
	booktitle = {Proceedings of the 3rd {Intl}.{\textbackslash} {Workshop} on {Security} and {Privacy} in {Spontaneous} {Interaction} and {Mobile} {Phone} {Use}},
	author = {Christin, D. and Freundenreich, T. and Hollick, M.},
	month = jun,
	year = {2011},
	keywords = {S1peer},
	pages = {6}
}

@inproceedings{christin_privacy-preserving_2011,
	title = {Privacy-preserving {Collaborative} {Path} {Hiding} for {Participatory} {Sensing} {Applications}},
	booktitle = {{IEEE} {Intl}.{\textbackslash} {Conference} on {Mobile} {Ad}-hoc and {Sensor} {Systems} ({MASS} 2011)},
	publisher = {IEEE Computer Society},
	author = {Christin, D. and Guillemet, J. and Reinhardt, A. and Hollick, M. and Kanhere, S. S.},
	month = oct,
	year = {2011},
	keywords = {S1peer},
	pages = {341--350}
}

@article{christin_privacy_2013,
	title = {Privacy {Bubbles}: {User}-{Centered} {Privacy} {Control} for {Mobile} {Content} {Sharing} {Applications}},
	volume = {17},
	number = {3},
	journal = {Information Security Technical Report. Security and Privacy for Digital Ecosystems},
	author = {Christin, Delphine and López, Pablo Sánchez and Reinhardt, Andreas and Hollick, Matthias and Kauer, Michaela},
	month = feb,
	year = {2013},
	keywords = {S1peer},
	pages = {105--116}
}

@article{christin_survey_2011,
	title = {A {Survey} on {Privacy} in {Mobile} {Participatory} {Sensing} {Applications}},
	volume = {84},
	number = {11},
	journal = {The Journal of Systems \& Software (JSS)},
	author = {Christin, D. and Reinhardt, A. and Kanhere, S. S. and Hollick, M.},
	month = nov,
	year = {2011},
	keywords = {S1peer},
	pages = {1928--1946}
}

@inproceedings{christin_incognisense:_2012,
	title = {{IncogniSense}: {An} {Anonymity}-preserving {Reputation} {Framework} for {Participatory} {Sensing} {Applications}},
	booktitle = {{IEEE} {Intl}.{\textbackslash} {Conference} on {Pervasive} {Computing} and {Communications} ({PerCom} 2012)},
	author = {Christin, D. and skopf, C. Ro{\textbackslash}s and Hollick, M. and Martucci, L. A. and Kanhere, S. S.},
	month = mar,
	year = {2012},
	keywords = {S1peer},
	pages = {135--143}
}

@inproceedings{habib_fusion_2012,
	title = {Fusion of {Opinions} under {Uncertainty} and {Conflict}.{\textbackslash} {Trust} {Assessment} for {Cloud} {Marketplaces}},
	booktitle = {{IEEE} {Intl}.{\textbackslash} {Conf}.{\textbackslash} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	publisher = {IEEE Computer Society},
	author = {Habib, Sheikh Mahbub and Ries, Sebastian and Hauke, Sascha and Mühlhäuser, Max},
	month = jun,
	year = {2012},
	keywords = {learning (artificial intelligence), S1peer, encryption, learning process, privacy preserving computation, recommendations, trust models, trusted computing, zero-knowledge proofs},
	pages = {109--118}
}

@article{habib_towards_2013,
	title = {Towards a trust management system for cloud computing marketplaces: using {CAIQ} as a trust information source},
	doi = {doi: 10.1002/sec.748},
	journal = {Security and Communication Networks (SCN)},
	author = {Habib, Sheikh Mahbub and Ries, Sebastian and Mühlhäuser, Max and Varikkattu, Prabhu},
	year = {2013},
	keywords = {S1peer},
	pages = {16}
}

@inproceedings{hauke_application_2013,
	title = {On the {Application} of {Supervised} {Machine} {Learning} to {Trustworthiness} {Assessment}},
	booktitle = {{IEEE} {Intl}.{\textbackslash} {Conf}.{\textbackslash} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	publisher = {IEEE Computer Society},
	author = {Hauke, S. and Biedermann, S. and Mühlhäuser, M. and Heider, D.},
	year = {2013},
	keywords = {S1peer},
	pages = {525--534}
}

@incollection{hauke_integrating_2012,
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Integrating {Indicators} of {Trustworthiness} into {Reputation}-{Based} {Trust} {Models}},
	volume = {374},
	isbn = {978-3-642-29851-6},
	abstract = {Reputation-based trust models are essentially reinforcement learning mechanisms reliant on feedback. As such, they face a cold start problem when attempting to assess an unknown service partner. State-of-the-art models address this by incorporating dispositional knowledge, the derivation of which is not described regularly. We propose three mechanisms for integrating knowledge readily available in cyber-physical services (e.g., online ordering) to determine the trust disposition of consumers towards unknown services (and their providers). These reputation-building indicators of trustworthiness can serve as cues for trust-based decision making in eCommerce scenarios and drive the evolution of reputation-based trust models towards trust management systems.},
	booktitle = {Trust {Management} {VI}},
	publisher = {Springer},
	author = {Hauke, Sascha and Volk, Florian and Habib, Sheikh Mahbub and Mühlhäuser, Max},
	editor = {Dimitrakos, Theo and Moona, Rajat and Patel, Dhiren and McKnight, D.},
	year = {2012},
	keywords = {S1peer},
	pages = {158--173}
}

@article{martucci_sybil-free_2011,
	title = {Sybil-{Free} {Pseudonyms}, {Privacy} and {Trust}: {Identity} {Management} in the {Internet} of {Services}},
	volume = {19},
	journal = {Journal of Information Processing},
	author = {Martucci, Leonardo A. and Ries, Sebastian and Mühlhäuser, Max},
	month = jun,
	year = {2011},
	keywords = {S1peer},
	pages = {317--331}
}

@inproceedings{ries_learning_2011,
	title = {Learning {Whom} to {Trust} in a {Privacy}-{Friendly} {Way}},
	booktitle = {{IEEE} {Intl}.{\textbackslash} {Conf}.{\textbackslash} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications} ({TrustCom})},
	publisher = {IEEE Computer Society},
	author = {Ries, S. and Fischlin, M. and Martucci, L.A. and Mühlhäuser, M.},
	month = nov,
	year = {2011},
	keywords = {S1peer},
	pages = {214 --225}
}

@inproceedings{ries_certainlogic:_2011,
	title = {{CertainLogic}: {A} {Logic} for {Modeling} {Trust} and {Uncertainty} ({Short} {Paper})},
	booktitle = {Intl.{\textbackslash} {Conference} on {Trust} and {Trustworthy} {Computing} ({TRUST} 2011)},
	publisher = {Springer},
	author = {Ries, Sebastian and Habib, Sheikh Mahbub and Mühlhäuser, Max and Varadharajan, Vijay},
	month = jun,
	year = {2011},
	keywords = {S1peer},
	pages = {254--261}
}

@incollection{weber_multilaterally_2011,
	series = {Studies in {Computational} {Intelligence}},
	title = {Multilaterally {Secure} {Ubiquitous} {Auditing}},
	volume = {329},
	isbn = {978-3-642-16792-8},
	booktitle = {Intelligent {Networking}, {Collaborative} {Systems} and {Applications}},
	publisher = {Springer},
	author = {Weber, Stefan and Mühlhäuser, Max},
	editor = {Caballé, Santi and Xhafa, Fatos and Abraham, Ajith},
	year = {2011},
	keywords = {S1peer},
	pages = {207--233}
}

@inproceedings{classen_distributed_2015,
	title = {A {Distributed} {Reputation} {System} for {Certification} {Authority} {Trust} {Management}},
	booktitle = {Trustcom/{BigDataSE}/{ISPA}},
	publisher = {IEEE},
	author = {Classen, Jiska and Braun, Johannes and Volk, Florian and Hollick, Matthias and Buchmann, Johannes and Mühlhäuser, Max},
	year = {2015},
	keywords = {S1peer},
	pages = {1349--1356}
}

@inproceedings{steinmetzer_lockpicking_2015,
	title = {Lockpicking physical layer key exchange: weak adversary models invite the thief},
	booktitle = {Proceedings of the 8th {ACM} {Conference} on {Security} \& {Privacy} in {Wireless} and {Mobile} {Networks}},
	publisher = {ACM},
	author = {Steinmetzer, Daniel and Schulz, Matthias and Hollick, Matthias},
	year = {2015},
	keywords = {S1peer},
	pages = {1--11}
}

@inproceedings{classen_spy_2015,
	title = {The spy next door: {Eavesdropping} on high throughput visible light communications},
	booktitle = {Proceedings of the 2nd {International} {Workshop} on {Visible} {Light} {Communications} {Systems}},
	publisher = {ACM},
	author = {Classen, Jiska and Chen, Joe and Steinmetzer, Daniel and Hollick, Matthias and Knightly, Edward},
	year = {2015},
	keywords = {S1peer},
	pages = {9--14}
}

@inproceedings{steinmetzer_eavesdropping_2015,
	title = {Eavesdropping with periscopes: {Experimental} security analysis of highly directional millimeter waves},
	booktitle = {Communications and {Network} {Security} ({CNS}), 2015 {IEEE} {Conference} on},
	publisher = {IEEE},
	author = {Steinmetzer, Daniel and Chen, Joe and Classen, Jiska and Knightly, Edward and Hollick, Matthias},
	year = {2015},
	keywords = {S1peer},
	pages = {335--343}
}

@inproceedings{habib_computational_2015,
	title = {Computational trust methods for security quantification in the cloud ecosystem},
	volume = {Syngress/Elsevier},
	booktitle = {The {Cloud} {Security} {Ecosystem}},
	author = {Habib, Sheikh Mahbub and Volk, Florian and Hauke, Sascha and Mühlhäuser, Max},
	year = {2015},
	keywords = {S1peer},
	pages = {463--493}
}

@inproceedings{vigil_lot:_2016,
	title = {{LoT}: a {Reputation}-based {Trust} {System} for {Long}-term {Archiving}},
	booktitle = {{SECURWARE}},
	author = {Vigil, Martın and Demirel, Denise and Habib, Sheikh Mahbub and Hauke, Sascha and Buchmann, Johannes and Mühlhäuser, Max},
	year = {2016},
	keywords = {S1peer},
	pages = {262--270}
}

@inproceedings{traverso_as_2016,
	title = {{AS} 3: {Adaptive} social secret sharing for distributed storage systems},
	booktitle = {Privacy, {Security} and {Trust} ({PST}), 2016 14th {Annual} {Conference} on},
	publisher = {IEEE},
	author = {Traverso, Giulia and Demirel, Denise and Habib, Sheikh Mahbub and Buchmann, Johannes},
	year = {2016},
	keywords = {S1peer},
	pages = {528--535}
}

@inproceedings{fereidooni_breaking_2017,
	title = {Breaking {Fitness} {Records} {Without} {Moving}: {Reverse} {Engineering} and {Spoofing} {Fitbit}},
	booktitle = {International {Symposium} on {Research} in {Attacks}, {Intrusions}, and {Defenses}},
	publisher = {Springer},
	author = {Fereidooni, Hossein and Classen, Jiska and Spink, Tom and Patras, Paul and Miettinen, Markus and Sadeghi, Ahmad-Reza and Hollick, Matthias and Conti, Mauro},
	year = {2017},
	keywords = {S1peer},
	pages = {48--69}
}

@inproceedings{alexopoulos_beyond_2017,
	title = {Beyond the {Hype}: {On} {Using} {Blockchains} in {Trust} {Management} for {Authentication}},
	booktitle = {Proceedings of the 16th {IEEE} {International} {Conference} {On} {Trust}, {Security} {And} {Privacy} {In} {Computing} {And} {Communications} ({IEEE} {TrustCom}-17)},
	publisher = {IEEE},
	author = {Alexopoulos, Nikolaos and Daubert, Jörg and Mühlhäuser, Max and Habib, Sheikh Mahbub},
	year = {2017},
	keywords = {S1peer}
}

@inproceedings{alexopoulos_enhancing_2017,
	title = {On enhancing trust in cryptographic solutions: student research abstract},
	booktitle = {Proceedings of the {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Alexopoulos, Nikolaos},
	year = {2017},
	keywords = {S1peer},
	pages = {1848--1849}
}

@inproceedings{alexopoulos_towards_2017,
	address = {Lucca, Italy},
	title = {Towards {Blockchain}-{Based} {Collaborative} {Intrusion} {Detection} {Systems}},
	booktitle = {International {Conference} on {Critical} {Information} {Infrastructures} {Security}},
	publisher = {Springer},
	author = {Alexopoulos, Nikolaos and Vasilomanolakis, Emmanouil and Ivanko, Natalia Reka and Mühlhäuser, Max},
	month = oct,
	year = {2017},
	keywords = {S1peer}
}

@article{fomichev_survey_2017,
	title = {Survey and {Systematization} of {Secure} {Device} {Pairing}},
	volume = {PP},
	doi = {10.1109/COMST.2017.2748278},
	number = {99},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Fomichev, Mikhail and Alvarez, Flor and Steinmetzer, Daniel and Gardner-Stephen, Paul and Hollick, Matthias},
	year = {2017},
	keywords = {S1peer},
	pages = {1--1}
}

@inproceedings{karuppayah_boobytrap:_2016,
	address = {Kuala Lumpur, Malaysia},
	title = {{BoobyTrap}: {On} {Autonomously} {Detecting} and {Characterizing} {Crawlers} in {P}2P {Botnets}},
	isbn = {978-1-4799-6664-6},
	doi = {10.1109/ICC.2016.7510885},
	booktitle = {{IEEE} {ICC} {Communication} and {Information} {Systems} {Security} {Symposium}},
	publisher = {IEEE},
	author = {Karuppayah, Shankar and Vasilomanolakis, Emmanouil and Haas, Steffen and Fischer, Mathias and Mühlhäuser, Max},
	month = may,
	year = {2016},
	keywords = {S1peer},
	pages = {1--7}
}

@inproceedings{daubert_anonymity_2016,
	address = {Las Vegas, USA},
	title = {On the anonymity of privacy-preserving many-to-many communication in the presence of node churn and attacks},
	doi = {10.1109/CCNC.2016.7444871},
	booktitle = {Proceedings of the 13th {Annual} {IEEE} {Consumer} {Communications} \& {Networking} {Conference} ({CCNC})},
	publisher = {IEEE},
	author = {Daubert, Jörg and Grube, Tim and Fischer, Mathias and Mühlhäuser, Max},
	month = jan,
	year = {2016},
	keywords = {S1peer},
	pages = {738--744}
}

@article{daubert_anonpubsub:_nodate,
	title = {{AnonPubSub}: {Anonymous} {Publish}-{Subscribe} {Overlays}},
	volume = {76},
	journal = {Elsevier Computer Communications ComCom},
	author = {Daubert, Jörg and Fischer, Mathias and Grube, Tim and Schiffner, Stefan and Kikiras, Panayotis and Mühlhäuser, Max}
}

@inproceedings{bock_hide_2015,
	address = {Florence, Italy},
	title = {Hide {And} {Seek}: {Detecting} {Sensors} in {P}2P {Botnets}},
	booktitle = {Communications and {Network} {Security} ({CNS}), 2015 {IEEE} {Conference} on},
	publisher = {IEEE},
	author = {Böck, Leon and Karuppayah, Shankar and Grube, Tim and Fischer, Mathias and Mühlhäuser, Max},
	month = sep,
	year = {2015},
	keywords = {S1peer},
	pages = {731--732}
}

@inproceedings{alexopoulos_mcmix:_2017,
	title = {{MCMix}: {Anonymous} {Messaging} via {Secure} {Multiparty} {Computation}},
	booktitle = {26th {USENIX} {Security} {Symposium}},
	author = {Alexopoulos, Nikolaos and Kiayias, Aggelos and Talviste, Riivo and Zacharias, Thomas},
	month = aug,
	year = {2017},
	keywords = {S1peer}
}

@article{alexopoulos_m-star:_nodate,
	title = {M-{STAR}: {A} {Modular}, {Evidence}-based {Software} {Trustworthiness} {Framework}},
	author = {Alexopoulos, Nikolaos and Habib, Sheikh Mahbub and Schulz, Steffen and Mühlhäuser, Max},
	month = jan
}

@misc{ca_veracode_state_2017,
	title = {State of {Software} {Security} 2017 {\textbar} {Veracode}},
	url = {https://info.veracode.com/report-state-of-software-security.html},
	urldate = {2018-01-02},
	author = {CA Veracode},
	year = {2017},
	keywords = {API misuse, Cryptographic misuse, misuse},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NSX38PGJ\\report-state-of-software-security.html:text/html;State of Software Security 2017  Veracode_CrypographicIussues.üpng.PNG:C\:\\Users\\Anna\\Zotero\\zotero.sqlite:image/png;State of Software Security 2017  Veracode.pdf:C\:\\Users\\Anna\\Documents\\55_Paper\\State of Software Security 2017  Veracode.pdf:application/pdf;vercode17_cryptomisuses.PNG:C\:\\Users\\Anna\\Zotero\\storage\\H57YAU49\\vercode17_cryptomisuses.PNG:image/png}
}

@inproceedings{corrigan-gibbs_recommendations_2015,
	address = {Berkeley, CA, USA},
	series = {{HOTOS}'15},
	title = {Recommendations for {Randomness} in the {Operating} {System} or, {How} to {Keep} {Evil} {Children} out of {Your} {Pool} and {Other} {Random} {Facts}},
	url = {http://dl.acm.org/citation.cfm?id=2831090.2831115},
	abstract = {Common misconceptions about randomness underlie the design and implementation of randomness sources in popular operating systems. We debunk these fallacies with a survey of the "realities of randomness" and derive a number of new architectural principles for OS randomness subsystems.},
	urldate = {2018-01-03},
	booktitle = {Proceedings of the 15th {USENIX} {Conference} on {Hot} {Topics} in {Operating} {Systems}},
	publisher = {USENIX Association},
	author = {Corrigan-Gibbs, Henry and Jana, Suman},
	year = {2015},
	pages = {25--25},
	file = {Corrigan-Gibbs und Jana - 2015 - Recommendations for Randomness in the Operating Sy.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Corrigan-Gibbs und Jana - 2015 - Recommendations for Randomness in the Operating Sy.pdf:application/pdf}
}

@inproceedings{chatzikonstantinou_evaluation_2016,
	address = {ICST, Brussels, Belgium, Belgium},
	series = {{BICT}'15},
	title = {Evaluation of {Cryptography} {Usage} in {Android} {Applications}},
	isbn = {978-1-63190-100-3},
	url = {http://dx.doi.org/10.4108/eai.3-12-2015.2262471},
	doi = {10.4108/eai.3-12-2015.2262471},
	abstract = {Mobile application developers are using cryptography in their products to protect sensitive data like passwords, short messages, documents etc. In this paper, we study whether cryptography and related techniques are employed in a proper way, in order to protect these private data. To this end, we downloaded 49 Android applications from the Google Play marketplace and performed static and dynamic analysis in an attempt to detect possible cryptographic misuses. The results showed that 87.8\% of the applications present some kind of misuse, while for the rest of them no cryptography usage was detected during the analysis. Finally, we suggest countermeasures, mainly intended for developers, to alleviate the issues identified by the analysis.},
	urldate = {2018-01-03},
	booktitle = {Proceedings of the 9th {EAI} {International} {Conference} on {Bio}-inspired {Information} and {Communications} {Technologies} ({Formerly} {BIONETICS})},
	publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
	author = {Chatzikonstantinou, Alexia and Ntantogian, Christoforos and Karopoulos, Georgios and Xenakis, Christos},
	year = {2016},
	keywords = {software security, android, cryptography misuse},
	pages = {83--90},
	file = {Chatzikonstantinou et al. - 2016 - Evaluation of Cryptography Usage in Android Applic.pdf:C\:\\Users\\Anna\\Zotero\\storage\\DGG46HDR\\Chatzikonstantinou et al. - 2016 - Evaluation of Cryptography Usage in Android Applic.pdf:application/pdf}
}

@inproceedings{braga_mining_2016,
	title = {Mining {Cryptography} {Misuse} in {Online} {Forums}},
	doi = {10.1109/QRS-C.2016.23},
	abstract = {This work analyzes cryptography misuse by software developers, from their contributions to online forums on cryptography-based security and cryptographic programming. We studied three popular forums: Oracle Java Cryptography, Google Android Developers, and Google Android Security Discussions. We applied a data mining technique, namely Apriori, to elicit association rules among cryptographic bad practices, platform-specific issues, cryptographic programming tasks, and cryptography-related use cases. We found that, with surprisingly high probabilities (90\% for Java and 71\% for Android), several types of cryptography misuse can be found in the posts, but unfortunately masked by technology-specific issues and programming concerns. We also found that cryptographic bad practices frequently occur in pairs or triples. We related triple associations to use cases and tasks, characterizing worst case scenarios of cryptography misuse. Finally, we observed that hard-to-use architectures confuse developers and contribute to perpetuate recurring errors in cryptographic programming.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Software} {Quality}, {Reliability} and {Security} {Companion} ({QRS}-{C})},
	author = {Braga, A. and Dahab, R.},
	month = aug,
	year = {2016},
	keywords = {Software, Java, data mining, Programming, Android (operating system), cryptography, Encryption, cryptography misuse, Apriori, Apriori algorithm, association rules, Computer architecture, cryptographic programming, cryptography misuse mining, cryptography-based security, Google Android developers, Google Android security discussions, Java cryptographic architecture, online forums, oracle Java cryptography, probabilities, probability, secure coding},
	pages = {143--150},
	file = {Braga und Dahab - 2016 - Mining Cryptography Misuse in Online Forums.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MAVFLVAV\\Braga und Dahab - 2016 - Mining Cryptography Misuse in Online Forums.pdf:application/pdf;Braga2016_cryptoCategories.PNG:C\:\\Users\\Anna\\Pictures\\Braga2016_cryptoCategories.PNG:image/png;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\3U5IR9CM\\7573736.html:text/html}
}

@article{naiakshina_why_2017,
	title = {Why {Do} {Developers} {Get} {Password} {Storage} {Wrong}? {A} {Qualitative} {Usability} {Study}},
	shorttitle = {Why {Do} {Developers} {Get} {Password} {Storage} {Wrong}?},
	url = {http://arxiv.org/abs/1708.08759},
	doi = {10.1145/3133956.3134082},
	abstract = {Passwords are still a mainstay of various security systems, as well as the cause of many usability issues. For end-users, many of these issues have been studied extensively, highlighting problems and informing design decisions for better policies and motivating research into alternatives. However, end-users are not the only ones who have usability problems with passwords! Developers who are tasked with writing the code by which passwords are stored must do so securely. Yet history has shown that this complex task often fails due to human error with catastrophic results. While an end-user who selects a bad password can have dire consequences, the consequences of a developer who forgets to hash and salt a password database can lead to far larger problems. In this paper we present a first qualitative usability study with 20 computer science students to discover how developers deal with password storage and to inform research into aiding developers in the creation of secure password systems.},
	urldate = {2018-01-03},
	journal = {arXiv:1708.08759 [cs]},
	author = {Naiakshina, Alena and Danilova, Anastasia and Tiefenau, Christian and Herzog, Marco and Dechand, Sergej and Smith, Matthew},
	year = {2017},
	note = {arXiv: 1708.08759},
	keywords = {Computer Science - Cryptography and Security},
	pages = {311--328},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZM5N9MIH\\1708.html:text/html;Naiakshina et al. - 2017 - Why Do Developers Get Password Storage Wrong A Qu.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TZRQGETS\\Naiakshina et al. - 2017 - Why Do Developers Get Password Storage Wrong A Qu.pdf:application/pdf}
}

@inproceedings{pradel_detecting_2011,
	address = {New York, NY, USA},
	series = {{ISSTA} '11},
	title = {Detecting {Anomalies} in the {Order} of {Equally}-typed {Method} {Arguments}},
	isbn = {978-1-4503-0562-4},
	url = {http://doi.acm.org/10.1145/2001420.2001448},
	doi = {10.1145/2001420.2001448},
	abstract = {In statically-typed programming languages, the compiler ensures that method arguments are passed in the expected order by checking the type of each argument. However, calls to methods with multiple equally-typed parameters slip through this check. The uncertainty about the correct argument order of equally-typed arguments can cause various problems, for example, if a programmer accidentally reverses two arguments. We present an automated, static program analysis that detects such problems without any input except for the source code of a program. The analysis leverages the observation that programmer-given identifier names convey information about the semantics of arguments, which can be used to assign equally-typed arguments to their expected position. We evaluate the approach with a large corpus of Java programs and show that our analysis finds relevant anomalies with a precision of 76\%.},
	urldate = {2018-01-04},
	booktitle = {Proceedings of the 2011 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Pradel, Michael and Gross, Thomas R.},
	year = {2011},
	keywords = {static analysis, anomaly detection, automated program analysis, maintenance, method arguments},
	pages = {232--242},
	file = {Pradel and Gross - 2011 - Detecting Anomalies in the Order of Equally-typed .pdf:C\:\\Users\\Anna\\Zotero\\storage\\9AEEKH8N\\Pradel and Gross - 2011 - Detecting Anomalies in the Order of Equally-typed .pdf:application/pdf}
}

@inproceedings{pradel_static_2012,
	address = {New York, NY, USA},
	series = {{ISSTA} 2012},
	title = {Static {Detection} of {Brittle} {Parameter} {Typing}},
	isbn = {978-1-4503-1454-1},
	url = {http://doi.acm.org/10.1145/2338965.2336785},
	doi = {10.1145/2338965.2336785},
	abstract = {To avoid receiving incorrect arguments, a method specifies the expected type of each formal parameter. However, some parameter types are too general and have subtypes that the method does not expect as actual argument types. For example, this may happen if there is no common supertype that precisely describes all expected types. As a result of such brittle parameter typing, a caller may accidentally pass arguments unexpected by the callee without any warnings from the type system. This paper presents a fully automatic, static analysis to find brittle parameter typing and unexpected arguments given to brittle parameters. First, the analysis infers from callers of a method the types that arguments commonly have. Then, the analysis reports potentially unexpected arguments that stand out by having an unusual type. We apply the approach to 21 real-world Java programs that use the Swing API, an API providing various methods with brittle parameters. The analysis reveals 15 previously unknown bugs and code smells where programmers pass arguments that are compatible with the declared parameter type but nevertheless unexpected by the callee. The warnings reported by the analysis have 47\% precision and 83\% recall.},
	urldate = {2018-01-04},
	booktitle = {Proceedings of the 2012 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Pradel, Michael and Heiniger, Severin and Gross, Thomas R.},
	year = {2012},
	pages = {265--275},
	file = {Pradel et al. - 2012 - Static Detection of Brittle Parameter Typing.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9UAEYKD8\\Pradel et al. - 2012 - Static Detection of Brittle Parameter Typing.pdf:application/pdf}
}

@inproceedings{nguyen_graph-based_2015,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '15},
	title = {Graph-based {Statistical} {Language} {Model} for {Code}},
	isbn = {978-1-4799-1934-5},
	url = {http://dl.acm.org/citation.cfm?id=2818754.2818858},
	abstract = {n-gram statistical language model has been successfully applied to capture programming patterns to support code completion and suggestion. However, the approaches using n-gram face challenges in capturing the patterns at higher levels of abstraction due to the mismatch between the sequence nature in n-grams and the structure nature of syntax and semantics in source code. This paper presents GraLan, a graph-based statistical language model and its application in code suggestion. GraLan can learn from a source code corpus and compute the appearance probabilities of any graphs given the observed (sub)graphs. We use GraLan to develop an API suggestion engine and an AST-based language model, ASTLan. ASTLan supports the suggestion of the next valid syntactic template and the detection of common syntactic templates. Our empirical evaluation on a large corpus of open-source projects has shown that our engine is more accurate in API code suggestion than the state-of-the-art approaches, and in 75\% of the cases, it can correctly suggest the API with only five candidates. ASTLan also has high accuracy in suggesting the next syntactic template and is able to detect many useful and common syntactic templates.},
	urldate = {2018-01-05},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Software} {Engineering} - {Volume} 1},
	publisher = {IEEE Press},
	author = {Nguyen, Anh Tuan and Nguyen, Tien N.},
	year = {2015},
	pages = {858--868},
	file = {Nguyen and Nguyen - 2015 - Graph-based Statistical Language Model for Code.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XX9AR6IR\\Nguyen and Nguyen - 2015 - Graph-based Statistical Language Model for Code.pdf:application/pdf}
}

@inproceedings{pradel_leveraging_2012,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '12},
	title = {Leveraging {Test} {Generation} and {Specification} {Mining} for {Automated} {Bug} {Detection} {Without} {False} {Positives}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337258},
	abstract = {Mining specifications and using them for bug detection is a promising way to reveal bugs in programs. Existing approaches suffer from two problems. First, dynamic specification miners require input that drives a program to generate common usage patterns. Second, existing approaches report false positives, that is, spurious warnings that mislead developers and reduce the practicability of the approach. We present a novel technique for dynamically mining and checking specifications without relying on existing input to drive a program and without reporting false positives. Our technique leverages automatically generated tests in two ways: Passing tests drive the program during specification mining, and failing test executions are checked against the mined specifications. The output are warnings that show with concrete test cases how the program violates commonly accepted specifications. Our implementation reports no false positives and 54 true positives in ten well-tested Java programs.},
	urldate = {2018-01-05},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Pradel, Michael and Gross, Thomas R.},
	year = {2012},
	pages = {288--298},
	file = {Pradel und Gross - 2012 - Leveraging Test Generation and Specification Minin.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Q9DCZED3\\Pradel und Gross - 2012 - Leveraging Test Generation and Specification Minin.pdf:application/pdf}
}

@article{azad_generating_2017,
	title = {Generating {API} {Call} {Rules} from {Version} {History} and {Stack} {Overflow} {Posts}},
	volume = {25},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/2990497},
	doi = {10.1145/2990497},
	abstract = {Researchers have shown that related functions can be mined from groupings of functions found in the version history of a system. Our first contribution is to expand this approach to a community of applications and set of similar applications. Android developers use a set of application programming interface (API) calls when creating apps. These API calls are used in similar ways across multiple applications. By clustering co-changing API calls used by 230 Android apps across 12k versions, we are able to predict the API calls that individual app developers will use with an average precision of 75\% and recall of 22\%. When we make predictions from the same category of app, such as Finance, we attain precision and recall of 81\% and 28\%, respectively. Our second contribution can be characterized as “programmers who discussed these functions were also interested in these functions.” Informal discussions on Stack Overflow provide a rich source of information about related API calls as developers provide solutions to common problems. By grouping API calls contained in each positively voted answer posts, we are able to create rules that predict the calls that app developers will use in their own apps with an average precision of 66\% and recall of 13\%. For comparison purposes, we developed a baseline by clustering co-changing API calls for each individual app and generated association rules from them. The baseline predicts API calls used by app developers with a precision and recall of 36\% and 23\%, respectively.},
	number = {4},
	urldate = {2018-01-05},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Azad, Shams and Rigby, Peter C. and Guerrouj, Latifa},
	month = jan,
	year = {2017},
	keywords = {Stack Overflow, API method calls, association rule mining, community of applications, informal documentation, version history},
	pages = {29:1--29:22},
	file = {Azad et al. - 2017 - Generating API Call Rules from Version History and.pdf:C\:\\Users\\Anna\\Zotero\\storage\\REHJNE6U\\Azad et al. - 2017 - Generating API Call Rules from Version History and.pdf:application/pdf}
}

@inproceedings{murali_bayesian_2017,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2017},
	title = {Bayesian {Specification} {Learning} for {Finding} {API} {Usage} {Errors}},
	isbn = {978-1-4503-5105-8},
	url = {http://doi.acm.org/10.1145/3106237.3106284},
	doi = {10.1145/3106237.3106284},
	abstract = {We present a Bayesian framework for learning probabilistic specifications from large, unstructured code corpora, and then using these specifications to statically detect anomalous, hence likely buggy, program behavior. Our key insight is to build a statistical model that correlates all specifications hidden inside a corpus with the syntax and observed behavior of programs that implement these specifications. During the analysis of a particular program, this model is conditioned into a posterior distribution that prioritizes specifications that are relevant to the program. The problem of finding anomalies is now framed quantitatively, as a problem of computing a distance between a "reference distribution" over program behaviors that our model expects from the program, and the distribution over behaviors that the program actually produces.   We implement our ideas in a system, called Salento, for finding anomalous API usage in Android programs. Salento learns specifications using a combination of a topic model and a neural network model. Our encouraging experimental results show that the system can automatically discover subtle errors in Android applications in the wild, and has high precision and recall compared to competing probabilistic approaches.},
	urldate = {2018-01-05},
	booktitle = {Proceedings of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Murali, Vijayaraghavan and Chaudhuri, Swarat and Jermaine, Chris},
	year = {2017},
	keywords = {Anomaly Detection, APIs, Bug Finding, Specification Learning},
	pages = {151--162},
	file = {Murali et al. - 2017 - Bayesian Specification Learning for Finding API Us.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Y45ZUGUR\\Murali et al. - 2017 - Bayesian Specification Learning for Finding API Us.pdf:application/pdf}
}

@inproceedings{nguyen_mining_2014,
	address = {New York, NY, USA},
	series = {{FSE} 2014},
	title = {Mining {Preconditions} of {APIs} in {Large}-scale {Code} {Corpus}},
	isbn = {978-1-4503-3056-5},
	url = {http://doi.acm.org/10.1145/2635868.2635924},
	doi = {10.1145/2635868.2635924},
	abstract = {Modern software relies on existing application programming interfaces (APIs) from libraries. Formal specifications for the APIs enable many software engineering tasks as well as help developers correctly use them. In this work, we mine large-scale repositories of existing open-source software to derive potential preconditions for API methods. Our key idea is that APIs’ preconditions would appear frequently in an ultra-large code corpus with a large number of API usages, while project-specific conditions will occur less frequently. First, we find all client methods invoking APIs. We then compute a control dependence relation from each call site and mine the potential conditions used to reach those call sites. We use these guard conditions as a starting point to automatically infer the preconditions for each API. We analyzed almost 120 million lines of code from SourceForge and Apache projects to infer preconditions for the standard Java Development Kit (JDK) library. The results show that our technique can achieve high accuracy with recall from 75–80\% and precision from 82–84\%. We also found 5 preconditions missing from human written specifications. They were all confirmed by a specification expert. In a user study, participants found 82\% of the mined preconditions as a good starting point for writing specifications. Using our mining result, we also built a benchmark of more than 4,000 precondition-related bugs.},
	urldate = {2018-01-08},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Nguyen, Hoan Anh and Dyer, Robert and Nguyen, Tien N. and Rajan, Hridesh},
	year = {2014},
	keywords = {Big Code Mining, JML, Preconditions, Specification Mining},
	pages = {166--177},
	file = {Nguyen et al. - 2014 - Mining Preconditions of APIs in Large-scale Code C.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JJMTZWH3\\Nguyen et al. - 2014 - Mining Preconditions of APIs in Large-scale Code C.pdf:application/pdf}
}

@misc{noauthor_checking_nodate,
	title = {Checking {Applications} using {Security} {APIs} with {JOANA} - {Google}-{Suche}},
	url = {https://www.google.de/search?q=Checking+Applications+using+Security+APIs+with+JOANA&ie=utf-8&oe=utf-8&client=firefox-b-ab&gfe_rd=cr&dcr=0&ei=yZZTWtPmGqistgfpxbnIBw},
	urldate = {2018-01-08},
	file = {Checking Applications using Security APIs with JOANA - Google-Suche:C\:\\Users\\Anna\\Zotero\\storage\\YJHMSDE3\\search.html:text/html}
}

@inproceedings{graf_checking_2015,
	title = {Checking {Applications} using {Security} {APIs} with {JOANA}},
	url = {http://www.dsi.unive.it/ focardi/ASA8/},
	author = {Graf, Jürgen and Hecker, Martin and Mohr, Martin and Snelting, Gregor},
	month = jul,
	year = {2015},
	file = {Graf et al. - 2015 - Checking Applications using Security APIs with JOA.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Graf et al. - 2015 - Checking Applications using Security APIs with JOA.pdf:application/pdf}
}

@inproceedings{rigby_discovering_2013,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '13},
	title = {Discovering {Essential} {Code} {Elements} in {Informal} {Documentation}},
	isbn = {978-1-4673-3076-3},
	url = {http://dl.acm.org/citation.cfm?id=2486788.2486897},
	abstract = {To access the knowledge contained in developer communication, such as forum posts, it is useful to determine automatically the code elements referred to in the discussions. We propose a novel traceability recovery approach to extract the code elements contained in various documents. As opposed to previous work, our approach does not require an index of code elements to find links, which makes it particularly well-suited for the analysis of informal documentation. When evaluated on 188 StackOverflow answer posts containing 993 code elements, the technique performs with average 0.92 precision and 0.90 recall. As a major refinement on traditional traceability approaches, we also propose to detect which of the code elements in a document are salient, or germane, to the topic of the post. To this end we developed a three-feature decision tree classifier that performs with a precision of 0.65-0.74 and recall of 0.30-0.65, depending on the subject of the document.},
	urldate = {2018-01-09},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Rigby, Peter C. and Robillard, Martin P.},
	year = {2013},
	pages = {832--841},
	file = {Rigby and Robillard - 2013 - Discovering Essential Code Elements in Informal Do.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JGYI8QTC\\Rigby and Robillard - 2013 - Discovering Essential Code Elements in Informal Do.pdf:application/pdf}
}

@inproceedings{anderson_why_1993,
	address = {New York, NY, USA},
	series = {{CCS} '93},
	title = {Why {Cryptosystems} {Fail}},
	isbn = {978-0-89791-629-5},
	url = {http://doi.acm.org/10.1145/168588.168615},
	doi = {10.1145/168588.168615},
	abstract = {Designers of cryptographic systems are at a disadvantage to most other engineers, in that information on how their systems fail is hard to get: their major users have traditionally been government agencies, which are very secretive about their mistakes.In this article, we present the results of a survey of the failure modes of retail banking systems, which constitute the next largest application of cryptology. It turns out that the threat model commonly used by cryptosystem designers was wrong: most frauds were not caused by cryptanalysis or other technical attacks, but by implementation errors and management failures. This suggests that a paradigm shift is overdue in computer security; we look at some of the alternatives, and see some signs that this shift may be getting under way.},
	urldate = {2018-01-10},
	booktitle = {Proceedings of the 1st {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Anderson, Ross},
	year = {1993},
	keywords = {to read},
	pages = {215--227},
	file = {Anderson - 1993 - Why Cryptosystems Fail.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UVGDE34S\\Anderson - 1993 - Why Cryptosystems Fail.pdf:application/pdf;wcf.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5Q6N686L\\wcf.pdf:application/pdf}
}

@inproceedings{hoffmann_slicing_2013,
	title = {Slicing droids: {Program} slicing for smali code},
	shorttitle = {Slicing droids},
	doi = {10.1145/2480362.2480706},
	abstract = {The popularity of mobile devices like smartphones and tablets has increased significantly in the last few years with many millions of sold devices. This growth also has its drawbacks: attackers have realized that smartphones are an attractive target and in the last months many different kinds of malicious software (short: malware) for such devices have emerged. This worrisome development has the potential to hamper the prospering ecosystem of mobile devices and the potential for damage is huge.
Considering these aspects, it is evident that malicious apps need to be detected early on in order to prevent further distribution and infections. This implies that it is necessary to develop techniques capable of detecting malicious apps in an automated way. In this paper, we present SAAF, a Static Android Analysis Framework for Android apps. SAAF analyzes smali code, a disassembled version of the DEX format used by Android's Java VM implementation. Our goal is to create program slices in order to perform data-flow analyses to backtrack parameters used by a given method. This helps us to identify suspicious code regions in an automated way. Several other analysis techniques such as visualization of control flow graphs or identification of ad-related code are also implemented in SAAF. In this paper, we report on program slicing for Android and present results obtained by using this technique to analyze more than 136,000 benign and about 6,100 malicious apps.},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Applied} {Computing}},
	author = {Hoffmann, Johannes and Ussath, Martin and Holz, Thorsten and Spreitzenbarth, Michael},
	month = mar,
	year = {2013},
	pages = {1844--1851},
	file = {Hoffmann et al. - 2013 - Slicing droids Program slicing for smali code.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Hoffmann et al. - 2013 - Slicing droids Program slicing for smali code.pdf:application/pdf}
}

@article{markovtsev_topic_2017,
	title = {Topic modeling of public repositories at scale using names in source code},
	url = {http://arxiv.org/abs/1704.00135},
	abstract = {Programming languages themselves have a limited number of reserved keywords and character based tokens that define the language specification. However, programmers have a rich use of natural language within their code through comments, text literals and naming entities. The programmer defined names that can be found in source code are a rich source of information to build a high level understanding of the project. The goal of this paper is to apply topic modeling to names used in over 13.6 million repositories and perceive the inferred topics. One of the problems in such a study is the occurrence of duplicate repositories not officially marked as forks (obscure forks). We show how to address it using the same identifiers which are extracted for topic modeling. We open with a discussion on naming in source code, we then elaborate on our approach to remove exact duplicate and fuzzy duplicate repositories using Locality Sensitive Hashing on the bag-of-words model and then discuss our work on topic modeling; and finally present the results from our data analysis together with open-access to the source code, tools and datasets.},
	urldate = {2018-01-29},
	journal = {arXiv:1704.00135 [cs]},
	author = {Markovtsev, Vadim and Kant, Eiso},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.00135},
	keywords = {Computer Science - Computation and Language, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\M6GKQI7B\\1704.html:text/html;Markovtsev und Kant - 2017 - Topic modeling of public repositories at scale usi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\FPFWDW8M\\Markovtsev und Kant - 2017 - Topic modeling of public repositories at scale usi.pdf:application/pdf}
}

@incollection{floyd_acm_2007,
	address = {New York, NY, USA},
	title = {{ACM} {Turing} {Award} {Lectures}},
	isbn = {978-1-4503-1049-9},
	url = {http://doi.acm.org/10.1145/1283920.1283934},
	urldate = {2018-01-29},
	publisher = {ACM},
	author = {Floyd, Robert W.},
	year = {2007},
	doi = {10.1145/1283920.1283934},
	keywords = {MACLISP, MYCIN program},
	file = {Floyd - 2007 - ACM Turing Award Lectures.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KU5W3Z4L\\Floyd - 2007 - ACM Turing Award Lectures.pdf:application/pdf}
}

@inproceedings{herzig_capturing_2010,
	address = {Cape Town, South Africa},
	title = {Capturing the {Long}-{Term} {Impact} of {Changes}},
	isbn = {978-1-60558-719-6},
	doi = {10.1145/1810295.1810401},
	booktitle = {{ICSE} '10: {Proceedings} of the 32nd {ACM}/{IEEE} {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Herzig, Kim},
	month = may,
	year = {2010},
	pages = {393--396},
	file = {Herzig - 2010 - Capturing the Long-Term Impact of Changes.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Herzig - 2010 - Capturing the Long-Term Impact of Changes.pdf:application/pdf}
}

@phdthesis{herzig_mining_2012,
	address = {D–66123 Saarland, Germany},
	type = {{PhD} {Thesis}},
	title = {Mining and {Untangling} {Change} {Genealogies}},
	school = {Universität des Saarlandes},
	author = {Herzig, Kim},
	month = dec,
	year = {2012},
	file = {Herzig - 2012 - Mining and Untangling Change Genealogies.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Herzig - 2012 - Mining and Untangling Change Genealogies.pdf:application/pdf}
}

@inproceedings{neuhaus_predicting_2007,
	address = {New York, NY, USA},
	series = {{CCS} '07},
	title = {Predicting {Vulnerable} {Software} {Components}},
	isbn = {978-1-59593-703-2},
	url = {http://doi.acm.org/10.1145/1315245.1315311},
	doi = {10.1145/1315245.1315311},
	abstract = {Where do most vulnerabilities occur in software? Our Vulture tool automatically mines existing vulnerability databases and version archives to map past vulnerabilities to components. The resulting ranking of the most vulnerable components is a perfect base for further investigations on what makes components vulnerable. In an investigation of the Mozilla vulnerability history, we surprisingly found that components that had a single vulnerability in the past were generally not likely to have further vulnerabilities. However, components that had similar imports or function calls were likely to be vulnerable. Based on this observation, we were able to extend Vulture by a simple predictor that correctly predicts about half of all vulnerable components, and about two thirds of all predictions are correct. This allows developers and project managers to focus their their efforts where it is needed most: "We should look at nsXPInstallManager because it is likely to contain yet unknown vulnerabilities.".},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the 14th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Neuhaus, Stephan and Zimmermann, Thomas and Holler, Christian and Zeller, Andreas},
	year = {2007},
	keywords = {software security, prediction},
	pages = {529--540},
	file = {Neuhaus et al. - 2007 - Predicting Vulnerable Software Components.pdf:C\:\\Users\\Anna\\Zotero\\storage\\23UY73HV\\Neuhaus et al. - 2007 - Predicting Vulnerable Software Components.pdf:application/pdf}
}

@mastersthesis{ravichandran_comprehensive_2017,
	address = {Darmstadt},
	title = {Comprehensive {Security} {Benchmark} for {Java} {Projects}},
	abstract = {With the growing popularity of Java in all walks of life and with the ever increasing number of applications being developed using Java, the security of these applications assume a very high level of importance. Developers tend to unwittingly, unknowingly introduce many bugs and security vulnerabilities into the code. As the applications are vulnerable to attacks, stored and processed data are under threat. Existing literature indicates these vulnerabilities can be identified using certain tools and mechanisms. Such tools are very effective in improving the security of data. However new refined techniques are constantly developed by malicious attackers to exploit the weaknesses in the code or from the libraries or frameworks used by the applications. A corpus of Java applications that could be used as a benchmark framework would assist in detecting and in turn preventing security vulnerabilities in the source code. The corpus could be analysed by static analysis researchers to understand the nature of these security vulnerabilities. In this thesis we present a new corpus of security benchmark Java applications called Securibench++ is presented. A classification of the types of Java applications has also been attempted in this research.},
	school = {Technische Universität Darmstadt},
	author = {Ravichandran, Manikandan},
	month = nov,
	year = {2017},
	file = {Ravichandran - 2017 - Comprehensive Security Benchmark for Java Projects.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Ravichandran - 2017 - Comprehensive Security Benchmark for Java Projects.pdf:application/pdf}
}

@inproceedings{al_omran_choosing_2017,
	title = {Choosing an {NLP} library for analyzing software documentation: a systematic literature review and a series of experiments},
	shorttitle = {Choosing an {NLP} library for analyzing software documentation},
	abstract = {To  uncover  interesting  and  actionable  information
from natural language documents authored by software develop-
ers,  many  researchers  rely  on  “out-of-the-box”  NLP  libraries.
However,   software   artifacts   written   in   natural   language   are
different  from  other  textual  documents  due  to  the  technical
language  used.  In  this  paper,  we  first  analyze  the  state  of  the
art through a systematic literature review in which we find that
only  a  small  minority  of  papers  justify  their  choice  of  an  NLP
library.  We  then  report  on  a  series  of  experiments  in  which  we
applied  four  state-of-the-art  NLP  libraries  to  publicly  available
software artifacts from three different sources. Our results show
low agreement between different libraries (only between 60\% and
71\%  of  tokens  were  assigned  the  same  part-of-speech  tag  by  all
four  libraries)  as  well  as  differences  in  accuracy  depending  on
source: For example, spaCy achieved the best accuracy on Stack
Overflow data with nearly 90\% of tokens tagged correctly, while
it was clearly outperformed by Google’s SyntaxNet when parsing
GitHub ReadMe files. Our work implies that researchers should
make an informed decision about the particular NLP library they
choose  and  that  customizations  to  libraries  might  be  necessary
to achieve good results when analyzing software artifacts written
in  natural  language.},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Al Omran, Fouad Nasser A. and Treude, Christoph},
	year = {2017},
	keywords = {natural language processing, part-of-speech tagging, NLP libraries, software documentation},
	pages = {187--197},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\7HTM2DSV\\Omran und Treude - 2017 - Choosing an NLP Library for Analyzing Software Doc.pdf:application/pdf;Al Omran und Treude - 2017 - Choosing an NLP library for analyzing software doc.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Z7PGI4IL\\Al Omran und Treude - 2017 - Choosing an NLP library for analyzing software doc.pdf:application/pdf}
}

@inproceedings{petrosyan_discovering_2015,
	title = {Discovering {Information} {Explaining} {API} {Types} {Using} {Text} {Classification}},
	volume = {1},
	doi = {10.1109/ICSE.2015.97},
	abstract = {Many software development tasks require developers to quickly learn a subset of an Application Programming Interface (API). API learning resources are crucial for helping developers learn an API, but the knowledge relevant to a particular topic of interest may easily be scattered across different documents, which makes finding the necessary information more challenging. This paper proposes an approach to discovering tutorial sections that explain a given API type. At the core of our approach, we classify fragmented tutorial sections using supervised text classification based on linguistic and structural features. Experiments conducted on five tutorials show that our approach is able to discover sections explaining an API type with precision between 0.69 and 0.87 (depending on the tutorial) when trained and tested on the same tutorial. When trained and tested across tutorials, we obtained a precision between 0.74 and 0.94 and lower recall values.},
	booktitle = {2015 {IEEE}/{ACM} 37th {IEEE} {International} {Conference} on {Software} {Engineering}},
	author = {Petrosyan, G. and Robillard, M. P. and Mori, R. De},
	month = may,
	year = {2015},
	keywords = {Libraries, learning (artificial intelligence), Java, Programming, pattern classification, software engineering, application program interfaces, API, application programming interface, Documentation, Feature extraction, HTML, linguistic feature, software development, structural feature, supervised text classification, text analysis, Tutorials},
	pages = {869--879},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\CPXLLYSU\\7194633.html:text/html;Petrosyan et al. - 2015 - Discovering Information Explaining API Types Using.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MNIF8QP7\\Petrosyan et al. - 2015 - Discovering Information Explaining API Types Using.pdf:application/pdf}
}

@inproceedings{tian_comparative_2015,
	title = {A comparative study on the effectiveness of part-of-speech tagging techniques on bug reports},
	doi = {10.1109/SANER.2015.7081879},
	abstract = {Many software artifacts are written in natural language or contain substantial amount of natural language contents. Thus these artifacts could be analyzed using text analysis techniques from the natural language processing (NLP) community, e.g., the part-of-speech (POS) tagging technique that assigns POS tags (e.g., verb, noun, etc.) to words in a sentence. In the literature, several studies have already applied POS tagging technique on software artifacts to recover important words in them, which are then used for automating various tasks, e.g., locating buggy files for a given bug report, etc. There are many POS tagging techniques proposed and they are trained and evaluated on non software engineering corpus (documents). Thus it is unknown whether they can correctly identify the POS of a word in a software artifact and which of them performs the best. To fill this gap, in this work, we investigate the effectiveness of seven POS taggers on bug reports. We randomly sample 100 bug reports from Eclipse and Mozilla project and create a text corpus that contains 21,713 words. We manually assign POS tags to these words and use them to evaluate the studied POS taggers. Our comparative study shows that the state-of-the-art POS taggers achieve an accuracy of 83.6\%-90.5\% on bug reports and the Stanford POS tagger and the TreeTagger achieve the highest accuracy on the sampled bug reports. Our findings show that researchers could use these POS taggers to analyze software artifacts, if an accuracy of 80-90\% is acceptable for their specific needs, and we recommend using the Stanford POS tagger or the TreeTagger.},
	booktitle = {2015 {IEEE} 22nd {International} {Conference} on {Software} {Analysis}, {Evolution}, and {Reengineering} ({SANER})},
	author = {Tian, Y. and Lo, D.},
	month = mar,
	year = {2015},
	keywords = {program debugging, Software, Software engineering, text analysis, Accuracy, bug report, buggy files, Eclipse project, Hidden Markov models, Mozilla project, natural language processing, Natural languages, NLP community, part-of-speech tagging technique, POS tagging technique, software artifacts, stanford POS tagger, Tagging, text analysis techniques, text corpus, Training, TreeTagger},
	pages = {570--574},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\8F888DR5\\7081879.html:text/html;Tian und Lo - 2015 - A comparative study on the effectiveness of part-o.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Tian und Lo - 2015 - A comparative study on the effectiveness of part-o.pdf:application/pdf}
}

@misc{noauthor_comparative_nodate,
	title = {A comparative study on the effectiveness of part-of-speech tagging techniques on bug reports - {IEEE} {Conference} {Publication}},
	url = {http://ieeexplore.ieee.org/document/7081879/},
	urldate = {2018-01-30},
	file = {A comparative study on the effectiveness of part-of-speech tagging techniques on bug reports - IEEE Conference Publication:C\:\\Users\\Anna\\Zotero\\storage\\D3DHHRVE\\7081879.html:text/html}
}

@inproceedings{treude_understanding_2017,
	title = {Understanding stack overflow code fragments},
	booktitle = {Software {Maintenance} and {Evolution} ({ICSME}), 2017 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Treude, Christoph and Robillard, Martin P.},
	year = {2017},
	pages = {509--513},
	file = {Treude und Robillard - 2017 - Understanding stack overflow code fragments.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7RRYQ79W\\Treude und Robillard - 2017 - Understanding stack overflow code fragments.pdf:application/pdf}
}

@inproceedings{pascarella_classifying_2017,
	title = {Classifying {Code} {Comments} in {Java} {Open}-{Source} {Software} {Systems}},
	doi = {10.1109/MSR.2017.63},
	abstract = {Code comments are a key software component containing information about the underlying implementation. Several studies have shown that code comments enhance the readability of the code. Nevertheless, not all the comments have the same goal and target audience. In this paper, we investigate how six diverse Java OSS projects use code comments, with the aim of understanding their purpose. Through our analysis, we produce a taxonomy of source code comments, subsequently, we investigate how often each category occur by manually classifying more than 2,000 code comments from the aforementioned projects. In addition, we conduct an initial evaluation on how to automatically classify code comments at line level into our taxonomy using machine learning, initial results are promising and suggest that an accurate classification is within reach.},
	booktitle = {2017 {IEEE}/{ACM} 14th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Pascarella, L. and Bacchelli, A.},
	month = may,
	year = {2017},
	keywords = {Maintenance engineering, public domain software, source code (software), learning (artificial intelligence), Java, Google, pattern classification, Measurement, to read, automatic code comment classification, comment taxonomy, Java OSS projects, line level, machine learning, object-oriented programming, Open source software, software component, software quality, source code comments, Taxonomy},
	pages = {227--237},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\IYEKJTW7\\7962372.html:text/html;Pascarella und Bacchelli - 2017 - Classifying Code Comments in Java Open-Source Soft.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Pascarella und Bacchelli - 2017 - Classifying Code Comments in Java Open-Source Soft.pdf:application/pdf}
}

@inproceedings{molderez_mining_2017,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '17},
	title = {Mining {Change} {Histories} for {Unknown} {Systematic} {Edits}},
	isbn = {978-1-5386-1544-7},
	url = {https://doi.org/10.1109/MSR.2017.12},
	doi = {10.1109/MSR.2017.12},
	abstract = {Software developers often need to repeat similar modifications in multiple different locations of a system's source code. These repeated similar modifications, or systematic edits, can be both tedious and error-prone to perform manually. While there are tools that can be used to assist in automating systematic edits, it is not straightforward to find out where the occurrences of a systematic edit are located in an existing system. This knowledge is valuable to help decide whether refactoring is needed, or whether future occurrences of an existing systematic edit should be automated. In this paper, we tackle the problem of finding unknown systematic edits using a closed frequent itemset mining algorithm, operating on sets of distilled source code changes. This approach has been implemented for Java programs in a tool called SysEdMiner. To evaluate the tool's precision and scalability, we have applied it to an industrial use case.},
	urldate = {2018-01-30},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Molderez, Tim and Stevens, Reinout and De Roover, Coen},
	year = {2017},
	keywords = {change distilling, frequent itemset mining, systematic edits},
	pages = {248--256},
	file = {Molderez et al. - 2017 - Mining Change Histories for Unknown Systematic Edi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\T4CGWCPJ\\Molderez et al. - 2017 - Mining Change Histories for Unknown Systematic Edi.pdf:application/pdf}
}

@inproceedings{chowdhury_mining_2015,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '15},
	title = {Mining {StackOverflow} to {Filter} out {Off}-topic {IRC} {Discussion}},
	isbn = {978-0-7695-5594-2},
	url = {http://dl.acm.org/citation.cfm?id=2820518.2820577},
	abstract = {Internet Relay Chat (IRC) is a commonly used tool by OpenSource developers. Developers use IRC channels to discuss programming related problems, but much of the discussion is irrelevant and off-topic. Essentially if we treat IRC discussions like email messages, and apply spam filtering, we can try to filter out the spam (the off-topic discussions) from the ham (the programming discussions). Yet we need labelled data that unfortunately takes time to curate. To avoid costly curration in order to filter out off-topic discussions, we need positive and negative data-sources. Online discussion forums, such as StackOverflow, are very effective for solving programming problems. By engaging in open-data, StackOverflow data becomes a powerful source of labelled text regarding programming. This work shows that we can train classifiers using StackOverflow posts as positive examples of on-topic programming discussion. YouTube video comments, notorious for their lack of quality, serve as training set of off-topic discussion. By exploiting these datasets, accurate classifiers can be built, tested and evaluated that require very little effort for end-users to deploy and exploit.},
	urldate = {2018-01-30},
	booktitle = {Proceedings of the 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Chowdhury, Shaiful Alam and Hindle, Abram},
	year = {2015},
	pages = {422--425},
	file = {Chowdhury und Hindle - 2015 - Mining StackOverflow to Filter out Off-topic IRC D.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NHH2JSMJ\\Chowdhury und Hindle - 2015 - Mining StackOverflow to Filter out Off-topic IRC D.pdf:application/pdf}
}

@inproceedings{weiss_how_2007,
	address = {Washington, DC, USA},
	series = {{MSR} '07},
	title = {How {Long} {Will} {It} {Take} to {Fix} {This} {Bug}?},
	isbn = {978-0-7695-2950-9},
	url = {http://dx.doi.org/10.1109/MSR.2007.13},
	doi = {10.1109/MSR.2007.13},
	abstract = {Predicting the time and effort for a software problem has long been a difficult task. We present an approach that automatically predicts the fixing effort, i.e., the person-hours spent on fixing an issue. Our technique leverages existing issue tracking systems: given a new issue report, we use the Lucene framework to search for similar, earlier reports and use their average time as a prediction. Our approach thus allows for early effort estimation, helping in assigning issues and scheduling stable releases. We evaluated our approach using effort data from the JBoss project. Given a sufficient number of issues reports, our automatic predictions are close to the actual effort; for issues that are bugs, we are off by only one hour, beating na¨ýve predictions by a factor of four.},
	urldate = {2018-01-30},
	booktitle = {Proceedings of the {Fourth} {International} {Workshop} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Computer Society},
	author = {Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
	year = {2007},
	pages = {1--},
	file = {Weiss et al. - 2007 - How Long Will It Take to Fix This Bug.pdf:C\:\\Users\\Anna\\Zotero\\storage\\23QMXWGZ\\Weiss et al. - 2007 - How Long Will It Take to Fix This Bug.pdf:application/pdf}
}

@inproceedings{camilo_bugs_2015,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '15},
	title = {Do {Bugs} {Foreshadow} {Vulnerabilities}?: {A} {Study} of the {Chromium} {Project}},
	isbn = {978-0-7695-5594-2},
	shorttitle = {Do {Bugs} {Foreshadow} {Vulnerabilities}?},
	url = {http://dl.acm.org/citation.cfm?id=2820518.2820551},
	abstract = {As developers face ever-increasing pressure to engineer secure software, researchers are building an understanding of security-sensitive bugs (i.e. vulnerabilities). Research into mining software repositories has greatly increased our understanding of software quality via empirical study of bugs. However, conceptually vulnerabilities are different from bugs: they represent abusive functionality as opposed to wrong or insufficient functionality commonly associated with traditional, non-security bugs. In this study, we performed an in-depth analysis of the Chromium project to empirically examine the relationship between bugs and vulnerabilities. We mined 374,686 bugs and 703 post-release vulnerabilities over five Chromium releases that span six years of development. Using logistic regression analysis, we examined how various categories of pre-release bugs (e.g. stability, compatibility, etc.) are associated with post-release vulnerabilities. While we found statistically significant correlations between pre-release bugs and post-release vulnerabilities, we also found the association to be weak. Number of features, SLOC, and number of pre-release security bugs are, in general, more closely associated with post-release vulnerabilities than any of our non-security bug categories. In a separate analysis, we found that the files with highest defect density did not intersect with the files of highest vulnerability density. These results indicate that bugs and vulnerabilities are empirically dissimilar groups, warranting the need for more research targeting vulnerabilities specifically.},
	urldate = {2018-01-30},
	booktitle = {Proceedings of the 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Camilo, Felivel and Meneely, Andrew and Nagappan, Meiyappan},
	year = {2015},
	pages = {269--279},
	file = {Camilo et al. - 2015 - Do Bugs Foreshadow Vulnerabilities A Study of th.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VG9IKZZE\\Camilo et al. - 2015 - Do Bugs Foreshadow Vulnerabilities A Study of th.pdf:application/pdf}
}

@inproceedings{hindle_green_2012,
	title = {Green mining: {A} methodology of relating software change to power consumption},
	shorttitle = {Green mining},
	doi = {10.1109/MSR.2012.6224303},
	abstract = {Power consumption is becoming more and more important with the increased popularity of smart-phones, tablets and laptops. The threat of reducing a customer's battery-life now hangs over the software developer who asks, “will this next change be the one that causes my software to drain a customer's battery?” One solution is to detect power consumption regressions by measuring the power usage of tests, but this is time-consuming and often noisy. An alternative is to rely on software metrics that allow us to estimate the impact that a change might have on power consumption thus relieving the developer from expensive testing. This paper presents a general methodology for investigating the impact of software change on power consumption, we relate power consumption to software changes, and then investigate the impact of static OO software metrics on power consumption. We demonstrated that software change can effect power consumption using the Firefox web-browser and the Azureus/Vuze BitTorrent client. We found evidence of a potential relationship between some software metrics and power consumption. In conclusion, we explored the effect of software change on power consumption on two projects; and we provide an initial investigation on the impact of software metrics on power consumption.},
	booktitle = {2012 9th {IEEE} {Working} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Hindle, A.},
	month = jun,
	year = {2012},
	keywords = {Software, software metrics, mobile computing, to read, Azureus/Vuze BitTorrent client, Data mining, dynamic analysis, Firefox web-browser, Fires, green mining, mining software repositories, Mobile communication, power, power aware computing, power consumption, power consumption regressions, Power demand, Power measurement, software change, Software metrics, sustainable-software},
	pages = {78--87},
	file = {Hindle - 2012 - Green mining A methodology of relating software c.html:C\:\\Users\\Anna\\Zotero\\storage\\2LXLHH4F\\Hindle - 2012 - Green mining A methodology of relating software c.html:text/html}
}

@inproceedings{zhou_harvesting_2015,
	address = {New York, NY, USA},
	series = {{WiSec} '15},
	title = {Harvesting {Developer} {Credentials} in {Android} {Apps}},
	isbn = {978-1-4503-3623-9},
	url = {http://doi.acm.org/10.1145/2766498.2766499},
	doi = {10.1145/2766498.2766499},
	abstract = {Developers often integrate third-party services into their apps. To access a service, an app must authenticate itself to the service with a credential. However, credentials in apps are often not properly or adequately protected, and might be easily extracted by attackers. A leaked credential could pose serious privacy and security threats to both the app developer and app users. In this paper, we propose CredMiner to systematically study the prevalence of unsafe developer credential uses in Android apps. CredMiner can programmatically identify and recover (obfuscated) developer credentials unsafely embedded in Android apps. Specifically, it leverages data flow analysis to identify the raw form of the embedded credential, and selectively executes the part of the program that builds the credential to recover it. We applied CredMiner to 36,561 apps collected from various Android markets to study the use of free email services and Amazon AWS. There were 237 and 196 apps that used these two services, respectively. CredMiner discovered that 51.5\% (121/237) and 67.3\% (132/196) of them were vulnerable. In total, CredMiner recovered 302 unique email login credentials and 58 unique Amazon AWS credentials, and verified that 252 and 28 of these credentials were still valid at the time of the experiments, respectively.},
	urldate = {2018-01-30},
	booktitle = {Proceedings of the 8th {ACM} {Conference} on {Security} \& {Privacy} in {Wireless} and {Mobile} {Networks}},
	publisher = {ACM},
	author = {Zhou, Yajin and Wu, Lei and Wang, Zhi and Jiang, Xuxian},
	year = {2015},
	keywords = {static analysis, Amazon AWS, CredMiner, information flow},
	pages = {23:1--23:12},
	file = {Zhou et al. - 2015 - Harvesting Developer Credentials in Android Apps.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VVM63VWE\\Zhou et al. - 2015 - Harvesting Developer Credentials in Android Apps.pdf:application/pdf}
}

@article{hutschenreiter_parametric_2017,
	title = {Parametric {Markov} {Chains}: {PCTL} {Complexity} and {Fraction}-free {Gaussian} {Elimination}},
	volume = {256},
	issn = {2075-2180},
	shorttitle = {Parametric {Markov} {Chains}},
	url = {http://arxiv.org/abs/1709.02093},
	doi = {10.4204/EPTCS.256.2},
	abstract = {Parametric Markov chains have been introduced as a model for families of stochastic systems that rely on the same graph structure, but differ in the concrete transition probabilities. The latter are specified by polynomial constraints for the parameters. Among the tasks typically addressed in the analysis of parametric Markov chains are (1) the computation of closed-form solutions for reachabilty probabilities and other quantitative measures and (2) finding symbolic representations of the set of parameter valuations for which a given temporal logical formula holds as well as (3) the decision variant of (2) that asks whether there exists a parameter valuation where a temporal logical formula holds. Our contribution to (1) is to show that existing implementations for computing rational functions for reachability probabilities or expected costs in parametric Markov chains can be improved by using fraction-free Gaussian elimination, a long-known technique for linear equation systems with parametric coefficients. Our contribution to (2) and (3) is a complexity-theoretic discussion of the model checking problem for parametric Markov chains and probabilistic computation tree logic (PCTL) formulas. We present an exponential-time algorithm for (2) and a PSPACE upper bound for (3). Moreover, we identify fragments of PCTL and subclasses of parametric Markov chains where (1) and (3) are solvable in polynomial time and establish NP-hardness for other PCTL fragments.},
	urldate = {2018-01-31},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Hutschenreiter, Lisa and Baier, Christel and Klein, Joachim},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.02093},
	keywords = {Computer Science - Logic in Computer Science, crossing reviewer 2018},
	pages = {16--30},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CQBU59HS\\1709.html:text/html;Hutschenreiter et al. - 2017 - Parametric Markov Chains PCTL Complexity and Frac.pdf:C\:\\Users\\Anna\\Zotero\\storage\\QTT7VMDI\\Hutschenreiter et al. - 2017 - Parametric Markov Chains PCTL Complexity and Frac.pdf:application/pdf}
}

@inproceedings{marcker_computing_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Computing {Conditional} {Probabilities}: {Implementation} and {Evaluation}},
	isbn = {978-3-319-66196-4 978-3-319-66197-1},
	shorttitle = {Computing {Conditional} {Probabilities}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-66197-1_22},
	doi = {10.1007/978-3-319-66197-1_22},
	abstract = {Conditional probabilities and expectations are an important concept in the quantitative analysis of stochastic systems, e.g., to analyze the impact and cost of error handling mechanisms in rare failure scenarios or for a utility-analysis assuming an exceptional shortage of resources. This paper reports on the main features of an implementation of computation schemes for conditional probabilities in discrete-time Markov chains and Markov decision processes within the probabilistic model checker Prism and a comparative experimental evaluation. Our implementation has full support for computing conditional probabilities where both the objective and condition are given as linear temporal logic formulas, as well as specialized algorithms for reachability and other simple types of path properties. In the case of Markov chains we provide implementations for three alternative methods (quotient, scale and reset). We support Prism’s explicit and (semi-)symbolic engines. Besides comparative studies exploring the three dimensions (methods, engines, general vs. special handling), we compare the performance of our implementation and the probabilistic model checker Storm that provides facilities for conditional probabilities of reachability properties.},
	language = {en},
	urldate = {2018-01-31},
	booktitle = {Software {Engineering} and {Formal} {Methods}},
	publisher = {Springer, Cham},
	author = {Märcker, Steffen and Baier, Christel and Klein, Joachim and Klüppelholz, Sascha},
	month = sep,
	year = {2017},
	keywords = {crossing reviewer 2018},
	pages = {349--366},
	file = {Märcker et al. - 2017 - Computing Conditional Probabilities Implementatio.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UIZYD34L\\Märcker et al. - 2017 - Computing Conditional Probabilities Implementatio.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BCIP8XT6\\10.html:text/html}
}

@inproceedings{baier_mean-payoff_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mean-{Payoff} {Optimization} in {Continuous}-{Time} {Markov} {Chains} with {Parametric} {Alarms}},
	isbn = {978-3-319-66334-0 978-3-319-66335-7},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-66335-7_12},
	doi = {10.1007/978-3-319-66335-7_12},
	abstract = {Continuous-time Markov chains with alarms (ACTMCs) allow for alarm events that can be non-exponentially distributed. Within parametric ACTMCs, the parameters of alarm-event distributions are not given explicitly and can be subject of parameter synthesis. An algorithm solving the εε{\textbackslash}varepsilon -optimal parameter synthesis problem for parametric ACTMCs with long-run average optimization objectives is presented. Our approach is based on reduction of the problem to finding long-run average optimal strategies in semi-Markov decision processes (semi-MDPs) and sufficient discretization of parameter (i.e., action) space. Since the set of actions in the discretized semi-MDP can be very large, a straightforward approach based on explicit action-space construction fails to solve even simple instances of the problem. The presented algorithm uses an enhanced policy iteration on symbolic representations of the action space. The soundness of the algorithm is established for parametric ACTMCs with alarm-event distributions satisfying four mild assumptions that are shown to hold for uniform, Dirac, exponential, and Weibull distributions in particular, but are satisfied for many other distributions as well. An experimental implementation shows that the symbolic technique substantially improves the efficiency of the synthesis algorithm and allows to solve instances of realistic size.},
	language = {en},
	urldate = {2018-01-31},
	booktitle = {Quantitative {Evaluation} of {Systems}},
	publisher = {Springer, Cham},
	author = {Baier, Christel and Dubslaff, Clemens and Korenčiak, Ľuboš and Kučera, Antonín and Řehák, Vojtěch},
	month = sep,
	year = {2017},
	keywords = {crossing reviewer 2018},
	pages = {190--206},
	file = {Baier et al. - 2017 - Mean-Payoff Optimization in Continuous-Time Markov.pdf:C\:\\Users\\Anna\\Zotero\\storage\\X6X7SZUJ\\Baier et al. - 2017 - Mean-Payoff Optimization in Continuous-Time Markov.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\QT6PDAVP\\10.html:text/html}
}

@inproceedings{baier_ensuring_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ensuring the {Reliability} of {Your} {Model} {Checker}: {Interval} {Iteration} for {Markov} {Decision} {Processes}},
	isbn = {978-3-319-63386-2 978-3-319-63387-9},
	shorttitle = {Ensuring the {Reliability} of {Your} {Model} {Checker}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-63387-9_8},
	doi = {10.1007/978-3-319-63387-9_8},
	abstract = {Probabilistic model checking provides formal guarantees on quantitative properties such as reliability, performance or risk, so the accuracy of the numerical results that it returns is critical. However, recent results have shown that implementations of value iteration, a widely used iterative numerical method for computing reachability probabilities, can return results that are incorrect by several orders of magnitude. To remedy this, interval iteration, which instead converges simultaneously from both above and below, has been proposed. In this paper, we present interval iteration techniques for computing expected accumulated weights (or costs), a considerably broader class of properties. This relies on an efficient, mainly graph-based method to determine lower and upper bounds for extremal expected accumulated weights. To offset the additional effort of dual convergence, we also propose topological interval iteration, which increases efficiency using a model decomposition into strongly connected components. Finally, we present a detailed experimental evaluation, which highlights inaccuracies in standard benchmarks, rather than just artificial examples, and illustrates the feasibility of our techniques.},
	language = {en},
	urldate = {2018-01-31},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Cham},
	author = {Baier, Christel and Klein, Joachim and Leuschner, Linda and Parker, David and Wunderlich, Sascha},
	month = jul,
	year = {2017},
	keywords = {crossing reviewer 2018},
	pages = {160--180},
	file = {Baier et al. - 2017 - Ensuring the Reliability of Your Model Checker In.pdf:C\:\\Users\\Anna\\Zotero\\storage\\BX7UP5HL\\Baier et al. - 2017 - Ensuring the Reliability of Your Model Checker In.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\9P6ZZLHD\\10.html:text/html}
}

@misc{noauthor_new_nodate,
	title = {{NEW} 4.0 @ {EEHH}},
	url = {http://new4-0.erneuerbare-energien-hamburg.de/de/},
	abstract = {Unternehmen aus Hamburg und Schleswig-Holstein tragen mit ihren Projekten zur Förderung Erneuerbarer Energien zum Gelingen der Energiewende bei.},
	language = {de},
	urldate = {2018-01-31},
	journal = {NEW 4.0 - Norddeutsche Energiewende},
	keywords = {crossing reviewer 2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\795PN35Y\\de.html:text/html}
}

@article{harborth_integrating_2017,
	title = {Integrating {Privacy}-{Enhancing} {Technologies} into the {Internet} {Infrastructure}},
	url = {http://arxiv.org/abs/1711.07220},
	abstract = {The AN.ON-Next project aims to integrate privacy-enhancing technologies into the internet's infrastructure and establish them in the consumer mass market. The technologies in focus include a basis protection at internet service provider level, an improved overlay network-based protection and a concept for privacy protection in the emerging 5G mobile network. A crucial success factor will be the viable adjustment and development of standards, business models and pricing strategies for those new technologies.},
	urldate = {2018-01-31},
	journal = {arXiv:1711.07220 [cs]},
	author = {Harborth, David and Herrmann, Dominik and Köpsell, Stefan and Pape, Sebastian and Roth, Christian and Federrath, Hannes and Kesdogan, Dogan and Rannenberg, Kai},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.07220},
	keywords = {Computer Science - Cryptography and Security, crossing reviewer 2018},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\26NHL45S\\1711.html:text/html;Harborth et al. - 2017 - Integrating Privacy-Enhancing Technologies into th.pdf:C\:\\Users\\Anna\\Zotero\\storage\\V62JM8IK\\Harborth et al. - 2017 - Integrating Privacy-Enhancing Technologies into th.pdf:application/pdf}
}

@inproceedings{micheloni_laribus:_2013,
	title = {Laribus: privacy-preserving detection of fake {SSL} certificates with a social {P}2P notary network},
	shorttitle = {Laribus},
	booktitle = {Availability, {Reliability} and {Security} ({ARES}), 2013 {Eighth} {International} {Conference} on},
	publisher = {IEEE},
	author = {Micheloni, Andrea and Fuchs, Karl-Peter and Herrmann, Dominik and Federrath, Hannes},
	year = {2013},
	keywords = {crossing reviewer 2018},
	pages = {1--10},
	file = {Micheloni et al. - 2013 - Laribus privacy-preserving detection of fake SSL .pdf:C\:\\Users\\Anna\\Zotero\\storage\\9R6L4H6I\\Micheloni et al. - 2013 - Laribus privacy-preserving detection of fake SSL .pdf:application/pdf}
}

@inproceedings{zimmer_catching_2015,
	title = {Catching {Inside} {Attackers}: {Balancing} {Forensic} {Detectability} and {Privacy} of {Employees}},
	shorttitle = {Catching {Inside} {Attackers}},
	booktitle = {International {Workshop} on {Open} {Problems} in {Network} {Security}},
	publisher = {Springer},
	author = {Zimmer, Ephraim and Lindemann, Jens and Herrmann, Dominik and Federrath, Hannes},
	year = {2015},
	keywords = {crossing reviewer 2018},
	pages = {43--55},
	file = {Zimmer et al. - 2015 - Catching Inside Attackers Balancing Forensic Dete.pdf:C\:\\Users\\Anna\\Zotero\\storage\\V3ZB55HW\\Zimmer et al. - 2015 - Catching Inside Attackers Balancing Forensic Dete.pdf:application/pdf}
}

@inproceedings{kulkarni_nfvnice:_2017,
	title = {{NFVnice}: {Dynamic} {Backpressure} and {Scheduling} for {NFV} {Service} {Chains}},
	isbn = {978-1-4503-4653-5},
	shorttitle = {{NFVnice}},
	url = {http://dl.acm.org/citation.cfm?doid=3098822.3098828},
	doi = {10.1145/3098822.3098828},
	abstract = {Managing Network Function (NF) service chains requires careful system resource management. We propose NFVnice, a user space NF scheduling and service chain management framework to provide fair, efficient and dynamic resource scheduling capabilities on Network Function Virtualization (NFV) platforms. The NFVnice framework monitors load on a service chain at high frequency (1000Hz) and employs backpressure to shed load early in the service chain, thereby preventing wasted work. Borrowing concepts such as rate proportional scheduling from hardware packet schedulers, CPU shares are computed by accounting for heterogeneous packet processing costs of NFs, I/O, and traffic arrival characteristics. By leveraging cgroups, a user space process scheduling abstraction exposed by the operating system, NFVnice is capable of controlling when network functions should be scheduled. NFVnice improves NF performance by complementing the capabilities of the OS scheduler but without requiring changes to the OS’s scheduling mechanisms. Our controlled experiments show that NFVnice provides the appropriate rate-cost proportional fair share of CPU to NFs and significantly improves NF performance (throughput and loss) by reducing wasted work across an NF chain, compared to using the default OS scheduler. NFVnice achieves this even for heterogeneous NFs with vastly different computational costs and for heterogeneous workloads.},
	language = {en},
	urldate = {2018-01-31},
	publisher = {ACM Press},
	author = {Kulkarni, Sameer G. and Zhang, Wei and Hwang, Jinho and Rajagopalan, Shriram and Ramakrishnan, K. K. and Wood, Timothy and Arumaithurai, Mayutan and Fu, Xiaoming},
	year = {2017},
	keywords = {crossing reviewer 2018},
	pages = {71--84},
	file = {Kulkarni et al. - 2017 - NFVnice Dynamic Backpressure and Scheduling for N.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MNG8U3XX\\Kulkarni et al. - 2017 - NFVnice Dynamic Backpressure and Scheduling for N.pdf:application/pdf}
}

@misc{noauthor_efficient_nodate,
	title = {Efficient {Multi}-{User} {Computation} {Offloading} for {Mobile}-{Edge} {Cloud} {Computing} - {IEEE} {Journals} \& {Magazine}},
	url = {http://ieeexplore.ieee.org/document/7307234/},
	urldate = {2018-01-31},
	file = {Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing - IEEE Journals & Magazine:C\:\\Users\\Anna\\Zotero\\storage\\XBLM2MMT\\7307234.html:text/html}
}

@article{chen_efficient_2015,
	title = {Efficient {Multi}-{User} {Computation} {Offloading} for {Mobile}-{Edge} {Cloud} {Computing}},
	url = {http://arxiv.org/abs/1510.00888},
	abstract = {Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.},
	urldate = {2018-01-31},
	journal = {arXiv:1510.00888 [cs]},
	author = {Chen, Xu and Jiao, Lei and Li, Wenzhong and Fu, Xiaoming},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.00888},
	keywords = {Computer Science - Networking and Internet Architecture, crossing reviewer 2018},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\3FZQNSC7\\1510.html:text/html;Chen et al. - 2015 - Efficient Multi-User Computation Offloading for Mo.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XE3TN8YP\\Chen et al. - 2015 - Efficient Multi-User Computation Offloading for Mo.pdf:application/pdf}
}

@misc{noauthor_d2d_nodate,
	title = {D2D {Fogging}: {An} {Energy}-{Efficient} and {Incentive}-{Aware} {Task} {Offloading} {Framework} via {Network}-assisted {D}2D {Collaboration} - {Semantic} {Scholar}},
	shorttitle = {D2D {Fogging}},
	url = {/paper/D2D-Fogging-An-Energy-Efficient-and-Incentive-Awar-Pu-Chen/8845784b812c272adc7d3a6980b56fc5989f7e32},
	abstract = {In this paper, we propose device-to-device (D2D) Fogging, a novel mobile task offloading framework based on network-assisted D2D collaboration, where mobile users can dynamically and beneficially share the computation and communication resources among each other via the control assistance by the network operators. The purpose of D2D Fogging is to achieve energy efficient task executions for network wide users. To this end, we propose an optimization problem formulation that aims at minimizing the time-average energy consumption for task executions of all users, meanwhile taking into account the incentive constraints of preventing the over-exploiting and free-riding behaviors which harm user\&\#39;s motivation for collaboration. To overcome the challenge that future system information such as user resource availability is difficult to predict, we develop an online task offloading algorithm, which leverages Lyapunov optimization methods and utilizes the current system information only. As the critical building block, we devise corresponding efficient task scheduling policies in terms of three kinds of system settings in a time frame. Extensive simulation results demonstrate that the proposed online algorithm not only achieves superior performance (e.g., it reduces approximately 30\% {\textasciitilde} 40\% energy consumption compared with user local execution), but also adapts to various situations in terms of task type, user amount, and task frequency.},
	urldate = {2018-01-31},
	keywords = {crossing reviewer 2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\8ZANQWVQ\\8845784b812c272adc7d3a6980b56fc5989f7e32.html:text/html}
}

@inproceedings{huang_mining_2014,
	address = {New York, NY, USA},
	series = {{WWW} '14 {Companion}},
	title = {Mining {Triadic} {Closure} {Patterns} in {Social} {Networks}},
	isbn = {978-1-4503-2745-9},
	url = {http://doi.acm.org/10.1145/2567948.2576940},
	doi = {10.1145/2567948.2576940},
	abstract = {A closed triad is a group of three people who are connected with each other. It is the most basic unit for studying group phenomena in social networks. In this paper, we study how closed triads are formed in dynamic networks. More specifically, given three persons, what are the fundamental factors that trigger the formation of triadic closure? There are various factors that may influence the formation of a relationship between persons. Can we design a unified model to predict the formation of triadic closure? Employing a large microblogging network as the source in our study, we formally define the problem and conduct a systematic investigation. The study uncovers how user demographics and network topology influence the process of triadic closure. We also present a probabilistic graphical model to predict whether three persons will form a closed triad in dynamic networks. The experimental results on the microblogging data demonstrate the efficiency of our proposed model for the prediction of triadic closure formation.},
	urldate = {2018-01-31},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Huang, Hong and Tang, Jie and Wu, Sen and Liu, Lu and fu, Xiaoming},
	year = {2014},
	keywords = {predictive model, social influence, social network, crossing reviewer 2018},
	pages = {499--504},
	file = {Huang et al. - 2014 - Mining Triadic Closure Patterns in Social Networks.pdf:C\:\\Users\\Anna\\Zotero\\storage\\3EST6LVR\\Huang et al. - 2014 - Mining Triadic Closure Patterns in Social Networks.pdf:application/pdf}
}

@inproceedings{banescu_detecting_2017,
	address = {New York, NY, USA},
	series = {{CODASPY} '17},
	title = {Detecting {Patching} of {Executables} {Without} {System} {Calls}},
	isbn = {978-1-4503-4523-1},
	url = {http://doi.acm.org/10.1145/3029806.3029835},
	doi = {10.1145/3029806.3029835},
	abstract = {Popular software applications (e.g. web browsers) are targeted by malicious organizations which develop potentially unwanted programs (PUPs). If such a PUP executes on benign user devices, it is able to manipulate the process memory of popular applications, their locally stored resources or their environment in a profitable way for the attacker and in detriment to benign end-users. We describe the implementation of a tamper detection mechanism based on code self-checksumming, able to detect static and dynamic patching of executables, performed by PUPs or other attackers. As opposed to other works based on code self-checksumming, our approach can also checksum instructions which contain absolute addresses affected by relocation, without using calls to external libraries. We implemented this solution for the x86 ISA and evaluated the performance impact and effectiveness. The results indicate that the run-time overhead of self-checksumming grows proportionally with the level of protection, which can be specified as input to our implementation. We have applied our implementation on the Chromium web-browser and observed that the overhead is practically unobservable for the end-user.},
	urldate = {2018-01-31},
	booktitle = {Proceedings of the {Seventh} {ACM} on {Conference} on {Data} and {Application} {Security} and {Privacy}},
	publisher = {ACM},
	author = {Banescu, Sebastian and Ahmadvand, Mohsen and Pretschner, Alexander and Shield, Robert and Hamilton, Chris},
	year = {2017},
	keywords = {potentially unwanted programs, software protection, tamper detection, crossing reviewer 2018},
	pages = {185--196},
	file = {Banescu et al. - 2017 - Detecting Patching of Executables Without System C.pdf:C\:\\Users\\Anna\\Zotero\\storage\\EKRVXS4F\\Banescu et al. - 2017 - Detecting Patching of Executables Without System C.pdf:application/pdf}
}

@inproceedings{golagha_reducing_2017,
	title = {Reducing failure analysis time: an industrial evaluation},
	shorttitle = {Reducing failure analysis time},
	doi = {10.1109/ICSE-SEIP.2017.15},
	abstract = {Testing and debugging automotive cyber physical systems are challenging. Developing and integrating cyber and physical components require extensive testing to ensure reliable and safe releases. One important cost factor in the debugging process is the time required to analyze failures. Since large number of failures usually happen due to a few underlying faults, clustering failures based on the responsible faults helps reduce analysis time. We focus on the software-in-the-loop and hardware-in-the-loop levels of testing where test execution times are high. We devise a methodology for adapting existing clustering techniques to a real context. We augment an existing clustering approach by a method for selecting representative tests. To analyze failures, rather than investigating all failing tests one by one, testers inspect only these representatives. We report on the results of a large scale industrial case study. We ran experiments on ca. 850 KLOC. Results show that utilizing our clustering tool, testers can reduce failure analysis time by more than 80\%.},
	booktitle = {2017 {IEEE}/{ACM} 39th {International} {Conference} on {Software} {Engineering}: {Software} {Engineering} in {Practice} {Track} ({ICSE}-{SEIP})},
	author = {Golagha, M. and Pretschner, A. and Fisch, D. and Nagy, R.},
	month = may,
	year = {2017},
	keywords = {program debugging, program testing, Software, Context, Measurement, Tools, automotive CPS, automotive cyber physical systems, automotive engineering, clustering techniques, Debugging, debugging process, failure analysis, Failure analysis, failure analysis time, failure clustering, hardware-in-the-loop, HiL testing, SiL testing, software-in-the-loop, testing process, crossing reviewer 2018},
	pages = {293--302},
	file = {Golagha et al. - 2017 - Reducing failure analysis time an industrial eval.pdf:C\:\\Users\\Anna\\Zotero\\storage\\SYDZ3EUV\\Golagha et al. - 2017 - Reducing failure analysis time an industrial eval.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\4IJC4TM7\\7965453.html:text/html}
}

@inproceedings{hauer_industrial_2017,
	title = {Industrial {Evaluation} of {Search}-{Based} {Test} {Generation} {Techniques} for {Control} {Systems}},
	doi = {10.1109/ISSREW.2017.10},
	abstract = {The systems and the software in the domain of industrial trucks are becoming increasingly complex due to the rapidly increasing demand for more functionality. This leads to an even faster rising effort for manual verification activities. Therefore, automated testing techniques need to be introduced into the verification process. In this work, a search-based test generation technique has been adapted for the requirements-based black box test of control systems for counterweight forklift trucks. Fitness functions are derived from industrial requirement documents and are utilized to automatically generate test cases consisting of multiple input signals. The designed approach has been evaluated on an industrial control system and the results show that failures can be detected in the system as well as in the environment model.},
	booktitle = {2017 {IEEE} {International} {Symposium} on {Software} {Reliability} {Engineering} {Workshops} ({ISSREW})},
	author = {Hauer, F. and Pretschner, A. and Schmitt, M. and Groetsch, M.},
	month = oct,
	year = {2017},
	keywords = {program testing, Testing, Acceleration, automated testing techniques, automatic testing, Automatic Testing, black box test, control engineering computing, Control systems, counterweight forklift trucks, Embedded Software, fitness functions, fork lift trucks, Genetic algorithms, Genetic Algorithms, industrial control system, industrial requirement documents, industrial trucks, Mathematical model, Modeling, Optimization, search problems, search-based test generation technique, System Verification, test generation techniques, verification process, crossing reviewer 2018},
	pages = {5--8},
	file = {Hauer et al. - 2017 - Industrial Evaluation of Search-Based Test Generat.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ZBNPACNA\\Hauer et al. - 2017 - Industrial Evaluation of Search-Based Test Generat.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\83JNMZ3H\\8109236.html:text/html}
}

@misc{noauthor_predicting_nodate,
	title = {Predicting the {Resilience} of {Obfuscated} {Code} {Against} {Symbolic} {Execution} {Attacks} via {Machine} {Learning} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/banescu},
	abstract = {Software obfuscation transforms code such that it is more difficult to reverse engineer. However, it is known that given enough resources, an attacker will successfully reverse engineer an obfuscated program. Therefore, an open challenge for software obfuscation is estimating the time an obfuscated program is able to withstand a given reverse engineering attack. This paper proposes a general framework for choosing the most relevant software features to estimate the effort of automated attacks. Our framework uses these software features to build regression models that can predict the resilience of different software protection transformations against automated attacks. To evaluate the effectiveness of our approach, we instantiate it in a case-study about predicting the time needed to deobfuscate a set of C programs, using an attack based on symbolic execution. To train regression models our system requires a large set of programs as input. We have therefore implemented a code generator that can generate large numbers of arbitrarily complex random C functions. Our results show that features such as the number of community structures in the graph representation of symbolic path-constraints, are far more relevant for predicting deobfuscation time than other features generally used to measure the potency of controlflow obfuscation (e.g. cyclomatic complexity). Our best model is able to predict the number of seconds of symbolic execution-based deobfuscation attacks with over 90\% accuracy for 80\% of the programs in our dataset, which also includes several realistic hash functions.},
	urldate = {2018-01-31},
	keywords = {crossing reviewer 2018},
	file = {Predicting the Resilience of Obfuscated Code Against Symbolic Execution Attacks via Machine Learning | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\TAAK96C5\\banescu.html:text/html}
}

@article{ognawala_improving_2017,
	title = {Improving {Function} {Coverage} with {Munch}: {A} {Hybrid} {Fuzzing} and {Directed} {Symbolic} {Execution} {Approach}},
	shorttitle = {Improving {Function} {Coverage} with {Munch}},
	url = {http://arxiv.org/abs/1711.09362},
	doi = {10.1145/3167132.3167289},
	abstract = {Fuzzing and symbolic execution are popular techniques for finding vulnerabilities and generating test-cases for programs. Fuzzing, a blackbox method that mutates seed input values, is generally incapable of generating diverse inputs that exercise all paths in the program. Due to the path-explosion problem and dependence on SMT solvers, symbolic execution may also not achieve high path coverage. A hybrid technique involving fuzzing and symbolic execution may achieve better function coverage than fuzzing or symbolic execution alone. In this paper, we present Munch, an open source framework implementing two hybrid techniques based on fuzzing and symbolic execution. We empirically show using nine large open-source programs that overall, Munch achieves higher (in-depth) function coverage than symbolic execution or fuzzing alone. Using metrics based on total analyses time and number of queries issued to the SMT solver, we also show that Munch is more efficient at achieving better function coverage.},
	urldate = {2018-01-31},
	journal = {arXiv:1711.09362 [cs]},
	author = {Ognawala, Saahil and Hutzelmann, Thomas and Psallida, Eirini and Pretschner, Alexander},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.09362},
	keywords = {Computer Science - Software Engineering, crossing reviewer 2018},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\DC5RFDFQ\\1711.html:text/html;Ognawala et al. - 2017 - Improving Function Coverage with Munch A Hybrid F.pdf:C\:\\Users\\Anna\\Zotero\\storage\\8H7WU5LM\\Ognawala et al. - 2017 - Improving Function Coverage with Munch A Hybrid F.pdf:application/pdf}
}

@misc{noauthor_invasive_nodate,
	title = {Invasive computing for timing-predictable stream processing on {MPSoCs} : it - {Information} {Technology}},
	url = {https://www.degruyter.com/view/j/itit.2016.58.issue-6/itit-2016-0021/itit-2016-0021.xml},
	abstract = {Multi-Processor Systems-on-a-Chip (MPSoCs) provide sufficient computing power for many applications in scientific as well as embedded applications. Unfortunately, when real-time requirements need to be guaranteed, applications suffer from the interference with other applications, uncertainty of dynamic workload and state of the hardware. Composable application/architecture design and timing analysis is therefore a must for guaranteeing real-time applications to satisfy their timing requirements independent from dynamic workload. Here, Invasive Computing is used as the key enabler for compositional timing analysis on MPSoCs, as it provides the required isolation of resources allocated to each application. On the basis of this paradigm, this work proposes a hybrid application mapping methodology that combines design-time analysis of application mappings with run-time management. Design space exploration delivers several resource reservation configurations with verified real-time guarantees for individual applications. These timing properties can then be guaranteed at run-time, as long as dynamic resource allocations comply with the offline analyzed resource configurations.

This article describes our methodology and presents programming, optimization, analysis, and hardware techniques for enforcing timing predictability. A case study illustrates the timing-predictable management of real-time computer vision applications in dynamic robot system scenarios.},
	urldate = {2018-01-31},
	file = {Invasive computing for timing-predictable stream p.html:C\:\\Users\\Anna\\Zotero\\storage\\53E8PAXQ\\Invasive computing for timing-predictable stream p.html:text/html}
}

@article{wildermann_invasive_2016,
	title = {Invasive {Computing} for {Timing}-{Predictable} {Stream} {Processing} on {MPSOCS}},
	volume = {58},
	doi = {10.1515/itit-2016-0021},
	abstract = {Multi-Processor Systems-on-a-Chip (MPSoCs) provide sufficient computing power for many applications in scientific as well as embedded applications. Unfortunately, when real-time requirements need to be guaranteed, applications suffer from the interference with other applications, uncertainty of dynamic workload and state of the hardware. Composable application/architecture design and timing analysis is therefore a must for guaranteeing real-time applications to satisfy their timing requirements independent from dynamic workload. Here, Invasive Computing is used as the key enabler for compositional timing analysis on MPSoCs, as it provides the required isolation of resources allocated to each application. On the basis of this paradigm, this work proposes a hybrid application mapping methodology that combines design-time analysis of application mappings with run-time management. Design space exploration delivers several resource reservation configurations with verified real-time guarantees for individual applications. These timing properties can then be guaranteed at run-time, as long as dynamic resource allocations comply with the offline analyzed resource configurations.

This article describes our methodology and presents programming, optimization, analysis, and hardware techniques for enforcing timing predictability. A case study illustrates the timing-predictable management of real-time computer vision applications in dynamic robot system scenarios.},
	number = {6},
	journal = {it – Information Technology},
	author = {Wildermann, Stefan and Bader, Michael and Bauer, Lars and Damschen, Marvin and Gabriel, Dirk and Gerndt, Michael and s, Michael Gla{\textbackslash}s and Henkel, Jörg and Paul, Johny and Pöppl, Alexander and Roloff, Sascha and Schwarzer, Tobias and Snelting, Gregor and a, Walter Stechele},
	year = {2016},
	keywords = {crossing reviewer 2018},
	pages = {267--280}
}

@article{snelting_understanding_2015,
	series = {Special {Issue} on {New} {Ideas} and {Emerging} {Results} in {Understanding} {Software}},
	title = {Understanding probabilistic software leaks},
	volume = {97},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S016764231300292X},
	doi = {10.1016/j.scico.2013.11.008},
	abstract = {Probabilistic security leaks in multi-threaded programs exploit nondeterminism and interleaving. Probabilistic leaks does not leak secret values directly, but secret values influence the probability of public events. The article explains probabilistic leaks, and discusses various methods for checking probabilistic noninterference.},
	urldate = {2018-01-31},
	journal = {Science of Computer Programming},
	author = {Snelting, Gregor},
	month = jan,
	year = {2015},
	keywords = {Noninterference, Program analysis, Software security, crossing reviewer 2018},
	pages = {122--126},
	file = {ScienceDirect Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZDJGHPK5\\S016764231300292X.html:text/html;Snelting - 2015 - Understanding probabilistic software leaks.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VFRY3JEM\\Snelting - 2015 - Understanding probabilistic software leaks.pdf:application/pdf}
}

@inproceedings{breitner_improvements_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Improvements} {Of} {Low}-{Deterministic} {Security}},
	volume = {9635},
	doi = {10.1007/978-3-662-49635-0_4},
	booktitle = {Principles of {Security} and {Trust} - 5th {International} {Conference}, {POST} 2016, {Held} as {Part} of the {European} {Joint} {Conferences} on {Theory} and {Practice} of {Software}, {ETAPS} 2016, {Eindhoven}, {The} {Netherlands}, {April} 2-8, 2016, {Proceedings}},
	publisher = {Springer Berlin Heidelberg},
	author = {Breitner, Joachim and Graf, Jürgen and Hecker, Martin and Mohr, Martin and Snelting, Gregor},
	editor = {Piessens, Frank and Viganò, Luca},
	year = {2016},
	keywords = {crossing reviewer 2018},
	pages = {68--88}
}

@article{bischof_low-deterministic_nodate,
	title = {Low-{Deterministic} {Security} {For} {Low}-{Nondeterministic} {Programs}},
	abstract = {We present a new algorithm, together with a full soundness proof, which guarantees
probabilistic noninterference
(PN) for
concurrent programs. The algorithm follows the “low-deterministic security” (LSOD) approach, but for the first time allows
general low-nondeterminism as long as PN is not violated.
The algorithm is based on the earlier observation by Giffhorn and Snelting that low-nondeterminism is secure as long as it
is not influenced by high events [1]. It uses a new system of classification flow equations in multi-threaded programs, together
with inter-thread / interprocedural dominators. Compared to LSOD and even [1], precision is boosted and false alarms are
minimized. We explain details of the new algorithm and its soundness proof.
The algorithm is integrated into the JOANA software security tool, and can handle full Java with arbitrary threads. We apply
JOANA to a multi-threaded e-voting system, and show how the algorithm eliminates false alarms. We thus demonstrate that
low-deterministic security is a highly precise and practically mature software security analysis method.},
	author = {Bischof, Simon and Breitner, Joachim and Graf, Jürgen and Hecker, Martin and Mohr, Martin and Snelting, Gregor},
	keywords = {crossing reviewer 2018},
	file = {Bischof et al. - Low-Deterministic Security For Low-Nondeterministi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TLEVB6VW\\Bischof et al. - Low-Deterministic Security For Low-Nondeterministi.pdf:application/pdf}
}

@article{broadnax_sicherheit_2017,
	title = {Sicherheit relativ definieren},
	volume = {41},
	issn = {1614-0702, 1862-2607},
	url = {https://link.springer.com/article/10.1007/s11623-017-0720-4},
	doi = {10.1007/s11623-017-0720-4},
	abstract = {In der modernen Kryptographie wird „Sicherheit“ mathematisch definiert. Einer der etablierten Ansätze, Sicherheit zu definieren, ist die „Simulationsbasierte Sicherheit“, bei der Sicherheit keine abso},
	language = {de},
	number = {1},
	urldate = {2018-01-31},
	journal = {Datenschutz und Datensicherheit - DuD},
	author = {Broadnax, Brandon and Mechler, Jeremias and Müller-Quade, Jörn and Nagel, Matthias and Rill, Jochen},
	month = jan,
	year = {2017},
	keywords = {crossing reviewer 2018},
	pages = {24--28},
	file = {Broadnax et al. - 2017 - Sicherheit relativ definieren.pdf:C\:\\Users\\Anna\\Zotero\\storage\\N6D9M8VV\\Broadnax et al. - 2017 - Sicherheit relativ definieren.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\YT8P25NJ\\10.html:text/html}
}

@inproceedings{fetzer_formal_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Formal} {Treatment} of {Privacy} in {Video} {Data}},
	isbn = {978-3-319-45740-6 978-3-319-45741-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-45741-3_21},
	doi = {10.1007/978-3-319-45741-3_21},
	abstract = {Video surveillance has become prevalent both in public spaces, e.g. to prevent crimes, and in private areas, e.g. in order to assist the staff in assisted living communities. This leads to privacy concerns regarding the ability of third parties to create profiles and track individuals, possibly across several services.Usually, techniques such as pixelation and silhouettes are used to anonymize individuals. However, no formal treatment of privacy for video data has been proposed and current anonymization techniques are simply “best practice”. To resolve this unsatisfactory state of affairs, we initiate a formal treatment of privacy in video data and propose a game-based notion for privacy in video data that is inspired by cryptographic security games.We show for an exemplary video privacy scheme that this scheme satisfies our notion with good parameters. In order to evaluate these parameters, we conduct a user study where the users essentially play the role of the adversary in the privacy game. Our approach can be used as a blueprint to evaluate the privacy of other video privacy schemes.},
	language = {en},
	urldate = {2018-01-31},
	booktitle = {Computer {Security} – {ESORICS} 2016},
	publisher = {Springer, Cham},
	author = {Fetzer, Valerie and Müller-Quade, Jörn and Nilges, Tobias},
	month = sep,
	year = {2016},
	keywords = {crossing reviewer 2018},
	pages = {406--424},
	file = {Fetzer et al. - 2016 - A Formal Treatment of Privacy in Video Data.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ZNZZWYUG\\Fetzer et al. - 2016 - A Formal Treatment of Privacy in Video Data.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZZD7KD3S\\10.html:text/html}
}

@misc{noauthor_iqst:_nodate,
	title = {{IQST}: {Overview}},
	url = {http://iqst.org/en/iqst/overview.html},
	urldate = {2018-01-31},
	keywords = {crossing reviewer 2018},
	file = {IQST\: Overview:C\:\\Users\\Anna\\Zotero\\storage\\9PWDN9LR\\overview.html:text/html}
}

@article{gleisberg_prime_2018,
	title = {Prime factorization of arbitrary integers with a logarithmic energy spectrum},
	volume = {51},
	issn = {0953-4075},
	url = {http://stacks.iop.org/0953-4075/51/i=3/a=035009},
	doi = {10.1088/1361-6455/aa9957},
	abstract = {We propose an iterative scheme to factor numbers based on the quantum dynamics of an ensemble of interacting bosonic atoms stored in a trap where the single-particle energy spectrum depends logarithmically on the quantum number. When excited by a time-dependent interaction these atoms perform Rabi oscillations between the ground state and an energy state characteristic of the factors. The number to be factored is encoded into the frequency of the sinusoidally modulated interaction. We show that a measurement of the energy of the atoms at a time chosen at random yields the factors with probability one half. We conclude by discussing a protocol to obtain the desired prime factors employing a logarithmic energy spectrum which consists of prime numbers only.},
	language = {en},
	number = {3},
	urldate = {2018-01-31},
	journal = {Journal of Physics B: Atomic, Molecular and Optical Physics},
	author = {Gleisberg, F. and Pumpo, F. Di and Wolff, G. and Schleich, W. P.},
	year = {2018},
	keywords = {crossing reviewer 2018},
	pages = {035009},
	file = {Gleisberg et al. - 2018 - Prime factorization of arbitrary integers with a l.pdf:C\:\\Users\\Anna\\Zotero\\storage\\2Y96EHP2\\Gleisberg et al. - 2018 - Prime factorization of arbitrary integers with a l.pdf:application/pdf}
}

@article{shor_polynomial-time_1997,
	title = {Polynomial-{Time} {Algorithms} for {Prime} {Factorization} and {Discrete} {Logarithms} on a {Quantum} {Computer}},
	volume = {26},
	issn = {0097-5397, 1095-7111},
	url = {http://arxiv.org/abs/quant-ph/9508027},
	doi = {10.1137/S0097539795293172},
	abstract = {A digital computer is generally believed to be an efficient universal computing device; that is, it is believed able to simulate any physical computing device with an increase in computation time of at most a polynomial factor. This may not be true when quantum mechanics is taken into consideration. This paper considers factoring integers and finding discrete logarithms, two problems which are generally thought to be hard on a classical computer and have been used as the basis of several proposed cryptosystems. Efficient randomized algorithms are given for these two problems on a hypothetical quantum computer. These algorithms take a number of steps polynomial in the input size, e.g., the number of digits of the integer to be factored.},
	number = {5},
	urldate = {2018-02-02},
	journal = {SIAM Journal on Computing},
	author = {Shor, Peter W.},
	month = oct,
	year = {1997},
	note = {arXiv: quant-ph/9508027},
	keywords = {Quantum Physics},
	pages = {1484--1509},
	file = {arXiv\:quant-ph/9508027 PDF:C\:\\Users\\Anna\\Zotero\\storage\\CTGLK85U\\Shor - 1997 - Polynomial-Time Algorithms for Prime Factorization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\U2XQETMK\\9508027.html:text/html}
}

@inproceedings{srivastava_security_2011,
	address = {New York, NY, USA},
	series = {{PLDI} '11},
	title = {A {Security} {Policy} {Oracle}: {Detecting} {Security} {Holes} {Using} {Multiple} {API} {Implementations}},
	isbn = {978-1-4503-0663-8},
	shorttitle = {A {Security} {Policy} {Oracle}},
	url = {http://doi.acm.org/10.1145/1993498.1993539},
	doi = {10.1145/1993498.1993539},
	abstract = {Even experienced developers struggle to implement security policies correctly. For example, despite 15 years of development, standard Java libraries still suffer from missing and incorrectly applied permission checks, which enable untrusted applications to execute native calls or modify private class variables without authorization. Previous techniques for static verification of authorization enforcement rely on manually specified policies or attempt to infer the policy by code-mining. Neither approach guarantees that the policy used for verification is correct. In this paper, we exploit the fact that many modern APIs have multiple, independent implementations. Our flow- and context-sensitive analysis takes as input an API, multiple implementations thereof, and the definitions of security checks and security-sensitive events. For each API entry point, the analysis computes the security policies enforced by the checks before security-sensitive events such as native method calls and API returns, compares these policies across implementations, and reports the differences. Unlike code-mining, this technique finds missing checks even if they are part of a rare pattern. Security-policy differencing has no intrinsic false positives: implementations of the same API must enforce the same policy, or at least one of them is wrong! Our analysis finds 20 new, confirmed security vulnerabilities and 11 interoperability bugs in the Sun, Harmony, and Classpath implementations of the Java Class Library, many of which were missed by prior analyses. These problems manifest in 499 entry points in these mature, well-studied libraries. Multiple API implementations are proliferating due to cloud-based software services and standardization of library interfaces. Comparing software implementations for consistency is a new approach to discovering "deep" bugs in them.},
	urldate = {2018-02-02},
	booktitle = {Proceedings of the 32Nd {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Srivastava, Varun and Bond, Michael D. and McKinley, Kathryn S. and Shmatikov, Vitaly},
	year = {2011},
	keywords = {static analysis, authorization, security, to read, access control, java class libraries},
	pages = {343--354},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\SEMV4EQ8\\Srivastava et al. - 2011 - A Security Policy Oracle Detecting Security Holes.pdf:application/pdf;Srivastava et al. - 2011 - A Security Policy Oracle Detecting Security Holes.pdf:C\:\\Users\\Anna\\Zotero\\storage\\X39DG3UR\\Srivastava et al. - 2011 - A Security Policy Oracle Detecting Security Holes.pdf:application/pdf;Srivastava et al. - 2011 - A Security Policy Oracle Detecting Security Holes.pdf:C\:\\Users\\Anna\\Zotero\\storage\\GZ2YQH6V\\Srivastava et al. - 2011 - A Security Policy Oracle Detecting Security Holes.pdf:application/pdf}
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	year = {1986},
	file = {Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf:C\:\\Users\\Anna\\Zotero\\storage\\2WKL9GE8\\Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf:application/pdf}
}

@article{preskill_quantum_2018,
	title = {Quantum {Computing} in the {NISQ} era and beyond},
	url = {http://arxiv.org/abs/1801.00862},
	abstract = {Noisy Intermediate-Scale Quantum (NISQ) technology will be available in the near future. Quantum computers with 50-100 qubits may be able to perform tasks which surpass the capabilities of today's classical digital computers, but noise in quantum gates will limit the size of quantum circuits that can be executed reliably. NISQ devices will be useful tools for exploring many-body quantum physics, and may have other useful applications, but the 100-qubit quantum computer will not change the world right away --- we should regard it as a significant step toward the more powerful quantum technologies of the future. Quantum technologists should continue to strive for more accurate quantum gates and, eventually, fully fault-tolerant quantum computing.},
	urldate = {2018-02-05},
	journal = {arXiv:1801.00862 [cond-mat, physics:quant-ph]},
	author = {Preskill, John},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.00862},
	keywords = {Quantum Physics, Condensed Matter - Strongly Correlated Electrons},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\A5WQHR7V\\1801.html:text/html;Preskill - 2018 - Quantum Computing in the NISQ era and beyond.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IU2YYGPI\\Preskill - 2018 - Quantum Computing in the NISQ era and beyond.pdf:application/pdf}
}

@article{montanaro_quantum_2016,
	title = {Quantum algorithms: an overview},
	volume = {2},
	issn = {2056-6387},
	shorttitle = {Quantum algorithms},
	url = {http://arxiv.org/abs/1511.04206},
	doi = {10.1038/npjqi.2015.23},
	abstract = {Quantum computers are designed to outperform standard computers by running quantum algorithms. Areas in which quantum algorithms can be applied include cryptography, search and optimisation, simulation of quantum systems, and solving large systems of linear equations. Here we briefly survey some known quantum algorithms, with an emphasis on a broad overview of their applications rather than their technical details. We include a discussion of recent developments and near-term applications of quantum algorithms.},
	number = {1},
	urldate = {2018-02-06},
	journal = {npj Quantum Information},
	author = {Montanaro, Ashley},
	month = nov,
	year = {2016},
	note = {arXiv: 1511.04206},
	keywords = {Quantum Physics},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\76RTW6ZE\\1511.html:text/html;Montanaro - 2016 - Quantum algorithms an overview.pdf:C\:\\Users\\Anna\\Zotero\\storage\\AN3LYNBZ\\Montanaro - 2016 - Quantum algorithms an overview.pdf:application/pdf}
}

@article{kearns_innovation_2008,
	title = {Innovation in {PhD} completion: the hardy shall succeed (and be happy!)},
	volume = {27},
	issn = {0729-4360},
	shorttitle = {Innovation in {PhD} completion},
	url = {https://doi.org/10.1080/07294360701658781},
	doi = {10.1080/07294360701658781},
	abstract = {What is it that makes a PhD such a difficult process, and prevents candidates from completing on time? In this paper, we propose that self‐sabotaging behaviours, including overcommitting, procrastination and perfectionism, have a role to play. At Flinders University, we have developed a program in which we work with PhD students to help to reduce these behaviours and give them the strategies and attitudes they need to successfully (and happily!) complete their thesis. The program utilises cognitive–behavioural coaching, an evidence‐based strategy that we claim leads to significant and long‐term behavioural change. An evaluation of the program indicates that it is very successful, improving students’ ability to manage their time, set specific times for writing, and show work to their supervisor regularly, and that these behaviours were associated with lower levels of stress and improved ability to complete.},
	number = {1},
	urldate = {2018-02-06},
	journal = {Higher Education Research \& Development},
	author = {Kearns, Hugh and Gardiner, Maria and Marshall, Kelly},
	month = mar,
	year = {2008},
	keywords = {cognitive–behavioural coaching, PhD completion, PhD students, self‐sabotage, stress},
	pages = {77--89},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RQ23LML2\\07294360701658781.html:text/html}
}

@misc{noauthor_research_nodate,
	title = {Research},
	url = {http://www.ithinkwell.com.au/research},
	urldate = {2018-02-06},
	file = {Research:C\:\\Users\\Anna\\Zotero\\storage\\Q3F9KTEL\\research.html:text/html}
}

@misc{thomas_finishing_2014,
	title = {Finishing your {PhD} thesis: 15 top tips from those in the know},
	shorttitle = {Finishing your {PhD} thesis},
	url = {http://www.theguardian.com/higher-education-network/blog/2014/aug/27/finishing-phd-thesis-top-tips-experts-advice},
	abstract = {Trying to complete a PhD thesis in time for the October deadline? We share some advice on getting over that final hurdle},
	language = {en},
	urldate = {2018-02-06},
	journal = {the Guardian},
	author = {Thomas, Kim},
	month = aug,
	year = {2014},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\3CRWIMHE\\finishing-phd-thesis-top-tips-experts-advice.html:text/html}
}

@inproceedings{mishne_typestate-based_2012,
	title = {Typestate-based semantic code search over partial programs},
	volume = {47},
	booktitle = {Acm {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Mishne, Alon and Shoham, Sharon and Yahav, Eran},
	year = {2012},
	pages = {997--1016},
	file = {Mishne et al. - 2012 - Typestate-based semantic code search over partial .pdf:C\:\\Users\\Anna\\Zotero\\storage\\JXVKK8G7\\Mishne et al. - 2012 - Typestate-based semantic code search over partial .pdf:application/pdf}
}

@misc{noauthor_blockstack:_nodate,
	title = {Blockstack: {A} {Global} {Naming} and {Storage} {System} {Secured} by {Blockchains} {\textbar} {USENIX}},
	url = {https://www.usenix.org/node/196209},
	urldate = {2018-02-07},
	file = {Blockstack\: A Global Naming and Storage System Secured by Blockchains | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\VHTJURHS\\196209.html:text/html}
}

@inproceedings{ali_blockstack:_2016,
	address = {Denver, CO},
	title = {Blockstack: {A} {Global} {Naming} and {Storage} {System} {Secured} by {Blockchains}},
	isbn = {978-1-931971-30-0},
	url = {https://www.usenix.org/conference/atc16/technical-sessions/presentation/ali},
	booktitle = {2016 {USENIX} {Annual} {Technical} {Conference} ({USENIX} {ATC} 16)},
	publisher = {USENIX Association},
	author = {Ali, Muneeb and Nelson, Jude and Shea, Ryan and Freedman, Michael J.},
	year = {2016},
	pages = {181--194},
	file = {Ali et al. - 2016 - Blockstack A Global Naming and Storage System Sec.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NISCJEXI\\Ali et al. - 2016 - Blockstack A Global Naming and Storage System Sec.pdf:application/pdf}
}

@inproceedings{weimer_mining_2005,
	address = {Berlin, Heidelberg},
	series = {{TACAS}'05},
	title = {Mining {Temporal} {Specifications} for {Error} {Detection}},
	isbn = {978-3-540-25333-4},
	url = {http://dx.doi.org/10.1007/978-3-540-31980-1_30},
	doi = {10.1007/978-3-540-31980-1_30},
	abstract = {Specifications are necessary in order to find software bugs using program verification tools. This paper presents a novel automatic specification mining algorithm that uses information about error handling to learn temporal safety rules. Our algorithm is based on the observation that programs often make mistakes along exceptional control-flow paths, even when they behave correctly on normal execution paths. We show that this focus improves the effectiveness of the miner for discovering specifications beneficial for bug finding. We present quantitative results comparing our technique to four existing miners. We highlight assumptions made by various miners that are not always born out in practice. Additionally, we apply our algorithm to existing Java programs and analyze its ability to learn specifications that find bugs in those programs. In our experiments, we find filtering candidate specifications to be more important than ranking them. We find 430 bugs in 1 million lines of code. Notably, we find 250 more bugs using per-program specifications learned by our algorithm than with generic specifications that apply to all programs.},
	urldate = {2018-02-07},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Tools} and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
	publisher = {Springer-Verlag},
	author = {Weimer, Westley and Necula, George C.},
	year = {2005},
	keywords = {to read},
	pages = {461--476},
	file = {Weimer und Necula - 2005 - Mining Temporal Specifications for Error Detection.pdf:C\:\\Users\\Anna\\Zotero\\storage\\EISWZ9KI\\Weimer und Necula - 2005 - Mining Temporal Specifications for Error Detection.pdf:application/pdf}
}

@inproceedings{raychev_code_2014,
	address = {New York, NY, USA},
	series = {{PLDI} '14},
	title = {Code {Completion} with {Statistical} {Language} {Models}},
	isbn = {978-1-4503-2784-8},
	url = {http://doi.acm.org/10.1145/2594291.2594321},
	doi = {10.1145/2594291.2594321},
	abstract = {We address the problem of synthesizing code completions for programs using APIs. Given a program with holes, we synthesize completions for holes with the most likely sequences of method calls. Our main idea is to reduce the problem of code completion to a natural-language processing problem of predicting probabilities of sentences. We design a simple and scalable static analysis that extracts sequences of method calls from a large codebase, and index these into a statistical language model. We then employ the language model to find the highest ranked sentences, and use them to synthesize a code completion. Our approach is able to synthesize sequences of calls across multiple objects together with their arguments. Experiments show that our approach is fast and effective. Virtually all computed completions typecheck, and the desired completion appears in the top 3 results in 90\% of the cases.},
	urldate = {2018-02-07},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Raychev, Veselin and Vechev, Martin and Yahav, Eran},
	year = {2014},
	keywords = {to read},
	pages = {419--428},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\K293R9C2\\Raychev et al. - 2014 - Code Completion with Statistical Language Models.pdf:application/pdf}
}

@inproceedings{oh_learning_2015,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2015},
	title = {Learning a {Strategy} for {Adapting} a {Program} {Analysis} via {Bayesian} {Optimisation}},
	isbn = {978-1-4503-3689-5},
	url = {http://doi.acm.org/10.1145/2814270.2814309},
	doi = {10.1145/2814270.2814309},
	abstract = {Building a cost-effective static analyser for real-world programs is still regarded an art. One key contributor to this grim reputation is the difficulty in balancing the cost and the precision of an analyser. An ideal analyser should be adaptive to a given analysis task, and avoid using techniques that unnecessarily improve precision and increase analysis cost. However, achieving this ideal is highly nontrivial, and it requires a large amount of engineering efforts. In this paper we present a new approach for building an adaptive static analyser. In our approach, the analyser includes a sophisticated parameterised strategy that decides, for each part of a given program, whether to apply a precision-improving technique to that part or not. We present a method for learning a good parameter for such a strategy from an existing codebase via Bayesian optimisation. The learnt strategy is then used for new, unseen programs. Using our approach, we developed partially flow- and context-sensitive variants of a realistic C static analyser. The experimental results demonstrate that using Bayesian optimisation is crucial for learning from an existing codebase. Also, they show that among all program queries that require flow- or context-sensitivity, our partially flow- and context-sensitive analysis answers the 75\% of them, while increasing the analysis cost only by 3.3x of the baseline flow- and context-insensitive analysis, rather than 40x or more of the fully sensitive version.},
	urldate = {2018-02-07},
	booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Oh, Hakjoo and Yang, Hongseok and Yi, Kwangkeun},
	year = {2015},
	keywords = {to read, Bayesian Optimization, rogram Analysis},
	pages = {572--588},
	file = {Oh et al. - 2015 - Learning a Strategy for Adapting a Program Analysi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NVD3XSRL\\Oh et al. - 2015 - Learning a Strategy for Adapting a Program Analysi.pdf:application/pdf}
}

@inproceedings{raghothaman_swim:_2016,
	title = {{SWIM}: {Synthesizing} {What} {I} {Mean} - {Code} {Search} and {Idiomatic} {Snippet} {Synthesis}},
	shorttitle = {{SWIM}},
	doi = {10.1145/2884781.2884808},
	abstract = {Modern programming frameworks come with large libraries, with diverse applications such as for matching regular expressions, parsing XML files and sending email. Programmers often use search engines such as Google and Bing to learn about existing APIs. In this paper, we describe SWIM, a tool which suggests code snippets given API-related natural language queries such as “generate md5 hash code”. The query does not need to contain framework-specific trivia such as the type names or methods of interest. We translate user queries into the APIs of interest using clickthrough data from the Bing search engine. Then, based on patterns learned from open-source code repositories, we synthesize idiomatic code describing the use of these APIs. We introduce structured call sequences to capture API-usage patterns. Structured call sequences are a generalized form of method call sequences, with if-branches and while-loops to represent conditional and repeated API usage patterns, and are simple to extract and amenable to synthesis. We evaluated SWIM with 30 common C\# API-related queries received by Bing. For 70\% of the queries, the first suggested snippet was a relevant solution, and a relevant solution was present in the top 10 results for all benchmarked queries. The online portion of the workflow is also very responsive, at an average of 1.5 seconds per snippet.},
	booktitle = {2016 {IEEE}/{ACM} 38th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Raghothaman, M. and Wei, Y. and Hamadi, Y.},
	month = may,
	year = {2016},
	keywords = {Data models, Libraries, Google, application program interface, application program interfaces, to read, Natural languages, API usage patterns, API-related natural language queries, Bing, C\# languages, code search, Free form queries, idiomatic snippet synthesis, method call sequences, Pattern matching, programming framework, query processing, search engines, Search engines, structured call sequences, SWIM framework, synthesizing what i mean, Web pages},
	pages = {357--367},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\UEXQEN4A\\7886917.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\NAZGWLRZ\\Raghothaman et al. - 2016 - SWIM Synthesizing What I Mean - Code Search and I.pdf:application/pdf}
}

@inproceedings{bielik_programming_2015,
	address = {Dagstuhl, Germany},
	series = {Leibniz {International} {Proceedings} in {Informatics} ({LIPIcs})},
	title = {Programming with "{Big} {Code}": {Lessons}, {Techniques} and {Applications}},
	volume = {32},
	isbn = {978-3-939897-80-4},
	shorttitle = {Programming with "{Big} {Code}"},
	url = {http://drops.dagstuhl.de/opus/volltexte/2015/5015},
	doi = {10.4230/LIPIcs.SNAPL.2015.41},
	urldate = {2018-02-07},
	booktitle = {1st {Summit} on {Advances} in {Programming} {Languages} ({SNAPL} 2015)},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Bielik, Pavol and Raychev, Veselin and Vechev, Martin},
	editor = {Ball, Thomas and Bodik, Rastislav and Krishnamurthi, Shriram and Lerner, Benjamin S. and Morrisett, Greg},
	year = {2015},
	keywords = {program analysis, to read, open-source software, probabilistic inference and learning, probabilistic tools},
	pages = {41--50},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\HWY8Y58T\\Bielik et al. - 2015 - Programming with Big Code Lessons, Techniques a.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\QYZVGKR8\\5015.html:text/html}
}

@inproceedings{nguyen_api_2016,
	address = {New York, NY, USA},
	series = {{FSE} 2016},
	title = {{API} {Code} {Recommendation} {Using} {Statistical} {Learning} from {Fine}-grained {Changes}},
	isbn = {978-1-4503-4218-6},
	url = {http://doi.acm.org/10.1145/2950290.2950333},
	doi = {10.1145/2950290.2950333},
	abstract = {Learning and remembering how to use APIs is difficult. While code-completion tools can recommend API methods, browsing a long list of API method names and their documentation is tedious. Moreover, users can easily be overwhelmed with too much information. We present a novel API recommendation approach that taps into the predictive power of repetitive code changes to provide relevant API recommendations for developers. Our approach and tool, APIREC, is based on statistical learning from fine-grained code changes and from the context in which those changes were made. Our empirical evaluation shows that APIREC correctly recommends an API call in the first position 59\% of the time, and it recommends the correct API call in the top five positions 77\% of the time. This is a significant improvement over the state-of-the-art approaches by 30-160\% for top-1 accuracy, and 10-30\% for top-5 accuracy, respectively. Our result shows that APIREC performs well even with a one-time, minimal training dataset of 50 publicly available projects.},
	urldate = {2018-02-07},
	booktitle = {Proceedings of the 2016 24th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Nguyen, Anh Tuan and Hilton, Michael and Codoban, Mihai and Nguyen, Hoan Anh and Mast, Lily and Rademacher, Eli and Nguyen, Tien N. and Dig, Danny},
	year = {2016},
	keywords = {API Recommendation, Fine-grained Code Changes, Statistical Learning},
	pages = {511--522},
	file = {Nguyen et al. - 2016 - API Code Recommendation Using Statistical Learning.pdf:C\:\\Users\\Anna\\Zotero\\storage\\W99Y927U\\Nguyen et al. - 2016 - API Code Recommendation Using Statistical Learning.pdf:application/pdf}
}

@article{niu_api_2017,
	title = {{API} usage pattern recommendation for software development},
	volume = {129},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121216301200},
	doi = {10.1016/j.jss.2016.07.026},
	abstract = {Application Programming Interfaces (APIs) facilitate pragmatic reuse and improve the productivity of software development. An API usage pattern documents a set of method calls from multiple API classes to achieve a reusable functionality. Existing approaches often use frequent-sequence mining to extract API usage patterns. However, as reported by earlier studies, frequent-sequence mining may not produce a complete set of usage patterns. In this paper, we explore the possibility of mining API usage patterns without relying on frequent-pattern mining. Our approach represents the source code as a network of object usages where an object usage is a set of method calls invoked on a single API class. We automatically extract usage patterns by clustering the data based on the co-existence relations between object usages. We conduct an empirical study using a corpus of 11,510 Android applications. The results demonstrate that our approach can effectively mine API usage patterns with high completeness and low redundancy. We observe 18\% and 38\% improvement on F-measure and response time respectively comparing to usage pattern extraction using frequent-sequence mining.},
	urldate = {2018-02-07},
	journal = {Journal of Systems and Software},
	author = {Niu, Haoran and Keivanloo, Iman and Zou, Ying},
	month = jul,
	year = {2017},
	keywords = {to read, Clustering, Object usage, Usage pattern},
	pages = {127--139},
	file = {Niu et al. - 2017 - API usage pattern recommendation for software deve.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KKY8WPHS\\Niu et al. - 2017 - API usage pattern recommendation for software deve.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EAMRJH32\\S0164121216301200.html:text/html}
}

@inproceedings{santhiar_discovering_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Discovering {Math} {APIs} by {Mining} {Unit} {Tests}},
	isbn = {978-3-642-37056-4 978-3-642-37057-1},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-37057-1_24},
	doi = {10.1007/978-3-642-37057-1_24},
	abstract = {In today’s API-rich world, programmer productivity depends heavily on the programmer’s ability to discover the required APIs. In this paper, we present a technique and tool, called MathFinder, to discover APIs for mathematical computations by mining unit tests of API methods. Given a math expression, MathFinder synthesizes pseudo-code to compute the expression by mapping its subexpressions to API method calls. For each subexpression, MathFinder searches for a method such that there is a mapping between method inputs and variables of the subexpression. The subexpression, when evaluated on the test inputs of the method under this mapping, should produce results that match the method output on a large number of tests. We implemented MathFinder as an Eclipse plugin for discovery of third-party Java APIs and performed a user study to evaluate its effectiveness. In the study, the use of MathFinder resulted in a 2x improvement in programmer productivity. In 96\% of the subexpressions queried for in the study, MathFinder retrieved the desired API methods as the top-most result. The top-most pseudo-code snippet to implement the entire expression was correct in 93\% of the cases. Since the number of methods and unit tests to mine could be large in practice, we also implement MathFinder in a MapReduce framework and evaluate its scalability and response time.},
	language = {en},
	urldate = {2018-02-07},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Santhiar, Anirudh and Pandita, Omesh and Kanade, Aditya},
	month = mar,
	year = {2013},
	pages = {327--342},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\F8ND4XGX\\Santhiar et al. - 2013 - Discovering Math APIs by Mining Unit Tests.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2BBLEKDC\\978-3-642-37057-1_24.html:text/html}
}

@incollection{barthe_easycrypt:_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{EasyCrypt}: {A} {Tutorial}},
	isbn = {978-3-319-10081-4 978-3-319-10082-1},
	shorttitle = {{\textless}{Emphasis} {FontCategory}="{SansSerif}"{\textgreater}{EasyCrypt}{\textless}/{Emphasis}{\textgreater}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-10082-1_6},
	abstract = {Cryptography plays a key role in the security of modern communication and computer infrastructures; therefore, it is of paramount importance to design cryptographic systems that yield strong security guarantees. To achieve this goal, cryptographic systems are supported by security proofs that establish an upper bound for the probability that a resource-constrained adversary is able to break the cryptographic system. In most cases, security proofs are reductionist, i.e. they construct from an (arbitrary but computationally bounded) adversary that would break the security of the cryptographic construction with some reasonable probability another computationally bounded adversary that would break a hardness assumption with reasonable probability. This approach, known as provable security, is in principle able to deliver rigorous and detailed mathematical proofs. However, new cryptographic designs (and consequently their security analyses) are increasingly complex, and there is a growing emphasis on shifting from algorithmic descriptions to implementation-level descriptions that account for implementation details, recommendations from standards when they exist, and possibly side-channels. As a consequence, cryptographic proofs are becoming increasingly error-prone and difficult to check. One promising solution to address these concerns is to develop machine-checked frameworks that support the construction and automated verification of cryptographic systems. Although many such frameworks exist for the symbolic model of cryptography, comparatively little work has been done to develop machine-checked frameworks to reason directly in the computational model commonly used by cryptographers},
	language = {en},
	urldate = {2018-02-07},
	booktitle = {Foundations of {Security} {Analysis} and {Design} {VII}},
	publisher = {Springer, Cham},
	author = {Barthe, Gilles and Dupressoir, François and Grégoire, Benjamin and Kunz, César and Schmidt, Benedikt and Strub, Pierre-Yves},
	year = {2014},
	doi = {10.1007/978-3-319-10082-1_6},
	keywords = {easycrypt},
	pages = {146--166},
	file = {Barthe et al. - 2014 - Emphasis FontCategory=SansSerifEasyCryptEmph.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7TZU6L3A\\Barthe et al. - 2014 - Emphasis FontCategory=SansSerifEasyCryptEmph.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\YTRGCKU9\\10.html:text/html}
}

@inproceedings{barthe_computer-aided_2014,
	title = {Computer-aided cryptography: some tools and applications},
	author = {Barthe, Gilles and Dupressoir, François and ́egoire, Benjamin and Schmidt, Benedikt and Strub, Pierre-Yves},
	year = {2014},
	keywords = {Computer security, Data encryption (Computer science), easycrypt},
	file = {Barthe et al. - 2014 - Computer-aided cryptography some tools and applic.pdf:C\:\\Users\\Anna\\Zotero\\storage\\QLMPR74P\\Barthe et al. - 2014 - Computer-aided cryptography some tools and applic.pdf:application/pdf}
}

@misc{noauthor_easycrypt_nodate,
	title = {{EasyCrypt}},
	url = {https://www.easycrypt.info/trac/wiki},
	urldate = {2018-02-07},
	keywords = {easycrypt},
	file = {EasyCrypt:C\:\\Users\\Anna\\Zotero\\storage\\SL69WSQM\\wiki.html:text/html}
}

@book{heys_selected_2000,
	address = {Berlin ; New York},
	series = {Lecture notes in computer science},
	title = {Selected areas in cryptography: 6th annual international workshop, {SAC}'99, {Kingston}, {Ontario}, {Canada}, {August} 9-10, 1999: proceedings},
	isbn = {978-3-540-67185-5},
	shorttitle = {Selected areas in cryptography},
	number = {1758},
	publisher = {Springer-Verlag},
	editor = {Heys, Howard and Adams, Carlisle},
	year = {2000},
	keywords = {Computer security, Data encryption (Computer science)},
	file = {tutorial-cac.pdf:C\:\\Users\\Anna\\Zotero\\storage\\N7HDCLCV\\tutorial-cac.pdf:application/pdf}
}

@misc{barthe_computer-aided_2017,
	address = {Madrid, Spain},
	title = {Computer-aided cryptography},
	url = {https://eurocrypt2017.di.ens.fr/slides/gilles-barthe.pdf},
	urldate = {2018-02-07},
	author = {Barthe, Gilles},
	month = may,
	year = {2017},
	keywords = {easycrypt},
	file = {Barthe - 2017 - Computer-aided cryptography.pdf:C\:\\Users\\Anna\\Zotero\\storage\\FS5WAMIX\\Barthe - 2017 - Computer-aided cryptography.pdf:application/pdf}
}

@misc{noauthor_easycrypt_2017,
	title = {{EasyCrypt} {Reference} {Manual}},
	url = {https://www.easycrypt.info/documentation/refman.pdf},
	month = jun,
	year = {2017},
	keywords = {easycrypt},
	file = {2017 - EasyCrypt Reference Manual.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HCNB87Z2\\2017 - EasyCrypt Reference Manual.pdf:application/pdf}
}

@misc{schmidt_lecture_2015,
	title = {Lecture 1},
	url = {https://www.easycrypt.info/trac/attachment/wiki/SchoolUMD2015/lecture1.pdf},
	urldate = {2018-02-07},
	author = {Schmidt, Benjamin},
	year = {2015},
	keywords = {easycrypt},
	file = {lecture1.pdf on SchoolUMD2015 – Attachment – EasyCrypt:C\:\\Users\\Anna\\Zotero\\storage\\A9MNJZQB\\lecture1.html:text/html}
}

@article{al-bassam_chainspace:_2017,
	title = {Chainspace: {A} {Sharded} {Smart} {Contracts} {Platform}},
	shorttitle = {Chainspace},
	url = {http://arxiv.org/abs/1708.03778},
	abstract = {Chainspace is a decentralized infrastructure, known as a distributed ledger, that supports user defined smart contracts and executes user-supplied transactions on their objects. The correct execution of smart contract transactions is verifiable by all. The system is scalable, by sharding state and the execution of transactions, and using S-BAC, a distributed commit protocol, to guarantee consistency. Chainspace is secure against subsets of nodes trying to compromise its integrity or availability properties through Byzantine Fault Tolerance (BFT), and extremely high-auditability, non-repudiation and `blockchain' techniques. Even when BFT fails, auditing mechanisms are in place to trace malicious participants. We present the design, rationale, and details of Chainspace; we argue through evaluating an implementation of the system about its scaling and other features; we illustrate a number of privacy-friendly smart contracts for smart metering, polling and banking and measure their performance.},
	urldate = {2018-02-08},
	journal = {arXiv:1708.03778 [cs]},
	author = {Al-Bassam, Mustafa and Sonnino, Alberto and Bano, Shehar and Hrycyszyn, Dave and Danezis, George},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.03778},
	keywords = {Computer Science - Cryptography and Security},
	file = {Al-Bassam et al. - 2017 - Chainspace A Sharded Smart Contracts Platform.pdf:C\:\\Users\\Anna\\Zotero\\storage\\QLEXUWHL\\Al-Bassam et al. - 2017 - Chainspace A Sharded Smart Contracts Platform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6FKWWTLA\\1708.html:text/html}
}

@mastersthesis{oberle_evaluating_2016,
	address = {Darmstadt},
	title = {Evaluating {Code}-{Similarity} {Metrics}},
	abstract = {Measuring the similarity between different fragments of program code is relevant for various application areas. Especially in the context of code clone detection, similarity measures for source code are crucial. In many cases it is useful not only to identify exact code duplicates in software systems, but also code fragments which are similar to a certain extent. Besides clone detection, notable areas of research include API-usage-pattern mining as well as API-misuse detection. Existing evaluations are largely centered around measuring precision of clone detection tools, while recall is not well known. Many tools have lots of parameters, which makes it hard to find an optimal configuration and compare them to other tools. Moreover, it is hard to find reliable reference data that allows to benchmark clone detection tools. The aim of this thesis is to evaluate existing code-similarity metrics in isolation, in order to identify their corresponding strengths and weaknesses. To this end, we provide a comprehensive benchmarking evaluation of various kinds of metrics, from lightweight text-based approaches to more sophisticated metrics based on object usage patterns. The results indicate surprising performance of textual metrics in identifying syntactic clones, and reveal weaknesses of metrics that compare code on a high abstraction level.},
	language = {Englisch},
	school = {Technische Universität Darmstadt},
	author = {Oberle, Carina},
	month = nov,
	year = {2016},
	file = {Oberle - 2016 - Evaluating Code-Similarity Metrics.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Oberle - 2016 - Evaluating Code-Similarity Metrics.pdf:application/pdf}
}

@techreport{kokoris-kogias_omniledger:_2017,
	title = {{OmniLedger}: {A} {Secure}, {Scale}-{Out}, {Decentralized} {Ledger} via {Sharding}},
	shorttitle = {{OmniLedger}},
	url = {http://eprint.iacr.org/2017/406},
	abstract = {Designing a secure permissionless distributed ledger that performs on par with centralized payment processors such as Visa is challenging. Most existing distributed ledgers are unable to "scale-out'' -- growing total processing capacity with number of participants -- and those that do compromise security or decentralization. This work presents OmniLedger, the first scale-out distributed ledger that can preserve long-term security under permissionless operation. OmniLedger ensures strong correctness and security by using a bias-resistant public randomness protocol to choose large statistically representative shards to process transactions, and by introducing an efficient cross-shard commit protocol to handle transactions affecting multiple shards atomically. In addition, OmniLedger optimizes performance via scalable intra-shard parallel transaction processing, ledger pruning via collectively-signed state blocks, and optional low-latency "trust-but-verify'' validation of low-value transactions. Evaluation of our working experimental prototype shows that OmniLedger's throughput scales linearly in the number of validators available, supporting Visa-level workloads and beyond, while confirming typical transactions in under two seconds.},
	number = {406},
	urldate = {2018-02-09},
	author = {Kokoris-Kogias, Eleftherios and Jovanovic, Philipp and Gasser, Linus and Gailly, Nicolas and Syta, Ewa and Ford, Bryan},
	year = {2017},
	keywords = {Blockchains, Decentralization, High throughput, Low latency, Scale-Out, Sharding, Trust-but-Verify},
	file = {ePrint IACR Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JHYBQT7W\\406.html:text/html;Kokoris-Kogias et al. - 2017 - OmniLedger A Secure, Scale-Out, Decentralized Led.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UE4SM7IP\\Kokoris-Kogias et al. - 2017 - OmniLedger A Secure, Scale-Out, Decentralized Led.pdf:application/pdf}
}

@inproceedings{ye_software-specific_2016,
	address = {New York, NY, USA},
	series = {{SAC} '16},
	title = {Software-specific {Part}-of-speech {Tagging}: {An} {Experimental} {Study} on {Stack} {Overflow}},
	isbn = {978-1-4503-3739-7},
	shorttitle = {Software-specific {Part}-of-speech {Tagging}},
	url = {http://doi.acm.org/10.1145/2851613.2851772},
	doi = {10.1145/2851613.2851772},
	abstract = {Part-of-speech (POS) tagging performance degrades on out-of-domain data due to the lack of domain knowledge. Software engineering knowledge, embodied in textual documentations, bug reports and online forum discussions, is expressed in natural language, but is full of domain terms, software entities and software-specific informal languages. Such software texts call for software-specific POS tagging. In the software engineering community, there have been several attempts leveraging POS tagging technique to help solve software engineering tasks. However, little work is done for POS tagging on software natural language texts. In this paper, we build a software-specific POS tagger, called S-POS, for processing the textual discussions on Stack Overflow. We target at Stack Overflow because it has become an important developer-generated knowledge repository for software engineering. We define a POS tagset that is suitable for describing software engineering knowledge, select corpus, develop a custom tokenizer, annotate data, design features for supervised model training, and demonstrate that the tagging accuracy of S-POS outperforms that of the Stanford POS Tagger when tagging software texts. Our work presents a feasible roadmap to build software-specific POS tagger for the socio-professional contents on Stack Overflow, and reveals challenges and opportunities for advanced software-specific information extraction.},
	urldate = {2018-02-09},
	booktitle = {Proceedings of the 31st {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Ye, Deheng and Xing, Zhenchang and Li, Jing and Kapre, Nachiket},
	year = {2016},
	keywords = {natural language processing, mining software repositories, information extraction, part-of-speech tagging},
	pages = {1378--1385},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\KHRLI4LX\\Ye et al. - 2016 - Software-specific Part-of-speech Tagging An Exper.pdf:application/pdf}
}

@inproceedings{olney_part_2016,
	title = {Part of {Speech} {Tagging} {Java} {Method} {Names}},
	doi = {10.1109/ICSME.2016.80},
	abstract = {Numerous software engineering tools for evolution and comprehension, including code search, comment generation, and analyzing bug reports, make use of part-of-speech (POS) information. However, many POS taggers are developed for, and trained on, natural language. In this paper, we investigate the accuracy of 9 POS taggers on over 200 source code identifiers taken from method names in open source Java programs. The set of taggers includes traditional POS taggers for English as well as some tuned to source code identifiers. Our results indicate that taggers tailored for source code are significantly more effective.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	author = {Olney, W. and Hill, E. and Thurber, C. and Lemma, B.},
	month = oct,
	year = {2016},
	keywords = {Computer bugs, Java, natural language processing, Natural languages, Tagging, object-oriented programming, part-of-speech tagging, Java method names, natural language, open source Java programs, POS information, software engineering tools, source code identifiers},
	pages = {483--487},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\AWR8JS7R\\7816499.html:text/html;Olney et al. - 2016 - Part of Speech Tagging Java Method Names.pdf:C\:\\Users\\Anna\\Zotero\\storage\\K4LREPQU\\Olney et al. - 2016 - Part of Speech Tagging Java Method Names.pdf:application/pdf}
}

@inproceedings{newman_lexical_2017,
	title = {Lexical categories for source code identifiers},
	doi = {10.1109/SANER.2017.7884624},
	abstract = {A set of lexical categories, analogous to part-of-speech categories for English prose, is defined for source-code identifiers. The lexical category for an identifier is determined from its declaration in the source code, syntactic meaning in the programming language, and static program analysis. Current techniques for assigning lexical categories to identifiers use natural-language part-of-speech taggers. However, these NLP approaches assign lexical tags based on how terms are used in English prose. The approach taken here differs in that it uses only source code to determine the lexical category. The approach assigns a lexical category to each identifier and stores this information along with each declaration. srcML is used as the infrastructure to implement the approach and so the lexical information is stored directly in the srcML markup as an additional XML element for each identifier. These lexical-category annotations can then be later used by tools that automatically generate such things as code summarization or documentation. The approach is applied to 50 open source projects and the soundness of the defined lexical categories evaluated. The evaluation shows that at every level of minimum support tested, categorization is consistent at least 79\% of the time with an overall consistency (across all supports) of at least 88\%. The categories reveal a correlation between how an identifier is named and how it is declared. This provides a syntax-oriented view (as opposed to English part-of-speech view) of developer intent of identifiers.},
	booktitle = {2017 {IEEE} 24th {International} {Conference} on {Software} {Analysis}, {Evolution} and {Reengineering} ({SANER})},
	author = {Newman, C. D. and AlSuhaibani, R. S. and Collard, M. L. and Maletic, J. I.},
	month = feb,
	year = {2017},
	keywords = {program diagnostics, public domain software, source code (software), programming language, Context, static program analysis, text analysis, natural language processing, Natural languages, Tagging, part-of-speech tagging, source code identifiers, Speech, code documentation, code summarization, Computer languages, English prose, identifier analysis, lexical category annotations, lexical information storage, Natural Language Processing, natural-language part-of-speech taggers, NLP, open source projects, program comprehension, srcML markup, syntactic meaning, Syntactics, syntax-oriented view, XML, XML element},
	pages = {228--239},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\GTFMWJBB\\7884624.html:text/html;Newman et al. - 2017 - Lexical categories for source code identifiers.pdf:C\:\\Users\\Anna\\Zotero\\storage\\4UEYABRP\\Newman et al. - 2017 - Lexical categories for source code identifiers.pdf:application/pdf}
}

@inproceedings{tong_towards_2015,
	address = {New York, NY, USA},
	series = {Internetware '15},
	title = {Towards {A} {Novel} {Approach} for {Defect} {Localization} {Based} on {Part}-of-{Speech} and {Invocation}},
	isbn = {978-1-4503-3641-3},
	url = {http://doi.acm.org/10.1145/2875913.2875919},
	doi = {10.1145/2875913.2875919},
	abstract = {Given a corpus of bug reports, software developers must read various descriptive sentences in order to identify corresponding buggy source files which potentially result in the defects. This process itself represents one of the most expensive, as well as time-consuming, activities during software maintenance and evolution. To alleviate the workload of developers, many methods have been proposed to automate this process and narrow down the scope of reviewing buggy files. In this paper, we present a novel buggy source file localization approach, leveraging both a part-of-speech based weighting strategy and the invocation relationship among source files. We also integrate an adaptive technique to strengthen the optimization of the performance. The adaptive technique consists of two modules. One is to maximize the accuracy of the first recommended file, and the other aims at improving the accuracy of the fixed defect file list. We evaluate our approach on three large-scale open source projects, i.e., ASpectJ, Eclipse, and SWT. Compared with the baseline work, our approach can improve 17.13\%, 6.29\% and 3.15\% on top 1, top 5 and top 10 respectively for ASpectJ, 6.40\%, 4.94\% and 4.39\% on top 1, top 5 and top 10 respectively for Eclipse, and 15.31\%, 8.16\% and 5.10\% on top 1, top 5 and top 10 respectively for SWT.},
	urldate = {2018-02-09},
	booktitle = {Proceedings of the 7th {Asia}-{Pacific} {Symposium} on {Internetware}},
	publisher = {ACM},
	author = {Tong, Yanxiang and Zhou, Yu and Fang, Lisheng and Chen, Taolue},
	year = {2015},
	keywords = {Bug Localization, Bug Report, Information Retrieval, Mining Software Repositories},
	pages = {52--61},
	file = {Tong et al. - 2015 - Towards A Novel Approach for Defect Localization B.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Z5K92UJQ\\Tong et al. - 2015 - Towards A Novel Approach for Defect Localization B.pdf:application/pdf}
}

@article{zhou_augmenting_2017,
	title = {Augmenting {Bug} {Localization} with {Part}-of-{Speech} and {Invocation}},
	volume = {27},
	issn = {0218-1940},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0218194017500346},
	doi = {10.1142/S0218194017500346},
	abstract = {Bug localization represents one of the most expensive, as well as time-consuming, activities during software maintenance and evolution. To alleviate the workload of developers, numerous methods have been proposed to automate this process and narrow down the scope of reviewing buggy files. In this paper, we present a novel buggy source-file localization approach, using the information from both the bug reports and the source files. We leverage the part-of-speech features of bug reports and the invocation relationship among source files. We also integrate an adaptive technique to further optimize the performance of the approach. The adaptive technique discriminates Top 1 and Top N recommendations for a given bug report and consists of two modules. One module is to maximize the accuracy of the first recommended file, and the other one aims at improving the accuracy of the fixed defect file list. We evaluate our approach on six large-scale open source projects, i.e. ASpectJ, Eclipse, SWT, Zxing, Birt and Tomcat. Compared to the previous work, empirical results show that our approach can improve the overall prediction performance in all of these cases. Particularly, in terms of the Top 1 recommendation accuracy, our approach achieves an enhancement from 22.73\% to 39.86\% for ASpectJ, from 24.36\% to 30.76\% for Eclipse, from 31.63\% to 46.94\% for SWT, from 40\% to 55\% for ZXing, from 7.97\% to 21.99\% for Birt, and from 33.37\% to 38.90\% for Tomcat.},
	number = {06},
	urldate = {2018-02-09},
	journal = {International Journal of Software Engineering and Knowledge Engineering},
	author = {Zhou, Yu and Tong, Yanxiang and Chen, Taolue and Han, Jin},
	month = jul,
	year = {2017},
	keywords = {no access},
	pages = {925--949},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\M73JZ7VX\\S0218194017500346.html:text/html}
}

@article{tian_mining_2017,
	title = {Mining software repositories for automatic software bug management from bug triaging to patch backporting},
	url = {http://ink.library.smu.edu.sg/etd_coll_all/26},
	journal = {Singapore Management University},
	author = {TIAN, Yuan},
	month = may,
	year = {2017},
	keywords = {to read},
	file = {"Mining software repositories for automatic software bug management fro" by Yuan TIAN:C\:\\Users\\Anna\\Zotero\\storage\\SJ4T9PWB\\26.html:text/html;"Mining software repositories for automatic software bug management fro" by Yuan TIAN:C\:\\Users\\Anna\\Zotero\\storage\\34UY7GSH\\26.html:text/html;TIAN - 2017 - Mining software repositories for automatic softwar.pdf:C\:\\Users\\Anna\\Zotero\\storage\\V432BH4L\\TIAN - 2017 - Mining software repositories for automatic softwar.pdf:application/pdf}
}

@inproceedings{ye_learning_2016,
	title = {Learning to {Extract} {API} {Mentions} from {Informal} {Natural} {Language} {Discussions}},
	doi = {10.1109/ICSME.2016.11},
	abstract = {When discussing programming issues on social platforms (e.g, Stack Overflow, Twitter), developers often mention APIs in natural language texts. Extracting API mentions in natural language texts is a prerequisite for effective indexing and searching for API-related information in software engineering social content. However, the informal nature of social discussions creates two fundamental challenges for API extraction: common-word polysemy and sentence-format variations. Common-word polysemy refers to the ambiguity between the API sense of a common word and the normal sense of the word (e.g., append, apply and merge). Sentence-format variations refer to the lack of consistent sentence writing format for inferring API mentions. Existing API extraction techniques fall short to address these two challenges, because they assume distinct API naming conventions (e.g., camel case, underscore) or structured sentence format (e.g., code-like phrase, API annotation, or full API name). In this paper, we propose a semi-supervised machine-learning approach that exploits name synonyms and rich semantic context of API mentions to extract API mentions in informal social text. The key innovation of our approach is to exploit two complementary unsupervised language models learned from the abundant unlabeled text to model sentence-format variations and to train a robust model with a small set of labeled data and an iterative self-training process. The evaluation of 1,205 API mentions of the three libraries (Pandas, Numpy, and Matplotlib) in Stack Overflow texts shows that our approach significantly outperforms existing API extraction techniques based on language-convention and sentence-format heuristics and our earlier machine-learning based method for named-entity recognition.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	author = {Ye, D. and Xing, Z. and Foo, C. Y. and Li, J. and Kapre, N.},
	month = oct,
	year = {2016},
	keywords = {Libraries, learning (artificial intelligence), social networking (online), Context, Software engineering, software engineering, application program interfaces, Feature extraction, text analysis, Natural languages, API mention extraction, API naming conventions, API-related information, common-word polysemy, indexing, informal natural language discussions, Joining processes, named-entity recognition, natural language texts, natural languages, semisupervised machine-learning, sentence-format variations, social platforms, software engineering social content, stack overflow texts, Standards},
	pages = {389--399},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\LKFHHG6M\\7816484.html:text/html;Ye et al. - 2016 - Learning to Extract API Mentions from Informal Nat.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JYVGENWW\\Ye et al. - 2016 - Learning to Extract API Mentions from Informal Nat.pdf:application/pdf}
}

@article{bano_consensus_2017,
	title = {Consensus in the {Age} of {Blockchains}},
	url = {http://arxiv.org/abs/1711.03936},
	abstract = {The blockchain initially gained traction in 2008 as the technology underlying bitcoin, but now has been employed in a diverse range of applications and created a global market worth over \$150B as of 2017. What distinguishes blockchains from traditional distributed databases is the ability to operate in a decentralized setting without relying on a trusted third party. As such their core technical component is consensus: how to reach agreement among a group of nodes. This has been extensively studied already in the distributed systems community for closed systems, but its application to open blockchains has revitalized the field and led to a plethora of new designs. The inherent complexity of consensus protocols and their rapid and dramatic evolution makes it hard to contextualize the design landscape. We address this challenge by conducting a systematic and comprehensive study of blockchain consensus protocols. After first discussing key themes in classical consensus protocols, we describe: first protocols based on proof-of-work (PoW), second proof-of-X (PoX) protocols that replace PoW with more energy-efficient alternatives, and third hybrid protocols that are compositions or variations of classical consensus protocols. We develop a framework to evaluate their performance, security and design properties, and use it to systematize key themes in the protocol categories described above. This evaluation leads us to identify research gaps and challenges for the community to consider in future research endeavours.},
	urldate = {2018-02-12},
	journal = {arXiv:1711.03936 [cs]},
	author = {Bano, Shehar and Sonnino, Alberto and Al-Bassam, Mustafa and Azouvi, Sarah and McCorry, Patrick and Meiklejohn, Sarah and Danezis, George},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.03936},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZRBRAAJU\\1711.html:text/html;Bano et al. - 2017 - Consensus in the Age of Blockchains.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VFNBQ27P\\Bano et al. - 2017 - Consensus in the Age of Blockchains.pdf:application/pdf}
}

@inproceedings{zhong_exposing_2013,
	address = {Berlin, Heidelberg},
	series = {{FASE}'13},
	title = {Exposing {Behavioral} {Differences} in {Cross}-language {API} {Mapping} {Relations}},
	isbn = {978-3-642-37056-4},
	url = {http://dx.doi.org/10.1007/978-3-642-37057-1_10},
	doi = {10.1007/978-3-642-37057-1_10},
	abstract = {Due to various considerations, software vendors often translate their applications from one programming language to another, either manually or with the support of translation tools. Both these scenarios require translation of many call sites of API elements (i.e., classes, methods, and fields of API libraries). API mapping relations, either acquired by experienced programmers or already incorporated in translation tools, are much valuable in the translation process, since they describe mapping relations between source API elements and their equivalent target API elements. However, in an API mapping relation, a source API element and its target API elements may have behavioral differences, and such differences could lead to defects in the translated code. So far, to the best of our knowledge, there exists no previous study for exposing or understanding such differences. In this paper, we make the first attempt to expose and analyze behavioral differences in cross-language API mapping relations. From our result, we summarize eight findings and their implications that can improve effectiveness of translation tools, and also assist programmers in understanding the differences between mapped API elements of different languages during the translation process. Some exposed behavioral differences can indicate defects in translation tools, and four such new defects were confirmed by the developers of those tools.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}},
	publisher = {Springer-Verlag},
	author = {Zhong, Hao and Thummalapenta, Suresh and Xie, Tao},
	year = {2013},
	pages = {130--145},
	file = {Zhong et al. - 2013 - Exposing Behavioral Differences in Cross-language .pdf:C\:\\Users\\Anna\\Documents\\Paper\\Zhong et al. - 2013 - Exposing Behavioral Differences in Cross-language .pdf:application/pdf}
}

@inproceedings{monshizadeh_patching_2016,
	address = {New York, NY, USA},
	series = {{CODASPY} '16},
	title = {Patching {Logic} {Vulnerabilities} for {Web} {Applications} {Using} {LogicPatcher}},
	isbn = {978-1-4503-3935-3},
	url = {http://doi.acm.org/10.1145/2857705.2857727},
	doi = {10.1145/2857705.2857727},
	abstract = {Logic vulnerabilities are an important class of programming flaws in web applications. These vulnerabilities occur when a desired property pertaining to an application's logic does not hold along certain paths in the application's code. Many analysis tools have been developed to find logic vulnerabilities in web applications. Given a web application with logic vulnerabilities, the question is whether one can design methods to patch application code and prevent these vulnerabilities from being exploited. We answer this question by developing an approach and tool called LogicPatcher for patching of logic vulnerabilities. We focus on correct patch placement, i.e. identifying the precise location in code where the patch code can be introduced, based on path profiling. As we show in this paper, finding the appropriate location as well as generating the right patch can get complicated and require deep code analysis. We demonstrate the utility of LogicPatcher by automatically fixing several critical parameter tampering and authorization vulnerabilities in large web applications.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the {Sixth} {ACM} {Conference} on {Data} and {Application} {Security} and {Privacy}},
	publisher = {ACM},
	author = {Monshizadeh, Maliheh and Naldurg, Prasad and Venkatakrishnan, V.N.},
	year = {2016},
	keywords = {static program analysis, logic vulnerabilities, patch generation, web security},
	pages = {73--84},
	file = {Monshizadeh et al. - 2016 - Patching Logic Vulnerabilities for Web Application.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XNTQU7WT\\Monshizadeh et al. - 2016 - Patching Logic Vulnerabilities for Web Application.pdf:application/pdf}
}

@inproceedings{bisht_waptec:_2011,
	address = {New York, NY, USA},
	series = {{CCS} '11},
	title = {{WAPTEC}: {Whitebox} {Analysis} of {Web} {Applications} for {Parameter} {Tampering} {Exploit} {Construction}},
	isbn = {978-1-4503-0948-6},
	shorttitle = {{WAPTEC}},
	url = {http://doi.acm.org/10.1145/2046707.2046774},
	doi = {10.1145/2046707.2046774},
	abstract = {Parameter tampering attacks are dangerous to a web application whose server fails to replicate the validation of user-supplied data that is performed by the client. Malicious users who circumvent the client can capitalize on the missing server validation. In this paper, we describe WAPTEC, a tool that is designed to automatically identify parameter tampering vulnerabilities and generate exploits by construction to demonstrate those vulnerabilities. WAPTEC involves a new approach to whitebox analysis of the server's code. We tested WAPTEC on six open source applications and found previously unknown vulnerabilities in every single one of them.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Bisht, Prithvi and Hinrichs, Timothy and Skrupsky, Nazari and Venkatakrishnan, V. N.},
	year = {2011},
	keywords = {program analysis, constraint solving, exploit construction, parameter tampering},
	pages = {575--586},
	file = {Bisht et al. - 2011 - WAPTEC Whitebox Analysis of Web Applications for .pdf:C\:\\Users\\Anna\\Zotero\\storage\\HHBF9ELR\\Bisht et al. - 2011 - WAPTEC Whitebox Analysis of Web Applications for .pdf:application/pdf}
}

@inproceedings{yamaguchi_chucky:_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {Chucky: {Exposing} {Missing} {Checks} in {Source} {Code} for {Vulnerability} {Discovery}},
	isbn = {978-1-4503-2477-9},
	shorttitle = {Chucky},
	url = {http://doi.acm.org/10.1145/2508859.2516665},
	doi = {10.1145/2508859.2516665},
	abstract = {Uncovering security vulnerabilities in software is a key for operating secure systems. Unfortunately, only some security flaws can be detected automatically and the vast majority of vulnerabilities is still identified by tedious auditing of source code. In this paper, we strive to improve this situation by accelerating the process of manual auditing. We introduce Chucky, a method to expose missing checks in source code. Many vulnerabilities result from insufficient input validation and thus omitted or false checks provide valuable clues for finding security flaws. Our method proceeds by statically tainting source code and identifying anomalous or missing conditions linked to security-critical objects.In an empirical evaluation with five popular open-source projects, Chucky is able to accurately identify artificial and real missing checks, which ultimately enables us to uncover 12 previously unknown vulnerabilities in two of the projects (Pidgin and LibTIFF).},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \& {Communications} {Security}},
	publisher = {ACM},
	author = {Yamaguchi, Fabian and Wressnegger, Christian and Gascon, Hugo and Rieck, Konrad},
	year = {2013},
	keywords = {static analysis, vulnerabilities, anomaly detection},
	pages = {499--510},
	file = {Yamaguchi et al. - 2013 - Chucky Exposing Missing Checks in Source Code for.pdf:C\:\\Users\\Anna\\Zotero\\storage\\G6632IA9\\Yamaguchi et al. - 2013 - Chucky Exposing Missing Checks in Source Code for.pdf:application/pdf}
}

@article{xing_api-evolution_2007,
	title = {{API}-{Evolution} {Support} with {Diff}-{CatchUp}},
	volume = {33},
	issn = {0098-5589},
	doi = {10.1109/TSE.2007.70747},
	abstract = {Applications built on reusable component frameworks are subject to two independent, and potentially conflicting, evolution processes. The application evolves in response to the specific requirements and desired qualities of the application's stakeholders. On the other hand, the evolution of the component framework is driven by the need to improve the framework functionality and quality while maintaining its generality. Thus, changes to the component framework frequently change its API on which its client applications rely and, as a result, these applications break. To date, there has been some work aimed at supporting the migration of client applications to newer versions of their underlying frameworks, but it usually requires that the framework developers do additional work for that purpose or that the application developers use the same tools as the framework developers. In this paper, we discuss our approach to tackle the API-evolution problem in the context of reuse-based software development, which automatically recognizes the API changes of the reused framework and proposes plausible replacements to the "obsolete" API based on working examples of the framework code base. This approach has been implemented in the Diff-CatchUp tool. We report on two case studies that we have conducted to evaluate the effectiveness of our approach with its Diff-CatchUp prototype.},
	number = {12},
	journal = {IEEE Transactions on Software Engineering},
	author = {Xing, Z. and Stroulia, E.},
	month = dec,
	year = {2007},
	keywords = {software tools, software maintenance, API evolution, application program interfaces, object-oriented programming, software quality, API-evolution support, client application migration, component framework functionality, component framework maintenance, component framework quality, D.2.10.g Object-oriented design methods, D.2.2.eProgrammer workbench, D.2.3.aObject-oriented programming, D.2.3Coding Tools and Techniques, Diff-CatchUp tool, reusable component framework evolution, reuse-based software development, software prototyping, software reusability},
	pages = {818--836},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\2NYZCHGL\\4359473.html:text/html;Xing und Stroulia - 2007 - API-Evolution Support with Diff-CatchUp.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MIBA2J7R\\Xing und Stroulia - 2007 - API-Evolution Support with Diff-CatchUp.pdf:application/pdf}
}

@inproceedings{meng_history-based_2012,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '12},
	title = {A {History}-based {Matching} {Approach} to {Identification} of {Framework} {Evolution}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337265},
	abstract = {In practice, it is common that a framework and its client programs evolve simultaneously. Thus, developers of client programs may need to migrate their programs to the new release of the framework when the framework evolves. As framework developers can hardly always guarantee backward compatibility during the evolution of a framework, migration of its client program is often time-consuming and error-prone. To facilitate this migration, researchers have proposed two categories of approaches to identification of framework evolution: operation-based approaches and matching-based approaches. To overcome the main limitations of the two categories of approaches, we propose a novel approach named HiMa, which is based on matching each pair of consecutive revisions recorded in the evolution history of the framework and aggregating revision-level rules to obtain framework-evolution rules. We implemented our HiMa approach as an Eclipse plug-in targeting at frameworks written in Java using SVN as the versioncontrol system. We further performed an experimental study on HiMa together with a state-of-art approach named AURA using six tasks based on three subject Java frameworks. Our experimental results demonstrate that HiMa achieves higher precision and higher recall than AURA in most circumstances and is never inferior to AURA in terms of precision and recall in any circumstances, although HiMa is computationally more costly than AURA.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Meng, Sichen and Wang, Xiaoyin and Zhang, Lu and Mei, Hong},
	year = {2012},
	pages = {353--363},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\IRYKHTV3\\Meng et al. - 2012 - A History-based Matching Approach to Identificatio.pdf:application/pdf}
}

@inproceedings{tan_/*icomment:_2007,
	address = {New York, NY, USA},
	series = {{SOSP} '07},
	title = {/*{Icomment}: {Bugs} or {Bad} {Comments}?*/},
	isbn = {978-1-59593-591-5},
	shorttitle = {/*{Icomment}},
	url = {http://doi.acm.org/10.1145/1294261.1294276},
	doi = {10.1145/1294261.1294276},
	abstract = {Commenting source code has long been a common practice in software development. Compared to source code, comments are more direct, descriptive and easy-to-understand. Comments and sourcecode provide relatively redundant and independent information regarding a program's semantic behavior. As software evolves, they can easily grow out-of-sync, indicating two problems: (1) bugs -the source code does not follow the assumptions and requirements specified by correct program comments; (2) bad comments - comments that are inconsistent with correct code, which can confuse and mislead programmers to introduce bugs in subsequent versions. Unfortunately, as most comments are written in natural language, no solution has been proposed to automatically analyze commentsand detect inconsistencies between comments and source code. This paper takes the first step in automatically analyzing commentswritten in natural language to extract implicit program rulesand use these rules to automatically detect inconsistencies between comments and source code, indicating either bugs or bad comments. Our solution, iComment, combines Natural Language Processing(NLP), Machine Learning, Statistics and Program Analysis techniques to achieve these goals. We evaluate iComment on four large code bases: Linux, Mozilla, Wine and Apache. Our experimental results show that iComment automatically extracts 1832 rules from comments with 90.8-100\% accuracy and detects 60 comment-code inconsistencies, 33 newbugs and 27 bad comments, in the latest versions of the four programs. Nineteen of them (12 bugs and 7 bad comments) have already been confirmed by the corresponding developers while the others are currently being analyzed by the developers.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of {Twenty}-first {ACM} {SIGOPS} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Tan, Lin and Yuan, Ding and Krishna, Gopal and Zhou, Yuanyuan},
	year = {2007},
	keywords = {comment analysis, natural language processing for software engineering, programming rules and static analysis},
	pages = {145--158},
	file = {Tan et al. - 2007 - Icomment Bugs or Bad Comments.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CV9WTH4I\\Tan et al. - 2007 - Icomment Bugs or Bad Comments.pdf:application/pdf}
}

@inproceedings{tan_acomment:_2011,
	address = {New York, NY, USA},
	series = {{ICSE} '11},
	title = {{aComment}: {Mining} {Annotations} from {Comments} and {Code} to {Detect} {Interrupt} {Related} {Concurrency} {Bugs}},
	isbn = {978-1-4503-0445-0},
	shorttitle = {{aComment}},
	url = {http://doi.acm.org/10.1145/1985793.1985796},
	doi = {10.1145/1985793.1985796},
	abstract = {Concurrency bugs in an operating system (OS) are detrimental as they can cause the OS to fail and affect all applications running on top of the OS. Detecting OS concurrency bugs is challenging due to the complexity of the OS synchronization, particularly with the presence of the OS specific interrupt context. Existing dynamic concurrency bug detection techniques are designed for user level applications and cannot be applied to operating systems. To detect OS concurrency bugs, we proposed a new type of annotations - interrupt related annotations - and generated 96,821 such annotations for the Linux kernel with little manual effort. These annotations have been used to automatically detect 9 real OS concurrency bugs (7 of which were previously unknown). Two of the key techniques that make the above contributions possible are: (1) using a hybrid approach to extract annotations from both code and comments written in natural language to achieve better coverage and accuracy in annotation extraction and bug detection; and (2) automatically propagating annotations to caller functions to improve annotating and bug detection. These two techniques are general and can be applied to non-OS code, code written in other programming languages such as Java, and for extracting other types of specifications.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Tan, Lin and Zhou, Yuanyuan and Padioleau, Yoann},
	year = {2011},
	keywords = {static analysis, comment analysis, annotation languages, concurrency bug detection, interrupts, operating systems, two sources -{\textgreater} improved result},
	pages = {11--20},
	file = {Tan et al. - 2011 - aComment Mining Annotations from Comments and Cod.pdf:C\:\\Users\\Anna\\Zotero\\storage\\4I6RYW3F\\Tan et al. - 2011 - aComment Mining Annotations from Comments and Cod.pdf:application/pdf}
}

@inproceedings{shi_empirical_2011,
	address = {Berlin, Heidelberg},
	series = {{FASE}'11/{ETAPS}'11},
	title = {An {Empirical} {Study} on {Evolution} of {API} {Documentation}},
	isbn = {978-3-642-19810-6},
	url = {http://dl.acm.org/citation.cfm?id=1987434.1987473},
	abstract = {With the evolution of an API library, its documentation also evolves. The evolution of API documentation is common knowledge for programmers and library developers, but not in a quantitative form. Without such quantitative knowledge, programmers may neglect important revisions of API documentation, and library developers may not effectively improve API documentation based on its revision histories. There is a strong need to conduct a quantitative study on API documentation evolution. However, as API documentation is large in size and revisions can be complicated, it is quite challenging to conduct such a study. In this paper, we present an analysis methodology to analyze the evolution of API documentation. Based on the methodology, we conduct a quantitative study on API documentation evolution of five widely used real-world libraries. The results reveal various valuable findings, and these findings allow programmers and library developers to better understand API documentation evolution.},
	urldate = {2018-02-14},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}: {Part} of the {Joint} {European} {Conferences} on {Theory} and {Practice} of {Software}},
	publisher = {Springer-Verlag},
	author = {Shi, Lin and Zhong, Hao and Xie, Tao and Li, Mingshu},
	year = {2011},
	pages = {416--431}
}

@article{nayebi_app_2018,
	title = {App {Store} {Mining} is {Not} {Enough} for {App} {Improvement}},
	abstract = {The rise in popularity of mobile devices has led to a parallel growth in the size of the app store market, intriguing several research studies and commercial platforms on mining app stores. App store reviews are used to analyze different aspects of app development and evolution. However, app users’ feedback does not only exist on the app store. In fact, despite the large quantity of posts that are made daily on social media, the importance and value that these discussions provide remain mostly unused in the context of mobile app development. In this paper, we study how Twitter can provide complementary information to support mobile app development. By analyzing a total of 30,793 apps over a period of six weeks, we found strong correlations between the number of reviews and tweets for most apps. Moreover, through applying machine learning classifiers, topic modeling and subsequent crowd-sourcing, we successfully mined 22.4\% additional feature requests and 12.89\% additional bug reports from Twitter. We also found that 52.1\% of all feature requests and bug reports were discussed on both tweets and reviews. In addition to finding common and unique information from Twitter and the app store, sentiment and content analysis were also performed for 70 randomly selected apps. From this, we found that tweets provided more critical and objective views on apps than reviews from the app store. These results show that app store review mining is indeed not enough; other information sources ultimately provide added value and information for app developers.},
	author = {Nayebi, Maleknaz and Cho, Henry and Ruhe, Guenther},
	year = {2018},
	keywords = {to read, incomplete},
	file = {Nayebi et al. - 2018 - App Store Mining is Not Enough for App Improvement.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KJHWSTBY\\Nayebi et al. - 2018 - App Store Mining is Not Enough for App Improvement.pdf:application/pdf}
}

@inproceedings{nayebi_app_2017,
	address = {Piscataway, NJ, USA},
	series = {{ICSE}-{C} '17},
	title = {App {Store} {Mining} is {Not} {Enough}},
	isbn = {978-1-5386-1589-8},
	url = {https://doi.org/10.1109/ICSE-C.2017.77},
	doi = {10.1109/ICSE-C.2017.77},
	abstract = {App store reviews are currently the main source of information for analyzing different aspects of app development and evolution. However, app users' feedback do not only occur on the app store. In fact, a large quantity of posts about apps are made daily on social media. In this paper, we study how Twitter can provide complementary information to support mobile app development. By analysing a total of 70 apps over a period of six weeks, we show that 22.4\% more feature requests and 12.89\% more bug reports could be found on Twitter.},
	urldate = {2018-02-15},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Software} {Engineering} {Companion}},
	publisher = {IEEE Press},
	author = {Nayebi, Maleknaz and Farrahi, Homayoon and Ruhe, Guenther and Cho, Henry},
	year = {2017},
	keywords = {machine learning, app store mining, mobile apps, topic modeling, Twitter},
	pages = {152--154},
	file = {Nayebi et al. - 2017 - App Store Mining is Not Enough.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TFBYASB5\\Nayebi et al. - 2017 - App Store Mining is Not Enough.pdf:application/pdf}
}

@inproceedings{wang_bugram:_2016,
	address = {New York, NY, USA},
	series = {{ASE} 2016},
	title = {Bugram: {Bug} {Detection} with {N}-gram {Language} {Models}},
	isbn = {978-1-4503-3845-5},
	shorttitle = {Bugram},
	url = {http://doi.acm.org/10.1145/2970276.2970341},
	doi = {10.1145/2970276.2970341},
	abstract = {To improve software reliability, many rule-based techniques have been proposed to infer programming rules and detect violations of these rules as bugs. These rule-based approaches often rely on the highly frequent appearances of certain patterns in a project to infer rules. It is known that if a pattern does not appear frequently enough, rules are not learned, thus missing many bugs.   In this paper, we propose a new approach—Bugram—that leverages n-gram language models instead of rules to detect bugs. Bugram models program tokens sequentially, using the n-gram language model. Token sequences from the program are then assessed according to their probability in the learned model, and low probability sequences are marked as potential bugs. The assumption is that low probability token sequences in a program are unusual, which may indicate bugs, bad practices, or unusual/special uses of code of which developers may want to be aware.   We evaluate Bugram in two ways. First, we apply Bugram on the latest versions of 16 open source Java projects. Results show that Bugram detects 59 bugs, 42 of which are manually verified as correct, 25 of which are true bugs and 17 are code snippets that should be refactored. Among the 25 true bugs, 23 cannot be detected by PR-Miner. We have reported these bugs to developers, 7 of which have already been confirmed by developers (4 of them have already been fixed), while the rest await confirmation. Second, we further compare Bugram with three additional graph- and rule-based bug detection tools, i.e., JADET, Tikanga, and GrouMiner. We apply Bugram on 14 Java projects evaluated in these three studies. Bugram detects 21 true bugs, at least 10 of which cannot be detected by these three tools. Our results suggest that Bugram is complementary to existing rule-based bug detection approaches.},
	urldate = {2018-02-19},
	booktitle = {Proceedings of the 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM},
	author = {Wang, Song and Chollak, Devin and Movshovitz-Attias, Dana and Tan, Lin},
	year = {2016},
	keywords = {mining software repositories, Bug Detection, N-gram Language Model, Static Code Analysis},
	pages = {708--719},
	file = {Wang et al. - 2016 - Bugram Bug Detection with N-gram Language Models.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NA4P8E5K\\Wang et al. - 2016 - Bugram Bug Detection with N-gram Language Models.pdf:application/pdf}
}

@inproceedings{ray_naturalness_2016,
	address = {New York, NY, USA},
	series = {{ICSE} '16},
	title = {On the "{Naturalness}" of {Buggy} {Code}},
	isbn = {978-1-4503-3900-1},
	url = {http://doi.acm.org/10.1145/2884781.2884848},
	doi = {10.1145/2884781.2884848},
	abstract = {Real software, the kind working programmers produce by the kLOC to solve real-world problems, tends to be "natural", like speech or natural language; it tends to be highly repetitive and predictable. Researchers have captured this naturalness of software through statistical models and used them to good effect in suggestion engines, porting tools, coding standards checkers, and idiom miners. This suggests that code that appears improbable, or surprising, to a good statistical language model is "unnatural" in some sense, and thus possibly suspicious. In this paper, we investigate this hypothesis. We consider a large corpus of bug fix commits (ca. 7,139), from 10 different Java projects, and focus on its language statistics, evaluating the naturalness of buggy code and the corresponding fixes. We find that code with bugs tends to be more entropic (i.e. unnatural), becoming less so as bugs are fixed. Ordering files for inspection by their average entropy yields cost-effectiveness scores comparable to popular defect prediction methods. At a finer granularity, focusing on highly entropic lines is similar in cost-effectiveness to some well-known static bug finders (PMD, FindBugs) and ordering warnings from these bug finders using an entropy measure improves the cost-effectiveness of inspecting code implicated in warnings. This suggests that entropy may be a valid, simple way to complement the effectiveness of PMD or FindBugs, and that search-based bug-fixing methods may benefit from using entropy both for fault-localization and searching for fixes.},
	urldate = {2018-02-19},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Ray, Baishakhi and Hellendoorn, Vincent and Godhane, Saheel and Tu, Zhaopeng and Bacchelli, Alberto and Devanbu, Premkumar},
	year = {2016},
	pages = {428--439},
	file = {Ray et al. - 2016 - On the Naturalness of Buggy Code.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XX2XPPI9\\Ray et al. - 2016 - On the Naturalness of Buggy Code.pdf:application/pdf}
}

@inproceedings{wu_tracing_2018,
	address = {New York, NY, USA},
	series = {{WSDM} '18},
	title = {Tracing {Fake}-{News} {Footprints}: {Characterizing} {Social} {Media} {Messages} by {How} {They} {Propagate}},
	isbn = {978-1-4503-5581-0},
	shorttitle = {Tracing {Fake}-{News} {Footprints}},
	url = {http://doi.acm.org/10.1145/3159652.3159677},
	doi = {10.1145/3159652.3159677},
	abstract = {When a message, such as a piece of news, spreads in social networks, how can we classify it into categories of interests, such as genuine or fake news? Classification of social media content is a fundamental task for social media mining, and most existing methods regard it as a text categorization problem and mainly focus on using content features, such as words and hashtags. However, for many emerging applications like fake news and rumor detection, it is very challenging, if not impossible, to identify useful features from content. For example, intentional spreaders of fake news may manipulate the content to make it look like real news. To address this problem, this paper concentrates on modeling the propagation of messages in a social network. Specifically, we propose a novel approach, TraceMiner, to (1) infer embeddings of social media users with social network structures; and (2) utilize an LSTM-RNN to represent and classify propagation pathways of a message. Since content information is sparse and noisy on social media, adopting TraceMiner allows to provide a high degree of classification accuracy even in the absence of content information. Experimental results on real-world datasets show the superiority over state-of-the-art approaches on the task of fake news detection and news categorization.},
	urldate = {2018-02-19},
	booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Wu, Liang and Liu, Huan},
	year = {2018},
	keywords = {classification, fake news detection, graph mining, misinformation, social media mining, social network analysis},
	pages = {637--645},
	file = {Wu und Liu - 2018 - Tracing Fake-News Footprints Characterizing Socia.pdf:C\:\\Users\\Anna\\Zotero\\storage\\8QJB769A\\Wu und Liu - 2018 - Tracing Fake-News Footprints Characterizing Socia.pdf:application/pdf}
}

@article{qiu_network_2017,
	title = {Network {Embedding} as {Matrix} {Factorization}: {Unifying} {DeepWalk}, {LINE}, {PTE}, and node2vec},
	shorttitle = {Network {Embedding} as {Matrix} {Factorization}},
	url = {https://scirate.com/arxiv/1710.02971},
	abstract = {Since the invention of word2vec, the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk empirically produces a low-rank transformation of a network's normalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk when the size of vertices' context is set to one; (3) As an extension of LINE, PTE can be viewed as the joint factorization of multiple networks' Laplacians; (4) node2vec is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.},
	language = {en},
	urldate = {2018-02-19},
	journal = {SciRate},
	author = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
	month = oct,
	year = {2017},
	keywords = {to read, not yet},
	file = {Qiu et al. - 2017 - Network Embedding as Matrix Factorization Unifyin.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5DQLWPY8\\Qiu et al. - 2017 - Network Embedding as Matrix Factorization Unifyin.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\5ZSCGBX9\\1710.html:text/html}
}

@inproceedings{beutel_latent_2018,
	address = {New York, NY, USA},
	series = {{WSDM} '18},
	title = {Latent {Cross}: {Making} {Use} of {Context} in {Recurrent} {Recommender} {Systems}},
	isbn = {978-1-4503-5581-0},
	shorttitle = {Latent {Cross}},
	url = {http://doi.acm.org/10.1145/3159652.3159727},
	doi = {10.1145/3159652.3159727},
	abstract = {The success of recommender systems often depends on their ability to understand and make use of the context of the recommendation request. Significant research has focused on how time, location, interfaces, and a plethora of other contextual features affect recommendations. However, in using deep neural networks for recommender systems, researchers often ignore these contexts or incorporate them as ordinary features in the model. In this paper, we study how to effectively treat contextual data in neural recommender systems. We begin with an empirical analysis of the conventional approach to context as features in feed-forward recommenders and demonstrate that this approach is inefficient in capturing common feature crosses. We apply this insight to design a state-of-the-art RNN recommender system. We first describe our RNN-based recommender system in use at YouTube. Next, we offer "Latent Cross," an easy-to-use technique to incorporate contextual data in the RNN by embedding the context feature first and then performing an element-wise product of the context embedding with model's hidden states. We demonstrate the improvement in performance by using this Latent Cross technique in multiple experimental settings.},
	urldate = {2018-02-19},
	booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Beutel, Alex and Covington, Paul and Jain, Sagar and Xu, Can and Li, Jia and Gatto, Vince and Chi, Ed H.},
	year = {2018},
	keywords = {machine learning, contextual recommendation, recommender system, recurrent neural network, not yet},
	pages = {46--54},
	file = {Beutel et al. - 2018 - Latent Cross Making Use of Context in Recurrent R.pdf:C\:\\Users\\Anna\\Zotero\\storage\\YDEW4S5K\\Beutel et al. - 2018 - Latent Cross Making Use of Context in Recurrent R.pdf:application/pdf}
}

@inproceedings{bui_neural_2018,
	title = {Neural {Graph} {Learning}: {Training} {Neural} {Networks} {Using} {Graphs}},
	isbn = {978-1-4503-5581-0},
	shorttitle = {Neural {Graph} {Learning}},
	url = {http://dl.acm.org/citation.cfm?doid=3159652.3159731},
	doi = {10.1145/3159652.3159731},
	language = {en},
	urldate = {2018-02-19},
	publisher = {ACM Press},
	author = {Bui, Thang D. and Ravi, Sujith and Ramavajjala, Vivek},
	year = {2018},
	keywords = {to read, machine learning, not yet},
	pages = {64--71},
	file = {Bui et al. - 2018 - Neural Graph Learning Training Neural Networks Us.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CJV3PUDY\\Bui et al. - 2018 - Neural Graph Learning Training Neural Networks Us.pdf:application/pdf}
}

@misc{wilding_revisiting_2018,
	title = {Revisiting the {Habits} of {Highly} {Effective} {People}},
	url = {https://medium.com/s/the-test-of-time/revisiting-the-habits-of-highly-effective-people-ebceca669193},
	language = {Englisch},
	urldate = {2018-02-19},
	journal = {Medium - The Test of Time},
	author = {Wilding, Melody},
	month = feb,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7ZQ7ZYM3\\revisiting-the-habits-of-highly-effective-people-ebceca669193.html:text/html}
}

@misc{noauthor_active_nodate,
	title = {Active {Listening}: {Hear} {What} {People} are {Really} {Saying}},
	shorttitle = {Active {Listening}},
	url = {http://www.mindtools.com/CommSkll/ActiveListening.htm},
	abstract = {Learn how to use active listening techniques, which are a valuable listening skill, to make a conscious effort to understand what people are really saying.},
	language = {en},
	urldate = {2018-02-19},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\NERQGS5N\\ActiveListening.html:text/html}
}

@misc{wilding_for_2015,
	title = {For {Peak} {Performance}, {Schedule} {Your} {Mental} {Maintenance}},
	url = {https://medium.com/@melodywilding/for-peak-performance-schedule-your-mental-maintenance-da9704d6c114},
	abstract = {When you’re at the top of your professional game, you’re using your brain on perpetual overdrive.},
	urldate = {2018-02-19},
	journal = {Medium},
	author = {Wilding, Melody},
	month = mar,
	year = {2015},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IMSFBTUY\\for-peak-performance-schedule-your-mental-maintenance-da9704d6c114.html:text/html}
}

@article{gardiner_abcde_2012,
	title = {The {ABCDE} of writing: coaching high-quality high-quantity writing},
	volume = {7},
	shorttitle = {The {ABCDE} of writing},
	number = {2},
	journal = {International Coaching Psychology Review},
	author = {Gardiner, Maria and Kearns, Hugh and Newsom, G. and Dent, E. B. and Newnham-Kanas, C. and Irwin, J. and Schmitt, N.},
	year = {2012},
	pages = {247--259},
	file = {Gardiner et al. - 2012 - The ABCDE of writing coaching high-quality high-q.pdf:C\:\\Users\\Anna\\Zotero\\storage\\YC696K4I\\Gardiner et al. - 2012 - The ABCDE of writing coaching high-quality high-q.pdf:application/pdf}
}

@article{kearns_waiting_2011,
	title = {Waiting for the motivation fairy},
	volume = {472},
	number = {7341},
	journal = {Nature},
	author = {Kearns, Hugh and Gardiner, Maria},
	year = {2011},
	pages = {127--127},
	file = {Kearns und Gardiner - 2011 - Waiting for the motivation fairy.pdf:C\:\\Users\\Anna\\Zotero\\storage\\D49G8EKW\\Kearns und Gardiner - 2011 - Waiting for the motivation fairy.pdf:application/pdf}
}

@inproceedings{chaudhari_putting_2018,
	address = {New York, NY, USA},
	series = {{WSDM} '18},
	title = {Putting {Data} in the {Driver}'s {Seat}: {Optimizing} {Earnings} for {On}-{Demand} {Ride}-{Hailing}},
	isbn = {978-1-4503-5581-0},
	shorttitle = {Putting {Data} in the {Driver}'s {Seat}},
	url = {http://doi.acm.org/10.1145/3159652.3159721},
	doi = {10.1145/3159652.3159721},
	abstract = {On-demand ride-hailing platforms like Uber and Lyft are helping reshape urban transportation, by enabling car owners to become drivers for hire with minimal overhead. Although there are many studies that consider ride-hailing platforms holistically, e.g., from the perspective of supply and demand equilibria, little emphasis has been placed on optimization for the individual, self-interested drivers that currently comprise these fleets. While some individuals drive opportunistically either as their schedule allows or on a fixed schedule, we show that strategic behavior regarding when and where to drive can substantially increase driver income. In this paper, we formalize the problem of devising a driver strategy to maximize expected earnings, describe a series of dynamic programming algorithms to solve these problems under different sets of modeled actions available to the drivers, and exemplify the models and methods on a large scale simulation of driving for Uber in NYC. In our experiments, we use a newly-collected dataset that combines the NYC taxi rides dataset along with Uber API data, to build time-varying traffic and payout matrices for a representative six-month time period in greater NYC. From this input, we can reason about prospective itineraries and payoffs. Moreover, the framework enables us to rigorously reason about and analyze the sensitivity of our results to perturbations in the input data. Among our main findings is that repositioning throughout the day is key to maximizing driver earnings, whereas »chasing surge' is typically misguided and sometimes a costly move.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-02-20},
	booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Chaudhari, Harshal A. and Byers, John W. and Terzi, Evimaria},
	year = {2018},
	keywords = {on-demand ride-hailing, sharing economy, surge pricing, uncertainty},
	pages = {90--98},
	file = {Chaudhari et al. - 2018 - Putting Data in the Driver's Seat Optimizing Earn.pdf:C\:\\Users\\Anna\\Zotero\\storage\\E6W8MLMA\\Chaudhari et al. - 2018 - Putting Data in the Driver's Seat Optimizing Earn.pdf:application/pdf}
}

@misc{noauthor_presentation_nodate,
	title = {Presentation {Zen}},
	url = {http://www.presentationzen.com/presentationzen/},
	abstract = {Best-selling author Garr Reynolds's popular website on how to design \& deliver powerful presentations including TED Talks and other forms of 21st-century presentation and digital storytelling.},
	urldate = {2018-02-21},
	journal = {Presentation Zen},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MPZ8JTIZ\\www.presentationzen.com.html:text/html}
}

@inproceedings{tu_localness_2014,
	address = {New York, NY, USA},
	series = {{FSE} 2014},
	title = {On the {Localness} of {Software}},
	isbn = {978-1-4503-3056-5},
	url = {http://doi.acm.org/10.1145/2635868.2635875},
	doi = {10.1145/2635868.2635875},
	abstract = {The n-gram language model, which has its roots in statistical natural language processing, has been shown to successfully capture the repetitive and predictable regularities (“naturalness") of source code, and help with tasks such as code suggestion, porting, and designing assistive coding devices. However, we show in this paper that this natural-language-based model fails to exploit a special property of source code: localness. We find that human-written programs are localized: they have useful local regularities that can be captured and exploited. We introduce a novel cache language model that consists of both an n-gram and an added “cache" component to exploit localness. We show empirically that the additional cache component greatly improves the n-gram approach by capturing the localness of software, as measured by both cross-entropy and suggestion accuracy. Our model’s suggestion accuracy is actually comparable to a state-of-the-art, semantically augmented language model; but it is simpler and easier to implement. Our cache language model requires nothing beyond lexicalization, and thus is applicable to all programming languages.},
	urldate = {2018-02-22},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Tu, Zhaopeng and Su, Zhendong and Devanbu, Premkumar},
	year = {2014},
	keywords = {to read, Cache Language Model, Code Suggestion, Localness},
	pages = {269--280},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\22EWMEUY\\Tu et al. - 2014 - On the Localness of Software.pdf:application/pdf}
}

@inproceedings{herzig_impact_2013,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '13},
	title = {The {Impact} of {Tangled} {Code} {Changes}},
	isbn = {978-1-4673-2936-1},
	url = {http://dl.acm.org/citation.cfm?id=2487085.2487113},
	booktitle = {Proceedings of the 10th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Herzig, Kim and Zeller, Andreas},
	year = {2013},
	pages = {121--130},
	file = {Herzig und Zeller - 2013 - The Impact of Tangled Code Changes.pdf:C\:\\Users\\Anna\\Zotero\\storage\\65WTKIXE\\Herzig und Zeller - 2013 - The Impact of Tangled Code Changes.pdf:application/pdf}
}

@inproceedings{hindle_naturalness_2012,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '12},
	title = {On the {Naturalness} of {Software}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337322},
	abstract = {Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition, natural language translation, question-answering, and text mining and comprehension. We begin with the conjecture that most software is also natural, in the sense that it is created by humans at work, with all the attendant constraints and limitations---and thus, like natural language, it is also likely to be repetitive and predictable. We then proceed to ask whether a) code can be usefully modeled by statistical language models and b) such models can be leveraged to support software engineers. Using the widely adopted n-gram model, we provide empirical evidence supportive of a positive answer to both these questions. We show that code is also very repetitive, and in fact even more so than natural languages. As an example use of the model, we have developed a simple code completion engine for Java that, despite its simplicity, already improves Eclipse's completion capability. We conclude the paper by laying out a vision for future research in this area.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Hindle, Abram and Barr, Earl T. and Su, Zhendong and Gabel, Mark and Devanbu, Premkumar},
	year = {2012},
	pages = {837--847},
	file = {Hindle et al. - 2012 - On the Naturalness of Software.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Z5MBLL9I\\Hindle et al. - 2012 - On the Naturalness of Software.pdf:application/pdf}
}

@inproceedings{allamanis_learning_2014,
	address = {New York, NY, USA},
	series = {{FSE} 2014},
	title = {Learning {Natural} {Coding} {Conventions}},
	isbn = {978-1-4503-3056-5},
	url = {http://doi.acm.org/10.1145/2635868.2635883},
	doi = {10.1145/2635868.2635883},
	abstract = {Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project’s coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately, programmers are often unaware of coding conventions because inferring them requires a global view, one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE, a framework that learns the style of a codebase, and suggests revisions to improve stylistic consistency. NATURALIZE builds on recent work in applying statistical natural language processing to source code. We apply NATURALIZE to suggest natural identifier names and formatting conventions. We present four tools focused on ensuring natural code during development and release management, including code review. NATURALIZE achieves 94 \% accuracy in its top suggestions for identifier names. We used NATURALIZE to generate 18 patches for 5 open source projects: 14 were accepted.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles},
	year = {2014},
	keywords = {to read, Coding conventions, naturalness of software},
	pages = {281--293},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DYXCBXZU\\Allamanis et al. - 2014 - Learning Natural Coding Conventions.pdf:application/pdf}
}

@inproceedings{thummalapenta_alattin:_2009,
	address = {Washington, DC, USA},
	series = {{ASE} '09},
	title = {Alattin: {Mining} {Alternative} {Patterns} for {Detecting} {Neglected} {Conditions}},
	isbn = {978-0-7695-3891-4},
	shorttitle = {Alattin},
	url = {http://dx.doi.org/10.1109/ASE.2009.72},
	doi = {10.1109/ASE.2009.72},
	abstract = {To improve software quality, static or dynamic verification tools accept programming rules as input and detect their violations in software as defects. As these programming rules are often not well documented in practice, previous work developed various approaches that mine programming rules as frequent patterns from program source code. Then these approaches use static defect-detection techniques to detect pattern violations in source code under analysis. These existing approaches often produce many false positives due to various factors. To reduce false positives produced by these mining approaches, we develop a novel approach, called Alattin, that includes a new mining algorithm and a technique for detecting neglected conditions based on our mining algorithm. Our new mining algorithm mines alternative patterns in example form "P1 or P2", where P1 and P2 are alternative rules such as condition checks on method arguments or return values related to the same API method. We conduct two evaluations to show the effectiveness of our Alattin approach. Our evaluation results show that (1) alternative patterns reach more than 40\% of all mined patterns for APIs provided by six open source libraries; (2) the mining of alternative patterns helps reduce nearly 28\% of false positives among detected violations.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2009 {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Thummalapenta, Suresh and Xie, Tao},
	year = {2009},
	keywords = {to read, frequent itemset mining, code search, alternative patterns},
	pages = {283--294},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\GV6FEN23\\Thummalapenta und Xie - 2009 - Alattin Mining Alternative Patterns for Detecting.pdf:application/pdf}
}

@inproceedings{li_pr-miner:_2005,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE}-13},
	title = {{PR}-{Miner}: {Automatically} {Extracting} {Implicit} {Programming} {Rules} and {Detecting} {Violations} in {Large} {Software} {Code}},
	isbn = {978-1-59593-014-9},
	shorttitle = {{PR}-{Miner}},
	url = {http://doi.acm.org/10.1145/1081706.1081755},
	doi = {10.1145/1081706.1081755},
	abstract = {Programs usually follow many implicit programming rules, most of which are too tedious to be documented by programmers. When these rules are violated by programmers who are unaware of or forget about them, defects can be easily introduced. Therefore, it is highly desirable to have tools to automatically extract such rules and also to automatically detect violations. Previous work in this direction focuses on simple function-pair based programming rules and additionally requires programmers to provide rule templates.This paper proposes a general method called PR-Miner that uses a data mining technique called frequent itemset mining to efficiently extract implicit programming rules from large software code written in an industrial programming language such as C, requiring little effort from programmers and no prior knowledge of the software. Benefiting from frequent itemset mining, PR-Miner can extract programming rules in general forms (without being constrained by any fixed rule templates) that can contain multiple program elements of various types such as functions, variables and data types. In addition, we also propose an efficient algorithm to automatically detect violations to the extracted programming rules, which are strong indications of bugs.Our evaluation with large software code, including Linux, PostgreSQL Server and the Apache HTTP Server, with 84K--3M lines of code each, shows that PR-Miner can efficiently extract thousands of general programming rules and detect violations within 2 minutes. Moreover, PR-Miner has detected many violations to the extracted rules. Among the top 60 violations reported by PR-Miner, 16 have been confirmed as bugs in the latest version of Linux, 6 in PostgreSQL and 1 in Apache. Most of them violate complex programming rules that contain more than 2 elements and are thereby difficult for previous tools to detect. We reported these bugs and they are currently being fixed by developers.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 10th {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 13th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Li, Zhenmin and Zhou, Yuanyuan},
	year = {2005},
	keywords = {static analysis, programming rules, automated specification generation, automated violation detection, data mining for software engineering, pattern recognition},
	pages = {306--315},
	file = {Li und Zhou - 2005 - PR-Miner Automatically Extracting Implicit Progra.pdf:C\:\\Users\\Anna\\Zotero\\storage\\W4DZDV44\\Li und Zhou - 2005 - PR-Miner Automatically Extracting Implicit Progra.pdf:application/pdf;Li und Zhou - 2005 - PR-Miner Automatically Extracting Implicit Progra.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Li und Zhou - 2005 - PR-Miner Automatically Extracting Implicit Progra.pdf:application/pdf}
}

@misc{noauthor_why_nodate,
	title = {Why don't software developers use static analysis tools to find bugs?},
	url = {https://dl.acm.org/citation.cfm?id=2486877},
	urldate = {2018-02-23},
	keywords = {to read},
	file = {Why don't software developers use static analysis tools to find bugs?:C\:\\Users\\Anna\\Zotero\\storage\\S6FJ3DWR\\citation.html:text/html}
}

@inproceedings{kim_which_2007,
	address = {New York, NY, USA},
	series = {{ESEC}-{FSE} '07},
	title = {Which {Warnings} {Should} {I} {Fix} {First}?},
	isbn = {978-1-59593-811-4},
	url = {http://doi.acm.org/10.1145/1287624.1287633},
	doi = {10.1145/1287624.1287633},
	abstract = {Automatic bug-finding tools have a high false positive rate: most warnings do not indicate real bugs. Usually bug-finding tools assign important warnings high priority. However, the prioritization of tools tends to be ineffective. We observed the warnings output by three bug-finding tools, FindBugs, JLint, and PMD, for three subject programs, Columba, Lucene, and Scarab. Only 6\%, 9\%, and 9\% of warnings are removed by bug fix changes during 1 to 4 years of the software development. About 90\% of warnings remain in the program or are removed during non-fix changes -- likely false positive warnings. The tools' warning prioritization is little help in focusing on important warnings: the maximum possible precision by selecting high-priority warning instances is only 3\%, 12\%, and 8\% respectively. In this paper, we propose a history-based warning prioritization algorithm by mining warning fix experience that is recorded in the software change history. The underlying intuition is that if warnings from a category are eliminated by fix-changes, the warnings are important. Our prioritization algorithm improves warning precision to 17\%, 25\%, and 67\% respectively.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the the 6th {Joint} {Meeting} of the {European} {Software} {Engineering} {Conference} and the {ACM} {SIGSOFT} {Symposium} on {The} {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Kim, Sunghun and Ernst, Michael D.},
	year = {2007},
	keywords = {to read, prediction, bug, bug-finding tool, fault, fix, patterns},
	pages = {45--54},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\XQHHKK8T\\Kim und Ernst - 2007 - Which Warnings Should I Fix First.pdf:application/pdf}
}

@article{arishold_systematic_2009,
	title = {A systematic and comprehensive investigation of methods to build and evaluate fault prediction models},
	volume = {83},
	journal = {The Journal of Systems and Software},
	author = {Arishold, E and Briand, L and Johannssen, E},
	year = {2009},
	keywords = {to read},
	pages = {2--17}
}

@inproceedings{rahman_comparing_2014,
	address = {New York, NY, USA},
	series = {{ICSE} 2014},
	title = {Comparing {Static} {Bug} {Finders} and {Statistical} {Prediction}},
	isbn = {978-1-4503-2756-5},
	url = {http://doi.acm.org/10.1145/2568225.2568269},
	doi = {10.1145/2568225.2568269},
	abstract = {The all-important goal of delivering better software at lower cost has led to a vital, enduring quest for ways to find and remove defects efficiently and accurately. To this end, two parallel lines of research have emerged over the last years. Static analysis seeks to find defects using algorithms that process well-defined semantic abstractions of code. Statistical defect prediction uses historical data to estimate parameters of statistical formulae modeling the phenomena thought to govern defect occurrence and predict where defects are likely to occur. These two approaches have emerged from distinct intellectual traditions and have largely evolved independently, in “splendid isolation”. In this paper, we evaluate these two (largely) disparate approaches on a similar footing. We use historical defect data to apprise the two approaches, compare them, and seek synergies. We find that under some accounting principles, they provide comparable benefits; we also find that in some settings, the performance of certain static bug-finders can be enhanced using information provided by statistical defect prediction.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Rahman, Foyzur and Khatri, Sameer and Barr, Earl T. and Devanbu, Premkumar},
	year = {2014},
	keywords = {Inspection, to read, Empirical Research, Empirical Software Engineering, Fault Prediction, Software Quality},
	pages = {424--434},
	file = {Rahman et al. - 2014 - Comparing Static Bug Finders and Statistical Predi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HZRBH6WR\\Rahman et al. - 2014 - Comparing Static Bug Finders and Statistical Predi.pdf:application/pdf}
}

@inproceedings{zhang_cost-effectiveness_2013,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2013},
	title = {A {Cost}-effectiveness {Criterion} for {Applying} {Software} {Defect} {Prediction} {Models}},
	isbn = {978-1-4503-2237-9},
	url = {http://doi.acm.org/10.1145/2491411.2494581},
	doi = {10.1145/2491411.2494581},
	abstract = {Ideally, software defect prediction models should help organize software quality assurance (SQA) resources and reduce cost of finding defects by allowing the modules most likely to contain defects to be inspected first. In this paper, we study the cost-effectiveness of applying defect prediction models in SQA and propose a basic cost-effectiveness criterion. The criterion implies that defect prediction models should be applied with caution. We also propose a new metric FN/(FN+TN) to measure the cost-effectiveness of a defect prediction model.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2013 9th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Zhang, Hongyu and Cheung, S. C.},
	year = {2013},
	keywords = {to read, cost effectiveness, Defect prediction, evaluation metrics},
	pages = {643--646},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\SQE8VRIL\\Zhang und Cheung - 2013 - A Cost-effectiveness Criterion for Applying Softwa.pdf:application/pdf}
}

@inproceedings{wasylkowski_detecting_2007,
	address = {New York, NY, USA},
	series = {{ESEC}-{FSE} '07},
	title = {Detecting {Object} {Usage} {Anomalies}},
	isbn = {978-1-59593-811-4},
	url = {http://doi.acm.org/10.1145/1287624.1287632},
	doi = {10.1145/1287624.1287632},
	abstract = {Interacting with objects often requires following a protocol---for instance, a specific sequence of method calls. These protocols are not always documented, and violations can lead to subtle problems. Our approach takes code examples to automatically infer legal sequences of method calls. The resulting patterns can then be used to detect anomalies such as "Before calling next, one normally calls hasNext". To our knowledge, this is the first fully automatic defect detection approach that learns and checks methodcall sequences. Our JADET prototype has detected yet undiscovered defects and code smells in five popular open-source programs, including two new defects in AspectJ.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the the 6th {Joint} {Meeting} of the {European} {Software} {Engineering} {Conference} and the {ACM} {SIGSOFT} {Symposium} on {The} {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Wasylkowski, Andrzej and Zeller, Andreas and Lindig, Christian},
	year = {2007},
	keywords = {static analysis, programming rules, to read, automated specification generation, data mining for software engineering, pattern recognition, automated defect detection, object usage anomalies},
	pages = {35--44},
	file = {Wasylkowski et al. - 2007 - Detecting Object Usage Anomalies.pdf:C\:\\Users\\Anna\\Zotero\\storage\\YRXQPEJH\\Wasylkowski et al. - 2007 - Detecting Object Usage Anomalies.pdf:application/pdf}
}

@misc{noauthor_uncertainty_nodate,
	title = {From uncertainty to belief},
	url = {https://dl.acm.org/citation.cfm?id=1298471},
	urldate = {2018-02-23},
	keywords = {to read},
	file = {From uncertainty to belief:C\:\\Users\\Anna\\Zotero\\storage\\APEHY8HY\\citation.html:text/html}
}

@inproceedings{ko_what_2016,
	address = {New York, NY, USA},
	series = {{PLATEAU} 2016},
	title = {What is a {Programming} {Language}, {Really}?},
	isbn = {978-1-4503-4638-2},
	url = {http://doi.acm.org/10.1145/3001878.3001880},
	doi = {10.1145/3001878.3001880},
	abstract = {In computing, we usually take a technical view of programming languages (PL), defining them as formal means of specifying a computer behavior. This view shapes much of the research that we do on PL, determining the questions we ask about them, the improvements we make to them, and how we teach people to use them. But to many people, PL are not purely technical things, but socio-technical things. This paper describes several alternative views of PL and how these views can reshape how we design, evolve, and use programming languages in research and practice.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 7th {International} {Workshop} on {Evaluation} and {Usability} of {Programming} {Languages} and {Tools}},
	publisher = {ACM},
	author = {Ko, Andrew J.},
	year = {2016},
	keywords = {to read, Definitions, human-computer interaction},
	pages = {32--33},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\HHDHDJGX\\Ko - 2016 - What is a Programming Language, Really.pdf:application/pdf}
}

@inproceedings{juchli_mining_2017,
	address = {Piscataway, NJ, USA},
	series = {{WAPI} '17},
	title = {Mining {Motivated} {Trends} of {Usage} of {Haskell} {Libraries}},
	url = {https://doi.org/10.1109/WAPI.2017..6},
	doi = {10.1109/WAPI.2017..6},
	abstract = {We propose an initial approach to mine the usage trends of libraries in Haskell, a popular functional programming language. We integrate it with a novel, initial method to automatically determine the reasons of clients for switching to different versions. Based on these, we conduct a preliminary investigation of trends of usage in Haskell libraries. Results suggest that trends are similar to those in the Java ecosystem and in line with Rogers theory on the diffusion of innovation. Our results also provide indication on Haskell libraries being all by and large stable.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {API} {Usage} and {Evolution}},
	publisher = {IEEE Press},
	author = {Juchli, Marc and Krombeen, Lars and Rao, Shashank and Yu, Chak Shun and Sawant, Anand Ashok and Bacchelli, Alberto},
	year = {2017},
	keywords = {to read},
	pages = {11--14},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\A5459UEV\\Juchli et al. - 2017 - Mining Motivated Trends of Usage of Haskell Librar.pdf:application/pdf}
}

@inproceedings{heo_machine-learning-guided_2017,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '17},
	title = {Machine-learning-guided {Selectively} {Unsound} {Static} {Analysis}},
	isbn = {978-1-5386-3868-2},
	url = {https://doi.org/10.1109/ICSE.2017.54},
	doi = {10.1109/ICSE.2017.54},
	abstract = {We present a machine-learning-based technique for selectively applying unsoundness in static analysis. Existing bug-finding static analyzers are unsound in order to be precise and scalable in practice. However, they are uniformly unsound and hence at the risk of missing a large amount of real bugs. By being sound, we can improve the detectability of the analyzer but it often suffers from a large number of false alarms. Our approach aims to strike a balance between these two approaches by selectively allowing unsoundness only when it is likely to reduce false alarms, while retaining true alarms. We use an anomaly-detection technique to learn such harmless unsoundness. We implemented our technique in two static analyzers for full C. One is for a taint analysis for detecting format-string vulnerabilities, and the other is for an interval analysis for buffer-overflow detection. The experimental results show that our approach significantly improves the recall of the original unsound analysis without sacrificing the precision.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Heo, Kihong and Oh, Hakjoo and Yi, Kwangkeun},
	year = {2017},
	keywords = {static analysis, to read, machine learning, bug-finding},
	pages = {519--529},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\EC5IUM25\\Heo et al. - 2017 - Machine-learning-guided Selectively Unsound Static.pdf:application/pdf}
}

@inproceedings{lin_uniqueness_2017,
	address = {Piscataway, NJ, USA},
	series = {{ICPC} '17},
	title = {On the {Uniqueness} of {Code} {Redundancies}},
	isbn = {978-1-5386-0535-6},
	url = {https://doi.org/10.1109/ICPC.2017.36},
	doi = {10.1109/ICPC.2017.36},
	abstract = {Code redundancy widely occurs in software projects. Researchers have investigated the existence, causes, and impacts of code redundancy, showing that it can be put to good use, for example in the context of code completion. When analyzing source code redundancy, previous studies considered software projects as sequences of tokens, neglecting the role of the syntactic structures enforced by programming languages. However, differences in the redundancy of such structures may jeopardize the performance of applications leveraging code redundancy. We present a study of the redundancy of several types of code constructs in a large-scale dataset of active Java projects mined from GitHub, unveiling that redundancy is not uniform and mainly resides in specific code constructs. We further investigate the implications of the locality of redundancy by analyzing the performance of language models when applied to code completion. Our study discloses the perils of exploiting code redundancy without taking into account its strong locality in specific code constructs.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Program} {Comprehension}},
	publisher = {IEEE Press},
	author = {Lin, Bin and Ponzanelli, Luca and Mocci, Andrea and Bavota, Gabriele and Lanza, Michele},
	year = {2017},
	keywords = {to read, code completion, code redundancy, empirical study},
	pages = {121--131},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\6S64KL8P\\Lin et al. - 2017 - On the Uniqueness of Code Redundancies.pdf:application/pdf}
}

@inproceedings{christakis_general_2017,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '17},
	title = {A {General} {Framework} for {Dynamic} {Stub} {Injection}},
	isbn = {978-1-5386-3868-2},
	url = {https://doi.org/10.1109/ICSE.2017.60},
	doi = {10.1109/ICSE.2017.60},
	abstract = {Stub testing is a standard technique to simulate the behavior of dependencies of an application under test such as the file system. Even though existing frameworks automate the actual stub injection, testers typically have to implement manually where and when to inject stubs, in addition to the stub behavior. This paper presents a novel framework that reduces this effort. The framework provides a domain specific language to describe stub injection strategies and stub behaviors via declarative rules, as well as a tool that automatically injects stubs dynamically into binary code according to these rules. Both the domain specific language and the injection are language independent, which enables the reuse of stubs and injection strategies across applications. We implemented this framework for both unmanaged (assembly) and managed (.NET) code and used it to perform fault injection for twelve large applications, which revealed numerous crashes and bugs in error handling code. We also show how to prioritize the analysis of test failures based on a comparison of the effectiveness of stub injection rules across applications.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Christakis, Maria and Emmisberger, Patrick and Godefroid, Patrice and Müller, Peter},
	year = {2017},
	keywords = {to read},
	pages = {586--596},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\SIJNSJHZ\\Christakis et al. - 2017 - A General Framework for Dynamic Stub Injection.pdf:application/pdf}
}

@inproceedings{hellendoorn_are_2017,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2017},
	title = {Are {Deep} {Neural} {Networks} the {Best} {Choice} for {Modeling} {Source} {Code}?},
	isbn = {978-1-4503-5105-8},
	url = {http://doi.acm.org/10.1145/3106237.3106290},
	doi = {10.1145/3106237.3106290},
	abstract = {Current statistical language modeling techniques, including deep-learning based models, have proven to be quite effective for source code. We argue here that the special properties of source code can be exploited for further improvements. In this work, we enhance established language modeling approaches to handle the special challenges of modeling source code, such as: frequent changes, larger, changing vocabularies, deeply nested scopes, etc. We present a fast, nested language modeling toolkit specifically designed for software, with the ability to add \& remove text, and mix \& swap out many models. Specifically, we improve upon prior cache-modeling work and present a model with a much more expansive, multi-level notion of locality that we show to be well-suited for modeling software. We present results on varying corpora in comparison with traditional N-gram, as well as RNN, and LSTM deep-learning language models, and release all our source code for public use. Our evaluations suggest that carefully adapting N-gram models for source code can yield performance that surpasses even RNN and LSTM based deep-learning models.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Hellendoorn, Vincent J. and Devanbu, Premkumar},
	year = {2017},
	keywords = {software tools, to read, language models, naturalness},
	pages = {763--773},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\5HRX4PTT\\Hellendoorn und Devanbu - 2017 - Are Deep Neural Networks the Best Choice for Model.pdf:application/pdf}
}

@inproceedings{vasilescu_recovering_2017,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2017},
	title = {Recovering {Clear}, {Natural} {Identifiers} from {Obfuscated} {JS} {Names}},
	isbn = {978-1-4503-5105-8},
	url = {http://doi.acm.org/10.1145/3106237.3106289},
	doi = {10.1145/3106237.3106289},
	abstract = {Well-chosen variable names are critical to source code readability, reusability, and maintainability. Unfortunately, in deployed JavaScript code (which is ubiquitous on the web) the identifier names are frequently minified and overloaded. This is done both for efficiency and also to protect potentially proprietary intellectual property. In this paper, we describe an approach based on statistical machine translation (SMT) that recovers some of the original names from the JavaScript programs minified by the very popular UglifyJS. This simple tool, Autonym, performs comparably to the best currently available deobfuscator for JavaScript, JSNice, which uses sophisticated static analysis. In fact, Autonym is quite complementary to JSNice, performing well when it does not, and vice versa. We also introduce a new tool, JSNaughty, which blends Autonym and JSNice, and significantly outperforms both at identifier name recovery, while remaining just as easy to use as JSNice. JSNaughty is available online at http://jsnaughty.org.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Vasilescu, Bogdan and Casalnuovo, Casey and Devanbu, Premkumar},
	year = {2017},
	keywords = {to read, Deobfuscation, JavaScript, Statistical Machine Translation},
	pages = {683--693},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\4E92CLCL\\Vasilescu et al. - 2017 - Recovering Clear, Natural Identifiers from Obfusca.pdf:application/pdf}
}

@inproceedings{kremenek_uncertainty_2006,
	address = {Berkeley, CA, USA},
	series = {{OSDI} '06},
	title = {From {Uncertainty} to {Belief}: {Inferring} the {Specification} {Within}},
	isbn = {978-1-931971-47-8},
	shorttitle = {From {Uncertainty} to {Belief}},
	url = {http://dl.acm.org/citation.cfm?id=1298455.1298471},
	abstract = {Automatic tools for finding software errors require a set of specifications before they can check code: if they do not know what to check, they cannot find bugs. This paper presents a novel framework based on factor graphs for automatically inferring specifications directly from programs. The key strength of the approach is that it can incorporate many disparate sources of evidence, allowing us to squeeze significantly more information from our observations than previously published techniques. We illustrate the strengths of our approach by applying it to the problem of inferring what functions in C programs allocate and release resources. We evaluated its effectiveness on five codebases: SDL, OpenSSH, GIMP, and the OS kernels for Linux and Mac OS X (XNU). For each codebase, starting with zero initially provided annotations, we observed an inferred annotation accuracy of 80--90\%, with often near perfect accuracy for functions called as little asfive times. Many of the inferred allocator and deallocator functions are functions for which we both lack the implementation and are rarely called---in some cases functions with at most one or two callsites. Finally, with the inferred annotations we quickly found both missing and incorrect properties in a specification used by a commercial static bug-finding tool.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 7th {Symposium} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Kremenek, Ted and Twohey, Paul and Back, Godmar and Ng, Andrew and Engler, Dawson},
	year = {2006},
	keywords = {to read},
	pages = {161--176},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\TC2XX42K\\Kremenek et al. - 2006 - From Uncertainty to Belief Inferring the Specific.pdf:application/pdf}
}

@article{bush_as_1945,
	title = {As {We} {May} {Think}},
	issn = {1072-7825},
	url = {https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/},
	urldate = {2018-02-23},
	journal = {The Atlantic},
	author = {Bush, Vannevar},
	month = jul,
	year = {1945},
	file = {The Atlantic Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CPVTRKMM\\303881.html:text/html}
}

@inproceedings{gabel_study_2010,
	address = {New York, NY, USA},
	series = {{FSE} '10},
	title = {A {Study} of the {Uniqueness} of {Source} {Code}},
	isbn = {978-1-60558-791-2},
	url = {http://doi.acm.org/10.1145/1882291.1882315},
	doi = {10.1145/1882291.1882315},
	abstract = {This paper presents the results of the first study of the uniqueness of source code. We define the uniqueness of a unit of source code with respect to the entire body of written software, which we approximate with a corpus of 420 million lines of source code. Our high-level methodology consists of examining a collection of 6,000 software projects and measuring the degree to which each project can be `assembled' solely from portions of this corpus, thus providing a precise measure of `uniqueness' that we call syntactic redundancy. We parameterized our study over a variety of variables, the most important of which being the level of granularity at which we view source code. Our suite of experiments together consumed approximately four months of CPU time, providing quantitative answers to the following questions: at what levels of granularity is software unique, and at a given level of granularity, how unique is software? While we believe these questions to be of intrinsic interest, we discuss possible applications to genetic programming and developer productivity tools.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Gabel, Mark and Su, Zhendong},
	year = {2010},
	keywords = {to read, large scale study, software uniqueness, source code},
	pages = {147--156},
	file = {Gabel und Su - 2010 - A Study of the Uniqueness of Source Code.pdf:C\:\\Users\\Anna\\Zotero\\storage\\FRCZ8XAH\\Gabel und Su - 2010 - A Study of the Uniqueness of Source Code.pdf:application/pdf}
}

@inproceedings{gabel_javert:_2008,
	address = {New York, NY, USA},
	series = {{SIGSOFT} '08/{FSE}-16},
	title = {Javert: {Fully} {Automatic} {Mining} of {General} {Temporal} {Properties} from {Dynamic} {Traces}},
	isbn = {978-1-59593-995-1},
	shorttitle = {Javert},
	url = {http://doi.acm.org/10.1145/1453101.1453150},
	doi = {10.1145/1453101.1453150},
	abstract = {Program specifications are important for many tasks during software design, development, and maintenance. Among these, temporal specifications are particularly useful. They express formal correctness requirements of an application's ordering of specific actions and events during execution, such as the strict alternation of acquisition and release of locks. Despite their importance, temporal specifications are often missing, incomplete, or described only informally. Many techniques have been proposed that mine such specifications from execution traces or program source code. However, existing techniques mine only simple patterns, or they mine a single complex pattern that is restricted to a particular set of manually selected events. There is no practical, automatic technique that can mine general temporal properties from execution traces. In this paper, we present Javert, the first general specification mining framework that can learn, fully automatically, complex temporal properties from execution traces. The key insight behind Javert is that real, complex specifications can be formed by composing instances of small generic patterns, such as the alternating pattern ((ab)) and the resource usage pattern ((ab c)). In particular, Javert learns simple generic patterns and composes them using sound rules to construct large, complex specifications. We have implemented the algorithm in a practical tool and conducted an extensive empirical evaluation on several open source software projects. Our results are promising; they show that Javert is scalable, general, and precise. It discovered many interesting, nontrivial specifications in real-world code that are beyond the reach of existing automatic techniques.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 16th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Gabel, Mark and Su, Zhendong},
	year = {2008},
	keywords = {to read, dynamic analysis, formal specifications, specification mining},
	pages = {339--349},
	file = {Gabel und Su - 2008 - Javert Fully Automatic Mining of General Temporal.pdf:C\:\\Users\\Anna\\Zotero\\storage\\L9VL8KJ9\\Gabel und Su - 2008 - Javert Fully Automatic Mining of General Temporal.pdf:application/pdf}
}

@inproceedings{mandelin_jungloid_2005,
	address = {New York, NY, USA},
	series = {{PLDI} '05},
	title = {Jungloid {Mining}: {Helping} to {Navigate} the {API} {Jungle}},
	isbn = {978-1-59593-056-9},
	shorttitle = {Jungloid {Mining}},
	url = {http://doi.acm.org/10.1145/1065010.1065018},
	doi = {10.1145/1065010.1065018},
	abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object.In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jungloids using both API method signatures and jungloids mined from a corpus of sample client programs.We implemented a tool, prospector, based on these techniques. prospector is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested prospector on a set of real programming problems involving APIs; prospector found the desired solution for 18 of 20 problems. We also evaluated prospector in a user study, finding that programmers solved programming problems more quickly and with more reuse when using prospector than without prospector.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Mandelin, David and Xu, Lin and Bodík, Rastislav and Kimelman, Doug},
	year = {2005},
	keywords = {to read, mining, program synthesis, reuse},
	pages = {48--61},
	file = {Mandelin et al. - 2005 - Jungloid Mining Helping to Navigate the API Jungl.pdf:C\:\\Users\\Anna\\Zotero\\storage\\GRYBUZV8\\Mandelin et al. - 2005 - Jungloid Mining Helping to Navigate the API Jungl.pdf:application/pdf}
}

@inproceedings{livshits_dynamine:_2005,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE}-13},
	title = {{DynaMine}: {Finding} {Common} {Error} {Patterns} by {Mining} {Software} {Revision} {Histories}},
	isbn = {978-1-59593-014-9},
	shorttitle = {{DynaMine}},
	url = {http://doi.acm.org/10.1145/1081706.1081754},
	doi = {10.1145/1081706.1081754},
	abstract = {A great deal of attention has lately been given to addressing software bugs such as errors in operating system drivers or security bugs. However, there are many other lesser known errors specific to individual applications or APIs and these violations of application-specific coding rules are responsible for a multitude of errors. In this paper we propose DynaMine, a tool that analyzes source code check-ins to find highly correlated method calls as well as common bug fixes in order to automatically discover application-specific coding patterns. Potential patterns discovered through mining are passed to a dynamic analysis tool for validation; finally, the results of dynamic analysis are presented to the user.The combination of revision history mining and dynamic analysis techniques leveraged in DynaMine proves effective for both discovering new application-specific patterns and for finding errors when applied to very large applications with many man-years of development and debugging effort behind them. We have analyzed Eclipse and jEdit, two widely-used, mature, highly extensible applications consisting of more than 3,600,000 lines of code combined. By mining revision histories, we have discovered 56 previously unknown, highly application-specific patterns. Out of these, 21 were dynamically confirmed as very likely valid patterns and a total of 263 pattern violations were found.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 10th {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 13th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Livshits, Benjamin and Zimmermann, Thomas},
	year = {2005},
	keywords = {data mining, to read, dynamic analysis, coding patterns, error patterns, one-line check-ins, revision histories, software bugs},
	pages = {296--305},
	file = {Livshits und Zimmermann - 2005 - DynaMine Finding Common Error Patterns by Mining .pdf:C\:\\Users\\Anna\\Zotero\\storage\\KDAMIP6R\\Livshits und Zimmermann - 2005 - DynaMine Finding Common Error Patterns by Mining .pdf:application/pdf}
}

@inproceedings{cergani_addressing_2016,
	address = {New York, NY, USA},
	series = {{SWAN} 2016},
	title = {Addressing {Scalability} in {API} {Method} {Call} {Analytics}},
	isbn = {978-1-4503-4395-4},
	url = {http://doi.acm.org/10.1145/2989238.2989240},
	doi = {10.1145/2989238.2989240},
	abstract = {Intelligent code completion recommends relevant code to developers by comparing the editor content to code patterns extracted by analyzing large repositories. However, with the vast amount of data available in such repositories, scalability of the recommender system becomes an issue. We propose using Boolean Matrix Factorization (BMF) as a clustering technique for analyzing code in order to improve scalability of the underlying models. We compare model size, inference speed, and prediction quality of an intelligent method call completion engine built on top of canopy clustering versus one built on top of BMF. Our results show that BMF reduces model size up to 80\% and increases inference speed up to 78\%, without significant change in prediction quality.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 2Nd {International} {Workshop} on {Software} {Analytics}},
	publisher = {ACM},
	author = {Cergani, Ervina and Proksch, Sebastian and Nadi, Sarah and Mezini, Mira},
	year = {2016},
	keywords = {Scalability, to read, Analytics of code repositories, Boolean Matrix Factorization, Intelligent Method Call Completion},
	pages = {1--7},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\KMXHQSC6\\Cergani et al. - 2016 - Addressing Scalability in API Method Call Analytic.pdf:application/pdf;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\KS5HA3E6\\Cergani et al. - 2016 - Addressing Scalability in API Method Call Analytic.pdf:application/pdf}
}

@inproceedings{proksch_evaluating_2016,
	address = {New York, NY, USA},
	series = {{ASE} 2016},
	title = {Evaluating the {Evaluations} of {Code} {Recommender} {Systems}: {A} {Reality} {Check}},
	isbn = {978-1-4503-3845-5},
	shorttitle = {Evaluating the {Evaluations} of {Code} {Recommender} {Systems}},
	url = {http://doi.acm.org/10.1145/2970276.2970330},
	doi = {10.1145/2970276.2970330},
	abstract = {While researchers develop many new exciting code recommender systems, such as method-call completion, code-snippet completion, or code search, an accurate evaluation of such systems is always a challenge. We analyzed the current literature and found that most of the current evaluations rely on artificial queries extracted from released code, which begs the question: Do such evaluations reflect real-life usages? To answer this question, we capture 6,189 fine-grained development histories from real IDE interactions. We use them as a ground truth and extract 7,157 real queries for a specific method-call recommender system. We compare the results of such real queries with different artificial evaluation strategies and check several assumptions that are repeatedly used in research, but never empirically evaluated. We find that an evolving context that is often observed in practice has a major effect on the prediction quality of recommender systems, but is not commonly reflected in artificial evaluations.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM},
	author = {Proksch, Sebastian and Amann, Sven and Nadi, Sarah and Mezini, Mira},
	year = {2016},
	keywords = {to read, Artificial Evaluation, Empirical Study, IDE Interaction Data},
	pages = {111--121},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\MY8XH4EU\\Proksch et al. - 2016 - Evaluating the Evaluations of Code Recommender Sys.pdf:application/pdf;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\57QU5ZWB\\Proksch et al. - 2016 - Evaluating the Evaluations of Code Recommender Sys.pdf:application/pdf}
}

@inproceedings{linares-vasquez_empirical_2017,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '17},
	title = {An {Empirical} {Study} on {Android}-related {Vulnerabilities}},
	isbn = {978-1-5386-1544-7},
	url = {https://doi.org/10.1109/MSR.2017.60},
	doi = {10.1109/MSR.2017.60},
	abstract = {Mobile devices are used more and more in everyday life. They are our cameras, wallets, and keys. Basically, they embed most of our private information in our pocket. For this and other reasons, mobile devices, and in particular the software that runs on them, are considered first-class citizens in the software-vulnerabilities landscape. Several studies investigated the software-vulnerabilities phenomenon in the context of mobile apps and, more in general, mobile devices. Most of these studies focused on vulnerabilities that could affect mobile apps, while just few investigated vulnerabilities affecting the underlying platform on which mobile apps run: the Operating System (OS). Also, these studies have been run on a very limited set of vulnerabilities. In this paper we present the largest study at date investigating Android-related vulnerabilities, with a specific focus on the ones affecting the Android OS. In particular, we (i) define a detailed taxonomy of the types of Android-related vulnerability; (ii) investigate the layers and subsystems from the Android OS affected by vulnerabilities; and (iii) study the survivability of vulnerabilities (i.e., the number of days between the vulnerability introduction and its fixing). Our findings could help OS and apps developers in focusing their verification \& validation activities, and researchers in building vulnerability detection tools tailored for the mobile world.},
	urldate = {2018-02-23},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Linares-Vásquez, Mario and Bavota, Gabriele and Escobar-Velásquez, Camilo},
	year = {2017},
	keywords = {to read},
	pages = {2--13},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\JGBKXBHV\\Linares-Vásquez et al. - 2017 - An Empirical Study on Android-related Vulnerabilit.pdf:application/pdf}
}

@misc{noauthor_understanding_nodate,
	title = {Understanding the origins of mobile app vulnerabilities},
	url = {https://dl.acm.org/citation.cfm?id=3104193},
	urldate = {2018-02-23},
	keywords = {to read},
	file = {Understanding the origins of mobile app vulnerabilities:C\:\\Users\\Anna\\Zotero\\storage\\LYHKIMES\\citation.html:text/html}
}

@misc{noauthor_fail-slow_nodate,
	title = {Fail-{Slow} at {Scale}: {Evidence} of {Hardware} {Performance} {Faults} in {Large} {Production} {Systems} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/fast18/presentation/gunawi},
	urldate = {2018-02-26},
	file = {Fail-Slow at Scale\: Evidence of Hardware Performance Faults in Large Production Systems | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\IS8TWAFQ\\gunawi.html:text/html}
}

@inproceedings{acar_comparing_2017,
	title = {Comparing the {Usability} of {Cryptographic} {APIs}},
	doi = {10.1109/SP.2017.52},
	abstract = {Potentially dangerous cryptography errors are well-documented in many applications. Conventional wisdom suggests that many of these errors are caused by cryptographic Application Programming Interfaces (APIs) that are too complicated, have insecure defaults, or are poorly documented. To address this problem, researchers have created several cryptographic libraries that they claim are more usable, however, none of these libraries have been empirically evaluated for their ability to promote more secure development. This paper is the first to examine both how and why the design and resulting usability of different cryptographic libraries affects the security of code written with them, with the goal of understanding how to build effective future libraries. We conducted a controlled experiment in which 256 Python developers recruited from GitHub attempt common tasks involving symmetric and asymmetric cryptography using one of five different APIs. We examine their resulting code for functional correctness and security, and compare their results to their self-reported sentiment about their assigned library. Our results suggest that while APIs designed for simplicity can provide security benefits - reducing the decision space, as expected, prevents choice of insecure parameters - simplicity is not enough. Poor documentation, missing code examples, and a lack of auxiliary features such as secure key storage, caused even participants assigned to simplified libraries to struggle with both basic functional correctness and security. Surprisingly, the availability of comprehensive documentation and easy-to-use code examples seems to compensate for more complicated APIs in terms of functionally correct results and participant reactions, however, this did not extend to security results. We find it particularly concerning that for about 20\% of functionally correct tasks, across libraries, participants believed their code was secure when it was not. Our results suggest that while ne- cryptographic libraries that want to promote effective security should offer a simple, convenient interface, this is not enough: they should also, and perhaps more importantly, ensure support for a broad range of common tasks and provide accessible documentation with secure, easy-to-use code examples.},
	booktitle = {2017 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Acar, Y. and Backes, M. and Fahl, S. and Garfinkel, S. and Kim, D. and Mazurek, M. L. and Stransky, C.},
	month = may,
	year = {2017},
	keywords = {Libraries, software libraries, Programming, code security, Cryptography, cryptography, application program interfaces, Documentation, API usability, auxiliary features, controlled experiment, cryptographic API usability, cryptographic application programming interfaces, cryptographic library, cryptography errors, documentation accessibility, GitHub, Guidelines, Python developers, symmetric cryptography, Usability, usable security},
	pages = {154--171},
	file = {Acar et al. - 2017 - Comparing the Usability of Cryptographic APIs.pdf:C\:\\Users\\Anna\\Zotero\\storage\\8EDP94Q8\\Acar et al. - 2017 - Comparing the Usability of Cryptographic APIs.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\488SBMQI\\7958576.html:text/html}
}

@inproceedings{acar_security_2017,
	address = {Santa Clara, CA, USA},
	title = {Security {Developer} {Studies} with {GitHub} {Users}: {Exploring} a {Convenience} {Sample} {\textbar} {USENIX}},
	isbn = {978-1-931971-39-3},
	url = {https://www.usenix.org/conference/soups2017/technical-sessions/presentation/acar},
	abstract = {The  usable  security  community  is  increasingly  considering
how  to  improve  security  decision-making  not  only  for  end
users, but also for information technology professionals, in-
cluding system administrators and software developers.  Re-
cruiting these professionals for user studies can prove chal-
lenging,  as,  relative  to  end  users  more  generally,  they  are
limited in numbers, geographically concentrated, and accus-
tomed to higher compensation.  One potential approach is
to recruit active GitHub users, who are (in some ways) con-
veniently  available  for  online  studies.   However,  it  is  not
well  understood  how  GitHub  users  perform  when  working
on security-related tasks.  As a first step in addressing this
question, we conducted an experiment in which we recruited
307 active GitHub users to each complete the same security-
relevant  programming  tasks.   We  compared  the  results  in
terms  of  functional  correctness  as  well  as  security,  finding
differences  in  performance  for  both  security  and  function-
ality  related  to  the  participant’s  self-reported  years  of  ex-
perience,  but  no  statistically  significant  differences  related
to the participant’s self-reported status as a student, status
as a professional developer, or security background.  These
results provide initial evidence for how to think about valid-
ity  when  recruiting  convenience  samples  as  substitutes  for
professional developers in security developer studie},
	urldate = {2018-02-26},
	author = {Acar, Yasemin and Stransky, Christian and Wermke, Dominik and Mazurek, Michelle L. and Fahl, Sascha},
	year = {2017},
	file = {Acar et al. - Security Developer Studies with GitHub Users Expl.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Acar et al. - Security Developer Studies with GitHub Users Expl.pdf:application/pdf}
}

@techreport{beurdouche_hacl*:_2017,
	title = {{HACL}*: {A} {Verified} {Modern} {Cryptographic} {Library}},
	shorttitle = {{HACL}*},
	url = {http://eprint.iacr.org/2017/536},
	abstract = {HACL* is a verified portable C cryptographic library that implements modern cryptographic primitives such as the ChaCha20 and Salsa20 encryption algorithms, Poly1305 and HMAC message authentication, SHA-256 and SHA-512 hash functions, the Curve25519 elliptic curve, and Ed25519 signatures.

HACL* is written in the F* programming language and then compiled to readable C code. The F* source code for each crypto- graphic primitive is verified for memory safety, mitigations against timing side-channels, and functional correctness with respect to a succinct high-level specification of the primitive derived from its published standard. The translation from F* to C preserves these properties and the generated C code can itself be compiled via the CompCert verified C compiler or mainstream compilers like GCC or CLANG. When compiled with GCC on 64-bit platforms, our primitives are as fast as the fastest pure C implementations in OpenSSL and Libsodium, significantly faster than the reference C code in TweetNaCl, and between 1.1x-5.7x slower than the fastest hand-optimized vectorized assembly code in SUPERCOP.

HACL* implements the NaCl cryptographic API and can be used as a drop-in replacement for NaCl libraries like Libsodium and TweetNaCl. HACL\&\#8727; provides the cryptographic components for a new mandatory ciphersuite in TLS 1.3 and is being developed as the main cryptographic provider for the miTLS verified implementation. Primitives from HACL* are also being integrated within Mozilla’s NSS cryptographic library. Our results show that writing fast, verified, and usable C cryptographic libraries is now practical.},
	number = {536},
	urldate = {2018-02-26},
	author = {Beurdouche, Karthikeyan Bhargavan, Jonathan Protzenko, Benjamin, Jean Karim Zinzindohoué},
	year = {2017},
	keywords = {formal verification, implementation},
	file = {Beurdouche - 2017 - HACL A Verified Modern Cryptographic Library.pdf:C\:\\Users\\Anna\\Zotero\\storage\\R7ETGKGA\\Beurdouche - 2017 - HACL A Verified Modern Cryptographic Library.pdf:application/pdf;ePrint IACR Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\8TPMJINK\\536.html:text/html}
}

@misc{noauthor_app_nodate,
	title = {App {Security} {Improvements}: {Looking} back at 2016},
	shorttitle = {App {Security} {Improvements}},
	url = {https://android-developers.googleblog.com/2017/01/app-security-improvements-looking-back.html},
	abstract = {The latest Android and Google Play news and tips for app and game developers.},
	language = {en},
	urldate = {2018-02-26},
	journal = {Android Developers Blog},
	file = {App Security Improvements Looking back at 2016.html:C\:\\Users\\Anna\\Zotero\\storage\\CBFJH8LL\\App Security Improvements Looking back at 2016.html:text/html}
}

@inproceedings{nappa_attack_2015,
	title = {The {Attack} of the {Clones}: {A} {Study} of the {Impact} of {Shared} {Code} on {Vulnerability} {Patching}},
	shorttitle = {The {Attack} of the {Clones}},
	doi = {10.1109/SP.2015.48},
	abstract = {Vulnerability exploits remain an important mechanism for malware delivery, despite efforts to speed up the creation of patches and improvements in software updating mechanisms. Vulnerabilities in client applications (e.g., Browsers, multimedia players, document readers and editors) are often exploited in spear phishing attacks and are difficult to characterize using network vulnerability scanners. Analyzing their lifecycle requires observing the deployment of patches on hosts around the world. Using data collected over 5 years on 8.4 million hosts, available through Symantec's WINE platform, we present the first systematic study of patch deployment in client-side vulnerabilities. We analyze the patch deployment process of 1,593 vulnerabilities from 10 popular client applications, and we identify several new threats presented by multiple installations of the same program and by shared libraries distributed with several applications. For the 80 vulnerabilities in our dataset that affect code shared by two applications, the time between patch releases in the different applications is up to 118 days (with a median of 11 days). Furthermore, as the patching rates differ considerably among applications, many hosts patch the vulnerability in one application but not in the other one. We demonstrate two novel attacks that enable exploitation by invoking old versions of applications that are used infrequently, but remain installed. We also find that the median fraction of vulnerable hosts patched when exploits are released is at most 14\%. Finally, we show that the patching rate is affected by user-specific and application-specific factors, for example, hosts belonging to security analysts and applications with an automated updating mechanism have significantly lower median times to patch.},
	booktitle = {2015 {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Nappa, A. and Johnson, R. and Bilge, L. and Caballero, J. and Dumitras, T.},
	month = may,
	year = {2015},
	keywords = {Software, software vulnerabilities, Security, Libraries, Databases, invasive software, application-specific factors, automated updating mechanism, client applications, Delays, malware delivery, network vulnerability scanners, patch deployment, shared code, Sociology, software lifecycle analysis, software reliability, software updating mechanisms, spear phishing attacks, Statistics, Symantec WINE platform, user-specific factors, vulnerability exploits, vulnerability patching},
	pages = {692--708},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\EGNZF9Y3\\7163055.html:text/html}
}

@inproceedings{lauinger_thou_2017,
	title = {Thou {Shalt} {Not} {Depend} on {Me}: {Analysing} the {Use} of {Outdated} {JavaScript} {Libraries} on the {Web}},
	isbn = {978-1-891562-46-4},
	shorttitle = {Thou {Shalt} {Not} {Depend} on {Me}},
	url = {https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/thou-shalt-not-depend-me-analysing-use-outdated-javascript-libraries-web/},
	doi = {10.14722/ndss.2017.23414},
	language = {en},
	urldate = {2018-02-26},
	publisher = {Internet Society},
	author = {Lauinger, Tobias and Chaabane, Abdelberi and Arshad, Sajjad and Robertson, William and Wilson, Christo and Kirda, Engin},
	year = {2017},
	file = {Lauinger et al. - 2017 - Thou Shalt Not Depend on Me Analysing the Use of .pdf:C\:\\Users\\Anna\\Zotero\\storage\\FPHX8QHP\\Lauinger et al. - 2017 - Thou Shalt Not Depend on Me Analysing the Use of .pdf:application/pdf}
}

@inproceedings{herold_new_2017,
	title = {New {Techniques} for {Structural} {Batch} {Verification} in {Bilinear} {Groups} with {Applications} to {Groth}-{Sahai} {Proofs}},
	isbn = {978-1-4503-4946-8},
	url = {http://dl.acm.org/citation.cfm?doid=3133956.3134068},
	doi = {10.1145/3133956.3134068},
	language = {en},
	urldate = {2018-02-26},
	publisher = {ACM Press},
	author = {Herold, Gottfried and Hoffmann, Max and Klooß, Michael and Ràfols, Carla and Rupp, Andy},
	year = {2017},
	pages = {1547--1564},
	file = {p1547-heroldA.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9IZ584SZ\\p1547-heroldA.pdf:application/pdf}
}

@misc{noauthor_developers_nodate,
	title = {Developers are {Not} the {Enemy}!: {The} {Need} for {Usable} {Security} {APIs}},
	url = {https://www.researchgate.net/publication/309444749_Developers_are_Not_the_Enemy_The_Need_for_Usable_Security_APIs},
	urldate = {2018-02-26},
	file = {Developers are Not the Enemy!\: The Need for Usable Security APIs:C\:\\Users\\Anna\\Zotero\\storage\\GE9Y7N97\\309444749_Developers_are_Not_the_Enemy_The_Need_for_Usable_Security_APIs.html:text/html}
}

@inproceedings{acar_you_2016,
	title = {You {Get} {Where} {You}'re {Looking} for: {The} {Impact} of {Information} {Sources} on {Code} {Security}},
	shorttitle = {You {Get} {Where} {You}'re {Looking} for},
	doi = {10.1109/SP.2016.25},
	abstract = {Vulnerabilities in Android code – including but not limited to insecure data storage, unprotected inter-component communication, broken TLS implementations, and violations of least privilege – have enabled real-world privacy leaks and motivated research cataloguing their prevalence and impact. Researchers have speculated that appification promotes security problems, as it increasingly allows inexperienced laymen to develop complex and sensitive apps. Anecdotally, Internet resources such as Stack Overflow are blamed for promoting insecure solutions that are naively copy-pasted by inexperienced developers. In this paper, we for the first time systematically analyzed how the use of information resources impacts code security. We first surveyed 295 app developers who have published in the Google Play market concerning how they use resources to solve security-related problems. Based on the survey results, we conducted a lab study with 54 Android developers (students and professionals), in which participants wrote security-and privacy-relevant code under time constraints. The participants were assigned to one of four conditions: free choice of resources, Stack Overflow only, official Android documentation only, or books only. Those participants who were allowed to use only Stack Overflow produced significantly less secure code than those using, the official Android documentation or books, while participants using the official Android documentation produced significantly less functional code than those using Stack Overflow. To assess the quality of Stack Overflow as a resource, we surveyed the 139 threads our participants accessed during the study, finding that only 25\% of them were helpful in solving the assigned tasks and only 17\% of them contained secure code snippets. In order to obtain ground truth concerning the prevalence of the secure and insecure code our participants wrote in the lab study, we statically analyzed a random sample of 200,000 apps from Google Pla- , finding that 93.6\% of the apps used at least one of the API calls our participants used during our study. We also found that many of the security errors made by our participants also appear in the wild, possibly also originating in the use of Stack Overflow to solve programming problems. Taken together, our results confirm that API documentation is secure but hard to use, while informal documentation such as Stack Overflow is more accessible but often leads to insecurity. Given time constraints and economic pressures, we can expect that Android developers will continue to choose those resources that are easiest to use, therefore, our results firmly establish the need for secure-but-usable documentation.},
	booktitle = {2016 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Acar, Y. and Backes, M. and Fahl, S. and Kim, D. and Mazurek, M. L. and Stransky, C.},
	month = may,
	year = {2016},
	keywords = {source code (software), Security, security of data, data privacy, Privacy, security, Programming, Android (operating system), Androids, code security, Humanoid robots, information source, Stack Overflow, Android, mobile computing, application program interface, application program interfaces, Documentation, Mobile communication, Android code vulnerability, Android developer, API documentation, developer resources, developer study, mobile device, privacy leak, usability},
	pages = {289--305},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\VIZFVIZB\\7546508.html:text/html}
}

@misc{noauthor_i_nodate,
	title = {"{I} {Have} {No} {Idea} {What} {I}'m {Doing}" - {On} the {Usability} of {Deploying} {HTTPS} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/krombholz},
	urldate = {2018-02-26},
	file = {"I Have No Idea What I'm Doing" - On the Usability of Deploying HTTPS | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\H4UTJ5GY\\krombholz.html:text/html}
}

@inproceedings{georgiev_most_2012,
	title = {The most dangerous code in the world: validating {SSL} certificates in non-browser software},
	shorttitle = {The most dangerous code in the world},
	booktitle = {Proceedings of the 2012 {ACM} conference on {Computer} and communications security},
	publisher = {ACM},
	author = {Georgiev, Martin and Iyengar, Subodh and Jana, Suman and Anubhai, Rishita and Boneh, Dan and Shmatikov, Vitaly},
	year = {2012},
	pages = {38--49},
	file = {Georgiev et al. - 2012 - The most dangerous code in the world validating S.pdf:C\:\\Users\\Anna\\Zotero\\storage\\YMCRZR89\\Georgiev et al. - 2012 - The most dangerous code in the world validating S.pdf:application/pdf}
}

@inproceedings{derr_keep_2017,
	title = {Keep me {Updated}: {An} {Empirical} {Study} of {Third}-{Party} {Library} {Updatability} on {Android}},
	isbn = {978-1-4503-4946-8},
	shorttitle = {Keep me {Updated}},
	url = {http://dl.acm.org/citation.cfm?doid=3133956.3134059},
	doi = {10.1145/3133956.3134059},
	language = {en},
	urldate = {2018-02-26},
	publisher = {ACM Press},
	author = {Derr, Erik and Bugiel, Sven and Fahl, Sascha and Acar, Yasemin and Backes, Michael},
	year = {2017},
	pages = {2187--2200},
	file = {Derr et al. - 2017 - Keep me Updated An Empirical Study of Third-Party.pdf:C\:\\Users\\Anna\\Zotero\\storage\\BYFLQ95C\\Derr et al. - 2017 - Keep me Updated An Empirical Study of Third-Party.pdf:application/pdf}
}

@techreport{das_iv_2014,
	title = {{IV}= 0 security: {Cryptographic} misuse of libraries},
	shorttitle = {{IV}= 0 security},
	institution = {Technical Report},
	author = {Das, Somak and Gopal, Vineet and King, Kevin and Venkatraman, Amruth},
	year = {2014},
	keywords = {to read, How much influences the choice of a parameter the security of the crypto API?},
	file = {Das et al. - 2014 - IV= 0 security Cryptographic misuse of libraries.pdf:C\:\\Users\\Anna\\Zotero\\storage\\3Y8G92GI\\Das et al. - 2014 - IV= 0 security Cryptographic misuse of libraries.pdf:application/pdf}
}

@misc{noauthor_tips_nodate,
	title = {Tips for making the most out of conferences when it comes to your career (opinion) {\textbar} {Inside} {Higher} {Ed}},
	url = {https://www.insidehighered.com/advice/2018/02/26/tips-making-most-out-conferences-when-it-comes-your-career-opinion},
	abstract = {Conferences have the potential to be great for your career, writes Derek Attig, but only if you approach them with focus and intentionality.},
	language = {en},
	urldate = {2018-02-27},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\S59AKLCZ\\tips-making-most-out-conferences-when-it-comes-your-career-opinion.html:text/html}
}

@inproceedings{gutmann_lessons_2002,
	title = {Lessons {Learned} in {Implementing} and {Deploying} {Crypto} {Software}.},
	booktitle = {Usenix {Security} {Symposium}},
	author = {Gutmann, Peter},
	year = {2002},
	keywords = {to read},
	pages = {315--325},
	file = {Gutmann - 2002 - Lessons Learned in Implementing and Deploying Cryp.pdf:C\:\\Users\\Anna\\Zotero\\storage\\B263A556\\Gutmann - 2002 - Lessons Learned in Implementing and Deploying Cryp.pdf:application/pdf}
}

@inproceedings{whitten_why_1999,
	title = {Why {Johnny} {Can}'t {Encrypt}: {A} {Usability} {Evaluation} of {PGP} 5.0.},
	volume = {348},
	shorttitle = {Why {Johnny} {Can}'t {Encrypt}},
	booktitle = {{USENIX} {Security} {Symposium}},
	author = {Whitten, Alma and Tygar, J. Doug},
	year = {1999},
	keywords = {to read},
	file = {Whitten und Tygar - 1999 - Why Johnny Can't Encrypt A Usability Evaluation o.pdf:C\:\\Users\\Anna\\Zotero\\storage\\6JMT5CEM\\Whitten und Tygar - 1999 - Why Johnny Can't Encrypt A Usability Evaluation o.pdf:application/pdf}
}

@article{robillard_automated_2013,
	title = {Automated {API} {Property} {Inference} {Techniques}},
	volume = {39},
	issn = {0098-5589},
	url = {http://dx.doi.org/10.1109/TSE.2012.63},
	doi = {10.1109/TSE.2012.63},
	abstract = {Frameworks and libraries offer reusable and customizable functionality through Application Programming Interfaces (APIs). Correctly using large and sophisticated APIs can represent a challenge due to hidden assumptions and requirements. Numerous approaches have been developed to infer properties of APIs, intended to guide their use by developers. With each approach come new definitions of API properties, new techniques for inferring these properties, and new ways to assess their correctness and usefulness. This paper provides a comprehensive survey of over a decade of research on automated property inference for APIs. Our survey provides a synthesis of this complex technical field along different dimensions of analysis: properties inferred, mining techniques, and empirical results. In particular, we derive a classification and organization of over 60 techniques into five different categories based on the type of API property inferred: unordered usage patterns, sequential usage patterns, behavioral specifications, migration mappings, and general information.},
	number = {5},
	urldate = {2018-02-28},
	journal = {IEEE Trans. Softw. Eng.},
	author = {Robillard, Martin P. and Bodden, Eric and Kawrykow, David and Mezini, Mira and Ratchford, Tristan},
	month = may,
	year = {2013},
	keywords = {API evolution, API property, API usage pattern, Association rules, Context, data mining, interface, Itemsets, pattern mining, Programming, programming rules, protocols, Protocols, Software engineering, specifications, E1peer, to read},
	pages = {613--637},
	file = {Robillard et al. - 2013 - Automated API Property Inference Techniques.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HVN8XFGS\\Robillard et al. - 2013 - Automated API Property Inference Techniques.pdf:application/pdf}
}

@article{stevenson_survey_2014,
	series = {Selected {Papers} from the {Fifth} {International} {Conference} on {Software} {Language} {Engineering} ({SLE} 2012)},
	title = {A survey of grammatical inference in software engineering},
	volume = {96},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642314002469},
	doi = {10.1016/j.scico.2014.05.008},
	abstract = {Grammatical inference – used successfully in a variety of fields such as pattern recognition, computational biology and natural language processing – is the process of automatically inferring a grammar by examining the sentences of an unknown language. Software engineering can also benefit from grammatical inference. Unlike these other fields, which use grammars as a convenient tool to model naturally occurring patterns, software engineering treats grammars as first-class objects typically created and maintained for a specific purpose by human designers. We introduce the theory of grammatical inference and review the state of the art as it relates to software engineering.},
	urldate = {2018-02-28},
	journal = {Science of Computer Programming},
	author = {Stevenson, Andrew and Cordy, James R.},
	month = dec,
	year = {2014},
	keywords = {Software engineering, to read, Grammar induction, Grammatical inference},
	pages = {444--459},
	file = {ScienceDirect Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MH7G9SRD\\S0167642314002469.html:text/html;Stevenson und Cordy - 2014 - A survey of grammatical inference in software engi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\SE2RWI9U\\Stevenson und Cordy - 2014 - A survey of grammatical inference in software engi.pdf:application/pdf}
}

@article{kruger_crysl:_2018,
	title = {{CrySL}: {Validating} {Correct} {Usage} of {Cryptographic} {APIs}},
	volume = {European Conference on Object-Oriented Programming (ECOOP)},
	shorttitle = {{CrySL}},
	url = {http://arxiv.org/abs/1710.00564},
	abstract = {Various studies have empirically shown that the majority of Java and Android apps misuse cryptographic libraries, causing devastating breaches of data security. Therefore, it is crucial to detect such misuses early in the development process. The fact that insecure usages are not the exception but the norm precludes approaches based on property inference and anomaly detection. In this paper, we present CrySL, a definition language that enables cryptography experts to specify the secure usage of the cryptographic libraries that they provide. CrySL combines the generic concepts of method-call sequences and data-flow constraints with domain-specific constraints related to cryptographic algorithms and their parameters. We have implemented a compiler that translates a CrySL ruleset into a context- and flow-sensitive demand-driven static analysis. The analysis automatically checks a given Java or Android app for violations of the CrySL-encoded rules. We empirically evaluated our ruleset through analyzing 10,001 Android apps. Our results show that misuse of cryptographic APIs is still widespread, with 96\% of apps containing at least one misuse. However, we observed fewer of the misuses that were reported in previous work.},
	urldate = {2018-03-05},
	journal = {arXiv:1710.00564 [cs]},
	author = {Krüger, Stefan and Späth, Johannes and Ali, Karim and Bodden, Eric and Mezini, Mira},
	year = {2018},
	note = {arXiv: 1710.00564},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\KNAYXF8B\\1710.html:text/html;Krüger et al. - 2017 - CrySL Validating Correct Usage of Cryptographic A.pdf:C\:\\Users\\Anna\\Zotero\\storage\\546PSBHQ\\Krüger et al. - 2017 - CrySL Validating Correct Usage of Cryptographic A.pdf:application/pdf}
}

@inproceedings{ren_bug_2018,
	title = {Bug {Fixes}, {Improvements}, ... and {Privacy} {Leaks} - {A} {Longitudinal} {Study} of {PII} {Leaks} {Across} {Android} {App} {Versions}},
	isbn = {978-1-891562-49-5},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_05B-2_Ren_paper.pdf},
	doi = {10.14722/ndss.2018.23143},
	language = {en},
	urldate = {2018-03-06},
	publisher = {Internet Society},
	author = {Ren, Jingjing and Lindorfer, Martina and Dubois, Daniel J. and Rao, Ashwin and Choffnes, David and Vallina-Rodriguez, Narseo},
	year = {2018},
	file = {Ren et al. - 2018 - Bug Fixes, Improvements, ... and Privacy Leaks - A.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TGWVNB9N\\Ren et al. - 2018 - Bug Fixes, Improvements, ... and Privacy Leaks - A.pdf:application/pdf}
}

@inproceedings{andreou_investigating_2018,
	title = {Investigating {Ad} {Transparency} {Mechanisms} in {Social} {Media}: {A} {Case} {Study} of {Facebook}'s {Explanations}},
	isbn = {978-1-891562-49-5},
	shorttitle = {Investigating {Ad} {Transparency} {Mechanisms} in {Social} {Media}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_10-1_Andreou_paper.pdf},
	doi = {10.14722/ndss.2018.23191},
	language = {en},
	urldate = {2018-03-07},
	publisher = {Internet Society},
	author = {Andreou, Athanasios and Venkatadri, Giridhari and Goga, Oana and Gummadi, Krishna P. and Loiseau, Patrick and Mislove, Alan},
	year = {2018},
	file = {Andreou et al. - 2018 - Investigating Ad Transparency Mechanisms in Social.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9N298TH9\\Andreou et al. - 2018 - Investigating Ad Transparency Mechanisms in Social.pdf:application/pdf}
}

@article{nikolic_finding_2018,
	title = {Finding {The} {Greedy}, {Prodigal}, and {Suicidal} {Contracts} at {Scale}},
	url = {http://arxiv.org/abs/1802.06038},
	abstract = {Smart contracts---stateful executable objects hosted on blockchains like Ethereum---carry billions of dollars worth of coins and cannot be updated once deployed. We present a new systematic characterization of a class of trace vulnerabilities, which result from analyzing multiple invocations of a contract over its lifetime. We focus attention on three example properties of such trace vulnerabilities: finding contracts that either lock funds indefinitely, leak them carelessly to arbitrary users, or can be killed by anyone. We implemented MAIAN, the first tool for precisely specifying and reasoning about trace properties, which employs inter-procedural symbolic analysis and concrete validator for exhibiting real exploits. Our analysis of nearly one million contracts flags 34,200 (2,365 distinct) contracts vulnerable, in 10 seconds per contract. On a subset of3,759 contracts which we sampled for concrete validation and manual analysis, we reproduce real exploits at a true positive rate of 89\%, yielding exploits for3,686 contracts. Our tool finds exploits for the infamous Parity bug that indirectly locked 200 million dollars worth in Ether, which previous analyses failed to capture.},
	urldate = {2018-03-07},
	journal = {arXiv:1802.06038 [cs]},
	author = {Nikolic, Ivica and Kolluri, Aashish and Sergey, Ilya and Saxena, Prateek and Hobor, Aquinas},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.06038},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BNSLUM64\\1802.html:text/html;Nikolic et al. - 2018 - Finding The Greedy, Prodigal, and Suicidal Contrac.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UUBFXR5C\\Nikolic et al. - 2018 - Finding The Greedy, Prodigal, and Suicidal Contrac.pdf:application/pdf}
}

@misc{gewin_how_2018,
	type = {News},
	title = {How to write a first-class paper},
	copyright = {2018 Nature},
	url = {http://www.nature.com/articles/d41586-018-02404-4},
	abstract = {Six experts offer advice on producing a manuscript that will get published and pull in readers.},
	language = {EN},
	urldate = {2018-03-07},
	journal = {Nature},
	author = {Gewin, Virginia},
	month = feb,
	year = {2018},
	doi = {10.1038/d41586-018-02404-4},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\4CUGD753\\d41586-018-02404-4.html:text/html}
}

@misc{noauthor_tense_nodate,
	title = {tense {\textbar} {Search} {Results} {\textbar} {DoctoralWriting} {SIG}},
	url = {https://doctoralwriting.wordpress.com//?s=tense&search=Go},
	language = {en},
	urldate = {2018-03-07},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\37A4C83K\\doctoralwriting.wordpress.com.html:text/html}
}

@article{mensh_ten_2017,
	title = {Ten simple rules for structuring papers},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005619},
	doi = {10.1371/journal.pcbi.1005619},
	language = {en},
	number = {9},
	urldate = {2018-03-07},
	journal = {PLOS Computational Biology},
	author = {Mensh, Brett and Kording, Konrad},
	month = sep,
	year = {2017},
	keywords = {to read, not yet, Careers, Cell differentiation, Communications, Crystals, Experimental design, Patient advocacy, Scientists, Syntax},
	pages = {e1005619},
	file = {Mensh und Kording - 2017 - Ten simple rules for structuring papers.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JCBBMQZI\\Mensh und Kording - 2017 - Ten simple rules for structuring papers.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2XF9A8X2\\article.html:text/html}
}

@inproceedings{zimmermann_mining_2004,
	address = {Washington, DC, USA},
	series = {{ICSE} '04},
	title = {Mining {Version} {Histories} to {Guide} {Software} {Changes}},
	isbn = {978-0-7695-2163-3},
	url = {http://dl.acm.org/citation.cfm?id=998675.999460},
	abstract = {We apply data mining to version histories in order toguide programmers along related changes: "Programmerswho changed these functions also changed. . . ". Given aset of existing changes, such rules (a) suggest and predictlikely further changes, (b) show up item coupling that is indetectableby program analysis, and (c) prevent errors dueto incomplete changes. After an initial change, our ROSEprototype can correctly predict 26\% of further files to bechanged ¿ and 15\% of the precise functions or variables.The topmost three suggestions contain a correct locationwith a likelihood of 64\%.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 26th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Zimmermann, Thomas and Weisgerber, Peter and Diehl, Stephan and Zeller, Andreas},
	year = {2004},
	keywords = {to read},
	pages = {563--572},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\SIQQ3JR3\\Zimmermann et al. - 2004 - Mining Version Histories to Guide Software Changes.pdf:application/pdf}
}

@inproceedings{zimmermann_predicting_2007,
	address = {Washington, DC, USA},
	series = {{PROMISE} '07},
	title = {Predicting {Defects} for {Eclipse}},
	isbn = {978-0-7695-2954-7},
	url = {http://dx.doi.org/10.1109/PROMISE.2007.10},
	doi = {10.1109/PROMISE.2007.10},
	abstract = {We have mapped defects from the bug database of Eclipse (one of the largest open-source projects) to source code locations. The resulting data set lists the number of pre- and post-release defects for every package and file in the Eclipse releases 2.0, 2.1, and 3.0. We additionally annotated the data with common complexity metrics. All data is publicly available and can serve as a benchmark for defect prediction models.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the {Third} {International} {Workshop} on {Predictor} {Models} in {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Zimmermann, Thomas and Premraj, Rahul and Zeller, Andreas},
	year = {2007},
	keywords = {to read},
	pages = {9--},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\2SHEZPKI\\Zimmermann et al. - 2007 - Predicting Defects for Eclipse.pdf:application/pdf}
}

@inproceedings{anvik_who_2006,
	address = {New York, NY, USA},
	series = {{ICSE} '06},
	title = {Who {Should} {Fix} {This} {Bug}?},
	isbn = {978-1-59593-375-1},
	url = {http://doi.acm.org/10.1145/1134285.1134336},
	doi = {10.1145/1134285.1134336},
	abstract = {Open source development projects typically support an open bug repository to which both developers and users can report bugs. The reports that appear in this repository must be triaged to determine if the report is one which requires attention and if it is, which developer will be assigned the responsibility of resolving the report. Large open source developments are burdened by the rate at which new bug reports appear in the bug repository. In this paper, we present a semi-automated approach intended to ease one part of this process, the assignment of reports to a developer. Our approach applies a machine learning algorithm to the open bug repository to learn the kinds of reports each developer resolves. When a new report arrives, the classifier produced by the machine learning technique suggests a small number of developers suitable to resolve the report. With this approach, we have reached precision levels of 57\% and 64\% on the Eclipse and Firefox development projects respectively. We have also applied our approach to the gcc open source development with less positive results. We describe the conditions under which the approach is applicable and also report on the lessons we learned about applying machine learning to repositories used in open source development.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Anvik, John and Hiew, Lyndon and Murphy, Gail C.},
	year = {2006},
	keywords = {to read, machine learning, bug report assignment, bug triage, issue tracking, problem tracking},
	pages = {361--370},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\X7EUZX34\\Anvik et al. - 2006 - Who Should Fix This Bug.pdf:application/pdf}
}

@inproceedings{li_characterizing_2011,
	address = {New York, NY, USA},
	series = {{ICSE} '11},
	title = {Characterizing the {Differences} {Between} {Pre}- and {Post}- {Release} {Versions} of {Software}},
	isbn = {978-1-4503-0445-0},
	url = {http://doi.acm.org/10.1145/1985793.1985894},
	doi = {10.1145/1985793.1985894},
	abstract = {Many software producers utilize beta programs to predict post-release quality and to ensure that their products meet quality expectations of users. Prior work indicates that software producers need to adjust predictions to account for usage environments and usage scenarios differences between beta populations and post-release populations. However, little is known about how usage characteristics relate to field quality and how usage characteristics differ between beta and post-release. In this study, we examine application crash, application hang, system crash, and usage information from millions of Windows® users to 1) examine the effects of usage characteristics differences on field quality (e.g. which usage characteristics impact quality), 2) examine usage characteristics differences between beta and post-release (e.g. do impactful usage characteristics differ), and 3) report experiences adjusting field quality predictions for Windows. Among the 18 usage characteristics that we examined, the five most important were: the number of application executed, whether the machines was pre-installed by the original equipment manufacturer, two sub-populations (two language/geographic locales), and whether Windows was 64-bit (not 32-bit). We found each of these usage characteristics to differ between beta and post-release, and by adjusting for the differences, accuracy of field quality predictions for Windows improved by {\textasciitilde}59\%.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Li, Paul Luo and Kivett, Ryan and Zhan, Zhiyuan and Jeon, Sung-eok and Nagappan, Nachiappan and Murphy, Brendan and Ko, Andrew J.},
	year = {2011},
	keywords = {to read, beta, customer experience improvement program, reliability analysis component (rac), usage, windows, windows error reporting (wer)},
	pages = {716--725},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\TJEQTMW8\\Li et al. - 2011 - Characterizing the Differences Between Pre- and Po.pdf:application/pdf}
}

@inproceedings{bird_fair_2009,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} '09},
	title = {Fair and {Balanced}?: {Bias} in {Bug}-fix {Datasets}},
	isbn = {978-1-60558-001-2},
	shorttitle = {Fair and {Balanced}?},
	url = {http://doi.acm.org/10.1145/1595696.1595716},
	doi = {10.1145/1595696.1595716},
	abstract = {Software engineering researchers have long been interested in where and why bugs occur in code, and in predicting where they might turn up next. Historical bug-occurence data has been key to this research. Bug tracking systems, and code version histories, record when, how and by whom bugs were fixed; from these sources, datasets that relate file changes to bug fixes can be extracted. These historical datasets can be used to test hypotheses concerning processes of bug introduction, and also to build statistical bug prediction models. Unfortunately, processes and humans are imperfect, and only a fraction of bug fixes are actually labelled in source code version histories, and thus become available for study in the extracted datasets. The question naturally arises, are the bug fixes recorded in these historical datasets a fair representation of the full population of bug fixes? In this paper, we investigate historical data from several software projects, and find strong evidence of systematic bias. We then investigate the potential effects of "unfair, imbalanced" datasets on the performance of prediction techniques. We draw the lesson that bias is a critical problem that threatens both the effectiveness of processes that rely on biased datasets to build prediction models and the generalizability of hypotheses tested on biased data.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the the 7th {Joint} {Meeting} of the {European} {Software} {Engineering} {Conference} and the {ACM} {SIGSOFT} {Symposium} on {The} {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Bird, Christian and Bachmann, Adrian and Aune, Eirik and Duffy, John and Bernstein, Abraham and Filkov, Vladimir and Devanbu, Premkumar},
	year = {2009},
	keywords = {to read, bias},
	pages = {121--130},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ALCCEGS2\\Bird et al. - 2009 - Fair and Balanced Bias in Bug-fix Datasets.pdf:application/pdf}
}

@inproceedings{bachmann_missing_2010,
	address = {New York, NY, USA},
	series = {{FSE} '10},
	title = {The {Missing} {Links}: {Bugs} and {Bug}-fix {Commits}},
	isbn = {978-1-60558-791-2},
	shorttitle = {The {Missing} {Links}},
	url = {http://doi.acm.org/10.1145/1882291.1882308},
	doi = {10.1145/1882291.1882308},
	abstract = {Empirical studies of software defects rely on links between bug databases and program code repositories. This linkage is typically based on bug-fixes identified in developer-entered commit logs. Unfortunately, developers do not always report which commits perform bug-fixes. Prior work suggests that such links can be a biased sample of the entire population of fixed bugs. The validity of statistical hypotheses-testing based on linked data could well be affected by bias. Given the wide use of linked defect data, it is vital to gauge the nature and extent of the bias, and try to develop testable theories and models of the bias. To do this, we must establish ground truth: manually analyze a complete version history corpus, and nail down those commits that fix defects, and those that do not. This is a diffcult task, requiring an expert to compare versions, analyze changes, find related bugs in the bug database, reverse-engineer missing links, and finally record their work for use later. This effort must be repeated for hundreds of commits to obtain a useful sample of reported and unreported bug-fix commits. We make several contributions. First, we present Linkster, a tool to facilitate link reverse-engineering. Second, we evaluate this tool, engaging a core developer of the Apache HTTP web server project to exhaustively annotate 493 commits that occurred during a six week period. Finally, we analyze this comprehensive data set, showing that there are serious and consequential problems in the data.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Bachmann, Adrian and Bird, Christian and Rahman, Foyzur and Devanbu, Premkumar and Bernstein, Abraham},
	year = {2010},
	keywords = {to read, bias, apache, case study, manual annotation, tool},
	pages = {97--106},
	file = {Bachmann et al. - 2010 - The Missing Links Bugs and Bug-fix Commits.pdf:C\:\\Users\\Anna\\Zotero\\storage\\73JZG28U\\Bachmann et al. - 2010 - The Missing Links Bugs and Bug-fix Commits.pdf:application/pdf}
}

@inproceedings{nguyen_case_2010,
	address = {Washington, DC, USA},
	series = {{WCRE} '10},
	title = {A {Case} {Study} of {Bias} in {Bug}-{Fix} {Datasets}},
	isbn = {978-0-7695-4123-5},
	url = {http://dx.doi.org/10.1109/WCRE.2010.37},
	doi = {10.1109/WCRE.2010.37},
	abstract = {Software quality researchers build software quality models by recovering traceability links between bug reports in issue tracking repositories and source code files. However, all too often the data stored in issue tracking repositories is not explicitly tagged or linked to source code. Researchers have to resort to heuristics to tag the data (e.g., to determine if an issue is a bug report or a work item), or to link a piece of code to a particular issue or bug. Recent studies by Bird et al. and by Antoniol et al. suggest that software models based on imperfect datasets with missing links to the code and incorrect tagging of issues, exhibit biases that compromise the validity and generality of the quality models built on top of the datasets. In this study, we verify the effects of such biases for a commercial project that enforces strict development guidelines and rules on the quality of the data in its issue tracking repository. Our results show that even in such a perfect setting, with a near-ideal dataset, biases do exist – leading us to conjecture that biases are more likely a symptom of the underlying software development process instead of being due to the used heuristics.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 2010 17th {Working} {Conference} on {Reverse} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Nguyen, Thanh H. D. and Adams, Bram and Hassan, Ahmed E.},
	year = {2010},
	keywords = {to read, prediction, bias, bug-fix, data quality, sample},
	pages = {259--268},
	file = {Nguyen et al. - 2010 - A Case Study of Bias in Bug-Fix Datasets.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Nguyen et al. - 2010 - A Case Study of Bias in Bug-Fix Datasets.pdf:application/pdf}
}

@article{kim_classifying_2008,
	title = {Classifying {Software} {Changes}: {Clean} or {Buggy}?},
	volume = {34},
	issn = {0098-5589},
	shorttitle = {Classifying {Software} {Changes}},
	doi = {10.1109/TSE.2007.70773},
	abstract = {This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features.},
	number = {2},
	journal = {IEEE Transactions on Software Engineering},
	author = {Kim, S. and Jr, E. J. Whitehead and Zhang, Y.},
	month = mar,
	year = {2008},
	keywords = {program debugging, learning (artificial intelligence), software maintenance, programming languages, data mining, software metrics, to read, Data mining, software change, Clustering, open source projects, classification, and association rules, association rule, change classification, Configuration Management, feature extraction, machine learning classifier, Metrics/Measurement, software configuration management repository, Software maintenance, software project},
	pages = {181--196},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\5MI7LFTF\\4408585.html:text/html}
}

@inproceedings{hindle_what_2008,
	address = {New York, NY, USA},
	series = {{MSR} '08},
	title = {What {Do} {Large} {Commits} {Tell} {Us}?: {A} {Taxonomical} {Study} of {Large} {Commits}},
	isbn = {978-1-60558-024-1},
	shorttitle = {What {Do} {Large} {Commits} {Tell} {Us}?},
	url = {http://doi.acm.org/10.1145/1370750.1370773},
	doi = {10.1145/1370750.1370773},
	abstract = {Research in the mining of software repositories has frequently ignored commits that include a large number of files (we call these large commits). The main goal of this paper is to understand the rationale behind large commits, and if there is anything we can learn from them. To address this goal we performed a case study that included the manual classification of large commits of nine open source projects. The contributions include a taxonomy of large commits, which are grouped according to their intention. We contrast large commits against small commits and show that large commits are more perfective while small commits are more corrective. These large commits provide us with a window on the development practices of maintenance teams.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 2008 {International} {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Hindle, Abram and German, Daniel M. and Holt, Ric},
	year = {2008},
	keywords = {to read, large commits, software evolution, source control system},
	pages = {99--108},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\GQ825HMB\\Hindle et al. - 2008 - What Do Large Commits Tell Us A Taxonomical Stud.pdf:application/pdf}
}

@book{hindle_automatic_nodate,
	title = {Automatic {Classification} of {Large} {Changes} into {Maintenance} {Categories}},
	abstract = {Large software systems undergo significant evolution during their lifespan, yet often individual changes are not well documented. In this work, we seek to automatically classify large changes into various categories of maintenance tasks — corrective, adaptive, perfective, feature addition, and non-functional improvement — using machine learning techniques. In a previous paper, we found that many commits could be classified easily and reliably based solely on the manual analysis of the commit metadata and commit messages (i.e., without reference to the source code). Our extension is the automation of classification by training Machine Learners on features extracted from the commit metadata, such as the word distribution of a commit message, commit author, and modules modified. We validated the results of the learners via 10-fold cross validation, which achieved accuracies consistently above 50\%, indicating good to fair results. We found that the identity of the author of a commit provided much information about the maintenance class of a commit, almost as much as the words of the commit message. This implies that for most large commits, the Source Control System (SCS) commit messages plus the commit author identity is enough information to accurately and automatically categorize the nature of the maintenance task. 1},
	author = {Hindle, Abram and German, Daniel M. and Holt, Richard C. and Godfrey, Michael W.},
	keywords = {to read},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\FI4SNE5X\\Hindle et al. - Automatic Classification of Large Changes into Mai.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\9N6BRGZM\\summary.html:text/html}
}

@inproceedings{stoerzer_finding_2006,
	address = {New York, NY, USA},
	series = {{SIGSOFT} '06/{FSE}-14},
	title = {Finding {Failure}-inducing {Changes} in {Java} {Programs} {Using} {Change} {Classification}},
	isbn = {978-1-59593-468-0},
	url = {http://doi.acm.org/10.1145/1181775.1181783},
	doi = {10.1145/1181775.1181783},
	abstract = {Testing and code editing are interleaved activities during program development. When tests fail unexpectedly, the changes that caused the failure(s) are not always easy to find. We explore how change classification can focus programmer attention on failure-inducing changes by automatically labeling changes Red, Yellow, or Green, indicating the likelihood that they have contributed to a test failure. We implemented our change classification tool JUnit/CIA as an ex-tension to the JUnit component within Eclipse, and evaluated its effectiveness in two case studies. Our results indicate that change classification is an effective technique for finding failure-inducing changes.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 14th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Stoerzer, Maximilian and Ryder, Barbara G. and Ren, Xiaoxia and Tip, Frank},
	year = {2006},
	keywords = {to read, change impact analysis, debugging, fault localization, testing, version control},
	pages = {57--68},
	file = {Stoerzer et al. - 2006 - Finding Failure-inducing Changes in Java Programs .pdf:C\:\\Users\\Anna\\Zotero\\storage\\CYB6M8E8\\Stoerzer et al. - 2006 - Finding Failure-inducing Changes in Java Programs .pdf:application/pdf}
}

@inproceedings{wloka_safe-commit_2009,
	address = {Washington, DC, USA},
	series = {{ICSE} '09},
	title = {Safe-commit {Analysis} to {Facilitate} {Team} {Software} {Development}},
	isbn = {978-1-4244-3453-4},
	url = {http://dx.doi.org/10.1109/ICSE.2009.5070549},
	doi = {10.1109/ICSE.2009.5070549},
	abstract = {Software development teams exchange source code in shared repositories. These repositories are kept consistent by having developers follow a commit policy, such as “Program edits can be committed only if all available tests succeed.” Such policies may result in long intervals between commits, increasing the likelihood of duplicative development and merge conflicts. Furthermore, commit policies are generally not automatically enforceable. We present a program analysis to identify committable changes that can be released early, without causing failures of existing tests, even in the presence of failing tests in a developer's local workspace. The algorithm can support relaxed commit policies that allow early release of changes, reducing the potential for merge conflicts. In experiments using several versions of a non-trivial software system with failing tests, 3 newly enabled commit policies were shown to allow a significant percentage of changes to be committed.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Wloka, Jan and Ryder, Barbara and Tip, Frank and Ren, Xiaoxia},
	year = {2009},
	keywords = {to read},
	pages = {507--517},
	file = {Wloka et al. - 2009 - Safe-commit Analysis to Facilitate Team Software D.pdf:C\:\\Users\\Anna\\Zotero\\storage\\LTLD38E9\\Wloka et al. - 2009 - Safe-commit Analysis to Facilitate Team Software D.pdf:application/pdf}
}

@article{williams_characterizing_2010,
	title = {Characterizing {Software} {Architecture} {Changes}: {A} {Systematic} {Review}},
	volume = {52},
	issn = {0950-5849},
	shorttitle = {Characterizing {Software} {Architecture} {Changes}},
	url = {http://dx.doi.org/10.1016/j.infsof.2009.07.002},
	doi = {10.1016/j.infsof.2009.07.002},
	abstract = {Loading...},
	number = {1},
	urldate = {2018-03-07},
	journal = {Inf. Softw. Technol.},
	author = {Williams, Byron J. and Carver, Jeffrey C.},
	month = jan,
	year = {2010},
	keywords = {to read, Software maintenance, Change characterization, Software architecture, Software changes, Software evolution, Systematic review},
	pages = {31--51}
}

@inproceedings{murphy-hill_how_2009,
	address = {Washington, DC, USA},
	series = {{ICSE} '09},
	title = {How {We} {Refactor}, and {How} {We} {Know} {It}},
	isbn = {978-1-4244-3453-4},
	url = {http://dx.doi.org/10.1109/ICSE.2009.5070529},
	doi = {10.1109/ICSE.2009.5070529},
	abstract = {Much of what we know about how programmers refactor in the wild is based on studies that examine just a few software projects. Researchers have rarely taken the time to replicate these studies in other contexts or to examine the assumptions on which they are based. To help put refactoring research on a sound scientific basis, we draw conclusions using four data sets spanning more than 13 000 developers, 240 000 tool-assisted refactorings, 2500 developer hours, and 3400 version control commits. Using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. For example, we find that programmers frequently do not indicate refactoring activity in commit logs, which contradicts assumptions made by several previous researchers. In contrast, we were able to confirm the assumption that programmers do frequently intersperse refactoring with other program changes. By confirming assumptions and replicating studies made by other researchers, we can have greater confidence that those researchers' conclusions are generalizable.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Murphy-Hill, Emerson and Parnin, Chris and Black, Andrew P.},
	year = {2009},
	keywords = {to read},
	pages = {287--297},
	file = {Murphy-Hill et al. - 2009 - How We Refactor, and How We Know It.pdf:C\:\\Users\\Anna\\Zotero\\storage\\B4CNL2UU\\Murphy-Hill et al. - 2009 - How We Refactor, and How We Know It.pdf:application/pdf}
}

@article{murphy-hill_refactoring_2008,
	title = {Refactoring tools: {Fitness} for purpose},
	shorttitle = {Refactoring tools},
	abstract = {Refactoring tools can improve the speed and accuracy with which we create and maintain software — but only if they are used. In practice, tools are not used as much as they could be; this seems to be because sometimes they do not align with the refactoring tactic preferred by the majority of programmers, a tactic we call floss refactoring. We propose five principles that characterize successful floss refactoring tools — principles that},
	journal = {IEEE Software},
	author = {Murphy-hill, Emerson and Black, Andrew P.},
	year = {2008},
	keywords = {to read},
	file = {Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\5AXJQGFI\\summary.html:text/html;Murphy-hill und Black - 2008 - Refactoring tools Fitness for purpose.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HAF6QJMM\\Murphy-hill und Black - 2008 - Refactoring tools Fitness for purpose.pdf:application/pdf}
}

@inproceedings{kawrykow_non-essential_2011,
	address = {New York, NY, USA},
	series = {{ICSE} '11},
	title = {Non-essential {Changes} in {Version} {Histories}},
	isbn = {978-1-4503-0445-0},
	url = {http://doi.acm.org/10.1145/1985793.1985842},
	doi = {10.1145/1985793.1985842},
	abstract = {Numerous techniques involve mining change data captured in software archives to assist engineering efforts, for example to identify components that tend to evolve together. We observed that important changes to software artifacts are sometimes accompanied by numerous non-essential modifications, such as local variable refactorings, or textual differences induced as part of a rename refactoring. We developed a tool-supported technique for detecting non-essential code differences in the revision histories of software systems. We used our technique to investigate code changes in over 24,000 change sets gathered from the change histories of seven long-lived open-source systems. We found that up to 15.5\% of a system's method updates were due solely to non-essential differences. We also report on numerous observations on the distribution of non-essential differences in change history and their potential impact on change-based analyses.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Kawrykow, David and Robillard, Martin P.},
	year = {2011},
	keywords = {to read, mining software repositories, differencing algorithms, software change analysis},
	pages = {351--360},
	file = {Kawrykow und Robillard - 2011 - Non-essential Changes in Version Histories.pdf:C\:\\Users\\Anna\\Zotero\\storage\\BK4XXPSW\\Kawrykow und Robillard - 2011 - Non-essential Changes in Version Histories.pdf:application/pdf}
}

@misc{noauthor_approach_nodate,
	title = {An approach to software evolution based on semantic change},
	url = {https://dl.acm.org/citation.cfm?id=1759400},
	urldate = {2018-03-07},
	keywords = {to read},
	file = {An approach to software evolution based on semantic change:C\:\\Users\\Anna\\Zotero\\storage\\KW544DGS\\citation.html:text/html}
}

@book{kawrykow_enabling_2011,
	title = {{ENABLING} {PRECISE} {INTERPRETATIONS} {OF} {SOFTWARE} {CHANGE} {DATA} by},
	abstract = {Numerous techniques mine change data captured in software archives to assist software engineering efforts. These change-based approaches typically analyze change sets – groups of co-committed changes – under the assumption that the development work represented by change sets is both meaningful and related to a single change task. However, we have found that change sets often violate this assumption by containing changes that we consider to be non-essential, or less likely to be representative of the kind of meaningful software development effort that is most interesting to typical change-based approaches. Furthermore, we have found many change sets addressing multiple subtasks – groups of isolated changes that are related to each other, but not to other changes within a change set. Information mined from such change sets has the potential for interfering with the analyses of various change-based approaches. We propose a catalog of non-essential changes and describe an automated technique for detecting such changes within version histories. We used our technique to conduct an empirical investigation of over 30 000 change sets capturing over 25 years of cumulative development activity in ten open-source Java systems. Our investigation found that between},
	author = {Kawrykow, David},
	year = {2011},
	keywords = {to read},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\3LSEHWDK\\Kawrykow - 2011 - ENABLING PRECISE INTERPRETATIONS OF SOFTWARE CHANG.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZTXCDEQ3\\summary.html:text/html}
}

@inproceedings{kim_dealing_2011,
	address = {New York, NY, USA},
	series = {{ICSE} '11},
	title = {Dealing with {Noise} in {Defect} {Prediction}},
	isbn = {978-1-4503-0445-0},
	url = {http://doi.acm.org/10.1145/1985793.1985859},
	doi = {10.1145/1985793.1985859},
	abstract = {Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises. This paper proposes approaches to deal with the noise in defect data. First, we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general, for large defect datasets, adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However, the prediction performance decreases significantly when the dataset contains 20\%-35\% of both FP and FN noises. Second, we propose a noise detection and elimination algorithm to address this problem. Our empirical study shows that our algorithm can identify noisy instances with reasonable accuracy. In addition, after eliminating the noises using our algorithm, defect prediction accuracy is improved.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Kim, Sunghun and Zhang, Hongyu and Wu, Rongxin and Gong, Liang},
	year = {2011},
	keywords = {to read, buggy files, data quality, buggy changes, defect prediction, noise resistance},
	pages = {481--490},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\F3BVPK6K\\Kim et al. - 2011 - Dealing with Noise in Defect Prediction.pdf:application/pdf}
}

@article{menzies_defect_2010,
	title = {Defect prediction from static code features: current results, limitations, new approaches},
	volume = {17},
	issn = {0928-8910, 1573-7535},
	shorttitle = {Defect prediction from static code features},
	url = {http://link.springer.com/10.1007/s10515-010-0069-5},
	doi = {10.1007/s10515-010-0069-5},
	language = {en},
	number = {4},
	urldate = {2018-03-07},
	journal = {Automated Software Engineering},
	author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ayşe},
	month = dec,
	year = {2010},
	keywords = {to read},
	pages = {375--407},
	file = {10which.pdf:C\:\\Users\\Anna\\Zotero\\storage\\58NGPZDY\\10which.pdf:application/pdf}
}

@inproceedings{bhattacharya_using_2011,
	title = {Using software evolution history to facilitate development and maintenance},
	booktitle = {Software {Engineering} ({ICSE}), 2011 33rd {International} {Conference} on},
	publisher = {IEEE},
	author = {Bhattacharya, Pamela},
	year = {2011},
	keywords = {to read},
	pages = {1122--1123},
	file = {bhattacharya_doct_symp_icse11.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CDX7LTMY\\bhattacharya_doct_symp_icse11.pdf:application/pdf}
}

@inproceedings{kalra_zeus:_2018,
	title = {{ZEUS}: {Analyzing} {Safety} of {Smart} {Contracts}},
	isbn = {978-1-891562-49-5},
	shorttitle = {{ZEUS}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_09-1_Kalra_paper.pdf},
	doi = {10.14722/ndss.2018.23082},
	language = {en},
	urldate = {2018-03-08},
	publisher = {Internet Society},
	author = {Kalra, Sukrit and Goel, Seep and Dhawan, Mohan and Sharma, Subodh},
	year = {2018},
	file = {Kalra et al. - 2018 - ZEUS Analyzing Safety of Smart Contracts.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XDQVNWUX\\Kalra et al. - 2018 - ZEUS Analyzing Safety of Smart Contracts.pdf:application/pdf}
}

@misc{noauthor_dejavu:_2017,
	title = {D{éjàVu}: a map of code duplicates on {GitHub}},
	shorttitle = {D{éjàVu}},
	url = {https://blog.acolyer.org/2017/11/20/dejavu-a-map-of-code-duplicates-on-github/},
	abstract = {DéjàVu: A map of code duplicates on GitHub Lopes et al., OOPSLA ‘17 ‘DéjàVu’ drew me in with its attention grabbing abstract: This paper analyzes a corpus of 4.5 million non-fork projects hosted on…},
	language = {en},
	urldate = {2018-03-08},
	journal = {the morning paper},
	month = nov,
	year = {2017},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\3TMT3EFX\\dejavu-a-map-of-code-duplicates-on-github.html:text/html}
}

@misc{noauthor_dissection_2017,
	title = {A dissection of the test-driven development process: does it really matter to test-first or test-last?},
	shorttitle = {A dissection of the test-driven development process},
	url = {https://blog.acolyer.org/2017/06/13/a-dissection-of-the-test-driven-development-process-does-it-really-matter-to-test-first-or-test-last/},
	abstract = {A dissection of the test-driven development process: does it really matter to test-first or to test-last? Fucci et al., ICSE’17 Here we have a study with a really interesting aim – to f…},
	language = {en},
	urldate = {2018-03-08},
	journal = {the morning paper},
	month = jun,
	year = {2017},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\KQ2P57P2\\a-dissection-of-the-test-driven-development-process-does-it-really-matter-to-test-first-or-test.html:text/html}
}

@misc{noauthor_what_nodate,
	title = {What is the best way to read scientific papers? - {Quora}},
	url = {https://www.quora.com/What-is-the-best-way-to-read-scientific-papers?redirected_qid=783928},
	urldate = {2018-03-08},
	file = {What is the best way to read scientific papers? - Quora:C\:\\Users\\Anna\\Zotero\\storage\\KKVZCTA6\\What-is-the-best-way-to-read-scientific-papers.html:text/html}
}

@inproceedings{roos_settling_2018,
	title = {Settling {Payments} {Fast} and {Private}: {Efficient} {Decentralized} {Routing} for {Path}-{Based} {Transactions}},
	isbn = {978-1-891562-49-5},
	shorttitle = {Settling {Payments} {Fast} and {Private}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_09-3_Roos_paper.pdf},
	doi = {10.14722/ndss.2018.23252},
	language = {en},
	urldate = {2018-03-09},
	publisher = {Internet Society},
	author = {Roos, Stefanie and Moreno-Sanchez, Pedro and Kate, Aniket and Goldberg, Ian},
	year = {2018},
	file = {Roos et al. - 2018 - Settling Payments Fast and Private Efficient Dece.pdf:C\:\\Users\\Anna\\Zotero\\storage\\25T5RV84\\Roos et al. - 2018 - Settling Payments Fast and Private Efficient Dece.pdf:application/pdf}
}

@inproceedings{zhang_automatic_2012,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '12},
	title = {Automatic {Parameter} {Recommendation} for {Practical} {API} {Usage}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337321},
	abstract = {Programmers extensively use application programming interfaces (APIs) to leverage existing libraries and frameworks. However, correctly and efficiently choosing and using APIs from unfamiliar libraries and frameworks is still a non-trivial task. Programmers often need to ruminate on API documentations (that are often incomplete) or inspect code examples (that are often absent) to learn API usage patterns. Recently, various techniques have been proposed to alleviate this problem by creating API summarizations, mining code examples, or showing common API call sequences. However, few techniques focus on recommending API parameters.   In this paper, we propose an automated technique, called Precise, to address this problem. Differing from common code completion systems, Precise mines existing code bases, uses an abstract usage instance representation for each API usage example, and then builds a parameter usage database. Upon a request, Precise queries the database for abstract usage instances in similar contexts and generates parameter candidates by concretizing the instances adaptively.   The experimental results show that our technique is more general and applicable than existing code completion systems, specially, 64\% of the parameter recommendations are useful and 53\% of the recommendations are exactly the same as the actual parameters needed. We have also performed a user study to show our technique is useful in practice.},
	urldate = {2018-03-09},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Zhang, Cheng and Yang, Juyuan and Zhang, Yi and Fan, Jing and Zhang, Xin and Zhao, Jianjun and Ou, Peizhao},
	year = {2012},
	pages = {826--836},
	file = {Zhang et al. - 2012 - Automatic Parameter Recommendation for Practical A.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JXLF6GV7\\Zhang et al. - 2012 - Automatic Parameter Recommendation for Practical A.pdf:application/pdf}
}

@inproceedings{liu_nomen_2016,
	address = {New York, NY, USA},
	series = {{ICSE} '16},
	title = {Nomen {Est} {Omen}: {Exploring} and {Exploiting} {Similarities} {Between} {Argument} and {Parameter} {Names}},
	isbn = {978-1-4503-3900-1},
	shorttitle = {Nomen {Est} {Omen}},
	url = {http://doi.acm.org/10.1145/2884781.2884841},
	doi = {10.1145/2884781.2884841},
	abstract = {Programmer-provided identifier names convey information about the semantics of a program. This information can complement traditional program analyses in various software engineering tasks, such as bug finding, code completion, and documentation. Even though identifier names appear to be a rich source of information, little is known about their properties and their potential usefulness. This paper presents an empirical study of the lexical similarity between arguments and parameters of methods, which is one prominent situation where names can provide otherwise missing information. The study involves 60 real-world Java programs. We find that, for most arguments, the similarity is either very high or very low, and that short and generic names often cause low similarities. Furthermore, we show that inferring a set of low-similarity parameter names from one set of programs allows for pruning such names in another set of programs. Finally, the study shows that many arguments are more similar to the corresponding parameter than any alternative argument available in the call site's scope. As applications of our findings, we present an anomaly detection technique that identifies 144 renaming opportunities and incorrect arguments in 14 programs, and a code recommendation system that suggests correct arguments with a precision of 83\%.},
	urldate = {2018-03-09},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Liu, Hui and Liu, Qiurong and Staicu, Cristian-Alexandru and Pradel, Michael and Luo, Yue},
	year = {2016},
	keywords = {static analysis, method arguments, empirical study, identifier names, name-based program analysis},
	pages = {1063--1073},
	file = {Liu et al. - 2016 - Nomen Est Omen Exploring and Exploiting Similarit.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ZKBVXNIJ\\Liu et al. - 2016 - Nomen Est Omen Exploring and Exploiting Similarit.pdf:application/pdf}
}

@article{rice_detecting_2017,
	title = {Detecting {Argument} {Selection} {Defects}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3133928},
	doi = {10.1145/3133928},
	abstract = {Identifier names are often used by developers to convey additional information about the meaning of a program over and above the semantics of the programming language itself. We present an algorithm that uses this information to detect argument selection defects, in which the programmer has chosen the wrong argument to a method call in Java programs. We evaluate our algorithm at Google on 200 million lines of internal code and 10 million lines of predominantly open-source external code and find defects even in large, mature projects such as OpenJDK, ASM, and the MySQL JDBC. The precision and recall of the algorithm vary depending on a sensitivity threshold. Higher thresholds increase precision, giving a true positive rate of 85\%, reporting 459 true positives and 78 false positives. Lower thresholds increase recall but lower the true positive rate, reporting 2,060 true positives and 1,207 false positives. We show that this is an order of magnitude improvement on previous approaches. By analyzing the defects found, we are able to quantify best practice advice for API design and show that the probability of an argument selection defect increases markedly when methods have more than five arguments.},
	number = {OOPSLA},
	urldate = {2018-03-09},
	journal = {Proc. ACM Program. Lang.},
	author = {Rice, Andrew and Aftandilian, Edward and Jaspan, Ciera and Johnston, Emily and Pradel, Michael and Arroyo-Paredes, Yulissa},
	month = oct,
	year = {2017},
	keywords = {static analysis, method arguments, empirical study, name-based program analysis},
	pages = {104:1--104:22},
	file = {Rice et al. - 2017 - Detecting Argument Selection Defects.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ATGT4FSB\\Rice et al. - 2017 - Detecting Argument Selection Defects.pdf:application/pdf}
}

@book{drucker_management_2008,
	address = {New York, NY},
	edition = {Revised ed. edition},
	title = {Management {Rev} {Ed}},
	isbn = {978-0-06-125266-2},
	abstract = {The essential book on management from the man who invented the disciplineNow completely revised and updated for the first time},
	language = {English},
	publisher = {HarperBusiness},
	author = {Drucker, Peter F.},
	month = apr,
	year = {2008},
	file = {Drucker - 2008 - Management Rev Ed.pdf:C\:\\Users\\Anna\\Zotero\\storage\\22T2JGF2\\Drucker - 2008 - Management Rev Ed.pdf:application/pdf;management-drucker-en-13805.mp3:C\:\\Users\\Anna\\Zotero\\storage\\Y7TQVDCU\\management-drucker-en-13805.mp3:audio/mpeg}
}

@inproceedings{staicu_synode:_2018,
	title = {{SYNODE}: {Understanding} and {Automatically} {Preventing} {Injection} {Attacks} on {NODE}.{JS}},
	isbn = {978-1-891562-49-5},
	shorttitle = {{SYNODE}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_07A-2_Staicu_paper.pdf},
	doi = {10.14722/ndss.2018.23071},
	language = {en},
	urldate = {2018-03-12},
	publisher = {Internet Society},
	author = {Staicu, Cristian-Alexandru and Pradel, Michael and Livshits, Benjamin},
	year = {2018},
	file = {Staicu et al. - 2018 - SYNODE Understanding and Automatically Preventing.pdf:C\:\\Users\\Anna\\Zotero\\storage\\FRN3PKYT\\Staicu et al. - 2018 - SYNODE Understanding and Automatically Preventing.pdf:application/pdf}
}

@inproceedings{nguyen_statistical_2013,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2013},
	title = {A {Statistical} {Semantic} {Language} {Model} for {Source} {Code}},
	isbn = {978-1-4503-2237-9},
	url = {http://doi.acm.org/10.1145/2491411.2491458},
	doi = {10.1145/2491411.2491458},
	abstract = {Recent research has successfully applied the statistical n-gram language model to show that source code exhibits a good level of repetition. The n-gram model is shown to have good predictability in supporting code suggestion and completion. However, the state-of-the-art n-gram approach to capture source code regularities/patterns is based only on the lexical information in a local context of the code units. To improve predictability, we introduce SLAMC, a novel statistical semantic language model for source code. It incorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. It combines the local context in semantic n-grams with the global technical concerns/functionality into an n-gram topic model, together with pairwise associations of program elements. Based on SLAMC, we developed a new code suggestion method, which is empirically evaluated on several projects to have relatively 18-68\% higher accuracy than the state-of-the-art approach.},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 2013 9th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Nguyen, Tung Thanh and Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tien N.},
	year = {2013},
	keywords = {to read, Code Completion, Statistical Semantic Language Model},
	pages = {532--542},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\UXF79GX2\\Nguyen et al. - 2013 - A Statistical Semantic Language Model for Source C.pdf:application/pdf}
}

@inproceedings{gokhale_inferring_2013,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '13},
	title = {Inferring {Likely} {Mappings} {Between} {APIs}},
	isbn = {978-1-4673-3076-3},
	url = {http://dl.acm.org/citation.cfm?id=2486788.2486800},
	abstract = {Software developers often need to port applications written for a source platform to a target platform. In doing so, a key task is to replace an application's use of methods from the source platform API with corresponding methods from the target platform API. However, this task is challenging because developers must manually identify mappings between methods in the source and target APIs, e.g., using API documentation.   We develop a novel approach to the problem of inferring mappings between the APIs of a source and target platform. Our approach is tailored to the case where the source and target platform each have independently-developed applications that implement similar functionality. We observe that in building these applications, developers exercised knowledge of the corresponding APIs. We develop a technique to systematically harvest this knowledge and infer likely mappings between the APIs of the source and target platform. The output of our approach is a ranked list of target API methods or method sequences that likely map to each source API method or method sequence. We have implemented this approach in a prototype tool called Rosetta, and have applied it to infer likely mappings between the Java2 Mobile Edition (JavaME) and Android graphics APIs.},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Gokhale, Amruta and Ganapathy, Vinod and Padmanaban, Yogesh},
	year = {2013},
	keywords = {to read},
	pages = {82--91},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\IDKHUN9V\\Gokhale et al. - 2013 - Inferring Likely Mappings Between APIs.pdf:application/pdf}
}

@inproceedings{proksch_towards_2014,
	address = {New York, NY, USA},
	series = {{RSSE} 2014},
	title = {Towards {Standardized} {Evaluation} of {Developer}-assistance {Tools}},
	isbn = {978-1-4503-2845-6},
	url = {http://doi.acm.org/10.1145/2593822.2593827},
	doi = {10.1145/2593822.2593827},
	abstract = {Over the last years, researchers proposed a variety of assistance tools to support developers in their development environments. Many of the respective publications introduce new evaluation strategies or use custom datasets. Size and quality of the performed evaluations differ. Additionally, the strategies often use metrics that are tailored to the respective tools. As a result, comparing different assistance tools is very difficult.   In this work, we present a framework for the standardized evaluation of assistance tools, on the example of code recommenders. The framework combines different ideas and demands from previous work. Furthermore, we discuss how the community could jointly realize the framework.},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {Recommendation} {Systems} for {Software} {Engineering}},
	publisher = {ACM},
	author = {Proksch, Sebastian and Amann, Sven and Mezini, Mira},
	year = {2014},
	keywords = {Tools, to read, Content Assistance, Evaluation, Integrated Development Environment, Repository, Standardization},
	pages = {14--18},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\PUGUA8IP\\Proksch et al. - 2014 - Towards Standardized Evaluation of Developer-assis.pdf:application/pdf}
}

@patent{laredo_using_2018,
	title = {Using an application programming interface ({API}) data structure in recommending an {API} composite},
	url = {https://patents.google.com/patent/US9886247B2/en},
	nationality = {US},
	language = {en},
	assignee = {International Business Machines Corp},
	number = {US9886247B2},
	urldate = {2018-03-12},
	author = {Laredo, Jim A. and Rajagopal, Sriram K. and Vukovic, Maja},
	month = feb,
	year = {2018},
	keywords = {to read, api, data, embodiments, entity, exploration},
	file = {Fulltext PDF:C\:\\Users\\Anna\\Zotero\\storage\\HQJ8VLW8\\Laredo et al. - 2018 - Using an application programming interface (API) d.pdf:application/pdf}
}

@inproceedings{asaduzzaman_parc:_2015,
	title = {{PARC}: {Recommending} {API} methods parameters},
	shorttitle = {{PARC}},
	doi = {10.1109/ICSM.2015.7332481},
	abstract = {APIs have grown considerably in size. To free developers from remembering every detail of an API, code completion has become an integral part of modern IDEs. Most work on code completion targets completing API method calls and leaves the task of completing method parameters to the developers. However, parameter completion is also a non-trivial task. We present an Eclipse plugin, called PARC, that supports automatic completion of API method parameters. The tool is based on the localness property of source code, which states that developers tend to put related code fragments close together. PARC combines contextual and static type analysis to support a wide range of parameter expression types.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	author = {Asaduzzaman, M. and Roy, C. K. and Schneider, K. A.},
	month = sep,
	year = {2015},
	keywords = {program diagnostics, Software, source code (software), Context, application program interfaces, Computer architecture, to read, code completion, source code, API methods, Code completion, Receivers, static type analysis, Adaptation models, API method parameter, code fragment, contextual type analysis, Eclipse plugin, IDE, Load modeling, Method parameter, PARC, Proposals},
	pages = {330--332},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\9SS72XAS\\7332481.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\CYRBTSEY\\7332481.html:text/html}
}

@article{wu_code_2017,
	title = {Code recommendation for android development: how does it work and what can be improved?},
	volume = {60},
	issn = {1674-733X, 1869-1919},
	shorttitle = {Code recommendation for android development},
	url = {https://link.springer.com/article/10.1007/s11432-017-9058-0},
	doi = {10.1007/s11432-017-9058-0},
	abstract = {Android applications are developed based on framework and are always pattern-based. For Android developers, they can be facilitated by code recommendation to ensure high development efficiency and quality. Existing research work has proposed several methods and tools to support recommendation in diverse ways. However, how code recommendation work in Android development and what can be further improved to better support Android development has not been clarified. To understand the reality, we conduct a qualitative review on current code recommendation techniques and tools reported in prime literature. The collected work is first grouped into three categories based on a multidimensional framework. Then the review is performed to draw a comprehensive image of the adoption of recommendation in Android development when meeting specific development requirements. Based on the review, we give out possible improvements of code recommendation from two aspects. First, a set of improvement suggestions are presented to enhance the ability of the state-ofthe- art code recommendation techniques. Second, a customizable tool framework is proposed to facilitate the design of code recommendation tools and the tool framework is able to integrate the recommendation features more easily.},
	language = {en},
	number = {9},
	urldate = {2018-03-12},
	journal = {Science China Information Sciences},
	author = {Wu, Junwei and Shen, Liwei and Guo, Wunan and Zhao, Wenyun},
	month = sep,
	year = {2017},
	keywords = {to read},
	pages = {092111},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\GIC5WXPL\\s11432-017-9058-0.html:text/html;Wu et al. - 2017 - Code recommendation for android development how d.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5AL8GJFC\\Wu et al. - 2017 - Code recommendation for android development how d.pdf:application/pdf}
}

@incollection{robillard_source_2014,
	address = {Berlin, Heidelberg},
	title = {Source {Code}-{Based} {Recommendation} {Systems}},
	isbn = {978-3-642-45134-8 978-3-642-45135-5},
	url = {http://link.springer.com/10.1007/978-3-642-45135-5_5},
	language = {en},
	urldate = {2018-03-12},
	booktitle = {Recommendation {Systems} in {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Mens, Kim and Lozano, Angela},
	editor = {Robillard, Martin P. and Maalej, Walid and Walker, Robert J. and Zimmermann, Thomas},
	year = {2014},
	doi = {10.1007/978-3-642-45135-5_5},
	keywords = {to read},
	pages = {93--130},
	file = {Mens und Lozano - 2014 - Source Code-Based Recommendation Systems.pdf:C\:\\Users\\Anna\\Zotero\\storage\\K574BQH5\\Mens und Lozano - 2014 - Source Code-Based Recommendation Systems.pdf:application/pdf}
}

@inproceedings{asaduzzaman_exploring_2015,
	address = {Washington, DC, USA},
	series = {{ICSME} '15},
	title = {Exploring {API} {Method} {Parameter} {Recommendations}},
	isbn = {978-1-4673-7532-0},
	url = {http://dx.doi.org/10.1109/ICSM.2015.7332473},
	doi = {10.1109/ICSM.2015.7332473},
	abstract = {A number of techniques have been developed that support method call completion. However, there has been little research on the problem of method parameter completion. In this paper, we first present a study that helps us to understand how developers complete method parameters. Based on our observations, we developed a recommendation technique, called Parc, that collects parameter usage context using a source code localness property that suggests that developers tend to collocate related code fragments. Parc uses previous code examples together with contextual and static type analysis to recommend method parameters. Evaluating our technique against the only available state-of-the-art tool using a number of subject systems and different Java libraries shows that our approach has potential. We also explore the parameter recommendation support provided by the Eclipse Java Development Tools (JDT). Finally, we discuss limitations of our proposed technique and outline future research directions.},
	urldate = {2018-03-12},
	booktitle = {Proceedings of the 2015 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	publisher = {IEEE Computer Society},
	author = {Asaduzzaman, Muhammad and Roy, Chanchal K. and Monir, Samiul and Schneider, Kevin A.},
	year = {2015},
	keywords = {program diagnostics, Software, source code (software), Libraries, Java, software libraries, Context, application program interfaces, Documentation, API method parameter recommendations, API methods, Arrays, Code completion, code fragments, contextual analysis, Eclipse Java Development Tools, Java libraries, JDT, Method parameter recommendations, parameter usage context, Parc, programming environments, Receivers, Recommendations, source code localness property, static type analysis, support method call completion},
	pages = {271--280},
	file = {Asaduzzaman et al. - 2015 - Exploring API Method Parameter Recommendations.pdf:C\:\\Users\\Anna\\Zotero\\storage\\DQ7RWE4J\\Asaduzzaman et al. - 2015 - Exploring API Method Parameter Recommendations.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\95HAQS8E\\7332473.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\SS2KHQKP\\7332473.html:text/html}
}

@inproceedings{lo_iacono_i_2017,
	title = {I {Do} and {I} {Understand}. {Not} {Yet} {True} for {Security} {APIs}. {So} {Sad}},
	doi = {10.14722/eurousec.2017.23015},
	abstract = {Usable security puts the users into the center of
cyber security developments. Software developers are a very
specific user group in this respect, since their points of contact with security are application programming interfaces (APIs). In
contrast to APIs providing functionalities of other domains than
security, security APIs are not approachable by habitual means.
Learning by doing exploration exercises is not well supported.
Reasons for this range from missing documentation, tutorials and
examples to lacking tools and impenetrable APIs, that makes this
complex matter accessible. In this paper we study what abstraction level of security APIs is more suitable to meet common developers’ needs and
expectations. For this purpose, we firstly define the term security API. Following this definition, we introduce a classification of
security APIs according to their abstraction level. We then
adopted this classification in two studies. In one we gathered
the current coverage of the distinct classes by the standard set of security functionality provided by popular software development
kits. The other study has been an online questionnaire in which we asked 55 software developers about their experiences and opinion
in respect of integrating security mechanisms into their coding
projects. Our findings emphasize that the right abstraction level of a security API is one important aspect to consider in usable
security API design that has not been addressed much so far.},
	author = {Lo Iacono, Luigi and Gorski, Peter},
	month = apr,
	year = {2017},
	keywords = {to read},
	file = {Lo Iacono und Gorski - 2017 - I Do and I Understand. Not Yet True for Security A.pdf:C\:\\Users\\Anna\\Zotero\\storage\\PAHHPSAS\\Lo Iacono und Gorski - 2017 - I Do and I Understand. Not Yet True for Security A.pdf:application/pdf}
}

@article{ukrop_why_nodate,
	title = {Why {Johnny} the {Developer} {Can}’t {Work} with {Public} {Key} {Certiﬁcates}},
	author = {Ukrop, Martin and Matyas, Vashek},
	pages = {20},
	file = {Ukrop und Matyas - Why Johnny the Developer Can’t Work with Public Ke.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VIEFBUTN\\Ukrop und Matyas - Why Johnny the Developer Can’t Work with Public Ke.pdf:application/pdf}
}

@misc{noauthor_morning_nodate,
	title = {The {Morning} {Paper}: {JavaScript} {Zero} - real {JavaScript}, and zero side-channel attacks},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-javascript-zero-real-javascript-and-zero-side-channel-attacks?e=6b9727817f},
	urldate = {2018-03-13},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\I7CRG6UJ\\the-morning-paper-javascript-zero-real-javascript-and-zero-side-channel-attacks.html:text/html}
}

@inproceedings{wang_game_2018,
	title = {Game of {Missuggestions}: {Semantic} {Analysis} of {Search}-{Autocomplete} {Manipulations}},
	isbn = {978-1-891562-49-5},
	shorttitle = {Game of {Missuggestions}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_07A-1_Wang_paper.pdf},
	doi = {10.14722/ndss.2018.23036},
	abstract = {As a new type of blackhat Search Engine Optimization (SEO), autocomplete manipulations are increasingly utilized by miscreants and promotion companies alike to advertise desired suggestion terms when related trigger terms are entered by the user into a search engine. Like other illicit SEO, such activities game the search engine, mislead the querier, and in some cases, spread harmful content. However, little has been done to understand this new threat, in terms of its scope, impact and techniques, not to mention any serious effort to detect such manipulated terms on a large scale.},
	language = {en},
	urldate = {2018-03-14},
	publisher = {Internet Society},
	author = {Wang, Peng and Mi, Xianghang and Liao, Xiaojing and Wang, XiaoFeng and Yuan, Kan and Qian, Feng and Beyah, Raheem},
	year = {2018},
	file = {Wang et al. - 2018 - Game of Missuggestions Semantic Analysis of Searc.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7JAPRQRW\\Wang et al. - 2018 - Game of Missuggestions Semantic Analysis of Searc.pdf:application/pdf}
}

@inproceedings{thung_api_2016,
	address = {New York, NY, USA},
	series = {{ASE} 2016},
	title = {{API} {Recommendation} {System} for {Software} {Development}},
	isbn = {978-1-4503-3845-5},
	url = {http://doi.acm.org/10.1145/2970276.2975940},
	doi = {10.1145/2970276.2975940},
	abstract = {Nowadays, software developers often utilize existing third party libraries and make use of Application Programming Interface (API) to develop a software. However, it is not always obvious which library to use or whether the chosen library will play well with other libraries in the system. Furthermore, developers need to spend some time to understand the API to the point that they can freely use the API methods and putting the right parameters inside them. In this work, I plan to automatically recommend relevant APIs to developers. This API recommendation can be divided into multiple stages. First, we can recommend relevant libraries provided a given task to complete. Second, we can recommend relevant API methods that developer can use to program the required task. Third, we can recommend correct parameters for a given method according to its context. Last but not least, we can recommend how different API methods can be combined to achieve a given task.   In effort to realize this API recommendation system, I have published two related papers. The first one deals with recommending additional relevant API libraries given known useful API libraries for the target program. This system can achieve recall rate@5 of 0.852 and recall rate@10 of 0.894 in recommending additional relevant libraries. The second one deals with recommending relevant API methods a given target API and a textual description of the task. This system can achieve recall-rate@5 of 0.690 and recallrate@10 of 0.779. The results for both system indicate that the systems are useful and capable in recommending the right API/library reasonably well. Currently, I am working on another system which can recommend web APIs (i.e., libraries) given a description of the task. I am also working on a system that recommends correct parameters given an API method. In the future, I also plan to realize API composition recommendation for the given task},
	urldate = {2018-03-14},
	booktitle = {Proceedings of the 31st {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM},
	author = {Thung, Ferdian},
	year = {2016},
	keywords = {API, Library, Recommendation System},
	pages = {896--899},
	file = {Thung - 2016 - API Recommendation System for Software Development.pdf:C\:\\Users\\Anna\\Zotero\\storage\\D65MYCJU\\Thung - 2016 - API Recommendation System for Software Development.pdf:application/pdf}
}

@article{acar_how_2017,
	title = {How {Internet} {Resources} {Might} {Be} {Helping} {You} {Develop} {Faster} but {Less} {Securely}},
	volume = {15},
	issn = {1540-7993},
	url = {https://doi.org/10.1109/MSP.2017.24},
	doi = {10.1109/MSP.2017.24},
	abstract = {In this experimental study, Android developers using Stack Overflow to solve common security issues were more likely to produce functional--but less secure--code. Given today's time constraints and economic pressures, developers need improved official documentation that's both secure and usable.},
	number = {2},
	urldate = {2018-03-14},
	journal = {IEEE Security and Privacy},
	author = {Acar, Yasemin and Backes, Michael and Fahl, Sascha and Kim, Doowon and Mazurek, Michelle L. and Stransky, Christian},
	month = apr,
	year = {2017},
	keywords = {source code (software), security of data, Internet, Privacy, privacy, security, Android (operating system), Androids, Cryptography, Humanoid robots, Stack Overflow, Computer security, Android, mobile computing, Smart phones, Access controls, Android developers, developers, education, Internet resources, mobile, mobile applications, Mobile communications, Permission, Resource management, secure code, security issues, How much influences the choice of a parameter the security of the crypto API?},
	pages = {50--60},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\86QXFD2Z\\7891515.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\TXSEBQUN\\7891515.html:text/html}
}

@inproceedings{chen_exposing_2018,
	title = {Exposing {Congestion} {Attack} on {Emerging} {Connected} {Vehicle} based {Traffic} {Signal} {Control}},
	isbn = {978-1-891562-49-5},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_01B-2_Chen_paper.pdf},
	doi = {10.14722/ndss.2018.23222},
	language = {en},
	urldate = {2018-03-15},
	publisher = {Internet Society},
	author = {Chen, Qi Alfred and Yin, Yucheng and Feng, Yiheng and Mao, Z. Morley and Liu, Henry X.},
	year = {2018}
}

@misc{rigby_science-backed_nodate,
	title = {The {Science}-{Backed} {Reasons} {You} {Shouldn}'t {Share} {Your} {Goals}},
	url = {https://blog.trello.com/science-backed-reasons-you-shouldnt-share-your-goals},
	abstract = {Setting goals to achieve big things in your life is a great practice. Staying accountable to your goals is good too. But before you share your goals with others, let’s dive into the science-backed reasons goal sharing may stop you from reaching them altogether.},
	language = {en-us},
	urldate = {2018-03-15},
	author = {Rigby, Amy},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\XFWSTN4E\\science-backed-reasons-you-shouldnt-share-your-goals.html:text/html}
}

@misc{gridley_deep_nodate,
	title = {A {Deep} {Dive} {Guide} {For} {Your} {Dream} {Job} {Search} ({With} {Trello})},
	url = {https://blog.trello.com/dream-job-search-guide-with-trello},
	abstract = {Every career journey is different, but with some organization and help from Trello, you can easily find and land your perfect job. This is a comprehensive guide complete with a Trello board, email examples, and 5 steps for a successful job search.},
	language = {en-us},
	urldate = {2018-03-15},
	author = {Gridley, Hilary},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WDNPERH6\\dream-job-search-guide-with-trello.html:text/html}
}

@misc{academic_skills_the_university_of_melbourne_writing_nodate,
	title = {Writing the {Literature} {Review}},
	url = {https://www.youtube.com/watch?v=70n2-gAp7J0},
	language = {Englisch},
	author = {Academic Skills, The University of Melbourne}
}

@inproceedings{caliskan_when_2018,
	title = {When {Coding} {Style} {Survives} {Compilation}: {De}-anonymizing {Programmers} from {Executable} {Binaries}},
	isbn = {978-1-891562-49-5},
	shorttitle = {When {Coding} {Style} {Survives} {Compilation}},
	url = {https://www.ndss-symposium.org/wp-content/uploads/sites/25/2018/02/ndss2018_06B-2_Caliskan_paper.pdf},
	doi = {10.14722/ndss.2018.23304},
	abstract = {The ability to identify authors of computer programs based on their coding style is a direct threat to the privacy and anonymity of programmers. While recent work found that source code can be attributed to authors with high accuracy, attribution of executable binaries appears to be much more difﬁcult. Many distinguishing features present in source code, e.g. variable names, are removed in the compilation process, and compiler optimization may alter the structure of a program, further obscuring features that are known to be useful in determining authorship. We examine programmer de-anonymization from the standpoint of machine learning, using a novel set of features that include ones obtained by decompiling the executable binary to source code. We adapt a powerful set of techniques from the domain of source code authorship attribution along with stylistic representations embedded in assembly, resulting in successful deanonymization of a large set of programmers.},
	language = {en},
	urldate = {2018-03-16},
	publisher = {Internet Society},
	author = {Caliskan, Aylin and Yamaguchi, Fabian and Dauber, Edwin and Harang, Richard and Rieck, Konrad and Greenstadt, Rachel and Narayanan, Arvind},
	year = {2018},
	file = {Caliskan et al. - 2018 - When Coding Style Survives Compilation De-anonymi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\LSY2ZBSY\\Caliskan et al. - 2018 - When Coding Style Survives Compilation De-anonymi.pdf:application/pdf}
}

@article{matzutt_quantitative_nodate,
	title = {A {Quantitative} {Analysis} of the {Impact} of {Arbitrary} {Blockchain} {Content} on {Bitcoin}},
	abstract = {Blockchains primarily enable credible accounting of digital events, e.g., money transfers in cryptocurrencies. However, beyond this original purpose, blockchains also irrevocably record arbitrary data, ranging from short messages to pictures. This does not come without risk for users as each participant has to locally replicate the complete blockchain, particularly including potentially harmful content. We provide the ﬁrst systematic analysis of the beneﬁts and threats of arbitrary blockchain content. Our analysis shows that certain content, e.g., illegal pornography, can render the mere possession of a blockchain illegal. Based on these insights, we conduct a thorough quantitative and qualitative analysis of unintended content on Bitcoin’s blockchain. Although most data originates from benign extensions to Bitcoin’s protocol, our analysis reveals more than 1600 ﬁles on the blockchain, over 99 \% of which are texts or images. Among these ﬁles there is clearly objectionable content such as links to child pornography, which is distributed to all Bitcoin participants. With our analysis, we thus highlight the importance for future blockchain designs to address the possibility of unintended data insertion and protect blockchain users accordingly.},
	author = {Matzutt, Roman and Hiller, Jens and Henze, Martin and Ziegeldorf, Jan Henrik},
	pages = {18},
	file = {Matzutt et al. - A Quantitative Analysis of the Impact of Arbitrary.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7J4WJ4GT\\Matzutt et al. - A Quantitative Analysis of the Impact of Arbitrary.pdf:application/pdf}
}

@article{wiedenhoft_mein_2018,
	title = {Mein {Leben} als {Investment}-{Banker}: "{So} viel {Geld} tut jungen {Menschen} nicht gut"},
	shorttitle = {Mein {Leben} als {Investment}-{Banker}},
	url = {http://www.spiegel.de/karriere/serie-bad-banks-ein-investmentpacker-erzaehlt-wie-der-job-wirklich-ist-a-1197233.html?xing_share=news},
	abstract = {100-Stunden-Wochen, Ritalin, Koks, hohe Boni und Geschäfte mit Waffenherstellern: Hier erzählt ein junger Investmentbanker von seinem Job - und wie viel die Serie "Bad Banks" mit der Realität zu tun hat.},
	urldate = {2018-03-19},
	journal = {Spiegel Online},
	author = {Wiedenhöft, Aufgezeichnet von Sarah},
	month = mar,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2VQU4NLI\\serie-bad-banks-ein-investmentpacker-erzaehlt-wie-der-job-wirklich-ist-a-1197233.html:text/html}
}

@inproceedings{tan_autoises:_2008,
	address = {Berkeley, CA, USA},
	series = {{SS}'08},
	title = {{AutoISES}: {Automatically} {Inferring} {Security} {Specifications} and {Detecting} {Violations}},
	shorttitle = {{AutoISES}},
	url = {http://dl.acm.org/citation.cfm?id=1496711.1496737},
	abstract = {The importance of software security cannot be overstated. In the past, researchers have applied program analysis techniques to automatically detect security vulnerabilities and verify security properties. However, such techniques have limited success in reality because they require manually provided code-level security specifications. Manually writing and generating these code-level security specifications are tedious and error-prone. Additionally, they seldom exist in production software. In this paper, we propose a novel method and tool, called AutoISES, which Automatically Infers Security Specifications by statically analyzing source code, and then directly use these specifications to automatically detect security violations. Our experiments with the Linux kernel and Xen demonstrated the effectiveness of this approach - AutoISES automatically generated 84 security specifications and detected 8 vulnerabilities in the Linux kernel and Xen, 7 of which have already been confirmed by the corresponding developers.},
	urldate = {2018-03-19},
	booktitle = {Proceedings of the 17th {Conference} on {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Tan, Lin and Zhang, Xiaolan and Ma, Xiao and Xiong, Weiwei and Zhou, Yuanyuan},
	year = {2008},
	pages = {379--394},
	file = {Tan et al. - 2008 - AutoISES Automatically Inferring Security Specifi.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Tan et al. - 2008 - AutoISES Automatically Inferring Security Specifi.pdf:application/pdf}
}

@inproceedings{ganapathy_mining_2007,
	address = {Washington, DC, USA},
	series = {{ICSE} '07},
	title = {Mining {Security}-{Sensitive} {Operations} in {Legacy} {Code} {Using} {Concept} {Analysis}},
	isbn = {978-0-7695-2828-1},
	url = {http://dx.doi.org/10.1109/ICSE.2007.54},
	doi = {10.1109/ICSE.2007.54},
	abstract = {his paper presents an approach to statically retrofit legacy servers with mechanisms for authorization policy enforcement. The approach is based upon the obser- vation that security-sensitive operations performed by a server are characterized by idiomatic resource manipula- tions, called fingerprints. Candidate fingerprints are auto- matically mined by clustering resource manipulations using concept analysis. These fingerprints are then used to iden- tify security-sensitive operations performed by the server. Case studies with three real-world servers show that the approach can be used to identify security-sensitive opera- tions with a few hours of manual effort and modest domain knowledge.},
	urldate = {2018-03-19},
	booktitle = {Proceedings of the 29th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Ganapathy, Vinod and King, David and Jaeger, Trent and Jha, Somesh},
	year = {2007},
	pages = {458--467},
	file = {Ganapathy et al. - 2007 - Mining Security-Sensitive Operations in Legacy Cod.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5X4TKVG2\\Ganapathy et al. - 2007 - Mining Security-Sensitive Operations in Legacy Cod.pdf:application/pdf}
}

@article{pistoia_programming_2009,
	title = {Programming {Languages} and {Program} {Analysis} for {Security}: {A} {Three}-year {Retrospective}},
	volume = {43},
	issn = {0362-1340},
	shorttitle = {Programming {Languages} and {Program} {Analysis} for {Security}},
	url = {http://doi.acm.org/10.1145/1513443.1513449},
	doi = {10.1145/1513443.1513449},
	abstract = {Software security has been traditionally enforced at the level of operating systems. However, operating systems have become increasingly large and complex, and it is very difficult--if not impossible--to enforce software security solely through them. Moreover, operating-system security allows dealing primarily with access-control policies on resources such as files and network connections. However, attacks may happen at both lower and higher levels of abstraction, and may target the internal behavior of applications, such as today's Web-based applications. Therefore, defenses must offer protection at the level of applications. Language-based security is the area of research that studies how to enforce application-level security using programming-language and program-analysis techniques. This area of research has become very active with the advent of Web applications. In 2006, the ACM SIGPLAN has introduced a new yearly forum entirely dedicated to the discussion of language-based-security research: Programming Languages and Analysis for Security (PLAS). This paper is a three-year survey of PLAS papers that discusses the progress made in the area of language-based security.},
	number = {12},
	urldate = {2018-03-19},
	journal = {SIGPLAN Not.},
	author = {Pistoia, Marco and Erlingsson, Úlfar},
	month = feb,
	year = {2009},
	keywords = {programming languages, security, program analysis, language-based security},
	pages = {32--39},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\V76BYSS5\\Pistoia und Erlingsson - 2009 - Programming Languages and Program Analysis for Sec.pdf:application/pdf}
}

@misc{noauthor_englische_nodate,
	title = {Englische {Sprichwörter} – {Wikiquote}},
	url = {https://de.wikiquote.org/wiki/Englische_Sprichw%C3%B6rter},
	urldate = {2018-03-19},
	file = {Englische Sprichwörter – Wikiquote:C\:\\Users\\Anna\\Zotero\\storage\\QZUX9RPC\\Englische_Sprichwörter.html:text/html}
}

@misc{noauthor_purdue_nodate,
	title = {Purdue {OWL}: {How} to {Use} {Articles} (a/an/the)},
	url = {https://owl.english.purdue.edu/owl/resource/540/01/},
	urldate = {2018-03-19},
	file = {Purdue OWL\: How to Use Articles (a/an/the):C\:\\Users\\Anna\\Zotero\\storage\\AXVDC59G\\01.html:text/html}
}

@article{mavridou_designing_nodate,
	title = {Designing {Secure} {Ethereum} {Smart} {Contracts}: {A} {Finite} {State} {Machine} {Based} {Approach}},
	abstract = {The adoption of blockchain-based distributed computation platforms is growing fast. Some of these platforms, such as Ethereum, provide support for implementing smart contracts, which are envisioned to have novel applications in a broad range of areas, including ﬁnance and the Internet-of-Things. However, a signiﬁcant number of smart contracts deployed in practice suﬀer from security vulnerabilities, which enable malicious users to steal assets from a contract or to cause damage. Vulnerabilities present a serious issue since contracts may handle ﬁnancial assets of considerable value, and contract bugs are non-ﬁxable by design. To help developers create more secure smart contracts, we introduce FSolidM, a framework rooted in rigorous semantics for designing contracts as Finite State Machines (FSM). We present a tool for creating FSM on an easy-to-use graphical interface and for automatically generating Ethereum contracts. Further, we introduce a set of design patterns, which we implement as plugins that developers can easily add to their contracts to enhance security and functionality.},
	author = {Mavridou, Anastasia and Laszka, Aron},
	pages = {18},
	file = {Mavridou und Laszka - Designing Secure Ethereum Smart Contracts A Finit.pdf:C\:\\Users\\Anna\\Zotero\\storage\\87SLJVL3\\Mavridou und Laszka - Designing Secure Ethereum Smart Contracts A Finit.pdf:application/pdf}
}

@article{basin_purpose_nodate,
	title = {On {Purpose} and by {Necessity}: {Compliance} under the {GDPR}},
	abstract = {The European General Data Protection Regulation (GDPR) gives primacy to purpose: Data may be collected and stored only when (i) end-users have consented, often explicitly, to the purposes for which that data is collected, and (ii) the collected data is actually necessary for achieving these purposes. This development in data protection regulations begets the question: how do we audit a computer system’s adherence to a purpose? We propose an approach that identiﬁes a purpose with a business process, and show how formal models of interprocess communication can be used to audit or even derive privacy policies. Based on this insight, we propose a methodology for auditing GDPR compliance. Moreover, we show how given a simple interprocess dataﬂow model, aspects of GDPR compliance can be determined algorithmically.},
	author = {Basin, David and Debois, Søren and Hildebrandt, Thomas},
	pages = {18},
	file = {Basin et al. - On Purpose and by Necessity Compliance under the .pdf:C\:\\Users\\Anna\\Zotero\\storage\\8S8JISUR\\Basin et al. - On Purpose and by Necessity Compliance under the .pdf:application/pdf}
}

@misc{walter_countable_2018,
	title = {Countable or uncountable, and why it matters},
	url = {https://dictionaryblog.cambridge.org/2018/03/21/countable-or-uncountable-and-why-it-matters/},
	abstract = {by Liz Walter Many dictionaries for learners of English (including the one on this site) show whether nouns are ‘countable’ or ‘uncountable’, often using the abbreviations C and U. Countable nouns …},
	language = {en},
	urldate = {2018-03-21},
	journal = {About Words - Cambridge Dictionaries Online blog},
	author = {Walter, Liz},
	month = mar,
	year = {2018},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CLTBKME7\\countable-or-uncountable-and-why-it-matters.html:text/html}
}

@article{bertram_three_nodate,
	title = {Three years of the {Right} to be {Forgotten}},
	abstract = {The “Right to be Forgotten” is a privacy ruling that enables Europeans to delist certain URLs appearing in search results related to their name. In order to illuminate the eﬀect this ruling has on information access, we conduct a retrospective measurement study of 2.4 million URLs that were requested for delisting from Google Search over the last three and a half years. We analyze the countries and anonymized parties generating the largest volume of requests; the news, government, social media, and directory sites most frequently targeted for delisting; and the prevalence of extraterritorial requests. Our results dramatically increase transparency around the Right to be Forgotten and reveal the complexity of weighing personal privacy against public interest when resolving multi-party privacy conﬂicts that occur across the Internet.},
	author = {Bertram, Theo and Bursztein, Elie and Caro, Stephanie and Chao, Hubert and Feman, Rutledge Chin},
	pages = {17},
	file = {Bertram et al. - Three years of the Right to be Forgotten.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TQA952DP\\Bertram et al. - Three years of the Right to be Forgotten.pdf:application/pdf}
}

@misc{bursztein_insights_nodate,
	title = {Insights about the first three years of the {Right} {To} {Be} {Forgotten} requests at {Google}},
	url = {https://www.elie.net/blog/web/insights-about-the-first-three-years-of-the-right-to-be-forgotten-requests-at-google},
	abstract = {The “Right To Be Forgotten”' (RTBF) is the landmark European ruling that governs the delisting of personal information from search results. Since this ruling came into effect a little over three years ago (May 2014), Google has received {\textasciitilde}2.4 millions URLs delisting requests. Each delisting decision requires careful consideration in order to strike the right balance between respecting user privacy and ensuring open access to information via Google Search. To be as transparent as possible about this removal process and to help the public understand how the RTBF requests impact Search results, Google has documented this removal process as part of its Transparency report since 2014. The result of this analysis was published in a paper that we release alongside with the improved transparency dashboard.  This blog post summarizes our paper’s key findings.},
	language = {en},
	urldate = {2018-03-22},
	journal = {Elie Bursztein's site},
	author = {Bursztein, Elie}
}

@book{robillard_recommendation_2014,
	address = {Berlin Heidelberg},
	title = {Recommendation {Systems} in {Software} {Engineering}},
	isbn = {978-3-642-45134-8},
	url = {//www.springer.com/us/book/9783642451348},
	abstract = {With the growth of public and private data stores and the emergence of off-the-shelf data-mining technology, recommendation systems have emerged that specifically address the unique challenges of navigating and interpreting software engineering data.This book collects, structures and formalizes knowledge on recommendation systems in software engineering. It adopts a pragmatic approach with an explicit focus on system design, implementation, and evaluation. The book is divided into three parts: “Part I – Techniques” introduces basics for building recommenders in software engineering, including techniques for collecting and processing software engineering data, but also for presenting recommendations to users as part of their workflow. “Part II – Evaluation” summarizes methods and experimental designs for evaluating recommendations in software engineering. “Part III – Applications” describes needs, issues and solution concepts involved in entire recommendation systems for specific software engineering tasks, focusing on the engineering insights required to make effective recommendations. The book is complemented by the webpage rsse.org/book, which includes free supplemental materials for readers of this book and anyone interested in recommendation systems in software engineering, including lecture slides, data sets, source code, and an overview of people, groups, papers and tools with regard to recommendation systems in software engineering.The book is particularly well-suited for graduate students and researchers building new recommendation systems for software engineering applications or in other high-tech fields. It may also serve as the basis for graduate courses on recommendation systems, applied data mining or software engineering. Software engineering practitioners developing recommendation systems or similar applications with predictive functionality will also benefit from the broad spectrum of topics covered.},
	language = {en},
	urldate = {2018-03-22},
	publisher = {Springer-Verlag},
	editor = {Robillard, Martin P. and Maalej, Walid and Walker, Robert J. and Zimmermann, Thomas},
	year = {2014},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZET5J5U8\\9783642451348.html:text/html}
}

@article{gu_deep_2016,
	title = {Deep {API} {Learning}},
	url = {http://arxiv.org/abs/1605.08535},
	abstract = {Developers often wonder how to implement a certain functionality (e.g., how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query, existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bag-of-words (i.e., keyword matching or word-to-word alignment) and lack a deep understanding of the semantics of the query. We propose DeepAPI, a deep learning based approach to generate API usage sequences for a given natural language query. Instead of a bags-of-words assumption, it learns the sequence of words in a query and the sequence of associated APIs. DeepAPI adapts a neural language model named RNN Encoder-Decoder. It encodes a word sequence (user query) into a fixed-length context vector, and generates an API sequence based on the context vector. We also augment the RNN Encoder-Decoder by considering the importance of individual APIs. We empirically evaluate our approach with more than 7 million annotated code snippets collected from GitHub. The results show that our approach generates largely accurate API sequences and outperforms the related approaches.},
	urldate = {2018-03-22},
	journal = {arXiv:1605.08535 [cs]},
	author = {Gu, Xiaodong and Zhang, Hongyu and Zhang, Dongmei and Kim, Sunghun},
	month = may,
	year = {2016},
	note = {arXiv: 1605.08535},
	keywords = {Computer Science - Software Engineering, Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, D.2.13},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\TI4BZEDE\\1605.html:text/html;Gu et al. - 2016 - Deep API Learning.pdf:C\:\\Users\\Anna\\Zotero\\storage\\X33WZ4N5\\Gu et al. - 2016 - Deep API Learning.pdf:application/pdf}
}

@inproceedings{li_parameter_2016,
	title = {Parameter {Values} of {Android} {APIs}: {A} {Preliminary} {Study} on 100,000 {Apps}},
	isbn = {978-1-5090-1855-0},
	shorttitle = {Parameter {Values} of {Android} {APIs}},
	url = {http://ieeexplore.ieee.org/document/7476677/},
	doi = {10.1109/SANER.2016.51},
	abstract = {Parameter values are important elements for understanding how Application Programming Interfaces (APIs) are used in practice. In the context of Android, a few number of API methods are used pervasively by millions of apps, where these API methods provide app core functionality. In this paper, we present preliminary insights from ParamHarver, a purely static analysis approach for automatically extracting parameter values from Android apps. Investigations on 100,000 apps illustrate how an in-depth study of parameter values can be leveraged in various scenarios (e.g., to recommend relevant parameter values, or even, to some extent, to identify malicious apps).},
	language = {en},
	urldate = {2018-03-22},
	publisher = {IEEE},
	author = {Li, Li and Bissyande, Tegawende F. and Klein, Jacques and Traon, Yves Le},
	month = mar,
	year = {2016},
	keywords = {parameter},
	pages = {584--588},
	file = {Li et al. - 2016 - Parameter Values of Android APIs A Preliminary St.pdf:C\:\\Users\\Anna\\Zotero\\storage\\DUTL843W\\Li et al. - 2016 - Parameter Values of Android APIs A Preliminary St.pdf:application/pdf}
}

@inproceedings{nguyen_recommending_2015,
	address = {Washington, DC, USA},
	series = {{ASE} '15},
	title = {Recommending {API} {Usages} for {Mobile} {Apps} with {Hidden} {Markov} {Model}},
	isbn = {978-1-5090-0025-8},
	url = {https://doi.org/10.1109/ASE.2015.109},
	doi = {10.1109/ASE.2015.109},
	abstract = {Mobile apps often rely heavily on standard API frameworks and libraries. However, learning to use those APIs is often challenging due to the fast-changing nature of API frameworks and the insufficiency of documentation and code examples. This paper introduces DroidAssist, a recommendation tool for API usages of Android mobile apps. The core of DroidAssist is HAPI, a statistical, generative model of API usages based on Hidden Markov Model. With HAPIs trained from existing mobile apps, DroidAssist could perform code completion for method calls. It can also check existing call sequences to detect and repair suspicious (i.e. unpopular) API usages.},
	urldate = {2018-03-22},
	booktitle = {Proceedings of the 2015 30th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	publisher = {IEEE Computer Society},
	author = {Nguyen, Tam The and Pham, Hung Viet and Vu, Phong Minh and Nguyen, Tung Thanh},
	year = {2015},
	keywords = {incomplete},
	pages = {795--800}
}

@misc{doctoralwriting_whats_2017,
	title = {What’s the best way to get writing done?},
	url = {https://doctoralwriting.wordpress.com/2017/11/27/whats-the-best-way-to-get-writing-done/},
	abstract = {By Alice Hague Alice Hague recently submitted her PhD at the University of Edinburgh, UK. She is interested in faith-based engagement in politics and the public sphere, and her thesis investigates …},
	language = {en},
	urldate = {2018-03-22},
	journal = {DoctoralWriting SIG},
	author = {{doctoralwriting}},
	month = nov,
	year = {2017},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EMXWXK8D\\whats-the-best-way-to-get-writing-done.html:text/html}
}

@book{strunk_elements_1999,
	address = {Boston},
	edition = {4th ed},
	title = {The elements of style},
	isbn = {978-0-205-30902-3 978-0-205-31342-6},
	language = {en},
	publisher = {Allyn and Bacon},
	author = {Strunk, William and White, E. B.},
	year = {1999},
	keywords = {to read, English language, Report writing, Rhetoric, Style},
	file = {Strunk und White - 1999 - The elements of style.pdf:C\:\\Users\\Anna\\Zotero\\storage\\RWES3U35\\Strunk und White - 1999 - The elements of style.pdf:application/pdf}
}

@article{huang_tracking_nodate,
	title = {Tracking {Ransomware} {End}-to-end},
	abstract = {Ransomware is a type of malware that encrypts the ﬁles of infected hosts and demands payment, often in a cryptocurrency such as Bitcoin. In this paper, we create a measurement framework that we use to perform a large-scale, two-year, end-to-end measurement of ransomware payments, victims, and operators. By combining an array of data sources, including ransomware binaries, seed ransom payments, victim telemetry from infections, and a large database of Bitcoin addresses annotated with their owners, we sketch the outlines of this burgeoning ecosystem and associated third-party infrastructure. In particular, we trace the ﬁnancial transactions, from the moment victims acquire bitcoins, to when ransomware operators cash them out. We ﬁnd that many ransomware operators cashed out using BTC-e, a now-defunct Bitcoin exchange. In total we are able to track over \$16 million in likely ransom payments made by 19,750 potential victims during a two-year period. While our study focuses on ransomware, our methods are potentially applicable to other cybercriminal operations that have similarly adopted Bitcoin as their payment channel.},
	language = {en},
	author = {Huang, Danny Yuxing and Aliapoulios, Maxwell Matthaios and Li, Vector Guo and Invernizzi, Luca and McRoberts, Kylie and Bursztein, Elie and Levin, Jonathan and Levchenko, Kirill and Snoeren, Alex C and McCoy, Damon},
	pages = {14},
	file = {Huang et al. - Tracking Ransomware End-to-end.pdf:C\:\\Users\\Anna\\Zotero\\storage\\PG2PB8C4\\Huang et al. - Tracking Ransomware End-to-end.pdf:application/pdf}
}

@inproceedings{lu_bugbench:_2005,
	title = {{BugBench}: {Benchmarks} for {Evaluating} {Bug} {Detection} {Tools}},
	shorttitle = {{BugBench}},
	abstract = {Benchmarking provides an effective way to evaluate different tools. Unfortunately, so far there is no good benchmark suite to systematically evaluate software bug detection tools. As a result, it is difcult to quantitatively compare the strengths and limita- tions of existing or newly proposed bug detection tools. In this paper, we share our experience of building a bug bench- mark suite called BugBench. Specically , we rst summarize the general guidelines on the criteria for selecting representative bug benchmarks, and the metrics for evaluating a bug detection tool. Second, we present a set of buggy applications collected by us, with various types of software bugs. Third, we conduct a pre- liminary study on the application and bug characteristics in the context of software bug detection. Finally, we evaluate several ex- isting bug detection tools including Purify, Valgrind, and CCured to validate the selection of our benchmarks.},
	author = {Lu, Shan and Li, Zhenmin and Qin, Feng and Tan, Lin and Zhou, Pin and Zhou, Y},
	month = jan,
	year = {2005},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\8Q2FZP4M\\Lu et al. - 2005 - BugBench Benchmarks for Evaluating Bug Detection .pdf:application/pdf}
}

@misc{noauthor_writing_nodate,
	title = {Writing {Academic} {Papers}},
	url = {http://sarahnadi.org/writing-papers/},
	urldate = {2018-03-26},
	file = {Writing Academic Papers:C\:\\Users\\Anna\\Zotero\\storage\\SD7BXXTR\\writing-papers.html:text/html}
}

@misc{meetup_how_2018,
	title = {How do {I} get people to show up?},
	shorttitle = {How do {I} get people to show up?},
	url = {https://medium.com/meetup-organizer-guide/how-do-i-get-people-to-show-up-1254e5da9b2},
	abstract = {Your Meetup is on the calendar and people are coming! How do you get them to actually show up?},
	urldate = {2018-03-25},
	journal = {The Organizer Guide by Meetup},
	author = {Meetup},
	month = jan,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\LZID9HGM\\how-do-i-get-people-to-show-up-1254e5da9b2.html:text/html}
}

@article{stewart_service_2017,
	title = {Service {Design}, {Strategy}, and the {Art} of {Customer} {Delight}},
	author = {Stewart, Thomas A and O’Connell, Patricia},
	year = {2017},
	pages = {5}
}

@book{results_woo_2016,
	address = {New York, NY},
	title = {Woo, {Wow}, and {Win}: {Service} {Design}, {Strategy}, and the {Art} of {Customer} {Delight}},
	isbn = {978-0-06-241569-1},
	shorttitle = {Woo, {Wow}, and {Win}},
	abstract = {In this pioneering guide, two business authorities introduce the new discipline of Service Design and reveal why trying new strategies for pleasing customers isn’t enough to differentiate your business—it needs to be designed for service from the ground up.Woo, Wow, and Win reveals the importance of designing your company around service, and offers clear, practical strategies based on the idea that the design of services is markedly different than manufacturing. Bestselling authors and business experts Thomas A. Stewart and Patricia O’Connell contend that most companies, both digital and brick-and-mortar, B2B or B2C; are not designed for service—to provide an experience that matches a customer’s expectations with every interaction and serves the company’s needs. When customers have more choices than ever before, study after study reveals that it’s the experience that makes the difference. To provide great experiences that keep customers coming back, businesses must design their services with as much care as their products. Service Design is proactive—it is about delivering on your promise to customers in accordance with your strategy, not about acceding to customer dictates. Woo, Wow, and Win teaches you how to create "Ahhh" moments when the customer makes a positive judgment, and to avoid Ow" moments—when you lose a sale or worse, customer trust. Whether you’re giving a haircut, selling life insurance, or managing an office building, your customer is as much a part of your business as your employees are. Together, you and customers create a bank of trust; fueled by knowledge of each other’s skills and preferences. This is Customer Capital, the authors explain, and it is jointly owned. But it’s up to you to manage it profitably. Innovative yet grounded in real world examples, Woo, Wow, and Win is the key strategy for winning customers—and keeping them.},
	language = {English},
	publisher = {HarperBusiness},
	author = {results, search and results, search},
	month = nov,
	year = {2016},
	file = {Stewart und O’Connell - 2017 - Service Design, Strategy, and the Art of Customer .pdf:C\:\\Users\\Anna\\Zotero\\storage\\QIC9B7PW\\Stewart und O’Connell - 2017 - Service Design, Strategy, and the Art of Customer .pdf:application/pdf;woo-wow-and-win-stewart-en-28566.mp3:C\:\\Users\\Anna\\Zotero\\storage\\7WPHMU7I\\woo-wow-and-win-stewart-en-28566.mp3:audio/mpeg}
}

@misc{noauthor_woo_nodate,
	title = {Woo, {Wow}, and {Win} {Summary} {\textbar} {Thomas} {A}. {Stewart} and {Patricia} {O}’{Connell}},
	url = {https://www.getabstract.com/en/summary/sales-and-marketing/woo-wow-and-win/28566},
	abstract = {In this getAbstract summary, you will learn: How to develop and nurture “service design and delivery” (SD2),; How to apply its 10 core elements and five basic principles to your business, and How to learn from consumers’ “Ahhh” and “Ow” moments.},
	language = {en},
	urldate = {2018-03-25},
	journal = {getAbstract},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IU3CLQHX\\28566.html:text/html}
}

@misc{getabstract_is_2018,
	title = {Is money a poor motivator?},
	url = {https://blog.getabstract.com/2018/03/14/is-money-a-poor-motivator/},
	abstract = {You’re good at your job, you’re satisfied with your salary and benefits and you like your company and your colleagues. You’re not a person who trudges into the office every morning, disengaged and …},
	language = {en-GB},
	urldate = {2018-03-25},
	journal = {getAbstract Life!},
	author = {getAbstract},
	month = mar,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\488L96CN\\is-money-a-poor-motivator.html:text/html}
}

@misc{clegoues_things_2016,
	title = {Things {I} {Keep} {Repeating} {About} {Writing}},
	url = {https://clairelegoues.com/2016/08/23/things-i-keep-repeating-about-writing/},
	abstract = {I often write papers with students, or read students’ papers to provide comments, and I find myself saying the same things over and over, especially the first time out.*  So: here’s a b…},
	language = {en},
	urldate = {2018-03-26},
	journal = {Claire Le Goues},
	author = {{clegoues}},
	month = aug,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BG4J8848\\things-i-keep-repeating-about-writing.html:text/html}
}

@article{bagrow_information_2017,
	title = {Information flow reveals prediction limits in online social activity},
	url = {http://arxiv.org/abs/1708.04575},
	abstract = {Modern society depends on the flow of information over online social networks, and popular social platforms now generate significant behavioral data. Yet it remains unclear what fundamental limits may exist when using these data to predict the activities and interests of individuals. Here we apply tools from information theory to estimate the predictive information content of the writings of Twitter users and to what extent that information flows between users. Distinct temporal and social effects are visible in the information flow, and these estimates provide a fundamental bound on the predictive accuracy achievable with these data. Due to the social flow of information, we estimate that approximately 95\% of the potential predictive accuracy attainable for an individual is available within the social ties of that individual only, without requiring the individual's data.},
	urldate = {2018-03-26},
	journal = {arXiv:1708.04575 [physics]},
	author = {Bagrow, James P. and Liu, Xipei and Mitchell, Lewis},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.04575},
	keywords = {Computer Science - Social and Information Networks, Physics - Physics and Society},
	file = {arXiv\:1708.04575 PDF:C\:\\Users\\Anna\\Zotero\\storage\\BQZ5ERAR\\Bagrow et al. - 2017 - Information flow reveals prediction limits in onli.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6RDN6STG\\1708.html:text/html}
}

@article{amann_systematic_2017-1,
	title = {A {Systematic} {Evaluation} of {Static} {API}-{Misuse} {Detectors}},
	url = {http://arxiv.org/abs/1712.00242},
	abstract = {Application Programming Interfaces (APIs) often have usage constraints, such as restrictions on call order or call conditions. API misuses, i.e., violations of these constraints, may lead to software crashes, bugs, and vulnerabilities. Though researchers developed many API-misuse detectors over the last two decades, recent studies show that API misuses are still prevalent. Therefore, we need to understand the capabilities and limitations of existing detectors in order to advance the state of the art. In this paper, we present the first-ever qualitative and quantitative evaluation that compares static API-misuse detectors along the same dimensions, and with original author validation. To accomplish this, we develop MUC, a classification of API misuses, and MUBenchPipe, an automated benchmark for detector comparison, on top of our misuse dataset, MUBench. Our results show that the capabilities of existing detectors vary greatly and that existing detectors, though capable of detecting misuses, suffer from extremely low precision and recall. A systematic root-cause analysis reveals that, most importantly, detectors need to go beyond the naive assumption that a deviation from the most-frequent usage corresponds to a misuse and need to obtain additional usage examples to train their models. We present possible directions towards more-powerful API-misuse detectors.},
	urldate = {2018-03-26},
	journal = {arXiv:1712.00242 [cs]},
	author = {Amann, Sven and Nguyen, Hoan Anh and Nadi, Sarah and Nguyen, Tien N. and Mezini, Mira},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.00242},
	keywords = {Software, Computer bugs, Computer Science - Software Engineering, Tools, Taxonomy, incomplete, API-Misuse Detectors, Detectors, Systematics, API-Misuse Detection, Benchmark, Benchmark testing, Misuse Classification, MUBench, Survey},
	file = {Amann et al. - 2017 - A Systematic Evaluation of Static API-Misuse Detec.pdf:C\:\\Users\\Anna\\Zotero\\storage\\V6ZCS2UV\\Amann et al. - 2017 - A Systematic Evaluation of Static API-Misuse Detec.pdf:application/pdf;Amann et al. - 2018 - A Systematic Evaluation of Static API-Misuse Detec.pdf:C\:\\Users\\Anna\\Zotero\\storage\\K6BCDALR\\Amann et al. - 2018 - A Systematic Evaluation of Static API-Misuse Detec.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\AZIIIU7Y\\1712.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\PIJ2C6EJ\\8338426.html:text/html}
}

@inproceedings{wang_nativespeaker:_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{NativeSpeaker}: {Identifying} {Crypto} {Misuses} in {Android} {Native} {Code} {Libraries}},
	isbn = {978-3-319-75159-7 978-3-319-75160-3},
	shorttitle = {{NativeSpeaker}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-75160-3_19},
	doi = {10.1007/978-3-319-75160-3_19},
	abstract = {The use of native code (ARM binary code) libraries in Android apps greatly promotes the execution performance of frequently used algorithms. Nonetheless, it increases the complexity of app assessment since the binary code analysis is often sophisticated and time-consuming. As a result, many defects still exist in native code libraries and potentially threat the security of users. To assess the native code libraries, current researches mainly focus on the API invoking correctness and less dive into the details of code. Hence, flaws may hide in internal implementation when the analysis of API does not discover them effectively.The assessment of native code requires a more detailed code comprehension process to pinpoint flaws. In response, we design and implement NativeSpeaker, an Android native code analysis system to assess native code libraries. NativeSpeaker provides not only the capability of recognizing certain pattern related to security flaws, but also the functionality of discovering and comparing native code libraries among a large-scale collection of apps from non-official Android markets. With the help of NativeSpeaker, we analyzed 20,353 dynamic libraries (.so) collected from 20,000 apps in non-official Android markets. Particularly, our assessment focuses on searching crypto misuse related insecure code pattern in those libraries. The analyzing results show even for those most frequently used (top 1\%) native code libraries, one third of them contain at least one misuse. Furthermore, our observation indicates the misuse of crypto is often related to insecure data communication: about 25\% most frequently used native code libraries suffer from this flaw. Our conducted analysis revealed the necessity of in-depth security assessment against popular native code libraries, and proved the effectiveness of the designed NativeSpeaker system.},
	language = {en},
	urldate = {2018-03-27},
	booktitle = {Information {Security} and {Cryptology}},
	publisher = {Springer, Cham},
	author = {Wang, Qing and Li, Juanru and Zhang, Yuanyuan and Wang, Hui and Hu, Yikun and Li, Bodong and Gu, Dawu},
	month = nov,
	year = {2017},
	keywords = {cryptography misuse, cryptography misuse mining},
	pages = {301--320},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\N4BYXYJN\\10.html:text/html;Wang et al. - 2017 - NativeSpeaker Identifying Crypto Misuses in Andro.pdf:C\:\\Users\\Anna\\Zotero\\storage\\V8B4L94D\\Wang et al. - 2017 - NativeSpeaker Identifying Crypto Misuses in Andro.pdf:application/pdf}
}

@misc{noauthor_92_nodate,
	title = {\#92 {Felienne} {Hermans}, {What} is {Programming}? {\textbar} no dogma podcast},
	shorttitle = {\#92 {Felienne} {Hermans}, {What} is {Programming}?},
	url = {https://nodogmapodcast.bryanhogan.net/92-felienne-hermans-what-is-programming/},
	language = {en-US},
	urldate = {2018-03-27},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6CS36TKZ\\92-felienne-hermans-what-is-programming.html:text/html}
}

@misc{noauthor_understanding_nodate-1,
	title = {Understanding {Bias} in {Peer} {Review}},
	url = {https://research.googleblog.com/2017/11/understanding-bias-in-peer-review.html},
	abstract = {Posted by Andrew Tomkins, Director of Engineering and William D. Heavlin, Statistician, Google Research   In the 1600’s, a series of practic...},
	language = {en},
	urldate = {2018-03-27},
	journal = {Research Blog},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\G3VW29BK\\understanding-bias-in-peer-review.html:text/html}
}

@article{wu_anna:_nodate,
	title = {Anna: {A} {KVS} {For} {Any} {Scale}},
	abstract = {Modern cloud providers offer dense hardware with multiple cores and large memories, hosted in global platforms. This raises the challenge of implementing high-performance software systems that can effectively scale from a single core to multicore to the globe. Conventional wisdom says that software designed for one scale point needs to be rewritten when scaling up by 10−100× [1]. In contrast, we explore how a system can be architected to scale across many orders of magnitude by design. We explore this challenge in the context of a new keyvalue store system called Anna: a partitioned, multi-mastered system that achieves high performance and elasticity via waitfree execution and coordination-free consistency. Our design rests on a simple architecture of coordination-free actors that perform state update via merge of lattice-based composite data structures. We demonstrate that a wide variety of consistency models can be elegantly implemented in this architecture with unprecedented consistency, smooth ﬁne-grained elasticity, and performance that far exceeds the state of the art.},
	language = {en},
	author = {Wu, Chenggang and Faleiro, Jose M and Lin, Yihan and Hellerstein, Joseph M},
	pages = {12},
	file = {Wu et al. - Anna A KVS For Any Scale.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NWSL5X24\\Wu et al. - Anna A KVS For Any Scale.pdf:application/pdf}
}

@article{hestness_deep_2017,
	title = {Deep {Learning} {Scaling} is {Predictable}, {Empirically}},
	url = {http://arxiv.org/abs/1712.00409},
	abstract = {Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, computational scale, and model accuracy improvements to advance the state-of-the-art. This paper presents a large scale empirical characterization of generalization error and model size growth as training sets grow. We introduce a methodology for this measurement and test four machine learning domains: machine translation, language modeling, image processing, and speech recognition. Our empirical results show power-law generalization error scaling across a breadth of factors, resulting in power-law exponents---the "steepness" of the learning curve---yet to be explained by theoretical work. Further, model improvements only shift the error but do not appear to affect the power-law exponent. We also show that model size scales sublinearly with data size. These scaling relationships have significant implications on deep learning research, practice, and systems. They can assist model debugging, setting accuracy targets, and decisions about data set growth. They can also guide computing system design and underscore the importance of continued computational scaling.},
	urldate = {2018-03-28},
	journal = {arXiv:1712.00409 [cs, stat]},
	author = {Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md Mostofa Ali and Yang, Yang and Zhou, Yanqi},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.00409},
	keywords = {to read, Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CJDS268G\\1712.html:text/html;Hestness et al. - 2017 - Deep Learning Scaling is Predictable, Empirically.pdf:C\:\\Users\\Anna\\Zotero\\storage\\4IGYXTRH\\Hestness et al. - 2017 - Deep Learning Scaling is Predictable, Empirically.pdf:application/pdf}
}

@inproceedings{i_pun_dont_2016,
	title = {Don't let data {Go} astray - {A} {Context}-{Sensitive} {Taint} {Analysis} for {Concurrent} {Programs} in {Go}},
	copyright = {All rights reserved},
	booktitle = {Nordic {Workshop} on {Programming} {Theory} ({NWPT}'16)},
	author = {I Pun, Ka and Steffen, Martin and Stolz, Volker and Wickert, Anna-Katharina and Bodden, Eric and Eichberg, Michael},
	month = oct,
	year = {2016}
}

@misc{noauthor_revealed:_nodate,
	title = {Revealed: {Body} {Language} {That} {Makes} {You} {Attractive} at {Work} and in {Dating}},
	url = {https://www.lifehack.org/572207/body-language-for-effective-communication-work-dating-and-social-gathering},
	urldate = {2018-03-28},
	keywords = {to read},
	file = {Revealed\: Body Language That Makes You Attractive at Work and in Dating:C\:\\Users\\Anna\\Zotero\\storage\\NF8GKA3Q\\body-language-for-effective-communication-work-dating-and-social-gathering.html:text/html}
}

@misc{peironcely_4_nodate,
	title = {The 4 {Hour} {Workweek} {Guide} {To} {PhD} {Motivation}},
	url = {http://www.nextscientist.com/4-hour-workweek-guide-phd-motivation/},
	abstract = {Boost your PhD motivation using the learnings from The 4 Hour Workweek. Be happier, increase the quality of your research and finish your PhD faster.},
	language = {en-US},
	urldate = {2018-03-28},
	author = {Peironcely, Julio},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\N9LBP4QI\\4-hour-workweek-guide-phd-motivation.html:text/html}
}

@misc{noauthor_top_nodate-1,
	title = {Top 42 {Books} {For} {PhD} {Students}},
	url = {http://www.nextscientist.com/top-42-books-phd-students/},
	urldate = {2018-03-28},
	file = {Top 42 Books For PhD Students:C\:\\Users\\Anna\\Zotero\\storage\\75GBJ66P\\top-42-books-phd-students.html:text/html}
}

@misc{peironcely_7_nodate,
	title = {The 7 {Habits} {Of} {Highly} {Effective} {PhD} {Students} - {Next} {Scientist}},
	url = {http://www.nextscientist.com/7-habits-highly-effective-phd-students/},
	abstract = {PhD students face many difficulties but are not helpless. They can become independent, resilient and productive scientists by developing these habits.},
	language = {en-US},
	urldate = {2018-03-28},
	author = {Peironcely, Julio},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RSZ79KCT\\7-habits-highly-effective-phd-students.html:text/html}
}

@article{lehman_surprising_2018,
	title = {The {Surprising} {Creativity} of {Digital} {Evolution}: {A} {Collection} of {Anecdotes} from the {Evolutionary} {Computation} and {Artificial} {Life} {Research} {Communities}},
	shorttitle = {The {Surprising} {Creativity} of {Digital} {Evolution}},
	url = {http://arxiv.org/abs/1803.03453},
	abstract = {Biological evolution provides a creative fount of complex and subtle adaptations, often surprising the scientists who discover them. However, because evolution is an algorithmic process that transcends the substrate in which it occurs, evolution's creativity is not limited to nature. Indeed, many researchers in the field of digital evolution have observed their evolving algorithms and organisms subverting their intentions, exposing unrecognized bugs in their code, producing unexpected adaptations, or exhibiting outcomes uncannily convergent with ones in nature. Such stories routinely reveal creativity by evolution in these digital worlds, but they rarely fit into the standard scientific narrative. Instead they are often treated as mere obstacles to be overcome, rather than results that warrant study in their own right. The stories themselves are traded among researchers through oral tradition, but that mode of information transmission is inefficient and prone to error and outright loss. Moreover, the fact that these stories tend to be shared only among practitioners means that many natural scientists do not realize how interesting and lifelike digital organisms are and how natural their evolution can be. To our knowledge, no collection of such anecdotes has been published before. This paper is the crowd-sourced product of researchers in the fields of artificial life and evolutionary computation who have provided first-hand accounts of such cases. It thus serves as a written, fact-checked collection of scientifically important and even entertaining stories. In doing so we also present here substantial evidence that the existence and importance of evolutionary surprises extends beyond the natural world, and may indeed be a universal property of all complex evolving systems.},
	urldate = {2018-04-03},
	journal = {arXiv:1803.03453 [cs]},
	author = {Lehman, Joel and Clune, Jeff and Misevic, Dusan and Adami, Christoph and Beaulieu, Julie and Bentley, Peter J. and Bernard, Samuel and Beslon, Guillaume and Bryson, David M. and Chrabaszcz, Patryk and Cheney, Nick and Cully, Antoine and Doncieux, Stephane and Dyer, Fred C. and Ellefsen, Kai Olav and Feldt, Robert and Fischer, Stephan and Forrest, Stephanie and Frénoy, Antoine and Gagné, Christian and Goff, Leni Le and Grabowski, Laura M. and Hodjat, Babak and Hutter, Frank and Keller, Laurent and Knibbe, Carole and Krcah, Peter and Lenski, Richard E. and Lipson, Hod and MacCurdy, Robert and Maestre, Carlos and Miikkulainen, Risto and Mitri, Sara and Moriarty, David E. and Mouret, Jean-Baptiste and Nguyen, Anh and Ofria, Charles and Parizeau, Marc and Parsons, David and Pennock, Robert T. and Punch, William F. and Ray, Thomas S. and Schoenauer, Marc and Shulte, Eric and Sims, Karl and Stanley, Kenneth O. and Taddei, François and Tarapore, Danesh and Thibault, Simon and Weimer, Westley and Watson, Richard and Yosinksi, Jason},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.03453},
	keywords = {to read, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\22RNRJKE\\1803.html:text/html;Lehman et al. - 2018 - The Surprising Creativity of Digital Evolution A .pdf:C\:\\Users\\Anna\\Zotero\\storage\\2TYZEDZJ\\Lehman et al. - 2018 - The Surprising Creativity of Digital Evolution A .pdf:application/pdf}
}

@article{brown_adversarial_2017,
	title = {Adversarial {Patch}},
	url = {http://arxiv.org/abs/1712.09665},
	abstract = {We present a method to create universal, robust, targeted adversarial image patches in the real world. The patches are universal because they can be used to attack any scene, robust because they work under a wide variety of transformations, and targeted because they can cause a classifier to output any target class. These adversarial patches can be printed, added to any scene, photographed, and presented to image classifiers; even when the patches are small, they cause the classifiers to ignore the other items in the scene and report a chosen target class.},
	urldate = {2018-04-03},
	journal = {arXiv:1712.09665 [cs]},
	author = {Brown, Tom B. and Mané, Dandelion and Roy, Aurko and Abadi, Martín and Gilmer, Justin},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.09665},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\PZ7USBIQ\\1712.html:text/html;Brown et al. - 2017 - Adversarial Patch.pdf:C\:\\Users\\Anna\\Zotero\\storage\\SGABHCW7\\Brown et al. - 2017 - Adversarial Patch.pdf:application/pdf}
}

@misc{noauthor_running_2017,
	title = {Running {Docker} containers on {Bash} on {Windows}},
	url = {https://blog.jayway.com/2017/04/19/running-docker-on-bash-on-windows/},
	abstract = {Running Docker directly on Bash on Windows is not supported, but this post shows how you can run the engine on Windows and connect to it from the WSL.},
	language = {en-US},
	urldate = {2018-04-03},
	journal = {Jayway},
	month = apr,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\YQZYVYPB\\running-docker-on-bash-on-windows.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\I5GPS4J9\\running-docker-on-bash-on-windows.html:text/html}
}

@misc{noauthor_install_nodate,
	title = {install docker bash on windows at {DuckDuckGo}},
	url = {https://duckduckgo.com/?q=install+docker+bash+on+windows&t=ffab&ia=qa},
	urldate = {2018-04-03},
	file = {install docker bash on windows at DuckDuckGo:C\:\\Users\\Anna\\Zotero\\storage\\2JMWUUGZ\\duckduckgo.com.html:text/html}
}

@misc{noauthor_lantern_nodate,
	title = {Lantern},
	url = {https://feiwang3311.github.io/Lantern/},
	urldate = {2018-04-04},
	file = {Lantern:C\:\\Users\\Anna\\Zotero\\storage\\VU6HMCL5\\Lantern.html:text/html}
}

@article{gorski_usability_2018,
	title = {Usability von {Security}-{APIs} für massiv-skalierbare vernetzte {Service}-orientierte {Systeme}},
	volume = {Lecture Notes in Informatics (LNI)},
	url = {https://dl.gi.de/bitstream/handle/20.500.12116/16292/sicherheit2018-26.pdf?sequence=1},
	abstract = {Kontemporäre Service-orientierte Systeme sind hochgradig vernetzt und haben zudem die Eigenschaft massiv-skalierbar zu sein. Diese Charakteristiken stellen im besonderen Maße Anforderungen an die Datensicherheit der Anwender solcher Systeme und damit primär an alle Stakeholder der Softwareentwicklung, die in der Verantwortung sind, passgenaue Sicherheitsmechanismen effektiv in die Softwareprodukte zu bringen.
Die Effektivität von Sicherheitsarchitekturen in service-orientierten Systemen hängt maßgeblich von der richtigen Nutzung und Integration von Security-APIs durch eine heterogene Gruppe von Softwareentwicklern ab, bei der nicht per se ein fundiertes Hintergrundwissen über komplexe digitale Sicherheitsmechanismen vorausgesetzt werden kann. Die Diskrepanz zwischen komplexen und in der Anwendung fehleranfälligen APIs und einem fehlenden Verständnis für die zugrundeliegenden Sicherheitskonzepte auf Seiten der Nutzer begünstigt in der Praxis unsichere Softwaresysteme. Aus diesem Grund ist die Gebrauchstauglichkeit von Security-APIs besonders relevant, damit Programmierer den benötigten Funktionsumfang effektiv, effizient und zufriedenstellend verwenden können.
Abgeleitet von dieser Problemstellung, konzentriert sich das Dissertationsvorhaben auf die gebrauchstaugliche Ausgestaltung von Security-APIs und den Herausforderungen die sich aus den Methoden zur Evaluation der Usability in typischen Umgebungen der Softwareentwicklung ergeben.},
	language = {de},
	number = {Sicherheit 2018},
	urldate = {2018-04-01},
	author = {Gorski, Peter},
	year = {2018},
	pages = {6},
	file = {Gorski - 2018 - Usability von Security-APIs für massiv-skalierbare.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MPEDYJQ3\\Gorski - 2018 - Usability von Security-APIs für massiv-skalierbare.pdf:application/pdf}
}

@misc{widrich_science_nodate,
	title = {The {Science} of {Storytelling}: {Why} {Telling} a {Story} is the {Most} {Powerful} {Way} to {Activate} {Our} {Brains}},
	shorttitle = {The {Science} of {Storytelling}},
	url = {https://lifehacker.com/5965703/the-science-of-storytelling-why-telling-a-story-is-the-most-powerful-way-to-activate-our-brains},
	abstract = {A good story can make or break a presentation, article, or conversation. But why is that? When Buffer co-founder Leo Widrich started to market his product through stories instead of benefits and bullet points, sign-ups went through the roof. Here he shares the science of why storytelling is so uniquely powerful.},
	language = {en-US},
	urldate = {2018-04-04},
	journal = {Lifehacker},
	author = {Widrich, Leo},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BX28SC53\\the-science-of-storytelling-why-telling-a-story-is-the-most-powerful-way-to-activate-our-brains.html:text/html}
}

@misc{noauthor_best_nodate,
	title = {The {Best} of {TED} 2014: {Lessons} for {Your} {Next} {Presentation}},
	url = {https://www.entrepreneur.com/article/233045},
	urldate = {2018-04-04},
	file = {The Best of TED 2014\: Lessons for Your Next Presentation:C\:\\Users\\Anna\\Zotero\\storage\\QXU5PVUQ\\233045.html:text/html;The Best of TED 2014\: Lessons for Your Next Presentation:C\:\\Users\\Anna\\Zotero\\storage\\L66DYN7H\\233045.html:text/html}
}

@misc{gallo_best_2014,
	title = {The {Best} of {TED} 2014: {Lessons} for {Your} {Next} {Presentation}},
	shorttitle = {The {Best} of {TED} 2014},
	url = {https://www.entrepreneur.com/article/233045},
	abstract = {From an astronaut talking fear, Bill and Melinda Gates on giving up their wealth to a surprise appearance by an outlaw, here are some key takeaways from this year's event.},
	language = {en},
	urldate = {2018-04-04},
	journal = {Entrepreneur},
	author = {Gallo, Carmine},
	month = apr,
	year = {2014},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\DR8MY7GB\\233045.html:text/html}
}

@misc{noauthor_gtd_nodate,
	title = {{GTD} in 15 minutes – {A} {Pragmatic} {Guide} to {Getting} {Things} {Done}},
	url = {https://hamberg.no/gtd/},
	urldate = {2018-04-05},
	keywords = {to read},
	file = {GTD in 15 minutes – A Pragmatic Guide to Getting Things Done:C\:\\Users\\Anna\\Zotero\\storage\\LEN8XYSC\\gtd.html:text/html}
}

@misc{noauthor_invited_nodate,
	title = {Invited {Speaker}: {A} {Brief}, {Opinionated} {History} of the {API} - {SPLASH} 2014},
	url = {https://2014.splashcon.org/event/plateau2014-invited-speaker-josh-bloch},
	urldate = {2018-04-06},
	file = {Invited Speaker\: A Brief, Opinionated History of the API - SPLASH 2014:C\:\\Users\\Anna\\Zotero\\storage\\PSRHEZIB\\plateau2014-invited-speaker-josh-bloch.html:text/html}
}

@misc{bloch_brief_2014,
	address = {Portland},
	title = {A {Brief}, {Opinionated} {History} of the {API}},
	url = {https://2014.splashcon.org/event/plateau2014-invited-speaker-josh-bloch},
	abstract = {APIs have been with us for 60 years or so. They come in all different shapes, sizes, and disguises. In this talk we’ll look at a few APIs, focusing on what makes them good, what makes them successful, and why the correlation between quality and success isn’t as high we might want it to be.},
	language = {englisch},
	urldate = {2018-04-06},
	author = {Bloch, Josh},
	month = oct,
	year = {2014},
	keywords = {to read},
	file = {Invited Speaker\: A Brief, Opinionated History of the API - SPLASH 2014:C\:\\Users\\Anna\\Zotero\\storage\\ZBZA96UF\\plateau2014-invited-speaker-josh-bloch.html:text/html}
}

@article{bond_understanding_nodate,
	title = {Understanding {Security} {APIs}},
	language = {en},
	author = {Bond, Michael},
	keywords = {to read},
	pages = {170},
	file = {Bond - Understanding Security APIs.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JYAYBKLK\\Bond - Understanding Security APIs.pdf:application/pdf}
}

@incollection{aldini_introduction_2011,
	address = {Berlin, Heidelberg},
	title = {An {Introduction} to {Security} {API} {Analysis}},
	volume = {6858},
	isbn = {978-3-642-23081-3 978-3-642-23082-0},
	url = {http://link.springer.com/10.1007/978-3-642-23082-0_2},
	language = {en},
	urldate = {2018-04-06},
	booktitle = {Foundations of {Security} {Analysis} and {Design} {VI}},
	publisher = {Springer Berlin Heidelberg},
	author = {Focardi, Riccardo and Luccio, Flaminia L. and Steel, Graham},
	editor = {Aldini, Alessandro and Gorrieri, Roberto},
	year = {2011},
	doi = {10.1007/978-3-642-23082-0_2},
	keywords = {to read},
	pages = {35--65},
	file = {Focardi et al. - 2011 - An Introduction to Security API Analysis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MBJTFAN2\\Focardi et al. - 2011 - An Introduction to Security API Analysis.pdf:application/pdf}
}

@misc{noauthor_formal_nodate,
	title = {Formal {Analysis} of {Security} {APIs} - {Semantic} {Scholar}},
	url = {/paper/Formal-Analysis-of-Security-APIs-Steel/bdb574c135cb692254f202cef51e91860798a605},
	abstract = {An Application Program Interface (API) is considered a security API when it is designed not only to offer access to functionality but also to enforce a security policy, i.e. no matter what commands are sent to the interface, some security properties continue to hold. They are used, for example, as interfaces to cryptographic hardware modules and smartcards. They are very difficult to design, and errors in security APIs have been shown to give rise to critical vulnerabilities in a variety of real world systems, from cash machine PIN processing modules to authentication tokens. Formal analysis of security APIs aims to use techniques from program verification both to find attacks on faulty APIs, and prove security properties of correct ones. This thesis describes some of my work on developing this area from 2004-2010. We focus on APIs for cryptographic key management. We start by defining a Dolev-Yao like model for security APIs, which leads in general to an undecidable security problem. We show decidability for a number of subclasses and soundness for some abstractions. We show how these results have been applied to real commercially available devices, resulting in the unearthing of a number of previously unknown vulnerabilities. We propose a new API for key management which we prove secure in our model. Finally we evaluate the work and give some perspectives.},
	urldate = {2018-04-06},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\5XYQLPLE\\bdb574c135cb692254f202cef51e91860798a605.html:text/html}
}

@incollection{van_tilborg_formal_2011,
	address = {Boston, MA},
	title = {Formal {Analysis} of {Security} {APIs}},
	isbn = {978-1-4419-5905-8 978-1-4419-5906-5},
	url = {http://www.springerlink.com/index/10.1007/978-1-4419-5906-5_873},
	language = {en},
	urldate = {2018-04-06},
	booktitle = {Encyclopedia of {Cryptography} and {Security}},
	publisher = {Springer US},
	author = {Biswas, Soma and Chellappa, Rama and Kaliski, Burt and Bernstein, Daniel J. and Bleumer, Gerrit and Schunter, Matthias and Zhang, Wensheng and Canteaut, Anne and Benot, Olivier and Cannière, Christophe De and Biryukov, Alex and Liskov, Moses and Liskov, Moses and Desmedt, Yvo and Kaliski, Burt and Canteaut, Anne and Donida Labati, Ruggero and Scotti, Fabio and Barg, Alexander and Kabatiansky, Gregory and Kaliski, Burt and Caddy, Tom and Provos, Niels and Al-Shaer, Ehab and Weimerskirch, André and Weimerskirch, André and Samarati, Pierangela and Bleumer, Gerrit and Meadows, Catherine and Steel, Graham and Huth, Michael and Millen, Jonathan K. and Meadows, Catherine and Güneysu, Tim E. and Thome, Emmanuel},
	editor = {van Tilborg, Henk C. A. and Jajodia, Sushil},
	year = {2011},
	doi = {10.1007/978-1-4419-5906-5_873},
	keywords = {to read},
	pages = {492--494}
}

@article{gorski_towards_2016,
	title = {Towards the {Usability} {Evaluation} of {Security} {APIs}},
	abstract = {Application Programming Interfaces (APIs) are a vital link between software components as well as between software and developers. Security APIs deliver crucial functionalities for programmers who see themselves in the increasing need for integrating security services into their software products. The ignorant or incorrect use of Security APIs leads to critical security flaws, as has been revealed by recent security studies. One major reason for this is rooted in usability issues. API Usability research has been deriving recommendations for designing usable APIs in general. Facing the growing relevance of Security APIs, the question arises, whether the observed usability aspects in the general space are already sufficient enough for building usable Security APIs. The currently available findings in the API Usability domain are selective fragments only, though. This still emerging field has not produced a comprehensive model yet. As a consequence, a first contribution of this paper is such a model that provides a consolidated view on the current research coverage of API Usability. On this baseline, the paper continues by conducting an analysis of relevant security studies, which give insights on usability problems developers had, when using Security APIs. This analysis leads to a proposal of eleven specific usability characteristics relevant for Security APIs. These have to be followed up by usability studies in order to evaluate how Security APIs need to be designed in a usable way and which potential trade-offs have to be balanced.},
	language = {en},
	author = {Gorski, P L and Iacono, L L},
	year = {2016},
	keywords = {to read},
	pages = {14},
	file = {Gorski und Iacono - 2016 - Towards the Usability Evaluation of Security APIs.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Gorski und Iacono - 2016 - Towards the Usability Evaluation of Security APIs.pdf:application/pdf}
}

@inproceedings{sawant_dataset_2015,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '15},
	title = {A {Dataset} for {API} {Usage}},
	isbn = {978-0-7695-5594-2},
	url = {http://dl.acm.org/citation.cfm?id=2820518.2820599},
	abstract = {An Application Programming Interface (API) provides a specific set of functionalities to a developer. The main aim of an API is to encourage the reuse of already existing functionality. There has been some work done into API popularity trends, API evolution and API usage. For all the aforementioned research avenues there has been a need to mine the usage of an API in order to perform any kind of analysis. Each one of the approaches that has been employed in the past involved a certain degree of inaccuracy as there was no type check that takes place. We introduce an approach that takes type information into account while mining API method invocations and annotation usages. This approach accurately makes a connection between a method invocation and the class of the API to which the method belongs to. We try collecting as many usages of an API as possible, this is achieved by targeting projects hosted on GitHub. Additionally, we look at the history of every project to collect the usage of an API from earliest version onwards. By making such a large and rich dataset public, we hope to stimulate some more research in the field of APIs with the aid of accurate API usage samples.},
	urldate = {2018-04-06},
	booktitle = {Proceedings of the 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Sawant, Anand Ashok and Bacchelli, Alberto},
	year = {2015},
	keywords = {to read},
	pages = {506--509},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\S78K44D9\\Sawant und Bacchelli - 2015 - A Dataset for API Usage.pdf:application/pdf}
}

@article{jezek_api_2017,
	title = {{API} {Evolution} and {Compatibility}: {A} {Data} {Corpus} and {Tool} {Evaluation}.},
	volume = {16},
	issn = {1660-1769},
	shorttitle = {{API} {Evolution} and {Compatibility}},
	url = {http://www.jot.fm/contents/issue_2017_04/article2.html},
	doi = {10.5381/jot.2017.16.4.a2},
	abstract = {The development of software components with independent release cycles is nowadays widely supported by multiple languages and frameworks. A critical feature of any such platform is to safeguard composition by ensuring backward compatibility of substituted components. In recent years, some tooling has been developed to help developers and DevOps engineers to establish whether components are backward compatible by means of static analysis. We investigate the state of the art in this space by benchmarking such tools for Java. For this purpose, we have developed a compact benchmark data set of less than 200KB. Using this dataset, we study possible API changes of Java libraries, and whether the tools investigated can detect them. We ﬁnd that only a small number of tools suitable to analyse API evolution exist. Those tools are only infrequently maintained by small communities. All tools investigated have some shortcomings in that they fail to detect certain API incompatibilities.},
	language = {en},
	number = {4},
	urldate = {2018-04-06},
	journal = {The Journal of Object Technology},
	author = {Jezek, Kamil and Dietrich, Jens},
	year = {2017},
	keywords = {to read},
	pages = {2:1},
	file = {Jezek und Dietrich - 2017 - API Evolution and Compatibility A Data Corpus and.pdf:C\:\\Users\\Anna\\Zotero\\storage\\TKFMS8JB\\Jezek und Dietrich - 2017 - API Evolution and Compatibility A Data Corpus and.pdf:application/pdf}
}

@article{bagge_nerding_nodate,
	title = {Nerding for {Newbies} 2014 {A} {Summer} {School} in {Computers} \& {Programming}},
	abstract = {Recruiting students to informatics can be a challenge, particularly when it comes to recruiting female students. The Department of Informatics at the University of Bergen has had severe problems with both recruitment and retention of female students.},
	language = {en},
	author = {Bagge, May-Lill and Buanes, Baste Nesse and Kristo, Alf and Bagge, Anya Helene and Eilertsen, Anna Maria and Ivanova, Soﬁja},
	keywords = {to read},
	pages = {12},
	file = {Bagge et al. - Nerding for Newbies 2014 A Summer School in Comput.pdf:C\:\\Users\\Anna\\Zotero\\storage\\8S485DXW\\Bagge et al. - Nerding for Newbies 2014 A Summer School in Comput.pdf:application/pdf}
}

@misc{cheney_practical_nodate,
	title = {Practical public speaking for {Nerds} {\textbar} {Dave} {Cheney}},
	url = {https://dave.cheney.net/2015/02/17/practical-public-speaking-for-nerds},
	language = {en-US},
	urldate = {2018-04-06},
	author = {Cheney, Dave},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\UPM7R4QT\\practical-public-speaking-for-nerds.html:text/html}
}

@misc{noauthor_how_nodate,
	title = {How to prepare and write a tech conference talk},
	url = {http://wunder.schoenaberselten.com/2016/02/16/how-to-prepare-and-write-a-tech-conference-talk/},
	abstract = {Why I’m writing this post A few weeks ago, @Charlotteis asked on Twitter about resources for preparing / giving conference talks. Their tweet reminded me that I had meant to write down my process for a very long time. So here it is. I’m planning to write two posts about this topic – this first…},
	language = {en-GB},
	urldate = {2018-04-09},
	journal = {very much alive.},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\HDAABG7Q\\how-to-prepare-and-write-a-tech-conference-talk.html:text/html}
}

@article{noauthor_are_2018,
	title = {Are {Code} {Examples} on an {Online} {Q}\&{A} {Forum} {Reliable}?},
	abstract = {Programmers often consult an online Q\&A forum such as Stack Overflow to learn new APIs. This paper presents an empirical study on the prevalence and severity of API misuse on Stack Overflow. To reduce manual assessment effort, we design Maple, an API usage mining approach that extracts patterns from over 380K Java repositories on GitHub and subsequently reports potential API usage violations in Stack Overflow posts. We analyze 217,818 Stack Overflow posts using Maple and find that around 31\% of them have potential API usage violations that may produce the symptoms such as program crashes and resource leaks. Such API misuse is caused by three main reasons—missing control constructs, missing or incorrect order of API calls, and incorrect guard conditions. Even the posts that are accepted as correct answers or upvoted by other programmers are not necessarily more reliable than other posts in terms of API misuse. This study result calls for a new human-inthe-loop approach to augment Stack Overflow code snippets and help the user consider better or alternative API usage.},
	language = {en},
	year = {2018},
	keywords = {to read},
	pages = {11},
	file = {2018 - Are Code Examples on an Online Q&A Forum Reliable.pdf:C\:\\Users\\Anna\\Zotero\\storage\\73HJULKN\\2018 - Are Code Examples on an Online Q&A Forum Reliable.pdf:application/pdf}
}

@misc{noauthor_getting_2017,
	title = {Getting {Started} with {Taskwarrior}},
	url = {https://fedoramagazine.org/getting-started-taskwarrior/},
	abstract = {Taskwarrior is a flexible command-line task management program. In their own words: Taskwarrior manages your TODO list from your command line. It is flexible, fast, efficient, unobtrusive, does its job then gets out of your way. Taskwarrior is highly customizable, but can also be used “right out of the box.” In this article, we’ll show …},
	language = {en-US},
	urldate = {2018-04-10},
	journal = {Fedora Magazine},
	month = feb,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\9FB953IQ\\getting-started-taskwarrior.html:text/html}
}

@misc{author_flipbook_2016,
	title = {Flipbook {Animation} {Tutorial}: {Fun} {With} {Shapes}},
	shorttitle = {Flipbook {Animation} {Tutorial}},
	url = {https://www.sketchbook.com/blog/flipbook-tutorial-fun-with-shapes/},
	abstract = {Learn how to make Flipbook-style animations with our handy downloadable PDF tutorial. Turn simple shapes into animations.},
	language = {en-US},
	urldate = {2018-04-10},
	journal = {Autodesk SketchBook},
	author = {Author, Guest},
	month = jul,
	year = {2016},
	keywords = {to read},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\GLFAFEN5\\flipbook-tutorial-fun-with-shapes.html:text/html}
}

@article{monperrus_detecting_2013,
	title = {Detecting {Missing} {Method} {Calls} {As} {Violations} of the {Majority} {Rule}},
	volume = {22},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/2430536.2430541},
	doi = {10.1145/2430536.2430541},
	abstract = {When using object-oriented frameworks it is easy to overlook certain important method calls that are required at particular places in code. In this article, we provide a comprehensive set of empirical facts on this problem, starting from traces of missing method calls in a bug repository. We propose a new system that searches for missing method calls in software based on the other method calls that are observable. Our key insight is that the voting theory concept of majority rule holds for method calls: a call is likely to be missing if there is a majority of similar pieces of code where this call is present. The evaluation shows that the system predictions go further missing method calls and often reveal different kinds of code smells (e.g., violations of API best practices).},
	number = {1},
	urldate = {2018-04-13},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Monperrus, Martin and Mezini, Mira},
	month = mar,
	year = {2013},
	keywords = {static analysis, data mining, to read, Bugdetection},
	pages = {7:1--7:25},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\UX7YWEFH\\Monperrus und Mezini - 2013 - Detecting Missing Method Calls As Violations of th.pdf:application/pdf}
}

@inproceedings{ramanathan_static_2007,
	address = {New York, NY, USA},
	series = {{PLDI} '07},
	title = {Static {Specification} {Inference} {Using} {Predicate} {Mining}},
	isbn = {978-1-59593-633-2},
	url = {http://doi.acm.org/10.1145/1250734.1250749},
	doi = {10.1145/1250734.1250749},
	abstract = {The reliability and correctness of complex software systems can be significantly enhanced through well-defined specifications that dictate the use of various units of abstraction (e.g., modules, or procedures). Often times, however, specifications are either missing, imprecise, or simply too complex to encode within a signature, necessitating specification inference. The process of inferring specifications from complex software systems forms the focus of this paper. We describe a static inference mechanism for identifying the preconditions that must hold whenever a procedure is called. These preconditions may reflect both data flow properties (e.g., whenever p is called, variable x must be non-null) as well as control-flow properties (e.g., every call to p must bepreceded by a call to q). We derive these preconditions using a ninter-procedural path-sensitive dataflow analysis that gathers predicates at each program point. We apply mining techniques to these predicates to make specification inference robust to errors. This technique also allows us to derive higher-level specifications that abstract structural similarities among predicates (e.g., procedure p is called immediately after a conditional test that checks whether some variable v is non-null.) We describe an implementation of these techniques, and validate the effectiveness of the approach on a number of large open-source benchmarks. Experimental results confirm that our mining algorithms are efficient, and that the specifications derived are both precise and useful-the implementation discovers several critical, yet previously, undocumented preconditions for well-tested libraries.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 28th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Ramanathan, Murali Krishna and Grama, Ananth and Jagannathan, Suresh},
	year = {2007},
	keywords = {program analysis, to read, preconditions, predicate mining, specification inference},
	pages = {123--134},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\IN4HPB29\\Ramanathan et al. - 2007 - Static Specification Inference Using Predicate Min.pdf:application/pdf}
}

@inproceedings{nguyen_graph-based_2009,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} '09},
	title = {Graph-based {Mining} of {Multiple} {Object} {Usage} {Patterns}},
	isbn = {978-1-60558-001-2},
	url = {http://doi.acm.org/10.1145/1595696.1595767},
	doi = {10.1145/1595696.1595767},
	abstract = {The interplay of multiple objects in object-oriented programming often follows specific protocols, for example certain orders of method calls and/or control structure constraints among them that are parts of the intended object usages. Unfortunately, the information is not always documented. That creates long learning curve, and importantly, leads to subtle problems due to the misuse of objects. In this paper, we propose GrouMiner, a novel graph-based approach for mining the usage patterns of one or multiple objects. GrouMiner approach includes a graph-based representation for multiple object usages, a pattern mining algorithm, and an anomaly detection technique that are efficient, accurate, and resilient to software changes. Our experiments on several real-world programs show that our prototype is able to find useful usage patterns with multiple objects and control structures, and to translate them into user-friendly code skeletons to assist developers in programming. It could also detect the usage anomalies that caused yet undiscovered defects and code smells in those programs.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the the 7th {Joint} {Meeting} of the {European} {Software} {Engineering} {Conference} and the {ACM} {SIGSOFT} {Symposium} on {The} {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Nguyen, Tung Thanh and Nguyen, Hoan Anh and Pham, Nam H. and Al-Kofahi, Jafar M. and Nguyen, Tien N.},
	year = {2009},
	keywords = {to read, graph mining, anomaly, api usage, clone, groum, object usage, pattern},
	pages = {383--392},
	file = {Nguyen et al. - 2009 - Graph-based Mining of Multiple Object Usage Patter.pdf:C\:\\Users\\Anna\\Zotero\\storage\\K2R7JZ4J\\Nguyen et al. - 2009 - Graph-based Mining of Multiple Object Usage Patter.pdf:application/pdf}
}

@inproceedings{acharya_mining_2009,
	address = {Berlin, Heidelberg},
	series = {{FASE} '09},
	title = {Mining {API} {Error}-{Handling} {Specifications} from {Source} {Code}},
	isbn = {978-3-642-00592-3},
	url = {http://dx.doi.org/10.1007/978-3-642-00593-0_25},
	doi = {10.1007/978-3-642-00593-0_25},
	abstract = {API error-handling specifications are often not documented, necessitating automated specification mining. Automated mining of error-handling specifications is challenging for procedural languages such as C, which lack explicit exception-handling mechanisms. Due to the lack of explicit exception handling, error-handling code is often scattered across different procedures and files making it difficult to mine error-handling specifications through manual inspection of source code. In this paper, we present a novel framework for mining API error-handling specifications automatically from API client code, without any user input. In our framework, we adapt a trace generation technique to distinguish and generate static traces representing different API run-time behaviors. We apply data mining techniques on the static traces to mine specifications that define correct handling of API errors. We then use the mined specifications to detect API error-handling violations. Our framework mines 62 error-handling specifications and detects 264 real error-handling defects from the analyzed open source packages.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}: {Held} {As} {Part} of the {Joint} {European} {Conferences} on {Theory} and {Practice} of {Software}, {ETAPS} 2009},
	publisher = {Springer-Verlag},
	author = {Acharya, Mithun and Xie, Tao},
	year = {2009},
	keywords = {to read},
	pages = {370--384}
}

@misc{noauthor_mining_nodate,
	title = {Mining exception-handling rules as sequence association rules},
	url = {https://dl.acm.org/citation.cfm?id=1555063},
	urldate = {2018-04-13},
	keywords = {to read},
	file = {Mining exception-handling rules as sequence association rules:C\:\\Users\\Anna\\Zotero\\storage\\AIQNF5R9\\citation.html:text/html}
}

@article{wasylkowski_mining_2011,
	title = {Mining {Temporal} {Specifications} from {Object} {Usage}},
	volume = {18},
	issn = {0928-8910},
	url = {http://dx.doi.org/10.1007/s10515-011-0084-1},
	doi = {10.1007/s10515-011-0084-1},
	abstract = {A caller must satisfy the callee's precondition--that is, reach a state in which the callee may be called. Preconditions describe the state that needs to be reached, but not how to reach it. We combine static analysis with model checking to mine Fair Computation Tree Logic (CTL

F

) formulas that describe the operations a parameter goes through: "In parseProperties(String xml), the parameter xml normally stems from getProperties()." Such operational preconditions can be learned from program code, and the code can be checked for their violations. Applied to AspectJ, our Tikanga prototype found 169 violations of operational preconditions, uncovering 7 unique defects and 27 unique code smells--with 52\% true positives in the 25\% top-ranked violations.},
	number = {3-4},
	urldate = {2018-04-13},
	journal = {Automated Software Engg.},
	author = {Wasylkowski, Andrzej and Zeller, Andreas},
	month = dec,
	year = {2011},
	keywords = {to read, Program analysis, Automatic defect detection, Computation Tree Logic, Mining specifications, Temporal logic},
	pages = {263--292}
}

@incollection{luo_rv-monitor:_2014,
	address = {Cham},
	title = {{RV}-{Monitor}: {Efficient} {Parametric} {Runtime} {Verification} with {Simultaneous} {Properties}},
	isbn = {978-3-319-11164-3},
	abstract = {Runtime verification can effectively increase the reliability of software systems. In recent years, parametric runtime verification has gained a lot of traction, with several systems proposed. However, lack of real specifications and prohibitive runtime overhead when checking numerous properties simultaneously prevent developers or users from using runtime verification. This paper reports on more than 150 formal specifications manually derived from the Java API documentation of commonly used packages, as well as a series of novel techniques which resulted in a new runtime verification system, RV-Monitor. Experiments show that these specifications are useful for finding bugs and bad software practice, and RV-Monitor is capable of monitoring all our specifications simultaneously, and runs substantially faster than other state-of-the-art runtime verification systems.},
	booktitle = {Runtime {Verification}},
	publisher = {Springer International Publishing},
	author = {Luo, Qingzhou and Zhang, Yi and Lee, Choonghwan and Jin, Dongyun and Meredith, Patrick O'Neil and ŞerbănuŢă, Traian Florin and Roşu, Grigore},
	editor = {Bonakdarpour, Borzoo and Smolka, Scott A.},
	year = {2014},
	keywords = {to read},
	pages = {285--300}
}

@inproceedings{pradel_statically_2012,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '12},
	title = {Statically {Checking} {API} {Protocol} {Conformance} with {Mined} {Multi}-object {Specifications}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337332},
	abstract = {Programmers using an API often must follow protocols that specify when it is legal to call particular methods. Several techniques have been proposed to find violations of such protocols based on mined specifications. However, existing techniques either focus on single-object protocols or on particular kinds of bugs, such as missing method calls. There is no practical technique to find multi-object protocol bugs without a priori known specifications. In this paper, we combine a dynamic analysis that infers multi-object protocols and a static checker of API usage constraints into a fully automatic protocol conformance checker. The combined system statically detects illegal uses of an API without human-written specifications. Our approach finds 41 bugs and code smells in mature, real-world Java programs with a true positive rate of 51\%. Furthermore, we show that the analysis reveals bugs not found by state of the art approaches.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Pradel, Michael and Jaspan, Ciera and Aldrich, Jonathan and Gross, Thomas R.},
	year = {2012},
	keywords = {static analysis, dynamic analysis, specification mining, -typestate},
	pages = {925--935},
	file = {Pradel et al. - 2012 - Statically Checking API Protocol Conformance with .pdf:C\:\\Users\\Anna\\Zotero\\storage\\LECNYNB9\\Pradel et al. - 2012 - Statically Checking API Protocol Conformance with .pdf:application/pdf}
}

@misc{noauthor_bugs_nodate,
	title = {Bugs as deviant behavior},
	url = {https://dl.acm.org/citation.cfm?id=502041},
	urldate = {2018-04-13},
	keywords = {to read},
	file = {Bugs as deviant behavior:C\:\\Users\\Anna\\Zotero\\storage\\L9APTLYS\\citation.html:text/html}
}

@inproceedings{ramanathan_path-sensitive_2007,
	address = {Washington, DC, USA},
	series = {{ICSE} '07},
	title = {Path-{Sensitive} {Inference} of {Function} {Precedence} {Protocols}},
	isbn = {978-0-7695-2828-1},
	url = {http://dx.doi.org/10.1109/ICSE.2007.63},
	doi = {10.1109/ICSE.2007.63},
	abstract = {Function precedence protocols define ordering relations among function calls in a program. In some instances, precedence protocols are well-understood (e.g., a call to pthread mutex init must always be present on all program paths before a call to pthread mutex lock ). Oftentimes, however, these protocols are neither well-documented, nor easily derived. As a result, protocol violations can lead to subtle errors that are difficult to identify and correct. In this paper, we present CHRONICLER, a tool that applies scalable inter-procedural path-sensitive static analysis to automatically infer accurate function precedence protocols. CHRONICLER computes precedence relations based on a program's control-flow structure, integrates these relations into a repository, and analyzes them using sequence mining techniques to generate a collection of feasible precedence protocols. Deviations from these protocols found in the program are tagged as violations, and represent potential sources of bugs. We demonstrate CHRONICLER's effectiveness by deriving protocols for a collection of benchmarks ranging in size from 66K to 2M lines of code. Our results not only confirm the existence of bugs in these programs due to precedence protocol violations, but also highlight the importance of path sensitivity on accuracy and scalability.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 29th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Ramanathan, Murali Krishna and Grama, Ananth and Jagannathan, Suresh},
	year = {2007},
	pages = {240--250},
	file = {Ramanathan et al. - 2007 - Path-Sensitive Inference of Function Precedence Pr.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IVF7NRWI\\Ramanathan et al. - 2007 - Path-Sensitive Inference of Function Precedence Pr.pdf:application/pdf}
}

@inproceedings{gruska_learning_2010,
	address = {New York, NY, USA},
	series = {{ISSTA} '10},
	title = {Learning from 6,000 {Projects}: {Lightweight} {Cross}-project {Anomaly} {Detection}},
	isbn = {978-1-60558-823-0},
	shorttitle = {Learning from 6,000 {Projects}},
	url = {http://doi.acm.org/10.1145/1831708.1831723},
	doi = {10.1145/1831708.1831723},
	abstract = {Real production code contains lots of knowledge - on the domain, on the architecture, and on the environment. How can we leverage this knowledge in new projects? Using a novel lightweight source code parser, we have mined more than 6,000 open source Linux projects (totaling 200,000,000 lines of code) to obtain 16,000,000 temporal properties reflecting normal interface usage. New projects can be checked against these rules to detect anomalies - that is, code that deviates from the wisdom of the crowds. In a sample of 20 projects, {\textasciitilde}25\% of the top-ranked anomalies uncovered actual code smells or defects.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 19th {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Gruska, Natalie and Wasylkowski, Andrzej and Zeller, Andreas},
	year = {2010},
	keywords = {to read, formal concept analysis, language independent parsing, lightweight parsing, mining specifications, temporal properties},
	pages = {119--130},
	file = {Gruska et al. - 2010 - Learning from 6,000 Projects Lightweight Cross-pr.pdf:C\:\\Users\\Anna\\Zotero\\storage\\FAPUJ6MR\\Gruska et al. - 2010 - Learning from 6,000 Projects Lightweight Cross-pr.pdf:application/pdf}
}

@misc{noauthor_mining_nodate-1,
	title = {Mining {StackOverflow} to turn the {IDE} into a self-confident programming prompter},
	url = {https://dl.acm.org/citation.cfm?id=2597077},
	urldate = {2018-04-13},
	keywords = {to read, incomplete},
	file = {Mining StackOverflow to turn the IDE into a self-confident programming prompter:C\:\\Users\\Anna\\Zotero\\storage\\BD7AR9EH\\citation.html:text/html}
}

@book{glaser_discovery_1967,
	title = {The {Discovery} of {Grounded} {Theory}: {Strategies} for {Qualitative} {Research}},
	volume = {46},
	publisher = {Aldine de Gruyter},
	author = {Glaser, Barney G. and Strauss, Anselm L.},
	year = {1967},
	doi = {10.2307/2575405},
	keywords = {to read, grounded\_theory, fse18 sven}
}

@article{landis_measurement_1977,
	title = {The {Measurement} of {Observer} {Agreement} for {Categorical} {Data}},
	volume = {33},
	issn = {0006341X, 15410420},
	url = {http://www.jstor.org/stable/2529310},
	doi = {10.2307/2529310},
	abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
	number = {1},
	journal = {Biometrics},
	author = {Landis, J. Richard and Koch, Gary G.},
	year = {1977},
	keywords = {to read, fse18 sven},
	pages = {159--174}
}

@book{fleiss_statistical_1981,
	title = {Statistical {Methods} for {Rates} and {Proportions}. {Second} {Edition}},
	publisher = {Wiley, John and Sons, Incorporated, New York, N.Y.},
	author = {Fleiss, J L},
	year = {1981},
	keywords = {to read, fse18 sven}
}

@article{rabiner_introduction_1986,
	title = {An {Introduction} to {Hidden} {Markov} {Models}},
	volume = {3},
	doi = {10.1109/massp.1986.1165342},
	number = {1},
	journal = {IEEE ASSp Magazine},
	author = {Rabiner, L. R. and Juang, B. H.},
	year = {1986},
	keywords = {to read, fse18 sven},
	pages = {4--16}
}

@article{liskov_keynote_1987,
	title = {Keynote {Address} - {Data} {Abstraction} and {Hierarchy}},
	volume = {23},
	doi = {10.1145/62138.62141},
	number = {5},
	journal = {Addendum to the Proceedings on Object-oriented Programming Systems, Languages and Applications (Addendum) - OOPSLA '87},
	author = {Liskov, Barbara},
	year = {1987},
	keywords = {to read, fse18 sven},
	pages = {17--34}
}

@article{chillarege_orthogonal_1992,
	title = {Orthogonal {Defect} {Classification}-{A} {Concept} for {In}-{Process} {Measurements}},
	volume = {18},
	issn = {0098-5589},
	url = {http://dx.doi.org/10.1109/32.177364},
	doi = {10.1109/32.177364},
	number = {11},
	journal = {IEEE Transactions on Software Engineering},
	author = {Chillarege, Ram and Bhandari, Inderpal S. and Chaar, Jarir K. and Halliday, Michael J. and Moebus, Diane S. and Ray, Bonnie K. and Wong, Man-Yuen},
	year = {1992},
	keywords = {inspection, to read, software development, software quality, software reliability, testing, cause-effect relationships, completeness, defect trigger distribution, feedback, in-process measurements, measurement and analysis methods, necessary and sufficient conditions, orthogonal defect classification, semantic information, verification processes, fse18 sven},
	pages = {943--956}
}

@inproceedings{brin_dynamic_1997,
	address = {Tucson, Arizona, USA},
	series = {{SIGMOD} '97},
	title = {Dynamic {Itemset} {Counting} and {Implication} {Rules} for {Market} {Basket} {Data}},
	isbn = {0-89791-911-4},
	url = {http://doi.acm.org/10.1145/253260.253325},
	doi = {10.1145/253260.253325},
	booktitle = {Proceedings of the {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM Press},
	author = {Brin, Sergey and Motwani, Rajeev and Ullman, Jeffrey D. and Tsur, Shalom},
	year = {1997},
	keywords = {to read, fse18 sven},
	pages = {255--264}
}

@book{ganter_formal_1997,
	edition = {1{\textbackslash}textsuperscriptst},
	title = {Formal {Concept} {Analysis}: {Mathematical} {Foundations}},
	isbn = {3-540-62771-5},
	url = {http://www.springer.com/de/book/9783540627715},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Ganter, Bernhard and Wille, Rudolf},
	year = {1997},
	keywords = {to read, fse18 sven}
}

@inproceedings{emam_repeatability_1998,
	title = {The {Repeatability} of {Code} {Defect} {Classifications}},
	doi = {10.1109/issre.1998.730897},
	booktitle = {Proceedings 9{\textbackslash}textsuperscriptth {International} {Symposium} on {Software} {Reliability} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Emam, K. El and Wieczorek, I.},
	year = {1998},
	keywords = {Inspection, Software engineering, Information analysis, to read, software quality, Data mining, classification scheme, code defect classifications, code inspections, commonly used defect classification scheme, Data analysis, defect data, defect defection activities, development project, Investments, Kappa statistic, Meeting planning, Orthogonal Defect Classification work, Personal Software Process, process improvement, Process planning, product quality evaluation, project management, repeatability, Sensitivity analysis, software fault tolerance, software performance evaluation, software projects, Software testing, statistical analysis, fse18 sven},
	pages = {322--333}
}

@article{boehm_managing_1999,
	title = {Managing {Software} {Productivity} and {Reuse}},
	volume = {32},
	doi = {10.1109/2.789755},
	number = {9},
	journal = {Computer},
	author = {Boehm, B},
	year = {1999},
	keywords = {to read, fse18 sven},
	pages = {111--113}
}

@inproceedings{engler_bugs_2001,
	address = {Banff, Alberta, Canada},
	series = {{SOSP} '01},
	title = {Bugs as {Deviant} {Behavior}: {A} {General} {Approach} to {Inferring} {Errors} in {Systems} {Code}},
	isbn = {1-58113-389-8},
	url = {http://doi.acm.org/10.1145/502034.502041},
	doi = {10.1145/502034.502041},
	booktitle = {Proceedings of the 18{\textbackslash}textsuperscriptth {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM Press},
	author = {Engler, Dawson and Chen, David Yu and Hallem, Seth and Chou, Andy and Chelf, Benjamin},
	year = {2001},
	keywords = {to read, fse18 sven},
	pages = {57--72}
}

@article{flanagan_extended_2002,
	title = {Extended {Static} {Checking} for {Java}},
	volume = {37},
	doi = {10.1145/543552.512558},
	number = {5},
	journal = {ACM SIGPLAN Notices},
	author = {Flanagan, Cormac and Leino, K Rustan M and Lillibridge, Mark and Nelson, Greg and Saxe, James B and Stata, Raymie and Lillibridge, Mark and Nelson, Greg and Saxe, James B and Stata, Raymie},
	year = {2002},
	keywords = {to read, fse18 sven},
	pages = {234--245}
}

@article{van_de_vanter_documentary_2002,
	title = {The {Documentary} {Structure} of {Source} {Code}},
	volume = {44},
	issn = {09505849},
	doi = {10.1016/S0950-5849(02)00103-9},
	number = {13},
	journal = {Information and Software Technology},
	author = {Van De Vanter, Michael L.},
	year = {2002},
	keywords = {Programming, to read, Comments, Linguistic structure, Source code, fse18 sven},
	pages = {767--782}
}

@inproceedings{cordy_comprehending_2003,
	series = {{IWPC} '03},
	title = {Comprehending {Reality} - {Practical} {Barriers} to {Industrial} {Adoption} of {Software} {Maintenance} {Automation}},
	isbn = {0-7695-1883-4},
	url = {http://dl.acm.org/citation.cfm?id=851042.857051},
	booktitle = {Proceedings of the 11{\textbackslash}textsuperscriptth {IEEE} {International} {Workshop} on {Program} {Comprehension}},
	publisher = {IEEE Computer Society},
	author = {Cordy, James R.},
	year = {2003},
	keywords = {to read, fse18 sven},
	pages = {196--}
}

@inproceedings{baxter_dms:_2004,
	series = {{ICSE} '04},
	title = {{DMS}®: {Program} {Transformations} for {Practical} {Scalable} {Software} {Evolution}},
	isbn = {0-7695-2163-0},
	url = {http://dl.acm.org/citation.cfm?id=998675.999466},
	doi = {10.1109/icse.2004.1317484},
	booktitle = {Proceedings of the 26{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Baxter, Ira D. and Pidgeon, Christopher and Mehlich, Michael},
	year = {2004},
	keywords = {to read, fse18 sven},
	pages = {625--634}
}

@article{hovemeyer_finding_2004,
	title = {Finding {Bugs} is {Easy}},
	volume = {39},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/1052883.1052895},
	doi = {10.1145/1052883.1052895},
	number = {12},
	journal = {ACM SIGPLAN Notices},
	author = {Hovemeyer, David and Pugh, William},
	year = {2004},
	keywords = {to read, fse18 sven},
	pages = {92--106}
}

@incollection{abadi_password-based_2005,
	title = {Password-based {Encryption} {Analyzed}},
	isbn = {978-3-540-31691-6},
	url = {https://doi.org/10.1007/11523468_54},
	booktitle = {Automata, {Languages} and {Programming}: 32{\textbackslash}textsuperscriptnd {International} {Colloquium}, {ICALP} 2005, {Lisbon}, {Portugal}, {July} 11-15, 2005. {Proceedings}},
	publisher = {Springer-Verlag GmbH},
	author = {Abadi, Martín and Warinschi, Bogdan},
	editor = {Caires, Luís and Italiano, Giuseppe F. and Monteiro, Luís and Palamidessi, Catuscia and Yung, Moti},
	year = {2005},
	doi = {10.1007/11523468_54},
	keywords = {to read, fse18 sven},
	pages = {664--676}
}

@article{do_supporting_2005,
	title = {Supporting {Controlled} {Experimentation} with {Testing} {Techniques}: {An} {Infrastructure} and its {Potential} {Impact}},
	volume = {10},
	url = {http://dx.doi.org/10.1007/s10664-005-3861-2},
	doi = {10.1007/s10664-005-3861-2},
	number = {4},
	journal = {Empirical Software Engineering},
	author = {Do, Hyunsook and Elbaum, Sebastian and Rothermel, Gregg},
	year = {2005},
	keywords = {to read, fse18 sven},
	pages = {405--435}
}

@inproceedings{holmes_using_2005,
	title = {Using {Structural} {Context} to {Recommend} {Source} {Code} {Examples}},
	doi = {10.1109/icse.2005.1553554},
	booktitle = {Proceedings of the 27{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Holmes, R. and Murphy, G. C.},
	year = {2005},
	keywords = {software tools, Protocols, to read, object-oriented programming, Permission, Application software, Computer science, Database languages, development environment framework, example repository, Programming environments, Programming profession, Software tools, source code example recommendation, structural context, Utility programs, Writing, fse18 sven},
	pages = {117--125}
}

@inproceedings{holmes_strathcona_2005,
	address = {Lisbon, Portugal},
	series = {{ESEC}/{FSE} '13},
	title = {Strathcona {Example} {Recommendation} {Tool}},
	isbn = {1-59593-014-0},
	url = {http://doi.acm.org/10.1145/1081706.1081744},
	doi = {10.1145/1081706.1081744},
	booktitle = {Proceedings of the 10{\textbackslash}textsuperscriptth {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 13{\textbackslash}textsuperscriptth {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Holmes, Reid and Walker, Robert J. and Murphy, Gail C.},
	year = {2005},
	keywords = {to read, examples, recommender, software structure, fse18 sven},
	pages = {237--240}
}

@inproceedings{li_pr-miner:_2005-1,
	series = {{ESEC}/{FSE} '13},
	title = {{PR}-{Miner}: {Automatically} {Extracting} {Implicit} {Programming} {Rules} and {Detecting} {Violations} in {Large} {Software} {Code}},
	url = {http://doi.acm.org/10.1145/1081706.1081755},
	doi = {10.1145/1095430.1081755},
	booktitle = {Proceedings of the 10{\textbackslash}textsuperscriptth {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 13{\textbackslash}textsuperscriptth {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Li, Zhenmin and Zhou, Yuanyuan},
	year = {2005},
	keywords = {to read, fse18 sven},
	pages = {306--315}
}

@inproceedings{spacco_software_2005,
	series = {{MSR} '05},
	title = {Software {Repository} {Mining} with {Marmoset}: {An} {Automated} {Programming} {Project} {Snapshot} and {Testing} {System}},
	url = {https://dl.acm.org/citation.cfm?id=1083149},
	doi = {10.1145/1083142.1083149},
	booktitle = {Proceedings of the {International} {Workshop} on {Mining} {Software} {Repositories}},
	publisher = {ACM Press},
	author = {Spacco, Jaime and Strecker, Jaymie and Hovemeyer, David and Pugh, William},
	year = {2005},
	keywords = {to read, fse18 sven}
}

@article{blackburn_dacapo_2006,
	title = {The {DaCapo} {Benchmarks}: {Java} {Benchmarking} {Development} and {Analysis}},
	volume = {41},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/1167515.1167488},
	doi = {10.1145/1167515.1167488},
	number = {10},
	journal = {ACM SIGPLAN Notices},
	author = {Blackburn, Stephen M. and Garner, Robin and Hoffmann, Chris and Khang, Asjad M. and McKinley, Kathryn S. and Bentzur, Rotem and Diwan, Amer and Feinberg, Daniel and Frampton, Daniel and Guyer, Samuel Z. and Hirzel, Martin and Hosking, Antony and Jump, Maria and Lee, Han and Moss, J. Eliot B. and Phansalkar, Aashish and Stefanović, Darko and VanDrunen, Thomas and von Dincklage, Daniel and Wiedermann, Ben},
	year = {2006},
	keywords = {Java, to read, benchmark, DaCapo, methodology, SPEC, fse18 sven},
	pages = {169--190}
}

@incollection{hinton_prism:_2006,
	title = {{PRISM}: {A} {Tool} for {Automatic} {Verification} of {Probabilistic} {Systems}},
	isbn = {978-3-540-33057-8},
	url = {https://doi.org/10.1007/11691372_29},
	booktitle = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}: 12{\textbackslash}textsuperscriptth {International} {Conference}, {TACAS} 2006, {Held} as {Part} of the {Joint} {European} {Conferences} on {Theory} and {Practice} of {Software}, {ETAPS} 2006, {Vienna}, {Austria}, {March} 25 - {April} 2, 2006. {Proceedings}},
	publisher = {Springer-Verlag GmbH},
	author = {Hinton, Andrew and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
	editor = {Hermanns, Holger and Palsberg, Jens},
	year = {2006},
	doi = {10.1007/11691372_29},
	keywords = {to read, fse18 sven},
	pages = {441--444}
}

@inproceedings{dallmeier_extraction_2007,
	series = {{ASE} '07},
	title = {Extraction of {Bug} {Localization} {Benchmarks} from {History}},
	doi = {10.1145/1321631.1321702},
	booktitle = {Proceedings of the 22{\textbackslash}textsuperscriptnd {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Dallmeier, Valentin and Zimmermann, Thomas},
	year = {2007},
	keywords = {to read, fse18 sven, benchmarking, defect localization},
	pages = {433--436},
	file = {Dallmeier und Zimmermann - 2007 - Extraction of Bug Localization Benchmarks from His.pdf:C\:\\Users\\Anna\\Zotero\\storage\\6XRDJM5F\\Dallmeier und Zimmermann - 2007 - Extraction of Bug Localization Benchmarks from His.pdf:application/pdf}
}

@techreport{lindig_mining_2007,
	title = {Mining {Patterns} and {Violations} using {Concept} {Analysis}},
	institution = {Universität des Saarlandes, Saarbrücken, Germany},
	author = {Lindig, Christian},
	year = {2007},
	keywords = {to read, fse18 sven}
}

@inproceedings{pacheco_feedback-directed_2007,
	series = {{ICSE} '07},
	title = {Feedback-directed {Random} {Test} {Generation}},
	isbn = {0-7695-2828-7},
	url = {http://dx.doi.org/10.1109/ICSE.2007.37},
	doi = {10.1109/icse.2007.37},
	booktitle = {Proceedings of the 29{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Pacheco, Carlos and Lahiri, Shuvendu K. and Ernst, Michael D. and Ball, Thomas},
	year = {2007},
	keywords = {to read, fse18 sven},
	pages = {75--84}
}

@article{waddington_high-fidelity_2007,
	title = {High-fidelity {C}/{C}++ code transformation},
	volume = {68},
	issn = {01676423},
	doi = {10.1016/j.scico.2006.04.010},
	number = {2},
	journal = {Science of Computer Programming},
	author = {Waddington, Daniel and Yao, Bin},
	year = {2007},
	keywords = {to read, High-fidelity, Preprocessing, Source transformation, fse18 sven},
	pages = {64--78}
}

@inproceedings{buse_automatic_2008,
	series = {{ISSTA}'08},
	title = {Automatic {Documentation} {Inference} for {Exceptions}},
	doi = {10.1145/1390630.1390664},
	booktitle = {Proceedings of the {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM Press},
	author = {Buse, Raymond P L and Weimer, Westley R},
	year = {2008},
	keywords = {to read, fse18 sven}
}

@article{csallner_dsd-crasher:_2008,
	title = {{DSD}-{Crasher}: {A} hybrid analysis tool for bug finding},
	volume = {17},
	doi = {10.1145/1348250.1348254},
	number = {2},
	journal = {ACM Transactions on Software Engineering and Methodology},
	author = {Csallner, Christoph and Smaragdakis, Yannis and Xie, Tao},
	year = {2008},
	keywords = {to read, fse18 sven},
	pages = {8--37}
}

@article{fink_effective_2008,
	title = {Effective {Typestate} {Verification} in the {Presence} of {Aliasing}},
	volume = {17},
	doi = {10.1145/1348250.1348255},
	number = {2},
	journal = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
	author = {Fink, Stephen J and Yahav, Eran and Dor, Nurit and Ramalingam, G and Geay, Emmanuel},
	year = {2008},
	keywords = {to read, fse18 sven},
	pages = {9--34}
}

@article{lo_mining_2008,
	title = {Mining {Temporal} {Rules} for {Software} {Maintenance}},
	volume = {20},
	doi = {10.1002/smr.375},
	number = {4},
	journal = {Journal of Software Maintenance and Evolution: Research and Practice},
	author = {Lo, David and Khoo, Siau-Cheng and Liu, Chao},
	year = {2008},
	keywords = {to read, fse18 sven},
	pages = {227--247}
}

@inproceedings{cifuentes_begbunch:_2009,
	series = {{DEFECTS} '09},
	title = {{BegBunch}: {Benchmarking} for {C} {Bug} {Detection} {Tools}},
	url = {http://doi.acm.org/10.1145/1555860.1555866},
	doi = {10.1145/1555860.1555866},
	booktitle = {Proceedings of the {International} {Workshop} on {Defects} in {Large} {Software} {Systems}},
	publisher = {ACM Press},
	author = {Cifuentes, Cristina and Hoermann, Christian and Keynes, Nathan and Li, Lian and Long, Simon and Mealy, Erica and Mounteney, Michael and Scholz, Bernhard},
	year = {2009},
	keywords = {to read, fse18 sven},
	pages = {16--20}
}

@inproceedings{dekel_improving_2009,
	series = {{ICSE} '09},
	title = {Improving {API} {Documentation} {Usability} with {Knowledge} {Pushing}},
	isbn = {978-1-4244-3452-7},
	doi = {10.1109/ICSE.2009.5070532},
	booktitle = {Proceedings of the 31{\textbackslash}textsuperscriptst {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Dekel, Uri and Herbsleb, James D.},
	year = {2009},
	keywords = {to read, fse18 sven},
	pages = {320--330}
}

@incollection{jaspan_checking_2009,
	title = {Checking {Framework} {Interactions} with {Relationships}},
	isbn = {978-3-642-03013-0},
	url = {https://doi.org/10.1007/978-3-642-03013-0_3},
	booktitle = {{ECOOP} 2009 – {Object}-{Oriented} {Programming}: 23{\textbackslash}textsuperscriptrd {European} {Conference}, {Genoa}, {Italy}, {July} 6-10, 2009. {Proceedings}},
	publisher = {Springer-Verlag GmbH},
	author = {Jaspan, Ciera and Aldrich, Jonathan},
	editor = {Drossopoulou, Sophia},
	year = {2009},
	doi = {10.1007/978-3-642-03013-0_3},
	keywords = {to read, fse18 sven},
	pages = {27--51}
}

@article{mantyla_what_2009,
	title = {What {Types} of {Defects} {Are} {Really} {Discovered} in {Code} {Reviews}?},
	volume = {35},
	issn = {0098-5589},
	doi = {10.1109/tse.2008.71},
	number = {3},
	journal = {IEEE Transactions on Software Engineering},
	author = {Mäntylä, M. V. and Lassenius, C.},
	year = {2009},
	keywords = {software maintenance, pattern classification, to read, software engineering tools, Code documentation, Code inspections and walkthroughs, Construction QA, defect classification, enhancement, execution-based quality assurance methods, extensibility, maintainability, Maintainability, Measurement applied to SQA and V\&\#x0026, Methods for SQA and V\&\#x0026, restructuring., software evolvability, software functionality, software products, software reviews, Source code organization, V, fse18 sven},
	pages = {430--448}
}

@inproceedings{nguyen_accurate_2009,
	address = {York, UK},
	series = {{FASE} '09},
	title = {Accurate and {Efficient} {Structural} {Characteristic} {Feature} {Extraction} for {Clone} {Detection}},
	isbn = {978-3-642-00592-3},
	url = {http://dx.doi.org/10.1007/978-3-642-00593-0_31},
	doi = {10.1007/978-3-642-00593-0_31},
	booktitle = {Proceedings of the 12{\textbackslash}textsuperscriptth {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}},
	publisher = {Springer-Verlag},
	author = {Nguyen, Hoan Anh and Nguyen, Tung Thanh and Pham, Nam H. and Al-Kofahi, Jafar M. and Nguyen, Tien N.},
	year = {2009},
	keywords = {to read, fse18 sven},
	pages = {440--455}
}

@inproceedings{pradel_automatic_2009,
	series = {{ASE} '09},
	title = {Automatic {Generation} of {Object} {Usage} {Specifications} from {Large} {Method} {Traces}},
	isbn = {978-0-7695-3891-4},
	url = {http://dx.doi.org/10.1109/ASE.2009.60},
	doi = {10.1109/ASE.2009.60},
	booktitle = {Proceedings of the 24{\textbackslash}textsuperscriptth {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Pradel, Michael and Gross, Thomas R.},
	year = {2009},
	keywords = {to read, dynamic analysis, formal specifications, temporal properties, Specification inference, fse18 sven},
	pages = {371--382}
}

@article{robillard_what_2009,
	title = {What {Makes} {APIs} {Hard} to {Learn}? {Answers} from {Developers}},
	volume = {26},
	issn = {0740-7459},
	url = {http://dx.doi.org/10.1109/MS.2009.193},
	doi = {10.1109/ms.2009.193},
	number = {6},
	journal = {IEEE Software},
	author = {Robillard, Martin P.},
	year = {2009},
	keywords = {to read, fse18 sven},
	pages = {27--34}
}

@inproceedings{thummalapenta_mining_2009,
	series = {{ICSE} '09},
	title = {Mining {Exception}-handling {Rules} {As} {Sequence} {Association} {Rules}},
	url = {http://dx.doi.org/10.1109/ICSE.2009.5070548},
	doi = {10.1109/icse.2009.5070548},
	booktitle = {Proceedings of the 31{\textbackslash}textsuperscriptst {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Thummalapenta, Suresh and Xie, Tao},
	year = {2009},
	keywords = {to read, fse18 sven},
	pages = {496--506}
}

@article{bessey_few_2010,
	title = {A {Few} {Billion} {Lines} of {Code} {Later}: {Using} {Static} {Analysis} to {Find} {Bugs} in the {Real} {World}},
	volume = {53},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1646353.1646374},
	doi = {10.1145/1646353.1646374},
	number = {2},
	journal = {Communications of the ACM},
	author = {Bessey, Al and Block, Ken and Chelf, Ben and Chou, Andy and Fulton, Bryan and Hallem, Seth and Henri-Gros, Charles and Kamsky, Asya and McPeak, Scott and Engler, Dawson},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {66--75}
}

@inproceedings{dallmeier_generating_2010,
	address = {Trento, Italy},
	series = {{ISSTA} '10},
	title = {Generating {Test} {Cases} for {Specification} {Mining}},
	isbn = {978-1-60558-823-0},
	url = {http://doi.acm.org/10.1145/1831708.1831719},
	doi = {10.1145/1831708.1831719},
	booktitle = {Proceedings of the 19{\textbackslash}textsuperscriptth {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM Press},
	author = {Dallmeier, Valentin and Knopp, Nikolai and Mallon, Christoph and Hack, Sebastian and Zeller, Andreas},
	year = {2010},
	keywords = {to read, specification mining, typestate analysis, test case generation, fse18 sven},
	pages = {85--96}
}

@inproceedings{doan_lm:_2010,
	series = {{ICSE} '10},
	title = {{LM}: {A} {Miner} for {Scenario}-based {Specifications}},
	volume = {2},
	doi = {10.1145/1810295.1810370},
	booktitle = {Proceedings of the 32{\textbackslash}textsuperscriptnd {ACM}/{IEEE} {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Doan, Tuan-Anh and Lo, David and Maoz, Shahar and Khoo, Siau-Cheng},
	year = {2010},
	keywords = {data mining, Software engineering, Measurement, to read, Feature extraction, Data mining, specification mining, tool, project management, formal specification, live sequence chart, live sequence charts, postprocessing extension, preprocessing extension, project management component, scenario-based specification mining, Semantics, Software algorithms, software management, visual language, visual languages, Visualization, visualization module, wizard-like interface, fse18 sven},
	pages = {319--320}
}

@inproceedings{gabel_online_2010,
	address = {Cape Town, South Africa},
	series = {{ICSE} '10},
	title = {Online {Inference} and {Enforcement} of {Temporal} {Properties}},
	isbn = {978-1-60558-719-6},
	url = {http://doi.acm.org/10.1145/1806799.1806806},
	doi = {10.1145/1806799.1806806},
	booktitle = {Proceedings of the 32{\textbackslash}{textsuperscriptNd} {ACM}/{IEEE} {International} {Conference} on {Software} {Engineering} - {Volume} 1},
	publisher = {ACM Press},
	author = {Gabel, Mark and Su, Zhendong},
	year = {2010},
	keywords = {to read, dynamic analysis, temporal properties, online algorithm, fse18 sven},
	pages = {15--24}
}

@inproceedings{grechanik_search_2010,
	address = {Cape Town, South Africa},
	series = {{ICSE} '10},
	title = {A {Search} {Engine} for {Finding} {Highly} {Relevant} {Applications}},
	isbn = {978-1-60558-719-6},
	url = {http://doi.acm.org/10.1145/1806799.1806868},
	doi = {10.1145/1806799.1806868},
	booktitle = {Proceedings of the 32{\textbackslash}textsuperscriptnd {ACM}/{IEEE} {International} {Conference} on {Software} {Engineering} - {Volume} 1},
	publisher = {ACM Press},
	author = {Grechanik, Mark and Fu, Chen and Xie, Qing and McMillan, Collin and Poshyvanyk, Denys and Cumby, Chad},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {475--484}
}

@inproceedings{monperrus_detecting_2010,
	series = {{ECOOP} '10},
	title = {Detecting {Missing} {Method} {Calls} in {Object}-oriented {Software}},
	doi = {10.1007/978-3-642-14107-2_2},
	booktitle = {Proceedings of the 24{\textbackslash}textsuperscriptth {European} {Conference} on {Object}-oriented {Programming}},
	publisher = {Springer-Verlag GmbH},
	author = {Monperrus, Martin and Bruch, Marcel and Mezini, Mira},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {2--25}
}

@inproceedings{nguyen_graph-based_2010,
	series = {{OOPSLA}'10},
	title = {A {Graph}-based {Approach} to {API} {Usage} {Adaptation}},
	doi = {10.1145/1869459.1869486},
	booktitle = {Proceedings of the {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM Press},
	author = {Nguyen, Hoan Anh and Nguyen, Tung Thanh and Wilson, Jr., Gary and Nguyen, Anh Tuan and Kim, Miryung and Nguyen, Tien N.},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {302--321}
}

@inproceedings{nguyen_recurring_2010,
	address = {Cape Town, South Africa},
	series = {{ICSE} '10},
	title = {Recurring {Bug} {Fixes} in {Object}-oriented {Programs}},
	isbn = {978-1-60558-719-6},
	url = {http://doi.acm.org/10.1145/1806799.1806847},
	doi = {10.1145/1806799.1806847},
	booktitle = {Proceedings of the 32{\textbackslash}textsuperscriptnd {ACM}/{IEEE} {International} {Conference} on {Software} {Engineering} - {Volume} 1},
	publisher = {ACM Press},
	author = {Nguyen, Tung Thanh and Nguyen, Hoan Anh and Pham, Nam H. and Al-Kofahi, Jafar and Nguyen, Tien N.},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {315--324}
}

@inproceedings{pradel_framework_2010,
	series = {{ICSM} '10},
	title = {A {Framework} for the {Evaluation} of {Specification} {Miners} {Based} on {Finite} {State} {Machines}},
	isbn = {978-1-4244-8630-4},
	url = {http://dx.doi.org/10.1109/ICSM.2010.5609576},
	doi = {10.1109/ICSM.2010.5609576},
	booktitle = {Proceedings of the 28{\textbackslash}textsuperscriptth {IEEE} {International} {Conference} on {Software} {Maintenance}},
	publisher = {IEEE Computer Society Press},
	author = {Pradel, Michael and Bichsel, Philipp and Gross, Thomas R.},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {1--10}
}

@article{robillard_recommendation_2010,
	title = {Recommendation {Systems} for {Software} {Engineering}},
	volume = {27},
	doi = {10.1109/ms.2009.161},
	number = {4},
	journal = {IEEE Software},
	author = {Robillard, Martin P and Walker, Robert J and Zimmermann, Thomas},
	year = {2010},
	keywords = {to read, fse18 sven},
	pages = {80--86}
}

@inproceedings{tempero_qualitas_2010,
	series = {{APSEC} '10},
	title = {The {Qualitas} {Corpus}: {A} {Curated} {Collection} of {Java} {Code} for {Empirical} {Studies}},
	isbn = {978-0-7695-4266-9},
	url = {http://dx.doi.org/10.1109/APSEC.2010.46},
	doi = {10.1109/apsec.2010.46},
	booktitle = {Proceedings of the {Asia} {Pacific} {Software} {Engineering} {Conference}},
	publisher = {IEEE Computer Society Press},
	author = {Tempero, Ewan and Anslow, Craig and Dietrich, Jens and Han, Ted and Li, Jing and Lumpe, Markus and Melton, Hayden and Noble, James},
	year = {2010},
	keywords = {to read, curated code corpus, Empirical studies, experimental infrastructure, fse18 sven},
	pages = {336--345}
}

@article{noauthor_ieee_2010,
	title = {{IEEE} {Standard} {Classification} for {Software} {Anomalies}},
	doi = {10.1109/ieeestd.2010.5399061},
	journal = {IEEE Std 1044-2009 (Revision of IEEE Std 1044-1993)},
	year = {2010},
	keywords = {security of data, to read, classification, bug, fault, Software maintenance, anomaly, project management, 1044-2009, Classification, classification data, defect, defect causal analysis, defect detection, error, failure, IEEE standard classification, IEEE standards, problem, software anomalies, software process improvement, fse18 sven},
	pages = {1--23}
}

@incollection{heinemann_top_2011,
	title = {Top {Productivity} through {Software} {Reuse}: 12{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Reuse}, {ICSR} 2011, {Pohang}, {South} {Korea}, {June} 13-17, 2011. {Proceedings}},
	isbn = {978-3-642-21347-2},
	url = {http://dx.doi.org/10.1007/978-3-642-21347-2_16},
	publisher = {Springer-Verlag GmbH},
	author = {Heinemann, Lars and Deissenboeck, Florian and Gleirscher, Mario and Hummel, Benjamin and Irlbeck, Maximilian},
	editor = {Schmid, Klaus},
	year = {2011},
	doi = {10.1007/978-3-642-21347-2_16},
	keywords = {to read, fse18 sven},
	pages = {207--222}
}

@inproceedings{mcmillan_portfolio:_2011,
	address = {Waikiki, Honolulu, HI, USA},
	series = {{ICSE} '11},
	title = {Portfolio: {Finding} {Relevant} {Functions} and {Their} {Usage}},
	isbn = {978-1-4503-0445-0},
	url = {http://doi.acm.org/10.1145/1985793.1985809},
	doi = {10.1145/1985793.1985809},
	booktitle = {Proceedings of the 33{\textbackslash}textsuperscriptrd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM Press},
	author = {McMillan, Collin and Grechanik, Mark and Poshyvanyk, Denys and Xie, Qing and Fu, Chen},
	year = {2011},
	keywords = {to read, code search, function call graph, pagerank, portfolio, ranking, fse18 sven},
	pages = {111--120}
}

@incollection{nguyen_extracting_2011,
	title = {Extracting {Significant} {Specifications} from {Mining} through {Mutation} {Testing}},
	booktitle = {Formal {Methods} and {Software} {Engineering}},
	publisher = {Springer-Verlag GmbH},
	author = {Nguyen, Anh Cuong and Khoo, Siau-Cheng},
	year = {2011},
	doi = {10.1007/978-3-642-24559-6_32},
	keywords = {to read, fse18 sven},
	pages = {472--488}
}

@inproceedings{wu_iterative_2011,
	series = {{ASE} '11},
	title = {Iterative {Mining} of {Resource}-releasing {Specifications}},
	doi = {10.1109/ase.2011.6100058},
	booktitle = {Proceedings of the 26{\textbackslash}textsuperscriptth {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Wu, Qian and Liang, Guangtai and Wang, Qianxiang and Xie, Tao and Mei, Hong},
	year = {2011},
	keywords = {to read, fse18 sven},
	pages = {233--242}
}

@inproceedings{bellare_multi-instance_2012,
	title = {Multi-instance {Security} and {Its} {Application} to {Password}-based {Cryptography}},
	isbn = {978-3-642-32008-8},
	url = {http://dx.doi.org/10.1007/978-3-642-32009-5_19},
	doi = {10.1007/978-3-642-32009-5_19},
	booktitle = {Lecture {Notes} in {Computer} {Science}},
	publisher = {Springer-Verlag GmbH},
	author = {Bellare, Mihir and Ristenpart, Thomas and Tessaro, Stefano},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {312--329}
}

@inproceedings{fahl_why_2012,
	address = {Raleigh, North Carolina, USA},
	series = {{CCS} '12},
	title = {Why {Eve} and {Mallory} {Love} {Android}: {An} {Analysis} of {Android} {SSL} (in){Security}},
	isbn = {978-1-4503-1651-4},
	url = {http://doi.acm.org/10.1145/2382196.2382205},
	doi = {10.1145/2382196.2382205},
	booktitle = {Proceedings of the 19{\textbackslash}textsuperscriptth {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM Press},
	author = {Fahl, Sascha and Harbach, Marian and Muders, Thomas and Baumgärtner, Lars and Freisleben, Bernd and Smith, Matthew},
	year = {2012},
	keywords = {security, android, to read, apps, mitma, ssl, fse18 sven},
	pages = {50--61}
}

@inproceedings{grill_methods_2012,
	address = {Toulouse, France},
	series = {{HCSE} '12},
	title = {Methods {Towards} {API} {Usability}: {A} {Structural} {Analysis} of {Usability} {Problem} {Categories}},
	isbn = {978-3-642-34346-9},
	url = {http://dx.doi.org/10.1007/978-3-642-34347-6_10},
	doi = {10.1007/978-3-642-34347-6_10},
	booktitle = {Proceedings of the 4{\textbackslash}textsuperscriptth {International} {Conference} on {Human}-{Centered} {Software} {Engineering}},
	publisher = {Springer-Verlag GmbH},
	author = {Grill, Thomas and Polacek, Ondrej and Tscheligi, Manfred},
	year = {2012},
	keywords = {to read, API, usability, contextual interaction framework, HCI, fse18 sven},
	pages = {164--180}
}

@inproceedings{jin_javamop:_2012,
	address = {Zurich, Switzerland},
	series = {{ICSE} '12},
	title = {{JavaMOP}: {Efficient} {Parametric} {Runtime} {Monitoring} {Framework}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337436},
	doi = {10.1109/icse.2012.6227231},
	booktitle = {Proceedings of the 34{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Jin, Dongyun and Meredith, Patrick O'Neil and Lee, Choonghwan and Roşu, Grigore},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {1427--1430}
}

@techreport{lee_towards_2012,
	title = {Towards {Categorizing} and {Formalizing} the {JDK} {API}},
	url = {http://hdl.handle.net/2142/30006},
	institution = {University of Illinois at Urbana-Champaign},
	author = {Lee, Choonghwan and Jin, Dongyun and Meredith, Patrick O'Neil and Roşu, Grigore},
	year = {2012},
	keywords = {to read, fse18 sven}
}

@article{monperrus_what_2012,
	title = {What {Should} {Developers} {Be} {Aware} {Of}? {An} {Empirical} {Study} on the {Directives} of {API} {Documentation}},
	volume = {17},
	issn = {1382-3256},
	url = {http://www.springerlink.com/content/lk11x7x4v4h030j3/},
	doi = {10.1007/s10664-011-9186-4},
	number = {6},
	journal = {Empirical Software Engineering},
	author = {Monperrus, Martin and Eichberg, Michael and Tekes, Elif and Mezini, Mira},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {703--737}
}

@inproceedings{nguyen_grapacc:_2012,
	address = {Zurich, Switzerland},
	series = {{ICSE} '12},
	title = {{GraPacc}: {A} {Graph}-based {Pattern}-oriented, {Context}-sensitive {Code} {Completion} {Tool}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337431},
	doi = {10.1109/icse.2012.6227236},
	booktitle = {Proceedings of the 34{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tung Thanh and Nguyen, Tien N.},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {1407--1410}
}

@inproceedings{nguyen_graph-based_2012,
	address = {Zurich, Switzerland},
	series = {{ICSE} '12},
	title = {Graph-based {Pattern}-oriented, {Context}-sensitive {Source} {Code} {Completion}},
	isbn = {978-1-4673-1067-3},
	url = {http://dl.acm.org/citation.cfm?id=2337223.2337232},
	doi = {10.1109/icse.2012.6227205},
	booktitle = {Proceedings of the 34{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Nguyen, Anh Tuan and Nguyen, Tung Thanh and Nguyen, Hoan Anh and Tamrawi, Ahmed and Nguyen, Hung Viet and Al-Kofahi, Jafar and Nguyen, Tien N.},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {69--79}
}

@article{nguyen_clone_2012,
	title = {Clone {Management} for {Evolving} {Software}},
	volume = {38},
	doi = {10.1109/tse.2011.90},
	number = {5},
	journal = {IEEE Transactions on Software Engineering},
	author = {Nguyen, Hoan Anh and Nguyen, Tung Thanh and Pham, Nam H. and Al-Kofahi, Jafar and Nguyen, Tien N.},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {1008--1026}
}

@inproceedings{panichella_mining_2012,
	series = {{ICPC} '12},
	title = {Mining {Source} {Code} {Descriptions} from {Developer} {Communications}},
	doi = {10.1109/icpc.2012.6240510},
	booktitle = {Proceedings of the 20{\textbackslash}textsuperscriptth {IEEE} {International} {Conference} on {Program} {Comprehension}},
	publisher = {IEEE Computer Society Press},
	author = {Panichella, Sebastiano and Aponte, Jairo and Di Penta, Massimiliano and Marcus, Andrian and Canfora, Gerardo},
	year = {2012},
	keywords = {to read, fse18 sven},
	pages = {63--72}
}

@inproceedings{dyer_boa:_2013,
	address = {San Francisco, CA},
	series = {{ICSE} '13},
	title = {Boa: {A} {Language} and {Infrastructure} for {Analyzing} {Ultra}-{Large}-{Scale} {Software} {Repositories}},
	doi = {10.1109/icse.2013.6606588},
	booktitle = {Proceedings of the 35{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Dyer, Robert and Nguyen, Hoan Anh and Rajan, Hridesh and Nguyen, Tien N.},
	year = {2013},
	keywords = {to read, fse18 sven},
	pages = {422--431}
}

@inproceedings{herzig_its_2013,
	series = {{ICSE} '13},
	title = {It's {Not} a {Bug}, {It}'s a {Feature}: {How} {Misclassification} {Impacts} {Bug} {Prediction}},
	url = {http://dl.acm.org/citation.cfm?id=2486788.2486840},
	doi = {10.1109/icse.2013.6606585},
	booktitle = {Proceedings of the 35{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Herzig, Kim and Just, Sascha and Zeller, Andreas},
	year = {2013},
	keywords = {to read, fse18 sven},
	pages = {392--401}
}

@inproceedings{johnson_why_2013,
	series = {{ICSE} '13},
	title = {Why {Don}'t {Software} {Developers} use {Static} {Analysis} {Tools} to {Find} {Bugs}?},
	doi = {10.1109/icse.2013.6606613},
	booktitle = {Proceedings of the 35{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Johnson, Brittany and Song, Yoonki},
	year = {2013},
	keywords = {to read, fse18 sven},
	file = {Johnson et al. - 2013 - Why don't software developers use static analysis .pdf:C\:\\Users\\Anna\\Zotero\\storage\\7A7DRLU5\\Johnson et al. - 2013 - Why don't software developers use static analysis .pdf:application/pdf}
}

@inproceedings{schwittek_study_2013,
	title = {A {Study} on {Third} {Party} {Component} {Reuse} in {Java} {Enterprise} {Open} {Source} {Software}},
	doi = {10.1145/2465449.2465468},
	booktitle = {Proceedings of the 16{\textbackslash}textsuperscriptth {International} {ACM} {SIGSOFT} {Symposium} on {Component}-based {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Schwittek, Widura and Eicker, Stefan},
	year = {2013},
	keywords = {to read, fse18 sven},
	pages = {75--80}
}

@inproceedings{zhong_detecting_2013,
	title = {Detecting {API} {Documentation} {Errors}},
	volume = {48},
	doi = {10.1145/2544173.2509523},
	booktitle = {Proceedings of the {International} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages} \& {Applications}},
	publisher = {ACM Press},
	author = {Zhong, Hao and Su, Zhendong},
	year = {2013},
	keywords = {to read, fse18 sven},
	pages = {803--816}
}

@inproceedings{beller_modern_2014,
	address = {Hyderabad, India},
	series = {{MSR} '14},
	title = {Modern {Code} {Reviews} in {Open}-source {Projects}: {Which} {Problems} {Do} {They} {Fix}?},
	isbn = {978-1-4503-2863-0},
	url = {http://doi.acm.org/10.1145/2597073.2597082},
	doi = {10.1145/2597073.2597082},
	booktitle = {Proceedings of the 11{\textbackslash}textsuperscriptth {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM Press},
	author = {Beller, Moritz and Bacchelli, Alberto and Zaidman, Andy and Juergens, Elmar},
	year = {2014},
	keywords = {to read, Code Review, Defects, Open Source Software, fse18 sven},
	pages = {202--211}
}

@inproceedings{eichberg_software_2014,
	address = {Edinburgh, United Kingdom},
	series = {{SOAP} '14},
	title = {A {Software} {Product} {Line} for {Static} {Analyses}: {The} {OPAL} {Framework}},
	isbn = {978-1-4503-2919-4},
	url = {http://doi.acm.org/10.1145/2614628.2614630},
	doi = {10.1145/2614628.2614630},
	booktitle = {Proceedings of the 3{\textbackslash}textsuperscriptrd {ACM} {SIGPLAN} {International} {Workshop} on the {State} of the {Art} in {Java} {Program} {Analysis}},
	publisher = {ACM Press},
	author = {Eichberg, Michael and Hermann, Ben},
	year = {2014},
	keywords = {static analysis, abstract interpretation, program analysis, to read, design, software product line engineering, fse18 sven},
	pages = {1--6}
}

@inproceedings{just_defects4j:_2014,
	series = {{ISSTA} '14},
	title = {Defects4J: {A} {Database} of {Existing} {Faults} to {Enable} {Controlled} {Testing} {Studies} for {Java} {Programs}},
	url = {http://doi.acm.org/10.1145/2610384.2628055},
	doi = {10.1145/2610384.2628055},
	booktitle = {Proceedings of the {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM Press},
	author = {Just, René and Jalali, Darioush and Ernst, Michael D.},
	year = {2014},
	keywords = {to read, fse18 sven},
	pages = {437--440}
}

@inproceedings{nguyen_statistical_2014,
	address = {Vasteras, Sweden},
	series = {{ASE} '14},
	title = {Statistical {Learning} {Approach} for {Mining} {API} {Usage} {Mappings} for {Code} {Migration}},
	isbn = {978-1-4503-3013-8},
	url = {http://doi.acm.org/10.1145/2642937.2643010},
	doi = {10.1145/2642937.2643010},
	booktitle = {Proceedings of the 29{\textbackslash}textsuperscriptth {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tung Thanh and Nguyen, Tien N.},
	year = {2014},
	keywords = {to read, api mappings, api usages, code migration, statistical learning, fse18 sven},
	pages = {457--468}
}

@inproceedings{ponzanelli_mining_2014,
	address = {Hyderabad, India},
	series = {{MSR} '14},
	title = {Mining {StackOverflow} to {Turn} the {IDE} into a {Self}-confident {Programming} {Prompter}},
	isbn = {978-1-4503-2863-0},
	url = {http://doi.acm.org/10.1145/2597073.2597077},
	doi = {10.1145/2597073.2597077},
	booktitle = {Proceedings of the 11{\textbackslash}textsuperscriptth {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM Press},
	author = {Ponzanelli, Luca and Bavota, Gabriele and Di Penta, Massimiliano and Oliveto, Rocco and Lanza, Michele},
	year = {2014},
	keywords = {to read, Developers Support, Empirical Studies, Recommender Systems, fse18 sven},
	pages = {102--111}
}

@book{robillard_recommendation_2014-1,
	title = {Recommendation {Systems} in {Software} {Engineering}},
	isbn = {3-642-45134-9 978-3-642-45134-8},
	publisher = {Springer-Verlag GmbH},
	editor = {Robillard, Martin P. and Maalej, Walid and Walker, Robert J. and Zimmermann, Thomas},
	year = {2014},
	doi = {10.1007/978-3-642-45135-5},
	keywords = {to read, fse18 sven}
}

@inproceedings{gao_fixing_2015,
	series = {{ASE} '15},
	title = {Fixing {Recurring} {Crash} {Bugs} via {Analyzing} {Q}\&{A} {Sites}},
	doi = {10.1109/ase.2015.81},
	booktitle = {Proceedings of the 30{\textbackslash}textsuperscriptth {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Gao, Qing and Zhang, Hansheng and Wang, Jie and Xiong, Yingfei and Zhang, Lu and Mei, Hong},
	year = {2015},
	keywords = {to read, fse18 sven},
	pages = {307--318}
}

@article{ramraj_frequent_2015,
	title = {Frequent {Subgraph} {Mining} {Algorithms} – {A} {Survey}},
	volume = {47},
	doi = {10.1016/j.procs.2015.03.198},
	journal = {Procedia Computer Science},
	author = {Ramraj, T and Prabhakar, R},
	year = {2015},
	keywords = {to read, fse18 sven},
	pages = {197--204}
}

@inproceedings{sushine_searching_2015,
	address = {Florence, Italy},
	series = {{ICPC} '15},
	title = {Searching the {State} {Space}: {A} {Qualitative} {Study} of {API} {Protocol} {Usability}},
	url = {http://dl.acm.org/citation.cfm?id=2820282.2820295},
	doi = {10.1109/icpc.2015.17},
	booktitle = {Proceedings of the 23{\textbackslash}textsuperscriptrd {IEEE} {International} {Conference} on {Program} {Comprehension}},
	publisher = {IEEE Computer Society Press},
	author = {Sushine, Joshua and Herbsleb, James D. and Aldrich, Jonathan},
	year = {2015},
	keywords = {to read, fse18 sven},
	pages = {82--93}
}

@article{uddin_how_2015,
	title = {How {API} {Documentation} {Fails}},
	volume = {32},
	doi = {10.1109/ms.2014.80},
	number = {4},
	journal = {IEEE Software},
	author = {Uddin, Gias and Robillard, Martin P},
	year = {2015},
	keywords = {to read, fse18 sven},
	pages = {68--75}
}

@inproceedings{zhong_empirical_2015,
	address = {Florence, Italy},
	series = {{ICSE} '15},
	title = {An {Empirical} {Study} on {Real} {Bug} {Fixes}},
	isbn = {978-1-4799-1934-5},
	url = {http://dl.acm.org/citation.cfm?id=2818754.2818864},
	doi = {10.1109/icse.2015.101},
	booktitle = {Proceedings of the 37{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering} - {Volume} 1},
	publisher = {IEEE Computer Society Press},
	author = {Zhong, Hao and Su, Zhendong},
	year = {2015},
	keywords = {to read, fse18 sven},
	pages = {913--923}
}

@mastersthesis{ziegler_analyse_2015,
	title = {Analyse der {Verwendung} von {Kryptographie}-{APIs} in {Java}-basierten {Anwendungen}},
	school = {Universität Bremen},
	author = {Ziegler, Henning},
	year = {2015},
	keywords = {to read, fse18 sven}
}

@inproceedings{beller_analyzing_2016,
	title = {Analyzing the {State} of {Static} {Analysis}: {A} {Large}-{Scale} {Evaluation} in {Open} {Source} {Software}},
	volume = {1},
	doi = {10.1109/SANER.2016.105},
	booktitle = {Proceedings of the 23{\textbackslash}textsuperscriptrd {IEEE} {International} {Conference} on {Software} {Analysis}, {Evolution}, and {Reengineering}},
	publisher = {IEEE Computer Society Press},
	author = {Beller, Moritz and Bholanath, Radjino and McIntosh, Shane and Zaidman, Andy},
	year = {2016},
	keywords = {to read, fse18 sven}
}

@inproceedings{legunsen_how_2016,
	address = {Singapore, Singapore},
	series = {{ASE} '16},
	title = {How {Good} {Are} the {Specs}? {A} {Study} of the {Bug}-finding {Effectiveness} of {Existing} {Java} {API} {Specifications}},
	isbn = {978-1-4503-3845-5},
	url = {http://doi.acm.org/10.1145/2970276.2970356},
	doi = {10.1145/2970276.2970356},
	booktitle = {Proceedings of the 31{\textbackslash}textsuperscriptst {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Legunsen, Owolabi and Hassan, Wajih Ul and Xu, Xinyue and Roşu, Grigore and Marinov, Darko},
	year = {2016},
	keywords = {to read, empirical study, runtime verification, specification quality, fse18 sven},
	pages = {602--613}
}

@inproceedings{nguyen_learning_2016,
	series = {{ICSE} '16},
	title = {Learning {API} {Usages} from {Bytecode} : {A} {Statistical} {Approach}},
	doi = {10.1145/2884781.2884873},
	booktitle = {Proceedings of the 38{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Nguyen, Tam The and Pham, Hung Viet and Vu, Phong Minh and Nguyen, Tung Thanh},
	year = {2016},
	keywords = {to read, fse18 sven}
}

@inproceedings{savor_continuous_2016,
	address = {Austin, Texas},
	series = {{ICSE} '16},
	title = {Continuous {Deployment} at {Facebook} and {OANDA}},
	isbn = {978-1-4503-4205-6},
	url = {http://doi.acm.org/10.1145/2889160.2889223},
	doi = {10.1145/2889160.2889223},
	booktitle = {Proceedings of the 38{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering} {Companion}},
	publisher = {ACM Press},
	author = {Savor, Tony and Douglas, Mitchell and Gentili, Michael and Williams, Laurie and Beck, Kent and Stumm, Michael},
	year = {2016},
	keywords = {to read, fse18 sven},
	pages = {21--30}
}

@inproceedings{soto_deeper_2016,
	title = {A {Deeper} {Look} into {Bug} {Fixes}: {Patterns}, {Replacements}, {Deletions}, and {Additions}},
	isbn = {978-1-4503-4186-8},
	doi = {10.1145/2901739.2903495},
	booktitle = {Proceedings of the 13{\textbackslash}textsuperscriptth {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM Press},
	author = {Soto, Mauricio and Thung, Ferdian and Wong, Chu-pan and Goues, Claire Le and Lo, David},
	year = {2016},
	keywords = {to read, maintainability, automatic error repair, human-like patches, fse18 sven},
	pages = {8--11}
}

@inproceedings{treude_augmenting_2016,
	address = {Austin, Texas},
	series = {{ICSE} '16},
	title = {Augmenting {API} {Documentation} with {Insights} from {Stack} {Overflow}},
	isbn = {978-1-4503-3900-1},
	url = {http://doi.acm.org/10.1145/2884781.2884800},
	doi = {10.1145/2884781.2884800},
	booktitle = {Proceedings of the 38{\textbackslash}textsuperscriptth {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM Press},
	author = {Treude, Christoph and Robillard, Martin P.},
	year = {2016},
	keywords = {stack overflow, to read, API documentation, insight sentences, fse18 sven},
	pages = {392--403}
}

@mastersthesis{weiler_integrating_2016,
	title = {Integrating an {API}-{Misuse} {Detector} into {Eclipse}},
	school = {Technische Universität Darmstadt},
	author = {Weiler, Simon},
	year = {2016},
	keywords = {to read, fse18 sven}
}

@inproceedings{reif_hermes:_2017,
	address = {Barcelona, Spain},
	series = {{SOAP} 2017},
	title = {Hermes: {Assessment} and {Creation} of {Effective} {Test} {Corpora}},
	isbn = {978-1-4503-5072-3},
	url = {http://doi.acm.org/10.1145/3088515.3088523},
	doi = {10.1145/3088515.3088523},
	booktitle = {Proceedings of the 6{\textbackslash}textsuperscriptth {ACM} {SIGPLAN} {International} {Workshop} on {State} {Of} the {Art} in {Program} {Analysis}},
	publisher = {ACM Press},
	author = {Reif, Michael and Eichberg, Michael and Hermann, Ben and Mezini, Mira},
	year = {2017},
	keywords = {Java, Program Analysis, to read, Benchmark Suites, Test Corpora, fse18 sven},
	pages = {43--48}
}

@inproceedings{wang_automatically_2017,
	series = {{SANER} '17},
	title = {Automatically {Generating} {Natural} {Language} {Descriptions} for {Object}-related {Statement} {Sequences}},
	doi = {10.1109/saner.2017.7884622},
	booktitle = {Proceedings of the 24{\textbackslash}textsuperscriptth {IEEE} {International} {Conference} on {Software} {Analysis}, {Evolution} and {Reengineering}},
	publisher = {IEEE Computer Society Press},
	author = {Wang, Xiaoran and Pollock, Lori and Vijay-Shanker, K},
	year = {2017},
	keywords = {to read, fse18 sven},
	pages = {205--216}
}

@inproceedings{zhou_analyzing_2017,
	series = {{ICSE} '17},
	title = {Analyzing {APIs} {Documentation} and {Code} to {Detect} {Directive} {Defects}},
	doi = {10.1109/icse.2017.11},
	booktitle = {Proceedings of the 39{\textbackslash}textsuperscriptth {IEEE}/{ACM} {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society Press},
	author = {Zhou, Yu and Gu, Ruihang and Chen, Taolue and Huang, Zhiqiu and Panichella, Sebastiano and Gall, Harald},
	year = {2017},
	keywords = {to read, fse18 sven},
	pages = {27--37}
}

@inproceedings{amann_mudetect:_2018,
	title = {{MUDetect}: {The} {Next} {Step} in {Static} {API}-{Misuse} {Detection}},
	booktitle = {Under {Review}},
	author = {Amann, Sven and Nadi, Sarah and Nguyen, Hoan A. and Nguyen, Tien N. and Mezini, Mira},
	year = {2018},
	keywords = {fse18 sven}
}

@inproceedings{kruger_crysl:_2018-1,
	series = {{ECOOP}'18},
	title = {{CrySL}: {An} {Extensible} {Approach} to {Validating} the {Correct} {Usage} of {Cryptographic} {APIs}},
	url = {https://arxiv.org/abs/1710.00564},
	booktitle = {Proceedings of the {European} {Conference} on {Object}-{Oriented} {Programming}},
	author = {Krüger, Stefan and Späth, Johannes and Ali, Karim and Bodden, Eric and Mezini, Mira},
	year = {2018},
	keywords = {fse18 sven}
}

@inproceedings{tesfay_privacyguide:_2018,
	address = {New York, NY, USA},
	series = {{IWSPA} '18},
	title = {{PrivacyGuide}: {Towards} an {Implementation} of the {EU} {GDPR} on {Internet} {Privacy} {Policy} {Evaluation}},
	isbn = {978-1-4503-5634-3},
	shorttitle = {{PrivacyGuide}},
	url = {http://doi.acm.org/10.1145/3180445.3180447},
	doi = {10.1145/3180445.3180447},
	abstract = {Nowadays Internet services have dramatically changed the way people interact with each other and many of our daily activities are supported by those services. Statistical indicators show that more than half of the world's population uses the Internet generating about 2.5 quintillion bytes of data on daily basis. While such a huge amount of data is useful in a number of fields, such as in medical and transportation systems, it also poses unprecedented threats for user's privacy. This is aggravated by the excessive data collection and user profiling activities of service providers. Yet, regulation require service providers to inform users about their data collection and processing practices. The de facto way of informing users about these practices is through the use of privacy policies. Unfortunately, privacy policies suffer from bad readability and other complexities which make them unusable for the intended purpose. To address this issue, we introduce PrivacyGuide, a privacy policy summarization tool inspired by the European Union (EU) General Data Protection Regulation (GDPR) and based on machine learning and natural language processing techniques. Our results show that PrivacyGuide is able to classify privacy policy content into eleven privacy aspects with a weighted average accuracy of 74\% and further shed light on the associated risk level with an accuracy of 90\%.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-04-16},
	booktitle = {Proceedings of the {Fourth} {ACM} {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {ACM},
	author = {Tesfay, Welderufael B. and Hofmann, Peter and Nakamura, Toru and Kiyomoto, Shinsaku and Serna, Jetzabel},
	year = {2018},
	keywords = {machine learning, privacy notice, privacy policy, text summarization},
	pages = {15--21},
	file = {Tesfay et al. - 2018 - PrivacyGuide Towards an Implementation of the EU .pdf:C\:\\Users\\Anna\\Zotero\\storage\\JL9U2ZU4\\Tesfay et al. - 2018 - PrivacyGuide Towards an Implementation of the EU .pdf:application/pdf}
}

@article{radicek_monadic_2017,
	title = {Monadic {Refinements} for {Relational} {Cost} {Analysis}},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158124},
	doi = {10.1145/3158124},
	number = {POPL},
	journal = {Proc. ACM Program. Lang.},
	author = {Radiček, Ivan and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Zuleger, Florian},
	month = dec,
	year = {2017},
	keywords = {Cost analysis, higher-order logic, monads, refinement types, relational verification, 20180419GillesBarthe},
	pages = {36:1--36:32},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\CINCKP8R\\Radiček et al. - 2017 - Monadic Refinements for Relational Cost Analysis.pdf:application/pdf;Radiček et al. - 2017 - Monadic Refinements for Relational Cost Analysis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VE2QT48Q\\Radiček et al. - 2017 - Monadic Refinements for Relational Cost Analysis.pdf:application/pdf}
}

@article{barthe_proving_2017,
	title = {Proving {Expected} {Sensitivity} of {Probabilistic} {Programs}},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158145},
	doi = {10.1145/3158145},
	number = {POPL},
	journal = {Proc. ACM Program. Lang.},
	author = {Barthe, Gilles and Espitau, Thomas and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	month = dec,
	year = {2017},
	keywords = {Kantorovich distance, Program sensitivity, relational program logics, 20180419GillesBarthe},
	pages = {57:1--57:29},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2017 - Proving Expected Sensitivity of Probabilistic Prog.pdf:C\:\\Users\\Anna\\Zotero\\storage\\89WSLZUB\\Barthe et al. - 2017 - Proving Expected Sensitivity of Probabilistic Prog.pdf:application/pdf}
}

@inproceedings{almeida_jasmin:_2017,
	address = {New York, NY, USA},
	series = {{CCS} '17},
	title = {Jasmin: {High}-{Assurance} and {High}-{Speed} {Cryptography}},
	isbn = {978-1-4503-4946-8},
	url = {http://doi.acm.org/10.1145/3133956.3134078},
	doi = {10.1145/3133956.3134078},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Almeida, José Bacelar and Barbosa, Manuel and Barthe, Gilles and Blot, Arthur and Grégoire, Benjamin and Laporte, Vincent and Oliveira, Tiago and Pacheco, Hugo and Schmidt, Benedikt and Strub, Pierre-Yves},
	year = {2017},
	keywords = {cryptographic implementations, constant-time security, safety, verified compiler, 20180419GillesBarthe},
	pages = {1807--1823},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Almeida et al. - 2017 - Jasmin High-Assurance and High-Speed Cryptography.pdf:C\:\\Users\\Anna\\Zotero\\storage\\T6HVZZJ3\\Almeida et al. - 2017 - Jasmin High-Assurance and High-Speed Cryptography.pdf:application/pdf}
}

@inproceedings{almeida_fast_2017,
	address = {New York, NY, USA},
	series = {{CCS} '17},
	title = {A {Fast} and {Verified} {Software} {Stack} for {Secure} {Function} {Evaluation}},
	isbn = {978-1-4503-4946-8},
	url = {http://doi.acm.org/10.1145/3133956.3134017},
	doi = {10.1145/3133956.3134017},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Almeida, José Bacelar and Barbosa, Manuel and Barthe, Gilles and Dupressoir, François and Grégoire, Benjamin and Laporte, Vincent and Pereira, Vitor},
	year = {2017},
	keywords = {certified compilation, secure function evaluation, verified implementation, 20180419GillesBarthe},
	pages = {1989--2006},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Almeida et al. - 2017 - A Fast and Verified Software Stack for Secure Func.pdf:C\:\\Users\\Anna\\Zotero\\storage\\A6FZFB2Q\\Almeida et al. - 2017 - A Fast and Verified Software Stack for Secure Func.pdf:application/pdf}
}

@inproceedings{ambrona_attribute-based_2017,
	address = {New York, NY, USA},
	series = {{CCS} '17},
	title = {Attribute-{Based} {Encryption} in the {Generic} {Group} {Model}: {Automated} {Proofs} and {New} {Constructions}},
	isbn = {978-1-4503-4946-8},
	url = {http://doi.acm.org/10.1145/3133956.3134088},
	doi = {10.1145/3133956.3134088},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Ambrona, Miguel and Barthe, Gilles and Gay, Romain and Wee, Hoeteck},
	year = {2017},
	keywords = {attribute-based encryption, automated proofs, generic group model, symbolic security, 20180419GillesBarthe},
	pages = {647--664},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Ambrona et al. - 2017 - Attribute-Based Encryption in the Generic Group Mo.pdf:C\:\\Users\\Anna\\Zotero\\storage\\WYTGQ5JQ\\Ambrona et al. - 2017 - Attribute-Based Encryption in the Generic Group Mo.pdf:application/pdf}
}

@article{aguirre_relational_2017,
	title = {A {Relational} {Logic} for {Higher}-order {Programs}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110265},
	doi = {10.1145/3110265},
	number = {ICFP},
	journal = {Proc. ACM Program. Lang.},
	author = {Aguirre, Alejandro and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Strub, Pierre-Yves},
	month = aug,
	year = {2017},
	keywords = {Formal Verification, Refinement Types, Relational Logic, 20180419GillesBarthe},
	pages = {21:1--21:29},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Aguirre et al. - 2017 - A Relational Logic for Higher-order Programs.pdf:C\:\\Users\\Anna\\Zotero\\storage\\WSYB8E93\\Aguirre et al. - 2017 - A Relational Logic for Higher-order Programs.pdf:application/pdf}
}

@inproceedings{dargenio_is_2017,
	address = {New York, NY, USA},
	title = {Is {Your} {Software} on {Dope}?},
	isbn = {978-3-662-54433-4},
	url = {https://doi.org/10.1007/978-3-662-54434-1_4},
	doi = {10.1007/978-3-662-54434-1_4},
	booktitle = {Proceedings of the 26th {European} {Symposium} on {Programming} {Languages} and {Systems} - {Volume} 10201},
	publisher = {Springer-Verlag New York, Inc.},
	author = {D'Argenio, Pedro R. and Barthe, Gilles and Biewer, Sebastian and Finkbeiner, Bernd and Hermanns, Holger},
	year = {2017},
	keywords = {20180419GillesBarthe},
	pages = {83--110},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;D'Argenio et al. - 2017 - Is Your Software on Dope.pdf:C\:\\Users\\Anna\\Documents\\Paper\\D'Argenio et al. - 2017 - Is Your Software on Dope.pdf:application/pdf}
}

@article{barthe_coupling_2017,
	title = {Coupling {Proofs} {Are} {Probabilistic} {Product} {Programs}},
	volume = {52},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/3093333.3009896},
	doi = {10.1145/3093333.3009896},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	month = jan,
	year = {2017},
	keywords = {Formal Verification, Probabilistic Algorithms, Probabilistic Couplings, Product Programs, Relational Hoare Logic},
	pages = {161--174}
}

@inproceedings{barthe_coupling_2017-1,
	address = {New York, NY, USA},
	series = {{POPL} 2017},
	title = {Coupling {Proofs} {Are} {Probabilistic} {Product} {Programs}},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009896},
	doi = {10.1145/3009837.3009896},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	year = {2017},
	keywords = {Formal Verification, Probabilistic Algorithms, Probabilistic Couplings, Product Programs, Relational Hoare Logic, 20180419GillesBarthe},
	pages = {161--174},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2017 - Coupling Proofs Are Probabilistic Product Programs.pdf:C\:\\Users\\Anna\\Zotero\\storage\\UVR9CP37\\Barthe et al. - 2017 - Coupling Proofs Are Probabilistic Product Programs.pdf:application/pdf}
}

@article{cicek_relational_2017,
	title = {Relational {Cost} {Analysis}},
	volume = {52},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/3093333.3009858},
	doi = {10.1145/3093333.3009858},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Çiçek, Ezgi and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Hoffmann, Jan},
	month = jan,
	year = {2017},
	keywords = {complexity analysis, Relational reasoning, type and effect systems},
	pages = {316--329}
}

@inproceedings{cicek_relational_2017-1,
	address = {New York, NY, USA},
	series = {{POPL} 2017},
	title = {Relational {Cost} {Analysis}},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009858},
	doi = {10.1145/3009837.3009858},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Çiçek, Ezgi and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Hoffmann, Jan},
	year = {2017},
	keywords = {complexity analysis, Relational reasoning, type and effect systems, 20180419GillesBarthe},
	pages = {316--329},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\G6EYBQYY\\Çiçek et al. - 2017 - Relational Cost Analysis.pdf:application/pdf;Çiçek et al. - 2017 - Relational Cost Analysis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ZF9DM29U\\Çiçek et al. - 2017 - Relational Cost Analysis.pdf:application/pdf}
}

@inproceedings{barthe_computer-aided_2016,
	address = {New York, NY, USA},
	series = {{WINE} 2016},
	title = {Computer-{Aided} {Verification} for {Mechanism} {Design}},
	isbn = {978-3-662-54109-8},
	url = {https://doi.org/10.1007/978-3-662-54110-4_20},
	doi = {10.1007/978-3-662-54110-4_20},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Web} and {Internet} {Economics} - {Volume} 10123},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Barthe, Gilles and Gaboardi, Marco and Arias, Emilio Jesús and Hsu, Justin and Roth, Aaron and Strub, Pierre-Yves},
	year = {2016},
	pages = {279--293}
}

@inproceedings{barthe_strong_2016,
	address = {New York, NY, USA},
	series = {{CCS} '16},
	title = {Strong {Non}-{Interference} and {Type}-{Directed} {Higher}-{Order} {Masking}},
	isbn = {978-1-4503-4139-4},
	url = {http://doi.acm.org/10.1145/2976749.2978427},
	doi = {10.1145/2976749.2978427},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Belaïd, Sonia and Dupressoir, François and Fouque, Pierre-Alain and Grégoire, Benjamin and Strub, Pierre-Yves and Zucchini, Rébecca},
	year = {2016},
	keywords = {formal verification, higher-order masking, non-interference, probing security, 20180419GillesBarthe},
	pages = {116--129},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2016 - Strong Non-Interference and Type-Directed Higher-O.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9TWKG7FU\\Barthe et al. - 2016 - Strong Non-Interference and Type-Directed Higher-O.pdf:application/pdf}
}

@inproceedings{baillot_implicit_2015,
	address = {New York, NY, USA},
	series = {{LPAR}-20 2015},
	title = {Implicit {Computational} {Complexity} of {Subrecursive} {Definitions} and {Applications} {toźCryptographic} {Proofs}},
	isbn = {978-3-662-48898-0},
	url = {https://doi.org/10.1007/978-3-662-48899-7_15},
	doi = {10.1007/978-3-662-48899-7_15},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Logic} for {Programming}, {Artificial} {Intelligence}, and {Reasoning} - {Volume} 9450},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Baillot, Patrick and Barthe, Gilles and Lago, Ugo Dal},
	year = {2015},
	pages = {203--218}
}

@inproceedings{barthe_relational_2015,
	address = {New York, NY, USA},
	series = {{LPAR}-20 2015},
	title = {Relational {Reasoning} via {Probabilistic} {Coupling}},
	isbn = {978-3-662-48898-0},
	url = {https://doi.org/10.1007/978-3-662-48899-7_27},
	doi = {10.1007/978-3-662-48899-7_27},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Logic} for {Programming}, {Artificial} {Intelligence}, and {Reasoning} - {Volume} 9450},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Barthe, Gilles and Espitau, Thomas and Grégoire, Benjamin and Hsu, Justin and Stefanesco, Léo and Strub, Pierre-Yves},
	year = {2015},
	pages = {387--401}
}

@inproceedings{barthe_automated_2015,
	address = {New York, NY, USA},
	series = {{CCS} '15},
	title = {Automated {Proofs} of {Pairing}-{Based} {Cryptography}},
	isbn = {978-1-4503-3832-5},
	url = {http://doi.acm.org/10.1145/2810103.2813697},
	doi = {10.1145/2810103.2813697},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Grégoire, Benjamin and Schmidt, Benedikt},
	year = {2015},
	keywords = {provable security, automated proofs, public-key encryption},
	pages = {1156--1168}
}

@article{barthe_sefm:_2015,
	title = {{SEFM}: {Software} {Engineering} and {Formal} {Methods}},
	volume = {14},
	issn = {1619-1366},
	url = {http://dx.doi.org/10.1007/s10270-014-0404-6},
	doi = {10.1007/s10270-014-0404-6},
	number = {1},
	journal = {Softw. Syst. Model.},
	author = {Barthe, Gilles and Pardo, Alberto and Schneider, Gerardo},
	month = feb,
	year = {2015},
	pages = {3--4}
}

@article{barthe_higher-order_2015,
	title = {Higher-{Order} {Approximate} {Relational} {Refinement} {Types} for {Mechanism} {Design} and {Differential} {Privacy}},
	volume = {50},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/2775051.2677000},
	doi = {10.1145/2775051.2677000},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Gaboardi, Marco and Gallego Arias, Emilio Jesús and Hsu, Justin and Roth, Aaron and Strub, Pierre-Yves},
	month = jan,
	year = {2015},
	keywords = {probabilistic programming, program logics},
	pages = {55--68}
}

@inproceedings{barthe_higher-order_2015-1,
	address = {New York, NY, USA},
	series = {{POPL} '15},
	title = {Higher-{Order} {Approximate} {Relational} {Refinement} {Types} for {Mechanism} {Design} and {Differential} {Privacy}},
	isbn = {978-1-4503-3300-9},
	url = {http://doi.acm.org/10.1145/2676726.2677000},
	doi = {10.1145/2676726.2677000},
	booktitle = {Proceedings of the 42Nd {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Gaboardi, Marco and Gallego Arias, Emilio Jesús and Hsu, Justin and Roth, Aaron and Strub, Pierre-Yves},
	year = {2015},
	keywords = {probabilistic programming, program logics},
	pages = {55--68}
}

@inproceedings{barthe_system-level_2014,
	address = {New York, NY, USA},
	series = {{CCS} '14},
	title = {System-level {Non}-interference for {Constant}-time {Cryptography}},
	isbn = {978-1-4503-2957-6},
	url = {http://doi.acm.org/10.1145/2660267.2660283},
	doi = {10.1145/2660267.2660283},
	booktitle = {Proceedings of the 2014 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Betarte, Gustavo and Campo, Juan and Luna, Carlos and Pichardie, David},
	year = {2014},
	keywords = {non-interference, cache-based attacks, constant-time cryptography, coq, stealth memory},
	pages = {1267--1279}
}

@inproceedings{barthe_synthesis_2014,
	address = {New York, NY, USA},
	series = {{CCS} '14},
	title = {Synthesis of {Fault} {Attacks} on {Cryptographic} {Implementations}},
	isbn = {978-1-4503-2957-6},
	url = {http://doi.acm.org/10.1145/2660267.2660304},
	doi = {10.1145/2660267.2660304},
	booktitle = {Proceedings of the 2014 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Dupressoir, François and Fouque, Pierre-Alain and Grégoire, Benjamin and Zapalowicz, Jean-Christophe},
	year = {2014},
	keywords = {program synthesis, automated proofs, fault attacks, program verification},
	pages = {1016--1027}
}

@inproceedings{barthe_making_2014,
	address = {New York, NY, USA},
	title = {Making {RSA}—{PSS} {Provably} {Secure} {Against} {Non}-random {Faults}},
	isbn = {978-3-662-44708-6},
	url = {http://dx.doi.org/10.1007/978-3-662-44709-3_12},
	doi = {10.1007/978-3-662-44709-3_12},
	booktitle = {Proceedings of the 16th {International} {Workshop} on {Cryptographic} {Hardware} and {Embedded} {Systems} — {CHES} 2014 - {Volume} 8731},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Barthe, Gilles and Dupressoir, François and Fouque, Pierre-Alain and Grégoire, Benjamin and Tibouchi, Mehdi and Zapalowicz, Jean-Christophe},
	year = {2014},
	keywords = {Formal Verification, EasyCrypt, Fault Attacks, Infective countermeasure, PSS, RSA—CRT},
	pages = {206--222}
}

@inproceedings{barthe_proving_2014,
	address = {Washington, DC, USA},
	series = {{CSF} '14},
	title = {Proving {Differential} {Privacy} in {Hoare} {Logic}},
	isbn = {978-1-4799-4290-9},
	url = {http://dx.doi.org/10.1109/CSF.2014.36},
	doi = {10.1109/CSF.2014.36},
	booktitle = {Proceedings of the 2014 {IEEE} 27th {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Gaboardi, Marco and Arias, Emilio Jesús Gallego and Hsu, Justin and Kunz, César and Strub, Pierre-Yves},
	year = {2014},
	keywords = {privacy, differential privacy, relational hoare logic, hoare logic, probabilistic hoare logic, verification},
	pages = {411--424}
}

@inproceedings{akinyele_certified_2014,
	address = {Washington, DC, USA},
	series = {{CSF} '14},
	title = {Certified {Synthesis} of {Efficient} {Batch} {Verifiers}},
	isbn = {978-1-4799-4290-9},
	url = {http://dx.doi.org/10.1109/CSF.2014.19},
	doi = {10.1109/CSF.2014.19},
	booktitle = {Proceedings of the 2014 {IEEE} 27th {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Akinyele, Joseph A. and Barthe, Gilles and Grégoire, Benjamin and Schmidt, Benedikt and Strub, Pierre-Yves},
	year = {2014},
	keywords = {cryptography, certified proofs, cryptographic design, signature schemes},
	pages = {153--165}
}

@article{barthe_formal_2014,
	title = {Formal {Verification} of an {SSA}-{Based} {Middle}-{End} for {CompCert}},
	volume = {36},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/2579080},
	doi = {10.1145/2579080},
	number = {1},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Barthe, Gilles and Demange, Delphine and Pichardie, David},
	month = mar,
	year = {2014},
	keywords = {compiler verification, mechanized proof, Single static assignment},
	pages = {4:1--4:35}
}

@article{barthe_probabilistic_2014,
	title = {Probabilistic {Relational} {Verification} for {Cryptographic} {Implementations}},
	volume = {49},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/2578855.2535847},
	doi = {10.1145/2578855.2535847},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Fournet, Cédric and Grégoire, Benjamin and Strub, Pierre-Yves and Swamy, Nikhil and Zanella-Béguelin, Santiago},
	month = jan,
	year = {2014},
	keywords = {probabilistic programming, program logics},
	pages = {193--205}
}

@inproceedings{barthe_probabilistic_2014-1,
	address = {New York, NY, USA},
	series = {{POPL} '14},
	title = {Probabilistic {Relational} {Verification} for {Cryptographic} {Implementations}},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535847},
	doi = {10.1145/2535838.2535847},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Fournet, Cédric and Grégoire, Benjamin and Strub, Pierre-Yves and Swamy, Nikhil and Zanella-Béguelin, Santiago},
	year = {2014},
	keywords = {probabilistic programming, program logics},
	pages = {193--205}
}

@inproceedings{almeida_certified_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {Certified {Computer}-aided {Cryptography}: {Efficient} {Provably} {Secure} {Machine} {Code} from {High}-level {Implementations}},
	isbn = {978-1-4503-2477-9},
	url = {http://doi.acm.org/10.1145/2508859.2516652},
	doi = {10.1145/2508859.2516652},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \&\#38; {Communications} {Security}},
	publisher = {ACM},
	author = {Almeida, José Bacelar and Barbosa, Manuel and Barthe, Gilles and Dupressoir, François},
	year = {2013},
	keywords = {formal methods},
	pages = {1217--1230}
}

@inproceedings{barthe_fully_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {Fully {Automated} {Analysis} of {Padding}-based {Encryption} in the {Computational} {Model}},
	isbn = {978-1-4503-2477-9},
	url = {http://doi.acm.org/10.1145/2508859.2516663},
	doi = {10.1145/2508859.2516663},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \&\#38; {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Crespo, Juan Manuel and Grégoire, Benjamin and Kunz, César and Lakhnech, Yassine and Schmidt, Benedikt and Zanella-Béguelin, Santiago},
	year = {2013},
	keywords = {provable security, automated proofs, public-key encryption, attack finding, static equivalence},
	pages = {1247--1260}
}

@inproceedings{barthe_computer-aided_2013,
	address = {Berlin, Heidelberg},
	series = {{QEST}'13},
	title = {Computer-{Aided} {Security} {Proofs}},
	isbn = {978-3-642-40195-4},
	url = {http://dx.doi.org/10.1007/978-3-642-40196-1_1},
	doi = {10.1007/978-3-642-40196-1_1},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Quantitative} {Evaluation} of {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {2013},
	pages = {1--2}
}

@inproceedings{barthe_beyond_2013,
	address = {Berlin, Heidelberg},
	series = {{ICALP}'13},
	title = {Beyond {Differential} {Privacy}: {Composition} {Theorems} and {Relational} {Logic} for \&{Lt};{I}\&{Gt};{F}\&{Lt};/{I}\&{Gt};-divergences {Between} {Probabilistic} {Programs}},
	isbn = {978-3-642-39211-5},
	url = {http://dx.doi.org/10.1007/978-3-642-39212-2_8},
	doi = {10.1007/978-3-642-39212-2_8},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Automata}, {Languages}, and {Programming} - {Volume} {Part} {II}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Olmedo, Federico},
	year = {2013},
	pages = {49--60}
}

@inproceedings{barthe_computer-aided_2013-1,
	address = {Berlin, Heidelberg},
	series = {{POST}'13},
	title = {Computer-aided {Cryptographic} {Proofs}},
	isbn = {978-3-642-36829-5},
	url = {http://dl.acm.org/citation.cfm?id=2450461.2450463},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Principles} of {Security} and {Trust}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {2013},
	pages = {xv--xv}
}

@article{barthe_relational_2013,
	title = {From {Relational} {Verification} to {SIMD} {Loop} {Synthesis}},
	volume = {48},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/2517327.2442529},
	doi = {10.1145/2517327.2442529},
	number = {8},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Crespo, Juan Manuel and Gulwani, Sumit and Kunz, Cesar and Marron, Mark},
	month = feb,
	year = {2013},
	keywords = {relational verification, program vectorization, synthesis},
	pages = {123--134}
}

@inproceedings{barthe_relational_2013-1,
	address = {New York, NY, USA},
	series = {{PPoPP} '13},
	title = {From {Relational} {Verification} to {SIMD} {Loop} {Synthesis}},
	isbn = {978-1-4503-1922-5},
	url = {http://doi.acm.org/10.1145/2442516.2442529},
	doi = {10.1145/2442516.2442529},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming}},
	publisher = {ACM},
	author = {Barthe, Gilles and Crespo, Juan Manuel and Gulwani, Sumit and Kunz, Cesar and Marron, Mark},
	year = {2013},
	keywords = {relational verification, program vectorization, synthesis},
	pages = {123--134}
}

@inproceedings{barthe_automation_2012,
	address = {Berlin, Heidelberg},
	series = {{CPP}'12},
	title = {Automation in {Computer}-aided {Cryptography}: {Proofs}, {Attacks} and {Designs}},
	isbn = {978-3-642-35307-9},
	url = {http://dx.doi.org/10.1007/978-3-642-35308-6_3},
	doi = {10.1007/978-3-642-35308-6_3},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Certified} {Programs} and {Proofs}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Kunz, César and Lakhnech, Yassine and Zanella Béguelin, Santiago},
	year = {2012},
	pages = {7--8}
}

@inproceedings{barthe_verified_2012,
	address = {New York, NY, USA},
	series = {{CCS} '12},
	title = {Verified {Security} of {Redundancy}-free {Encryption} from {Rabin} and {RSA}},
	isbn = {978-1-4503-1651-4},
	url = {http://doi.acm.org/10.1145/2382196.2382272},
	doi = {10.1145/2382196.2382272},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Pointcheval, David and Zanella Béguelin, Santiago},
	year = {2012},
	keywords = {provable security, public-key encryption, machine-checked proofs},
	pages = {724--735}
}

@inproceedings{bacelar_almeida_full_2012,
	address = {New York, NY, USA},
	series = {{CCS} '12},
	title = {Full {Proof} {Cryptography}: {Verifiable} {Compilation} of {Efficient} {Zero}-knowledge {Protocols}},
	isbn = {978-1-4503-1651-4},
	url = {http://doi.acm.org/10.1145/2382196.2382249},
	doi = {10.1145/2382196.2382249},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Bacelar Almeida, José and Barbosa, Manuel and Bangerter, Endre and Barthe, Gilles and Krenn, Stephan and Zanella Béguelin, Santiago},
	year = {2012},
	keywords = {cryptographic compiler, verifying compilation, zero-knowledge},
	pages = {488--500}
}

@article{barthe_preface_2012,
	title = {Preface},
	volume = {20},
	issn = {0926-227X},
	url = {http://dl.acm.org/citation.cfm?id=2590602.2590603},
	number = {4},
	journal = {J. Comput. Secur.},
	author = {Barthe, Gilles and Cuellar, Jorge and Lopez, Javier and Pretschner, Alexander},
	month = jul,
	year = {2012},
	pages = {307--308}
}

@inproceedings{barthe_cache-leakage_2012,
	address = {Washington, DC, USA},
	series = {{CSF} '12},
	title = {Cache-{Leakage} {Resilient} {OS} {Isolation} in an {Idealized} {Model} of {Virtualization}},
	isbn = {978-0-7695-4718-3},
	url = {http://dx.doi.org/10.1109/CSF.2012.17},
	doi = {10.1109/CSF.2012.17},
	booktitle = {Proceedings of the 2012 {IEEE} 25th {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Betarte, Gustavo and Campo, Juan Diego and Luna, Carlos},
	year = {2012},
	keywords = {Cache-leakage, Isolation, Transparency, Virtualization},
	pages = {186--197}
}

@inproceedings{backes_verified_2012,
	address = {Washington, DC, USA},
	series = {{CSF} '12},
	title = {Verified {Security} of {Merkle}-{Damg}{\textbackslash}a ard},
	isbn = {978-0-7695-4718-3},
	url = {http://dx.doi.org/10.1109/CSF.2012.14},
	doi = {10.1109/CSF.2012.14},
	booktitle = {Proceedings of the 2012 {IEEE} 25th {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Backes, Michael and Barthe, Gilles and Berg, Matthias and Gregoire, Benjamin and Kunz, Cesar and Skoruppa, Malte and Beguelin, Santiago Zanella},
	year = {2012},
	keywords = {collision-resistance, Cryptographic hash functions, Easy Crypt, indifferentiability, Merkle-Damgaard, SHA-3},
	pages = {354--368}
}

@inproceedings{barthe_probabilistic_2012,
	address = {Berlin, Heidelberg},
	series = {{MPC}'12},
	title = {Probabilistic {Relational} {Hoare} {Logics} for {Computer}-aided {Security} {Proofs}},
	isbn = {978-3-642-31112-3},
	url = {http://dx.doi.org/10.1007/978-3-642-31113-0_1},
	doi = {10.1007/978-3-642-31113-0_1},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Mathematics} of {Program} {Construction}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Zanella Béguelin, Santiago},
	year = {2012},
	pages = {1--6}
}

@inproceedings{barthe_secure_2012,
	address = {Berlin, Heidelberg},
	series = {{FMOODS}'12/{FORTE}'12},
	title = {Secure {Multi}-execution {Through} {Static} {Program} {Transformation}},
	isbn = {978-3-642-30792-8},
	url = {http://dx.doi.org/10.1007/978-3-642-30793-5_12},
	doi = {10.1007/978-3-642-30793-5_12},
	booktitle = {Proceedings of the 14th {Joint} {IFIP} {WG} 6.1 {International} {Conference} and {Proceedings} of the 32Nd {IFIP} {WG} 6.1 {International} {Conference} on {Formal} {Techniques} for {Distributed} {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Crespo, Juan Manuel and Devriese, Dominique and Piessens, Frank and Rivas, Exequiel},
	year = {2012},
	pages = {186--202}
}

@inproceedings{barthe_formally_2012,
	address = {Berlin, Heidelberg},
	series = {{ESOP}'12},
	title = {A {Formally} {Verified} {SSA}-{Based} {Middle}-end: {Static} {Single} {Assignment} {Meets} {Compcert}},
	isbn = {978-3-642-28868-5},
	url = {http://dx.doi.org/10.1007/978-3-642-28869-2_3},
	doi = {10.1007/978-3-642-28869-2_3},
	booktitle = {Proceedings of the 21st {European} {Conference} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Demange, Delphine and Pichardie, David},
	year = {2012},
	pages = {47--66}
}

@inproceedings{barthe_verified_2012-1,
	address = {Berlin, Heidelberg},
	series = {{POST}'12},
	title = {Verified {Indifferentiable} {Hashing} into {Elliptic} {Curves}},
	isbn = {978-3-642-28640-7},
	url = {http://dx.doi.org/10.1007/978-3-642-28641-4_12},
	doi = {10.1007/978-3-642-28641-4_12},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Principles} of {Security} and {Trust}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Heraud, Sylvain and Olmedo, Federico and Zanella Béguelin, Santiago},
	year = {2012},
	pages = {209--228}
}

@article{barthe_probabilistic_2012-1,
	title = {Probabilistic {Relational} {Reasoning} for {Differential} {Privacy}},
	volume = {47},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/2103621.2103670},
	doi = {10.1145/2103621.2103670},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Köpf, Boris and Olmedo, Federico and Zanella Béguelin, Santiago},
	month = jan,
	year = {2012},
	keywords = {differential privacy, relational hoare logic, coq proof assistant},
	pages = {97--110}
}

@inproceedings{barthe_probabilistic_2012-2,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {Probabilistic {Relational} {Reasoning} for {Differential} {Privacy}},
	isbn = {978-1-4503-1083-3},
	url = {http://doi.acm.org/10.1145/2103656.2103670},
	doi = {10.1145/2103656.2103670},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Köpf, Boris and Olmedo, Federico and Zanella Béguelin, Santiago},
	year = {2012},
	keywords = {differential privacy, relational hoare logic, coq proof assistant},
	pages = {97--110}
}

@article{barthe_secure_2011,
	title = {Secure {Information} {Flow} by {Self}-composition},
	volume = {21},
	issn = {0960-1295},
	url = {http://dx.doi.org/10.1017/S0960129511000193},
	doi = {10.1017/S0960129511000193},
	number = {6},
	journal = {Mathematical. Structures in Comp. Sci.},
	author = {Barthe, Gilles and D'argenio, Pedro R. and Rezk, Tamara},
	month = dec,
	year = {2011},
	pages = {1207--1252}
}

@inproceedings{barthe_verifiable_2011,
	address = {Berlin, Heidelberg},
	series = {{ProvSec}'11},
	title = {Verifiable {Security} of {Boneh}-{Franklin} {Identity}-based {Encryption}},
	isbn = {978-3-642-24315-8},
	url = {http://dl.acm.org/citation.cfm?id=2042756.2042766},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Provable} {Security}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Olmedo, Federico and Béguelin, Santiago Zanella},
	year = {2011},
	keywords = {bilinear diffie-hellman problem, Boneh-Franklin scheme, certicrypt, iddentity-based encryption, pairing-based cryptography, verifiable security},
	pages = {68--83}
}

@inproceedings{barthe_computer-aided_2011,
	address = {Berlin, Heidelberg},
	series = {{CRYPTO}'11},
	title = {Computer-aided {Security} {Proofs} for the {Working} {Cryptographer}},
	isbn = {978-3-642-22791-2},
	url = {http://dl.acm.org/citation.cfm?id=2033036.2033043},
	booktitle = {Proceedings of the 31st {Annual} {Conference} on {Advances} in {Cryptology}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Heraud, Sylvain and Béguelin, Santiago Zanella},
	year = {2011},
	keywords = {provable security, verifiable security, Cramer-Shoup cryptosystem, ElGamal encryption, game-based proofs},
	pages = {71--90}
}

@article{barthe_abstract_2011,
	title = {An {Abstract} {Model} of {Certificate} {Translation}},
	volume = {33},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1985342.1985344},
	doi = {10.1145/1985342.1985344},
	number = {4},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Barthe, Gilles and Kunz, César},
	month = jul,
	year = {2011},
	keywords = {static analysis, program optimizations, Program verification, proof-carrying code},
	pages = {13:1--13:46}
}

@inproceedings{barthe_relational_2011,
	address = {Berlin, Heidelberg},
	series = {{FM}'11},
	title = {Relational {Verification} {Using} {Product} {Programs}},
	isbn = {978-3-642-21436-3},
	url = {http://dl.acm.org/citation.cfm?id=2021296.2021319},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Formal} {Methods}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Crespo, Juan Manuel and Kunz, César},
	year = {2011},
	pages = {200--214}
}

@inproceedings{barthe_formally_2011,
	address = {Berlin, Heidelberg},
	series = {{FM}'11},
	title = {Formally {Verifying} {Isolation} and {Availability} in an {Idealized} {Model} of {Virtualization}},
	isbn = {978-3-642-21436-3},
	url = {http://dl.acm.org/citation.cfm?id=2021296.2021322},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Formal} {Methods}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Betarte, Gustavo and Campo, Juan Diego and Luna, Carlos},
	year = {2011},
	pages = {231--245}
}

@inproceedings{barthe_static_2012,
	address = {Berlin, Heidelberg},
	series = {{TGC}'11},
	title = {Static {Enforcement} of {Information} {Flow} {Policies} for a {Concurrent} {JVM}-like {Language}},
	isbn = {978-3-642-30064-6},
	url = {http://dx.doi.org/10.1007/978-3-642-30065-3_5},
	doi = {10.1007/978-3-642-30065-3_5},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Trustworthy} {Global} {Computing}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Rivas, Exequiel},
	year = {2012},
	pages = {73--88}
}

@inproceedings{barthe_computational_2012,
	address = {Berlin, Heidelberg},
	series = {{FPS}'11},
	title = {A {Computational} {Indistinguishability} {Logic} for the {Bounded} {Storage} {Model}},
	isbn = {978-3-642-27900-3},
	url = {http://dx.doi.org/10.1007/978-3-642-27901-0_9},
	doi = {10.1007/978-3-642-27901-0_9},
	booktitle = {Proceedings of the 4th {Canada}-{France} {MITACS} {Conference} on {Foundations} and {Practice} of {Security}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Duclos, Mathilde and Lakhnech, Yassine},
	year = {2012},
	keywords = {formal verification, bounded storage model, computational model, provable cryptography},
	pages = {102--117}
}

@inproceedings{barthe_beyond_2011,
	address = {Berlin, Heidelberg},
	series = {{CT}-{RSA}'11},
	title = {Beyond {Provable} {Security} {Verifiable} {IND}-{CCA} {Security} of {OAEP}},
	isbn = {978-3-642-19073-5},
	url = {http://dl.acm.org/citation.cfm?id=1964621.1964640},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Topics} in {Cryptology}: {CT}-{RSA} 2011},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Lakhnech, Yassine and Béguelin, Santiago Zanella},
	year = {2011},
	pages = {180--196}
}

@inproceedings{barthe_computational_2010,
	address = {New York, NY, USA},
	series = {{CCS} '10},
	title = {Computational {Indistinguishability} {Logic}},
	isbn = {978-1-4503-0245-6},
	url = {http://doi.acm.org/10.1145/1866307.1866350},
	doi = {10.1145/1866307.1866350},
	booktitle = {Proceedings of the 17th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Daubignard, Marion and Kapron, Bruce and Lakhnech, Yassine},
	year = {2010},
	keywords = {provable security, cryptography, concrete security, logic},
	pages = {375--386}
}

@article{barthe_security_2010,
	title = {Security of {Multithreaded} {Programs} by {Compilation}},
	volume = {13},
	issn = {1094-9224},
	url = {http://doi.acm.org/10.1145/1805974.1805977},
	doi = {10.1145/1805974.1805977},
	number = {3},
	journal = {ACM Trans. Inf. Syst. Secur.},
	author = {Barthe, Gilles and Rezk, Tamara and Russo, Alejandro and Sabelfeld, Andrei},
	month = jul,
	year = {2010},
	keywords = {Noninterference, type systems, compilers, schedulers},
	pages = {21:1--21:32}
}

@inproceedings{barthe_robustness_2010,
	address = {Washington, DC, USA},
	series = {{CSF} '10},
	title = {Robustness {Guarantees} for {Anonymity}},
	isbn = {978-0-7695-4082-5},
	url = {http://dx.doi.org/10.1109/CSF.2010.14},
	doi = {10.1109/CSF.2010.14},
	booktitle = {Proceedings of the 2010 23rd {IEEE} {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Hevia, Alejandro and Luo, Zhengqin and Rezk, Tamara and Warinschi, Bogdan},
	year = {2010},
	pages = {91--106}
}

@inproceedings{barthe_machine-checked_2010,
	address = {Washington, DC, USA},
	series = {{CSF} '10},
	title = {A {Machine}-{Checked} {Formalization} of {Sigma}-{Protocols}},
	isbn = {978-0-7695-4082-5},
	url = {http://dx.doi.org/10.1109/CSF.2010.24},
	doi = {10.1109/CSF.2010.24},
	booktitle = {Proceedings of the 2010 23rd {IEEE} {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Hedin, Daniel and Béguelin, Santiago Zanella and Grégoire, Benjamin and Heraud, Sylvain},
	year = {2010},
	pages = {246--260}
}

@inproceedings{barthe_programming_2010,
	address = {Berlin, Heidelberg},
	series = {{ITP}'10},
	title = {Programming {Language} {Techniques} for {Cryptographic} {Proofs}},
	isbn = {3-642-14051-3 978-3-642-14051-8},
	url = {http://dx.doi.org/10.1007/978-3-642-14052-5_10},
	doi = {10.1007/978-3-642-14052-5_10},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Interactive} {Theorem} {Proving}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Zanella Béguelin, Santiago},
	year = {2010},
	pages = {115--130}
}

@inproceedings{barthe_equality_2010,
	address = {Berlin, Heidelberg},
	series = {{LPAR}'10},
	title = {On the {Equality} of {Probabilistic} {Terms}},
	isbn = {3-642-17510-4 978-3-642-17510-7},
	url = {http://dl.acm.org/citation.cfm?id=1939141.1939145},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Logic} for {Programming}, {Artificial} {Intelligence}, and {Reasoning}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Daubignard, Marion and Kapron, Bruce and Lakhnech, Yassine and Laporte, Vincent},
	year = {2010},
	pages = {46--63}
}

@inproceedings{barthe_functional_2010,
	address = {Berlin, Heidelberg},
	series = {{FLOPS}'10},
	title = {A {Functional} {Framework} for {Result} {Checking}},
	isbn = {3-642-12250-7 978-3-642-12250-7},
	url = {http://dx.doi.org/10.1007/978-3-642-12251-4_7},
	doi = {10.1007/978-3-642-12251-4_7},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Functional} and {Logic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Buiras, Pablo and Kunz, César},
	year = {2010},
	pages = {72--86}
}

@inproceedings{barthe_perspectives_2010,
	address = {Berlin, Heidelberg},
	series = {{TGC}'10},
	title = {Perspectives in {Certificate} {Translation}},
	isbn = {3-642-15639-8 978-3-642-15639-7},
	url = {http://dl.acm.org/citation.cfm?id=1893701.1893704},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Trustworthly} {Global} {Computing}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Kunz, César},
	year = {2010},
	pages = {23--34}
}

@inproceedings{barthe_implementing_2009,
	address = {Berlin, Heidelberg},
	series = {{ICFEM} '09},
	title = {Implementing a {Direct} {Method} for {Certificate} {Translation}},
	isbn = {978-3-642-10372-8},
	url = {http://dx.doi.org/10.1007/978-3-642-10373-5_28},
	doi = {10.1007/978-3-642-10373-5_28},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Formal} {Engineering} {Methods}: {Formal} {Methods} and {Software} {Engineering}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Heraud, Sylvain and Kunz, César and Pacalet, Anne},
	year = {2009},
	pages = {541--560}
}

@incollection{barthe_foundations_2009,
	address = {Berlin, Heidelberg},
	title = {Foundations of {Security} {Analysis} and {Design} {V}},
	isbn = {978-3-642-03828-0},
	url = {http://dx.doi.org/10.1007/978-3-642-03829-7_2},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Kunz, César},
	editor = {Aldini, Alessandro and Barthe, Gilles and Gorrieri, Roberto},
	year = {2009},
	doi = {10.1007/978-3-642-03829-7_2},
	pages = {51--95}
}

@incollection{barthe_language_2009,
	address = {Berlin, Heidelberg},
	title = {Language {Engineering} and {Rigorous} {Software} {Development}},
	isbn = {978-3-642-03152-6},
	url = {http://dx.doi.org/10.1007/978-3-642-03153-3_3},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Riba, Colin},
	editor = {Bove, Ana and Barbosa, Luís Soares and Pardo, Alberto and Pinto, Jorge Sousa},
	year = {2009},
	doi = {10.1007/978-3-642-03153-3_3},
	pages = {100--152}
}

@article{barthe_certificate_2009,
	title = {Certificate {Translation} for {Optimizing} {Compilers}},
	volume = {31},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1538917.1538919},
	doi = {10.1145/1538917.1538919},
	number = {5},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Barthe, Gilles and Grégoire, Benjamin and Kunz, César and Rezk, Tamara},
	month = jul,
	year = {2009},
	keywords = {static analysis, program verification, program optimizations, Proof-carrying code},
	pages = {18:1--18:45}
}

@inproceedings{zanella-beguelin_formally_2009,
	address = {Washington, DC, USA},
	series = {{SP} '09},
	title = {Formally {Certifying} the {Security} of {Digital} {Signature} {Schemes}},
	isbn = {978-0-7695-3633-0},
	url = {http://dx.doi.org/10.1109/SP.2009.17},
	doi = {10.1109/SP.2009.17},
	booktitle = {Proceedings of the 2009 30th {IEEE} {Symposium} on {Security} and {Privacy}},
	publisher = {IEEE Computer Society},
	author = {Zanella-Beguelin, Santiago and Barthe, Gilles and Gregoire, Benjamin and Olmedo, Federico},
	year = {2009},
	keywords = {programming language, provable security, cryptography, signature schemes, game-based proofs, Coq proof assistant, cryptographic proofs, exact security, Full Domain Hash, probabilistic progams, semantics},
	pages = {237--250}
}

@incollection{barthe_formal_2009,
	address = {Berlin, Heidelberg},
	title = {Formal {Aspects} in {Security} and {Trust}},
	isbn = {978-3-642-01464-2},
	url = {http://dx.doi.org/10.1007/978-3-642-01465-9_1},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Heraud, Sylvain and Zanella Béguelin, Santiago},
	editor = {Degano, Pierpaolo and Guttman, Joshua and Martinelli, Fabio},
	year = {2009},
	doi = {10.1007/978-3-642-01465-9_1},
	pages = {1--19}
}

@article{barthe_formal_2009-1,
	title = {Formal {Certification} of {Code}-based {Cryptographic} {Proofs}},
	volume = {44},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/1594834.1480894},
	doi = {10.1145/1594834.1480894},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Grégoire, Benjamin and Zanella Béguelin, Santiago},
	month = jan,
	year = {2009},
	keywords = {relational hoare logic, coq proof assistant, cryptographic proofs, observational equivalence, program transformations},
	pages = {90--101}
}

@inproceedings{barthe_formal_2009-2,
	address = {New York, NY, USA},
	series = {{POPL} '09},
	title = {Formal {Certification} of {Code}-based {Cryptographic} {Proofs}},
	isbn = {978-1-60558-379-2},
	url = {http://doi.acm.org/10.1145/1480881.1480894},
	doi = {10.1145/1480881.1480894},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Grégoire, Benjamin and Zanella Béguelin, Santiago},
	year = {2009},
	keywords = {relational hoare logic, coq proof assistant, cryptographic proofs, observational equivalence, program transformations},
	pages = {90--101}
}

@inproceedings{barthe_certified_2008,
	address = {Berlin, Heidelberg},
	series = {{APLAS} '08},
	title = {Certified {Reasoning} in {Memory} {Hierarchies}},
	isbn = {978-3-540-89329-5},
	url = {http://dx.doi.org/10.1007/978-3-540-89330-1_6},
	doi = {10.1007/978-3-540-89330-1_6},
	booktitle = {Proceedings of the 6th {Asian} {Symposium} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Kunz, César and Sacchini, Jorge Luis},
	year = {2008},
	pages = {75--90}
}

@incollection{barthe_formal_2008,
	address = {Berlin, Heidelberg},
	title = {Formal {Methods} for {Components} and {Objects}},
	isbn = {978-3-540-92187-5},
	url = {http://dx.doi.org/10.1007/978-3-540-92188-2_1},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Crégut, Pierre and Grégoire, Benjamin and Jensen, Thomas and Pichardie, David},
	editor = {Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and Roever, Willem-Paul},
	year = {2008},
	doi = {10.1007/978-3-540-92188-2_1},
	pages = {1--24}
}

@inproceedings{barthe_preservation_2008,
	address = {Washington, DC, USA},
	series = {{SEFM} '08},
	title = {Preservation of {Proof} {Pbligations} for {Hybrid} {Verification} {Methods}},
	isbn = {978-0-7695-3437-4},
	url = {https://doi.org/10.1109/SEFM.2008.10},
	doi = {10.1109/SEFM.2008.10},
	booktitle = {Proceedings of the 2008 {Sixth} {IEEE} {International} {Conference} on {Software} {Engineering} and {Formal} {Methods}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Kunz, César and Pichardie, David and Samborski-Forlese, Julián},
	year = {2008},
	keywords = {Compilation, Program Verification, Proof Carrying Code},
	pages = {127--136}
}

@inproceedings{barthe_type-based_2008,
	address = {Berlin, Heidelberg},
	series = {{CSL} '08},
	title = {Type-{Based} {Termination} with {Sized} {Products}},
	isbn = {978-3-540-87530-7},
	url = {http://dx.doi.org/10.1007/978-3-540-87531-4_35},
	doi = {10.1007/978-3-540-87531-4_35},
	booktitle = {Proceedings of the 22Nd {International} {Workshop} on {Computer} {Science} {Logic}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Riba, Colin},
	year = {2008},
	pages = {493--507}
}

@inproceedings{barthe_preservation_2008-1,
	address = {Berlin, Heidelberg},
	series = {{IJCAR} '08},
	title = {Preservation of {Proof} {Obligations} from {Java} to the {Java} {Virtual} {Machine}},
	isbn = {978-3-540-71069-1},
	url = {http://dx.doi.org/10.1007/978-3-540-71070-7_7},
	doi = {10.1007/978-3-540-71070-7_7},
	booktitle = {Proceedings of the 4th {International} {Joint} {Conference} on {Automated} {Reasoning}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Pavlova, Mariela},
	year = {2008},
	pages = {83--99}
}

@inproceedings{barthe_tractable_2008,
	address = {Washington, DC, USA},
	series = {{CSF} '08},
	title = {Tractable {Enforcement} of {Declassification} {Policies}},
	isbn = {978-0-7695-3182-3},
	url = {https://doi.org/10.1109/CSF.2008.11},
	doi = {10.1109/CSF.2008.11},
	booktitle = {Proceedings of the 2008 21st {IEEE} {Computer} {Security} {Foundations} {Symposium}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Cavadini, Salvador and Rezk, Tamara},
	year = {2008},
	keywords = {type systems, declassification, information flow security},
	pages = {83--97}
}

@inproceedings{barthe_certificate_2008,
	address = {New York, NY, USA},
	series = {{FOAL} '08},
	title = {Certificate {Translation} for {Specification}-preserving {Advices}},
	isbn = {978-1-60558-110-1},
	url = {http://doi.acm.org/10.1145/1394496.1394498},
	doi = {10.1145/1394496.1394498},
	booktitle = {Proceedings of the 7th {Workshop} on {Foundations} of {Aspect}-oriented {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Kunz, César},
	year = {2008},
	keywords = {program verification, proof-carrying code, AOP},
	pages = {9--18}
}

@inproceedings{barthe_certificate_2008-1,
	address = {Berlin, Heidelberg},
	series = {{ESOP}'08/{ETAPS}'08},
	title = {Certificate {Translation} in {Abstract} {Interpretation}},
	isbn = {3-540-78738-0 978-3-540-78738-9},
	url = {http://dl.acm.org/citation.cfm?id=1792878.1792916},
	booktitle = {Proceedings of the {Theory} and {Practice} of {Software}, 17th {European} {Conference} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Kunz, César},
	year = {2008},
	pages = {368--382}
}

@article{barthe_secure_2007,
	title = {Secure {Information} {Flow} for a {Concurrent} {Language} with {Scheduling}},
	volume = {15},
	issn = {0926-227X},
	url = {http://dl.acm.org/citation.cfm?id=1370677.1370680},
	number = {6},
	journal = {J. Comput. Secur.},
	author = {Barthe, Gilles and Prensa Nieto, Leonor},
	month = dec,
	year = {2007},
	pages = {647--689}
}

@inproceedings{barthe_security_2007,
	address = {Berlin, Heidelberg},
	series = {{ESORICS}'07},
	title = {Security of {Multithreaded} {Programs} by {Compilation}},
	isbn = {3-540-74834-2 978-3-540-74834-2},
	url = {http://dl.acm.org/citation.cfm?id=2393847.2393851},
	booktitle = {Proceedings of the 12th {European} {Conference} on {Research} in {Computer} {Security}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Rezk, Tamara and Russo, Alejandro and Sabelfeld, Andrei},
	year = {2007},
	pages = {2--18}
}

@article{barthe_security_2007-1,
	title = {Security {Types} {Preserving} {Compilation}},
	volume = {33},
	issn = {1477-8424},
	url = {http://dx.doi.org/10.1016/j.cl.2005.05.002},
	doi = {10.1016/j.cl.2005.05.002},
	number = {2},
	journal = {Comput. Lang. Syst. Struct.},
	author = {Barthe, Gilles and Rezk, Tamara and Basu, Amitabh},
	month = jul,
	year = {2007},
	keywords = {Security, Program analysis, Low-level languages, Non-interference},
	pages = {35--59}
}

@inproceedings{barthe_certified_2007,
	address = {Berlin, Heidelberg},
	series = {{ESOP}'07},
	title = {A {Certified} {Lightweight} {Non}-interference {Java} {Bytecode} {Verifier}},
	isbn = {978-3-540-71314-2},
	url = {http://dl.acm.org/citation.cfm?id=1762174.1762189},
	booktitle = {Proceedings of the 16th {European} {Symposium} on {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Pichardie, David and Rezk, Tamara},
	year = {2007},
	pages = {125--140}
}

@inproceedings{barthe_cic&8743;:_2006,
	address = {Berlin, Heidelberg},
	series = {{LPAR}'06},
	title = {{CIC}\&\#8743;: {Type}-based {Termination} of {Recursive} {Definitions} in the {Calculus} of {Inductive} {Constructions}},
	isbn = {3-540-48281-4 978-3-540-48281-9},
	url = {http://dx.doi.org/10.1007/11916277_18},
	doi = {10.1007/11916277_18},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Logic} for {Programming}, {Artificial} {Intelligence}, and {Reasoning}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Pastawski, Fernando},
	year = {2006},
	pages = {257--271}
}

@inproceedings{barthe_jack:_2007,
	address = {Berlin, Heidelberg},
	series = {{FMCO}'06},
	title = {{JACK}: {A} {Tool} for {Validation} of {Security} and {Behaviour} of {Java} {Applications}},
	isbn = {3-540-74791-5 978-3-540-74791-8},
	url = {http://dl.acm.org/citation.cfm?id=1777707.1777717},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Formal} {Methods} for {Components} and {Objects}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Burdy, Lilian and Charles, Julien and Grégoire, Benjamin and Huisman, Marieke and Lanet, Jean-Louis and Pavlova, Mariela and Requet, Antoine},
	year = {2007},
	pages = {152--174}
}

@inproceedings{barthe_mobius:_2007,
	address = {Berlin, Heidelberg},
	series = {{TGC}'06},
	title = {{MOBIUS}: {Mobility}, {Ubiquity}, {Security} {Objectives} and {Progress} {Report}},
	isbn = {3-540-75333-8 978-3-540-75333-9},
	url = {http://dl.acm.org/citation.cfm?id=1776656.1776659},
	booktitle = {Proceedings of the 2Nd {International} {Conference} on {Trustworthy} {Global} {Computing}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Beringer, Lennart and Crégut, Pierre and Grégoire, Benjamin and Hofmann, Martin and Müller, Peter and Poll, Erik and Puebla, Germán and Stark, Ian and Vétillard, Eric},
	year = {2007},
	pages = {10--29}
}

@inproceedings{barthe_certificate_2006,
	address = {Berlin, Heidelberg},
	series = {{SAS}'06},
	title = {Certificate {Translation} for {Optimizing} {Compilers}},
	isbn = {3-540-37756-5 978-3-540-37756-6},
	url = {http://dx.doi.org/10.1007/11823230_20},
	doi = {10.1007/11823230_20},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Static} {Analysis}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Kunz, César and Rezk, Tamara},
	year = {2006},
	pages = {301--317}
}

@inproceedings{barthe_deriving_2006,
	address = {Washington, DC, USA},
	series = {{SP} '06},
	title = {Deriving an {Information} {Flow} {Checker} and {Certifying} {Compiler} for {Java}},
	isbn = {0-7695-2574-1},
	url = {https://doi.org/10.1109/SP.2006.13},
	doi = {10.1109/SP.2006.13},
	booktitle = {Proceedings of the 2006 {IEEE} {Symposium} on {Security} and {Privacy}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Rezk, Tamara and Naumann, David},
	year = {2006},
	pages = {230--242}
}

@article{barthe_preventing_2006,
	title = {Preventing {Timing} {Leaks} {Through} {Transactional} {Branching} {Instructions}},
	volume = {153},
	issn = {1571-0661},
	url = {http://dx.doi.org/10.1016/j.entcs.2005.10.031},
	doi = {10.1016/j.entcs.2005.10.031},
	number = {2},
	journal = {Electron. Notes Theor. Comput. Sci.},
	author = {Barthe, Gilles and Rezk, Tamara and Warnier, Martijn},
	month = may,
	year = {2006},
	keywords = {Security, Semantics, Non-interference, Program transformation, Timing leaks},
	pages = {33--55}
}

@book{barthe_construction_2006,
	address = {Secaucus, NJ, USA},
	title = {Construction and {Analysis} of {Safe}, {Secure}, and {Interoperable} {Smart} {Devices}: {Second} {International} {Workshop}, {CASSIS} 2005, {Nice}, {France}, {March} 8-11, 2005, ... {Papers} ({Lecture} {Notes} in {Computer} {Science})},
	isbn = {3-540-33689-3},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Barthe, Gilles and Gregoire, Benjamin and Huisman, Marieke and Lanet, Jean-Luis},
	year = {2006}
}

@inproceedings{barthe_defining_2006,
	address = {Berlin, Heidelberg},
	series = {{FLOPS}'06},
	title = {Defining and {Reasoning} {About} {Recursive} {Functions}: {A} {Practical} {Tool} for the {Coq} {Proof} {Assistant}},
	isbn = {3-540-33438-6 978-3-540-33438-5},
	url = {http://dx.doi.org/10.1007/11737414_9},
	doi = {10.1007/11737414_9},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Functional} and {Logic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Forest, Julien and Pichardie, David and Rusu, Vlad},
	year = {2006},
	pages = {114--129}
}

@article{barthe_remarks_2006,
	title = {Remarks on the {Equational} {Theory} of {Non}-normalizing {Pure} {Type} {Systems}},
	volume = {16},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796803004726},
	doi = {10.1017/S0956796803004726},
	number = {2},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles and Coquand, Thierry},
	month = mar,
	year = {2006},
	pages = {137--155}
}

@article{barthe_tool-assisted_2005,
	title = {Tool-{Assisted} {Specification} and {Verification} of {Typed} {Low}-{Level} {Languages}},
	volume = {35},
	issn = {0168-7433},
	url = {http://dx.doi.org/10.1007/s10817-005-0084-6},
	doi = {10.1007/s10817-005-0084-6},
	number = {4},
	journal = {J. Autom. Reason.},
	author = {Barthe, Gilles and Courtieu, Pierre and Dufay, Guillaume and Melo De Sousa, Simão},
	month = nov,
	year = {2005},
	keywords = {bytecode verification, Java Card, theorem proving, virtual machine},
	pages = {295--354}
}

@article{barthe_computational_2005,
	title = {A {Computational} {View} of {Implicit} {Coercions} in {Type} {Theory}},
	volume = {15},
	issn = {0960-1295},
	url = {http://dx.doi.org/10.1017/S0960129505004901},
	doi = {10.1017/S0960129505004901},
	number = {5},
	journal = {Mathematical. Structures in Comp. Sci.},
	author = {Barthe, Gilles},
	month = oct,
	year = {2005},
	pages = {839--874}
}

@inproceedings{barthe_precise_2005,
	address = {Washington, DC, USA},
	series = {{SEFM} '05},
	title = {Precise {Analysis} of {Memory} {Consumption} {Using} {Program} {Logics}},
	isbn = {0-7695-2435-4},
	url = {http://dx.doi.org/10.1109/SEFM.2005.34},
	doi = {10.1109/SEFM.2005.34},
	booktitle = {Proceedings of the {Third} {IEEE} {International} {Conference} on {Software} {Engineering} and {Formal} {Methods}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and Pavlova, Mariela and Schneider, Gerardo},
	year = {2005},
	pages = {86--95}
}

@inproceedings{barthe_proof_2006,
	address = {Berlin, Heidelberg},
	series = {{FAST}'05},
	title = {Proof {Obligations} {Preserving} {Compilation}},
	isbn = {3-540-32628-6 978-3-540-32628-1},
	url = {http://dx.doi.org/10.1007/11679219_9},
	doi = {10.1007/11679219_9},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {Formal} {Aspects} in {Security} and {Trust}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Rezk, Tamara and Saabas, Ando},
	year = {2006},
	pages = {112--126}
}

@inproceedings{barthe_practical_2005,
	address = {Berlin, Heidelberg},
	series = {{TLCA}'05},
	title = {Practical {Inference} for {Type}-based {Termination} in a {Polymorphic} {Setting}},
	isbn = {3-540-25593-1 978-3-540-25593-2},
	url = {http://dx.doi.org/10.1007/11417170_7},
	doi = {10.1007/11417170_7},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Typed} {Lambda} {Calculi} and {Applications}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Grégoire, Benjamin and Pastawski, Fernando},
	year = {2005},
	pages = {71--85}
}

@book{barthe_construction_2005,
	address = {Secaucus, NJ, USA},
	title = {Construction and {Analysis} of {Safe}, {Secure}, and {Interoperable} {Smart} {Devices}: {International} {Workshop}, {CASSIS} 2004, {Marseille}, {France}, {March} 10-14, 2004, ... {Papers} ({Lecture} {Notes} in {Computer} {Science})},
	isbn = {3-540-24287-2},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Barthe, Gilles and Burdy, Lilian and Huisman, Marieke and Lanet, Jean-Louis and Muntean, Traian},
	year = {2005}
}

@inproceedings{barthe_non-interference_2005,
	address = {New York, NY, USA},
	series = {{TLDI} '05},
	title = {Non-interference for a {JVM}-like {Language}},
	isbn = {1-58113-999-3},
	url = {http://doi.acm.org/10.1145/1040294.1040304},
	doi = {10.1145/1040294.1040304},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} {International} {Workshop} on {Types} in {Languages} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Barthe, Gilles and Rezk, Tamara},
	year = {2005},
	keywords = {confidentiality, type systems, low level languages},
	pages = {103--112}
}

@incollection{barthe_foundations_2005,
	address = {Berlin, Heidelberg},
	title = {Foundations of {Security} {Analysis} and {Design} {III}},
	isbn = {3-540-28955-0 978-3-540-28955-5},
	url = {http://dl.acm.org/citation.cfm?id=2137760.2137767},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Dufay, Guillaume},
	editor = {Aldini, Alessandro and Gorrieri, Roberto and Martinelli, Fabio},
	year = {2005},
	pages = {133--177}
}

@inproceedings{barthe_machine-checked_2006,
	address = {Berlin, Heidelberg},
	series = {{TYPES}'04},
	title = {A {Machine}-checked {Formalization} of the {Random} {Oracle} {Model}},
	isbn = {3-540-31428-8 978-3-540-31428-8},
	url = {http://dx.doi.org/10.1007/11617990_3},
	doi = {10.1007/11617990_3},
	booktitle = {Proceedings of the 2004 {International} {Conference} on {Types} for {Proofs} and {Programs}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Tarento, Sabrina},
	year = {2006},
	pages = {33--49}
}

@inproceedings{barthe_formally_2004,
	address = {New York, NY, USA},
	series = {{FMSE} '04},
	title = {Formally {Verifying} {Information} {Flow} {Type} {Systems} for {Concurrent} and {Thread} {Systems}},
	isbn = {1-58113-971-3},
	url = {http://doi.acm.org/10.1145/1029133.1029136},
	doi = {10.1145/1029133.1029136},
	booktitle = {Proceedings of the 2004 {ACM} {Workshop} on {Formal} {Methods} in {Security} {Engineering}},
	publisher = {ACM},
	author = {Barthe, Gilles and Nieto, Leonor Prensa},
	year = {2004},
	keywords = {concurrency, machine-checked proofs, noninterference},
	pages = {13--22}
}

@inproceedings{barthe_secure_2004,
	address = {Washington, DC, USA},
	series = {{CSFW} '04},
	title = {Secure {Information} {Flow} by {Self}-{Composition}},
	isbn = {0-7695-2169-X},
	url = {https://doi.org/10.1109/CSFW.2004.17},
	doi = {10.1109/CSFW.2004.17},
	booktitle = {Proceedings of the 17th {IEEE} {Workshop} on {Computer} {Security} {Foundations}},
	publisher = {IEEE Computer Society},
	author = {Barthe, Gilles and D'Argenio, Pedro R. and Rezk, Tamara},
	year = {2004},
	pages = {100--}
}

@article{barthe_type-based_2004,
	title = {Type-based {Termination} of {Recursive} {Definitions}},
	volume = {14},
	issn = {0960-1295},
	url = {http://dx.doi.org/10.1017/S0960129503004122},
	doi = {10.1017/S0960129503004122},
	number = {1},
	journal = {Mathematical. Structures in Comp. Sci.},
	author = {Barthe, G. and Frade, M. J. and Giménez, E. and Pinto, L. and Uustalu, T.},
	month = feb,
	year = {2004},
	pages = {97--141}
}

@article{barthe_introduction_2004,
	title = {Introduction to the {Special} {Issue} on {Dependent} {Type} {Theory} {Meets} {Practical} {Programming}},
	volume = {14},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796803004866},
	doi = {10.1017/S0956796803004866},
	number = {1},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles and Dybjen, Peter and Thiemann, Peter},
	month = jan,
	year = {2004},
	pages = {1--2}
}

@inproceedings{barthe_validation_2003,
	address = {Berlin, Heidelberg},
	series = {{RTA}'03},
	title = {Validation of the {JavaCard} {Platform} with {Implicit} {Induction} {Techniques}},
	isbn = {3-540-40254-3},
	url = {http://dl.acm.org/citation.cfm?id=1759148.1759174},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Rewriting} {Techniques} and {Applications}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Stratulat, Sorin},
	year = {2003},
	pages = {337--351}
}

@article{barthe_setoids_2003,
	title = {Setoids in {Type} {Theory}},
	volume = {13},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796802004501},
	doi = {10.1017/S0956796802004501},
	number = {2},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles and Capretta, Venanzio and Pons, Olivier},
	month = mar,
	year = {2003},
	pages = {261--293}
}

@inproceedings{barthe_pure_2003,
	address = {New York, NY, USA},
	series = {{POPL} '03},
	title = {Pure {Patterns} {Type} {Systems}},
	isbn = {1-58113-628-5},
	url = {http://doi.acm.org/10.1145/604131.604152},
	doi = {10.1145/604131.604152},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Barthe, Gilles and Cirstea, Horatiu and Kirchner, Claude and Liquori, Luigi},
	year = {2003},
	keywords = {patterns, Curry-Howard, Lambda-calculus, logics, matching, pure type systems, rewriting},
	pages = {250--261}
}

@article{barthe_pure_2003-1,
	title = {Pure {Patterns} {Type} {Systems}},
	volume = {38},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/640128.604152},
	doi = {10.1145/640128.604152},
	number = {1},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Cirstea, Horatiu and Kirchner, Claude and Liquori, Luigi},
	month = jan,
	year = {2003},
	keywords = {patterns, Curry-Howard, Lambda-calculus, logics, matching, pure type systems, rewriting},
	pages = {250--261}
}

@inproceedings{barthe_tool-assisted_2002,
	address = {London, UK, UK},
	series = {{AMAST} '02},
	title = {Tool-{Assisted} {Specification} and {Verification} of the {JavaCard} {Platform}},
	isbn = {3-540-44144-1},
	url = {http://dl.acm.org/citation.cfm?id=646061.676163},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Algebraic} {Methodology} and {Software} {Technology}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Courtieu, Pierre and Dufay, Guillaume and Sousa, Simão Melo de},
	year = {2002},
	pages = {41--59}
}

@inproceedings{barthe_efficient_2002,
	address = {London, UK, UK},
	series = {{TPHOLs} '02},
	title = {Efficient {Reasoning} {About} {Executable} {Specifications} in {Coq}},
	isbn = {3-540-44039-9},
	url = {http://dl.acm.org/citation.cfm?id=646529.695212},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Theorem} {Proving} in {Higher} {Order} {Logics}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Courtieu, Pierre},
	year = {2002},
	pages = {31--46}
}

@inproceedings{barthe_compositional_2002,
	address = {London, UK, UK},
	series = {{FASE} '02},
	title = {Compositional {Verification} of {Secure} {Applet} {Interactions}},
	isbn = {3-540-43353-8},
	url = {http://dl.acm.org/citation.cfm?id=645370.651302},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Gurov, Dilian and Huisman, Marieke},
	year = {2002},
	pages = {15--32}
}

@inproceedings{barthe_formal_2002,
	address = {London, UK, UK},
	series = {{VMCAI} '02},
	title = {A {Formal} {Correspondence} {Between} {Offensive} and {Defensive} {JavaCard} {Virtual} {Machines}},
	isbn = {3-540-43631-6},
	url = {http://dl.acm.org/citation.cfm?id=646541.696190},
	booktitle = {Revised {Papers} from the {Third} {International} {Workshop} on {Verification}, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Dufay, Guillaume and Jakubiec, Line and Sousa, Simão Melo de},
	year = {2002},
	pages = {32--45}
}

@article{barthe_cps_2002,
	title = {{CPS} {Translating} {Inductive} and {Coinductive} {Types}},
	volume = {37},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/509799.503043},
	doi = {10.1145/509799.503043},
	number = {3},
	journal = {SIGPLAN Not.},
	author = {Barthe, Gilles and Uustalu, Tarmo},
	month = jan,
	year = {2002},
	keywords = {classical logic and control, CPS translations, dependent types, inductive and coinductive types, typed \${\textbackslash}lambda\$-calculi},
	pages = {131--142}
}

@inproceedings{barthe_cps_2002-1,
	address = {New York, NY, USA},
	series = {{PEPM} '02},
	title = {{CPS} {Translating} {Inductive} and {Coinductive} {Types}},
	isbn = {1-58113-455-X},
	url = {http://doi.acm.org/10.1145/503032.503043},
	doi = {10.1145/503032.503043},
	booktitle = {Proceedings of the 2002 {ACM} {SIGPLAN} {Workshop} on {Partial} {Evaluation} and {Semantics}-based {Program} {Manipulation}},
	publisher = {ACM},
	author = {Barthe, Gilles and Uustalu, Tarmo},
	year = {2002},
	keywords = {classical logic and control, CPS translations, dependent types, inductive and coinductive types, typed \${\textbackslash}lambda\$-calculi},
	pages = {131--142}
}

@inproceedings{barthe_jakarta:_2001,
	address = {London, UK, UK},
	series = {E-{SMART} '01},
	title = {Jakarta: {A} {Toolset} for {Reasoning} {About} {JavaCard}},
	isbn = {3-540-42610-8},
	url = {http://dl.acm.org/citation.cfm?id=646803.706113},
	booktitle = {Proceedings of the {International} {Conference} on {Research} in {Smart} {Cards}: {Smart} {Card} {Programming} and {Security}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Dufay, Guillaume and Huisman, Marieke and Sousa, Simão Melo de},
	year = {2001},
	pages = {2--18}
}

@article{barthe_induction_2001,
	title = {An {Induction} {Principle} for {Pure} {Type} {Systems}},
	volume = {266},
	issn = {0304-3975},
	url = {http://dx.doi.org/10.1016/S0304-3975(00)00373-X},
	doi = {10.1016/S0304-3975(00)00373-X},
	number = {1-2},
	journal = {Theor. Comput. Sci.},
	author = {Barthe, Gilles and Hatcliff, John and Sørensen, Morten Heine Bo},
	month = sep,
	year = {2001},
	pages = {773--818}
}

@article{barthe_call_2001,
	title = {{CALL} {FOR} {PAPERS}: {Special} {Issue} on {Dependent} {Type} {Theory} {Meets} {Programming} {Practice}},
	volume = {11},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796801004105},
	doi = {10.1017/S0956796801004105},
	number = {4},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles and Dybjer, Peter and Thiemann, Peter},
	month = jul,
	year = {2001},
	pages = {437--437}
}

@inproceedings{barthe_type_2001,
	address = {London, UK, UK},
	series = {{FoSSaCS} '01},
	title = {Type {Isomorphisms} and {Proof} {Reuse} in {Dependent} {Type} {Theory}},
	isbn = {3-540-41864-4},
	url = {http://dl.acm.org/citation.cfm?id=646793.704711},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Foundations} of {Software} {Science} and {Computation} {Structures}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Pons, Olivier},
	year = {2001},
	pages = {57--71}
}

@inproceedings{barthe_formal_2001,
	address = {London, UK, UK},
	series = {{ESOP} '01},
	title = {A {Formal} {Executable} {Semantics} of the {JavaCard} {Platform}},
	isbn = {3-540-41862-8},
	url = {http://dl.acm.org/citation.cfm?id=645395.757559},
	booktitle = {Proceedings of the 10th {European} {Symposium} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Dufay, Guillaume and Jakubiec, Line and Serpette, Bernard P. and Sousa, Simão Melo de},
	year = {2001},
	pages = {302--319}
}

@inproceedings{barthe_static_2000,
	address = {Berlin, Heidelberg},
	series = {{LPAR}'00},
	title = {Static {Reduction} {Analysis} for {Imperative} {Object} {Oriented} {Languages}},
	isbn = {3-540-41285-9},
	url = {http://dl.acm.org/citation.cfm?id=1765236.1765267},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Logic} for {Programming} and {Automated} {Reasoning}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Serpette, Bernard Paul},
	year = {2000},
	pages = {344--361}
}

@inproceedings{barthe_introduction_2002,
	address = {London, UK, UK},
	title = {An {Introduction} to {Dependent} {Type} {Theory}},
	isbn = {3-540-44044-5},
	url = {http://dl.acm.org/citation.cfm?id=647424.725800},
	booktitle = {Applied {Semantics}, {International} {Summer} {School}, {APPSEM} 2000, {Caminha}, {Portugal}, {September} 9-15, 2000, {Advanced} {Lectures}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Coquand, Thierry},
	year = {2002},
	pages = {1--41}
}

@article{barthe_domain-free_2000,
	title = {Domain-free {Pure} {Type} {Systems}},
	volume = {10},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796800003750},
	doi = {10.1017/S0956796800003750},
	number = {5},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles and Sørensen, Morten Heine},
	month = sep,
	year = {2000},
	pages = {417--452}
}

@inproceedings{barthe_constructor_2000,
	address = {London, UK, UK},
	series = {{FOSSACS} '00},
	title = {Constructor {Subtyping} in the {Calculus} of {Inductive} {Constructions}},
	isbn = {3-540-67257-5},
	url = {http://dl.acm.org/citation.cfm?id=646792.704689},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {Foundations} of {Software} {Science} and {Computation} {Structures}: {Held} {As} {Part} of the {Joint} {European} {Conferences} on {Theory} and {Practice} of {Software},{ETAPS} 2000},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Raamsdonk, Femke van},
	year = {2000},
	pages = {17--34}
}

@inproceedings{barthe_partial_1999,
	address = {London, UK, UK},
	series = {{FLOPS} '99},
	title = {Partial {Evaluation} and {Non}-inference for {Object} {Calculi}},
	isbn = {3-540-66677-X},
	url = {http://dl.acm.org/citation.cfm?id=646189.683543},
	booktitle = {Proceedings of the 4th {Fuji} {International} {Symposium} on {Functional} and {Logic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Serpette, Bernard P.},
	year = {1999},
	pages = {53--67}
}

@article{barthe_type-checking_1999,
	title = {Type-checking {Injective} {Pure} {Type} {Systems}},
	volume = {9},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796899003573},
	doi = {10.1017/S0956796899003573},
	number = {6},
	journal = {J. Funct. Program.},
	author = {Barthe, Gilles},
	month = nov,
	year = {1999},
	pages = {675--698}
}

@article{barthe_cps_1999,
	title = {{CPS} {Translations} and {Applications}: {The} {Cube} and {Beyond}},
	volume = {12},
	issn = {1388-3690},
	url = {https://doi.org/10.1023/A:1010000206149},
	doi = {10.1023/A:1010000206149},
	number = {2},
	journal = {Higher Order Symbol. Comput.},
	author = {Barthe, Gilles and Hatcliff, John and Sørensen, Morten Heine B.},
	month = sep,
	year = {1999},
	keywords = {continuation-passing style{\textless}/kwd{\textgreater}, dependent types{\textless}/kwd{\textgreater}, pure type systems{\textless}/kwd{\textgreater}, the lambda cube{\textless}/kwd{\textgreater}},
	pages = {125--170}
}

@inproceedings{barthe_constructor_1999,
	address = {London, UK, UK},
	series = {{ESOP} '99},
	title = {Constructor {Subtyping}},
	isbn = {3-540-65699-5},
	url = {http://dl.acm.org/citation.cfm?id=645393.651892},
	booktitle = {Proceedings of the 8th {European} {Symposium} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Frade, Maria João},
	year = {1999},
	pages = {109--127}
}

@inproceedings{barthe_expanding_1999,
	address = {London, UK, UK},
	series = {{FoSSaCS} '99},
	title = {Expanding the {Cube}},
	isbn = {3-540-65719-3},
	url = {http://dl.acm.org/citation.cfm?id=646791.759639},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Foundations} of {Software} {Science} and {Computation} {Structure}, {Held} {As} {Part} of the {European} {Joint} {Conferences} on the {Theory} and {Practice} of {Software}, {ETAPS}'99},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1999},
	pages = {90--103}
}

@inproceedings{barthe_semi-full_1998,
	address = {London, UK, UK},
	series = {{MFCS} '98},
	title = {The {Semi}-{Full} {Closure} of {Pure} {Type} {Systems}},
	isbn = {3-540-64827-5},
	url = {http://dl.acm.org/citation.cfm?id=645727.667526},
	booktitle = {Proceedings of the 23rd {International} {Symposium} on {Mathematical} {Foundations} of {Computer} {Science}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1998},
	pages = {316--325}
}

@inproceedings{barthe_existence_1999,
	address = {London, UK, UK},
	title = {Existence and {Uniqueness} of {Normal} {Forms} in {Pure} {Type} {Systems} with betaeta-{Conversion}},
	isbn = {3-540-65922-6},
	url = {http://dl.acm.org/citation.cfm?id=647848.736924},
	booktitle = {Proceedings of the 12th {International} {Workshop} on {Computer} {Science} {Logic}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1999},
	pages = {241--259}
}

@inproceedings{barthe_relevance_1998,
	address = {London, UK, UK},
	series = {{ICALP} '98},
	title = {The {Relevance} of {Proof}-{Irrelevance}},
	isbn = {3-540-64781-3},
	url = {http://dl.acm.org/citation.cfm?id=646252.686172},
	booktitle = {Proceedings of the 25th {International} {Colloquium} on {Automata}, {Languages} and {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1998},
	pages = {755--768}
}

@article{barthe_monadic_1998,
	title = {Monadic {Type} {Systems}},
	volume = {10},
	issn = {1571-0661},
	url = {http://dx.doi.org/10.1016/S1571-0661(05)80691-7},
	doi = {10.1016/S1571-0661(05)80691-7},
	number = {C},
	journal = {Electron. Notes Theor. Comput. Sci.},
	author = {Barthe, Gilles and Hatcliff, John and Thiemann, Peter},
	month = may,
	year = {1998},
	keywords = {monads, pure type systems, Functional programming, operational semantics, polymorphism},
	pages = {54--120}
}

@inproceedings{barthe_termination_1997,
	address = {London, UK, UK},
	series = {{ALP} '97-{HOA} '97},
	title = {Termination of {Algebraic} {Type} {Systems}: {The} {Syntactic} {Approach}},
	isbn = {3-540-63459-2},
	url = {http://dl.acm.org/citation.cfm?id=647709.734957},
	booktitle = {Proceedings of the 6th {International} {Joint} {Conference} on {Algebraic} and {Logic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Raamsdonk, Femke van},
	year = {1997},
	pages = {174--193}
}

@inproceedings{barthe_reflections_1997,
	address = {London, UK, UK},
	series = {{PLILP} '97},
	title = {Reflections on {Reflections}},
	isbn = {3-540-63398-7},
	url = {http://dl.acm.org/citation.cfm?id=646452.692951},
	booktitle = {Proceedings of the9th {International} {Symposium} on {Programming} {Languages}: {Implementations}, {Logics}, and {Programs}: {Including} a {Special} {Trach} on {Declarative} {Programming} {Languages} in {Education}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Hatcliff, John and Sørensen, Morten Heine},
	year = {1997},
	pages = {241--258}
}

@inproceedings{barthe_domain-free_1997,
	address = {London, UK, UK},
	series = {{LFCS} '97},
	title = {Domain-{Free} {Pure} {Type} {Systems}},
	isbn = {3-540-63045-7},
	url = {http://dl.acm.org/citation.cfm?id=645682.664433},
	booktitle = {Proceedings of the 4th {International} {Symposium} on {Logical} {Foundations} of {Computer} {Science}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Sørensen, Morten Heine},
	year = {1997},
	pages = {9--20}
}

@inproceedings{barthe_subject_1997,
	address = {London, UK, UK},
	series = {{CSL} '96},
	title = {On the {Subject} {Reduction} {Property} for {Algebraic} {Type} {Systems}},
	isbn = {3-540-63172-0},
	url = {http://dl.acm.org/citation.cfm?id=647846.760809},
	booktitle = {Selected {Papers} from the10th {International} {Workshop} on {Computer} {Science} {Logic}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Melliès, Paul-André},
	year = {1997},
	pages = {34--57}
}

@inproceedings{barthe_towards_1996,
	address = {London, UK, UK},
	series = {{DISCO} '96},
	title = {Towards {Lean} {Proof} {Checking}},
	isbn = {3-540-61697-7},
	url = {http://dl.acm.org/citation.cfm?id=646138.680765},
	booktitle = {Proceedings of the {International} {Symposium} on {Design} and {Implementation} of {Symbolic} {Computation} {Systems}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Elbers, Hugo},
	year = {1996},
	pages = {61--62}
}

@inproceedings{barthe_congruence_1996,
	address = {London, UK, UK},
	series = {{CSL} '95},
	title = {Congruence {Types}},
	isbn = {3-540-61377-3},
	url = {http://dl.acm.org/citation.cfm?id=647845.736731},
	booktitle = {Selected {Papers} from the9th {International} {Workshop} on {Computer} {Science} {Logic}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Geuvers, Herman},
	year = {1996},
	pages = {36--51}
}

@inproceedings{barthe_modular_1996,
	address = {London, UK, UK},
	series = {{HOA} '95},
	title = {Modular {Properties} of {Algebraic} {Type} {Systems}},
	isbn = {3-540-61254-8},
	url = {http://dl.acm.org/citation.cfm?id=647964.743817},
	booktitle = {Selected {Papers} from the {Second} {International} {Workshop} on {Higher}-{Order} {Algebra}, {Logic}, and {Term} {Rewriting}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Geuvers, Herman},
	year = {1996},
	pages = {37--56}
}

@inproceedings{barthe_two-level_1996,
	address = {London, UK, UK},
	series = {{TYPES} '95},
	title = {A {Two}-{Level} {Approach} {Towards} {Lean} {Proof}-{Checking}},
	isbn = {3-540-61780-9},
	url = {http://dl.acm.org/citation.cfm?id=646536.695867},
	booktitle = {Selected {Papers} from the {International} {Workshop} on {Types} for {Proofs} and {Programs}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles and Ruys, Mark and Barendregt, Henk},
	year = {1996},
	pages = {16--35}
}

@inproceedings{barthe_implicit_1996,
	address = {London, UK, UK},
	series = {{TYPES} '95},
	title = {Implicit {Coercions} in {Type} {Systems}},
	isbn = {3-540-61780-9},
	url = {http://dl.acm.org/citation.cfm?id=646536.695866},
	booktitle = {Selected {Papers} from the {International} {Workshop} on {Types} for {Proofs} and {Programs}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1996},
	pages = {1--15}
}

@inproceedings{barthe_extensions_1995,
	address = {London, UK, UK},
	series = {{TLCA} '95},
	title = {Extensions of {Pure} {Type} {Systems}},
	isbn = {3-540-59048-X},
	url = {http://dl.acm.org/citation.cfm?id=645892.671589},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Typed} {Lambda} {Calculi} and {Applications}},
	publisher = {Springer-Verlag},
	author = {Barthe, Gilles},
	year = {1995},
	pages = {16--31}
}

@misc{noauthor_jasmin_nodate,
	title = {Jasmin},
	url = {https://dl.acm.org/citation.cfm?id=3134078},
	urldate = {2018-04-16},
	file = {Jasmin:C\:\\Users\\Anna\\Zotero\\storage\\EKC3GMTX\\citation.html:text/html}
}

@misc{noauthor_morning_nodate-1,
	title = {The {Morning} {Paper}: {Securing} wireless neurostimulators},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-securing-wireless-neurostimulators?e=6b9727817f},
	urldate = {2018-04-17},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\K5JYES78\\the-morning-paper-securing-wireless-neurostimulators.html:text/html}
}

@misc{noauthor_is_nodate,
	title = {Is {Your} {Software} on {Dope}?},
	url = {https://dl.acm.org/citation.cfm?id=3089363},
	urldate = {2018-04-17},
	file = {Is Your Software on Dope?:C\:\\Users\\Anna\\Zotero\\storage\\UNLL744N\\citation.html:text/html}
}

@misc{noauthor_thesis_nodate,
	title = {Thesis {Guide}},
	url = {https://thesisguide.org/},
	abstract = {Advice for great computer science thesis projects.},
	language = {en},
	urldate = {2018-04-17},
	journal = {Thesis Guide},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ERF88ZVS\\thesisguide.org.html:text/html}
}

@article{barthe_computer-aided_2015,
	title = {Computer-aided verification in mechanism design},
	abstract = {In mechanism design, the gold standard solution concepts are {\textbackslash}emph\{dominant strategy incentive compatibility\}, and {\textbackslash}emph\{Bayesian incentive compatibility\}. These simple solution concepts relieve the (possibly unsophisticated) bidders from the need to engage in complicated strategizing. This is a clean story when the mechanism is "obviously" incentive compatible, as with a simple second price auction. However, when the proof of incentive compatibility is complex, unsophisticated agents may strategize in unpredictable ways if they are not {\textbackslash}emph\{convinced\} of the incentive properties. In practice, this concern may limit the mechanism designer to {\textbackslash}emph\{simple\} mechanisms, simple enough that agents can easily understand.
To alleviate this problem, we propose to use techniques from computer-aided verification in order to construct formal proofs of incentive properties. Because formal proofs can be automatically checked by (trustworthy) computer programs, agents do not need to verify complicated paper proofs by themselves. To confirm the viability of this approach, we present the verification of one sophisticated mechanism: the generic reduction from Bayesian incentive compatible mechanism design to algorithm design given by Hartline, Kleinberg, and Malekian (2011). This mechanism presents new challenges for formal verification, including essential use of randomness from both the execution of the mechanism and from prior type distributions. As a by-product, we also verify the entire family of mechanisms derived via this reduction.},
	author = {Barthe, Gilles and Gaboardi, Marco and Jesús Gallego Arias, Emilio and Hsu, Justin and Roth, Aaron and Strub, Pierre-Yves},
	month = feb,
	year = {2015},
	keywords = {20180419GillesBarthe},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2015 - Computer-aided verification in mechanism design.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NEGRKYZ6\\Barthe et al. - 2015 - Computer-aided verification in mechanism design.pdf:application/pdf}
}

@inproceedings{barthe_differentially_2016,
	address = {New York, NY, USA},
	series = {{CCS} '16},
	title = {Differentially {Private} {Bayesian} {Programming}},
	isbn = {978-1-4503-4139-4},
	url = {http://doi.acm.org/10.1145/2976749.2978371},
	doi = {10.1145/2976749.2978371},
	abstract = {We present PrivInfer, an expressive framework for writing and verifying differentially private Bayesian machine learning algorithms. Programs in PrivInfer are written in a rich functional probabilistic programming language with constructs for performing Bayesian inference. Then, differential privacy of programs is established using a relational refinement type system, in which refinements on probability types are indexed by a metric on distributions. Our framework leverages recent developments in Bayesian inference, probabilistic programming languages, and in relational refinement types. We demonstrate the expressiveness of PrivInfer by verifying privacy for several examples of private Bayesian inference.},
	urldate = {2018-04-17},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Farina, Gian Pietro and Gaboardi, Marco and Arias, Emilio Jesus Gallego and Gordon, Andy and Hsu, Justin and Strub, Pierre-Yves},
	year = {2016},
	keywords = {Bayesian learning, differential privacy, probabilistic programming, type systems, 20180419GillesBarthe},
	pages = {68--79},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2016 - Differentially Private Bayesian Programming.pdf:C\:\\Users\\Anna\\Zotero\\storage\\H4NXYTMA\\Barthe et al. - 2016 - Differentially Private Bayesian Programming.pdf:application/pdf}
}

@inproceedings{barthe_advanced_2016,
	address = {New York, NY, USA},
	series = {{CCS} '16},
	title = {Advanced {Probabilistic} {Couplings} for {Differential} {Privacy}},
	isbn = {978-1-4503-4139-4},
	url = {http://doi.acm.org/10.1145/2976749.2978391},
	doi = {10.1145/2976749.2978391},
	abstract = {Differential privacy is a promising formal approach to data privacy, which provides a quantitative bound on the privacy cost of an algorithm that operates on sensitive information. Several tools have been developed for the formal verification of differentially private algorithms, including program logics and type systems. However, these tools do not capture fundamental techniques that have emerged in recent years, and cannot be used for reasoning about cutting-edge differentially private algorithms. Existing techniques fail to handle three broad classes of algorithms: 1) algorithms where privacy depends on accuracy guarantees, 2) algorithms that are analyzed with the advanced composition theorem, which shows slower growth in the privacy cost, 3) algorithms that interactively accept adaptive inputs. We address these limitations with a new formalism extending apRHL, a relational program logic that has been used for proving differential privacy of non-interactive algorithms, and incorporating aHL, a (non-relational) program logic for accuracy properties. We illustrate our approach through a single running example, which exemplifies the three classes of algorithms and explores new variants of the Sparse Vector technique, a well-studied algorithm from the privacy literature. We implement our logic in EasyCrypt, and formally verify privacy. We also introduce a novel coupling technique called optimal subset coupling that may be of independent interest.},
	urldate = {2018-04-17},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Barthe, Gilles and Fong, Noémie and Gaboardi, Marco and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	year = {2016},
	keywords = {differential privacy, probabilistic couplings, relational hoare logic, 20180419GillesBarthe},
	pages = {55--67},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2016 - Advanced Probabilistic Couplings for Differential .pdf:C\:\\Users\\Anna\\Zotero\\storage\\D8Z2RKRX\\Barthe et al. - 2016 - Advanced Probabilistic Couplings for Differential .pdf:application/pdf}
}

@inproceedings{barthe_proving_2016,
	address = {New York, NY, USA},
	series = {{LICS} '16},
	title = {Proving {Differential} {Privacy} via {Probabilistic} {Couplings}},
	isbn = {978-1-4503-4391-6},
	url = {http://doi.acm.org/10.1145/2933575.2934554},
	doi = {10.1145/2933575.2934554},
	abstract = {Over the last decade, differential privacy has achieved widespread adoption within the privacy community. Moreover, it has attracted significant attention from the verification community, resulting in several successful tools for formally proving differential privacy. Although their technical approaches vary greatly, all existing tools rely on reasoning principles derived from the composition theorem of differential privacy. While this suffices to verify most common private algorithms, there are several important algorithms whose privacy analysis does not rely solely on the composition theorem. Their proofs are significantly more complex, and are currently beyond the reach of verification tools. In this paper, we develop compositional methods for formally verifying differential privacy for algorithms whose analysis goes beyond the composition theorem. Our methods are based on deep connections between differential privacy and probabilistic couplings, an established mathematical tool for reasoning about stochastic processes. Even when the composition theorem is not helpful, we can often prove privacy by a coupling argument. We demonstrate our methods on two algorithms: the Exponential mechanism and the Above Threshold algorithm, the critical component of the famous Sparse Vector algorithm. We verify these examples in a relational program logic apRHL+, which can construct approximate couplings. This logic extends the existing apRHL logic with more general rules for the Laplace mechanism and the one-sided Laplace mechanism, and new structural rules enabling pointwise reasoning about privacy; all the rules are inspired by the connection with coupling. While our paper is presented from a formal verification perspective, we believe that its main insight is of independent interest for the differential privacy community.},
	urldate = {2018-04-17},
	booktitle = {Proceedings of the 31st {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {ACM},
	author = {Barthe, Gilles and Gaboardi, Marco and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	year = {2016},
	keywords = {20180419GillesBarthe},
	pages = {749--758},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Barthe et al. - 2016 - Proving Differential Privacy via Probabilistic Cou.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ANDHCY6E\\Barthe et al. - 2016 - Proving Differential Privacy via Probabilistic Cou.pdf:application/pdf}
}

@inproceedings{ambrona_automated_2016,
	address = {New York, NY, USA},
	title = {Automated {Unbounded} {Analysis} of {Cryptographic} {Constructions} in the {Generic} {Group} {Model}},
	isbn = {978-3-662-49895-8},
	url = {https://doi.org/10.1007/978-3-662-49896-5_29},
	doi = {10.1007/978-3-662-49896-5_29},
	abstract = {We develop a new method to automatically prove security statements in the Generic Group Model as they occur in actual papers. We start by defining i a general language to describe security definitions, ii a class of logical formulas that characterize how an adversary can win, and iii a translation from security definitions to such formulas. We prove a Master Theorem that relates the security of the construction to the existence of a solution for the associated logical formulas. Moreover, we define a constraint solving algorithm that proves the security of a construction by proving the absence of solutions. We implement our approach in a fully automated tool, the \$\${\textbackslash}mathsf \{gga\}{\textasciicircum}\{{\textbackslash}infty \}\$\$gga∞ï¾¿tool, and use it to verify different examples from the literature. The results improve on the tool by Barthe et al. CRYPTO'14, PKC'15: for many constructions, \$\${\textbackslash}mathsf \{gga\}{\textasciicircum}\{{\textbackslash}infty \}\$\$gga∞ï¾¿succeeds in proving standard unbounded security, whereas Barthe's tool is only able to prove security for a small number of oracle queries.},
	urldate = {2018-04-17},
	booktitle = {Proceedings, {Part} {II}, of the 35th {Annual} {International} {Conference} on {Advances} in {Cryptology} — {EUROCRYPT} 2016 - {Volume} 9666},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Ambrona, Miguel and Barthe, Gilles and Schmidt, Benedikt},
	year = {2016},
	keywords = {20180419GillesBarthe},
	pages = {822--851},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;Ambrona et al. - 2016 - Automated Unbounded Analysis of Cryptographic Cons.pdf:C\:\\Users\\Anna\\Documents\\Paper\\Ambrona et al. - 2016 - Automated Unbounded Analysis of Cryptographic Cons.pdf:application/pdf}
}

@misc{noauthor_morning_nodate-2,
	title = {The {Morning} {Paper}: {Google} workloads for consumer devices - mitigating data movement bottlenecks},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-google-workloads-for-consumer-devices-mitigating-data-movement-bottlenecks?e=6b9727817f},
	urldate = {2018-04-18},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\AM4G7I5F\\the-morning-paper-google-workloads-for-consumer-devices-mitigating-data-movement-bottlenecks.html:text/html}
}

@inproceedings{almeida_verifiable_2016,
	address = {New York, NY, USA},
	series = {{FSE} 2016},
	title = {Verifiable {Side}-{Channel} {Security} of {Cryptographic} {Implementations}: {Constant}-{Time} {MEE}-{CBC}},
	isbn = {978-3-662-52992-8},
	shorttitle = {Verifiable {Side}-{Channel} {Security} of {Cryptographic} {Implementations}},
	url = {https://doi.org/10.1007/978-3-662-52993-5_9},
	doi = {10.1007/978-3-662-52993-5_9},
	abstract = {We provide further evidence that implementing software countermeasures against timing attacks is a non-trivial task and requires domain-specific software development processes: we report an implementation bug in the s2n library, recently released by AWS Labs. This bug now fixed allowed bypassing the balancing countermeasures against timing attacks deployed in the implementation of the MAC-then-Encode-then-CBC-Encrypt MEE-CBC component, creating a timing side-channel similar to that exploited by Lucky 13. Although such an attack could only be launched when the MEE-CBC component is used in isolation --- Albrecht and Paterson recently confirmed in independent work that s2n's second line of defence, once reinforced, provides adequate mitigation against current adversary capabilities --- its existence serves as further evidence to the fact that conventional software validation processes are not effective in the study and validation of security properties. To solve this problem, we define a methodology for proving security of implementations in the presence of timing attackers: first, prove black-box security of an algorithmic description of a cryptographic construction; then, establish functional correctness of an implementation with respect to the algorithmic description; and finally, prove that the implementation is leakage secure. We present a proof-of-concept application of our methodology to MEE-CBC, bringing together three different formal verification tools to produce an assembly implementation of this construction that is verifiably secure against adversaries with access to some timing leakage. Our methodology subsumes previous work connecting provable security and side-channel analysis at the implementation level, and supports the verification of a much larger case study. Our case study itself provides the first provable security validation of complex timing countermeasures deployed, for example, in OpenSSL.},
	urldate = {2018-04-18},
	booktitle = {Revised {Selected} {Papers} of the 23rd {International} {Conference} on {Fast} {Software} {Encryption} - {Volume} 9783},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Almeida, José Bacelar and Barbosa, Manuel and Barthe, Gilles and Dupressoir, François},
	year = {2016},
	keywords = {20180419GillesBarthe},
	pages = {163--184},
	file = {20180416-17_GillesBarthe.xlsx:C\:\\Users\\Anna\\Documents\\50_Research\\20180416-17_GillesBarthe.xlsx:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet}
}

@article{barthe_programming_2016,
	title = {Programming {Language} {Techniques} for {Differential} {Privacy}},
	volume = {3},
	issn = {2372-3491},
	url = {http://doi.acm.org/10.1145/2893582.2893591},
	doi = {10.1145/2893582.2893591},
	abstract = {Differential privacy is rigorous framework for stating and enforcing privacy guarantees on computations over sensitive data. Informally, differential privacy ensures that the presence or absence of a single individual in a database has only a negligible statistical effect on the computation's result. Many specific algorithms have been proved differentially private, but manually checking that a given program is differentially private can be subtle, tedious, or both. This approach becomes unfeasible when larger programs are considered.},
	number = {1},
	urldate = {2018-04-18},
	journal = {ACM SIGLOG News},
	author = {Barthe, Gilles and Gaboardi, Marco and Hsu, Justin and Pierce, Benjamin},
	month = feb,
	year = {2016},
	keywords = {20180419GillesBarthe},
	pages = {34--53},
	file = {Barthe et al. - 2016 - Programming Language Techniques for Differential P.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JXD2385Q\\Barthe et al. - 2016 - Programming Language Techniques for Differential P.pdf:application/pdf}
}

@misc{noauthor_morning_nodate-3,
	title = {The {Morning} {Paper}: {Darwin} - a genomics co-processor provides up to 15,000x acceleration on long read assembly},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-darwin-a-genomics-co-processor-provides-up-to-15000x-acceleration-on-long-read-assembly?e=6b9727817f},
	urldate = {2018-04-19},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\Q3JLPAA5\\the-morning-paper-darwin-a-genomics-co-processor-provides-up-to-15000x-acceleration-on-long-rea.html:text/html}
}

@misc{oracle_and/or_its_affiliate_cipher_2018,
	title = {Cipher ({Java} {SE} 10 \& {JDK} 10 )},
	url = {https://docs.oracle.com/javase/10/docs/api/javax/crypto/Cipher.html},
	urldate = {2018-04-19},
	author = {Oracle and/or its affiliate},
	year = {2018},
	file = {Cipher (Java SE 10 & JDK 10 ):C\:\\Users\\Anna\\Zotero\\storage\\S9YQ7V4E\\Cipher.html:text/html}
}

@misc{oracle_and/or_its_affiliate_pbekeyspec_2018,
	title = {{PBEKeySpec} ({Java} {SE} 10 \& {JDK} 10 )},
	url = {https://docs.oracle.com/javase/10/docs/api/javax/crypto/spec/PBEKeySpec.html},
	urldate = {2018-04-19},
	author = {Oracle and/or its affiliate},
	year = {2018},
	file = {PBEKeySpec (Java SE 10 & JDK 10 ):C\:\\Users\\Anna\\Zotero\\storage\\TFRXQ55G\\PBEKeySpec.html:text/html}
}

@misc{noauthor_morning_nodate-4,
	title = {The {Morning} {Paper}: {The} architectural implications of autonomous driving - constraints and acceleration},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-the-architectural-implications-of-autonomous-driving-constraints-and-acceleration?e=6b9727817f},
	urldate = {2018-04-20},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\M6INNWSL\\the-morning-paper-the-architectural-implications-of-autonomous-driving-constraints-and-accelera.html:text/html}
}

@misc{noauthor_notitle_nodate,
	url = {https://jevopi.blogspot.co.uk/2010/05/latex-listings-and-labels.html}
}

@misc{noauthor_jevopis_nodate,
	title = {jevopi's little blog: {LaTeX}: {Listings} and labels},
	url = {https://jevopi.blogspot.de/2010/05/latex-listings-and-labels.html},
	urldate = {2018-04-24},
	file = {jevopi's little blog\: LaTeX\: Listings and labels:C\:\\Users\\Anna\\Zotero\\storage\\UWZDMWPA\\latex-listings-and-labels.html:text/html}
}

@misc{noauthor_morning_nodate-5,
	title = {The {Morning} {Paper}: {Espresso} - brewing {Java} for more non-volatility with non-volatile memory},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-espresso-brewing-java-for-more-non-volatility-with-non-volatile-memory?e=6b9727817f},
	urldate = {2018-04-25},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\LFZMWLI8\\the-morning-paper-espresso-brewing-java-for-more-non-volatility-with-non-volatile-memory.html:text/html}
}

@article{wu_espresso:_2017,
	title = {Espresso: {Brewing} {Java} {For} {More} {Non}-{Volatility} with {Non}-volatile {Memory}},
	shorttitle = {Espresso},
	url = {http://arxiv.org/abs/1710.09968},
	abstract = {Fast, byte-addressable non-volatile memory (NVM) embraces both near-DRAM latency and disk-like persistence, which has generated considerable interests to revolutionize system software stack and programming models. However, it is less understood how NVM can be combined with managed runtime like Java virtual machine (JVM) to ease persistence management. This paper proposes Espresso, a holistic extension to Java and its runtime, to enable Java programmers to exploit NVM for persistence management with high performance. Espresso first provides a general persistent heap design called Persistent Java Heap (PJH) to manage persistent data as normal Java objects. The heap is then strengthened with a recoverable mechanism to provide crash consistency for heap metadata. It then provides a new abstraction called Persistent Java Object (PJO) to provide an easy-to-use but safe persistent programming model for programmers to persist application data. The evaluation confirms that Espresso significantly outperforms state-of-art NVM support for Java (i.e., JPA and PCJ) while being compatible to existing data structures in Java programs.},
	urldate = {2018-04-25},
	journal = {arXiv:1710.09968 [cs]},
	author = {Wu, Mingyu and Zhao, Ziming and Li, Haoyu and Li, Heting and Chen, Haibo and Zang, Binyu and Guan, Haibing},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.09968},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2RN8XUL4\\1710.html:text/html;Wu et al. - 2017 - Espresso Brewing Java For More Non-Volatility wit.pdf:C\:\\Users\\Anna\\Zotero\\storage\\3MTYZSUY\\Wu et al. - 2017 - Espresso Brewing Java For More Non-Volatility wit.pdf:application/pdf}
}

@misc{noauthor_morning_nodate-6,
	title = {The {Morning} {Paper}: {Skyway} - connecting managed heaps in distributed big data systems},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/the-morning-paper-skyway-connecting-managed-heaps-in-distributed-big-data-systems?e=6b9727817f},
	urldate = {2018-04-26},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\M2D6CN3V\\the-morning-paper-skyway-connecting-managed-heaps-in-distributed-big-data-systems.html:text/html}
}

@misc{noauthor_smoothoperator:_nodate,
	title = {{SmoothOperator}: {Reducing} {Power} {Fragmentation} and {Improving} {Power} {Utilization} in {Large}-scale {Datacenters}},
	shorttitle = {{SmoothOperator}},
	url = {https://research.fb.com/publications/smoothoperator-reducing-power-fragmentation-and-improving-power-utilization-in-large-scale-datacenters},
	abstract = {With the ever growing popularity of cloud computing and web services, Internet companies are in need of increased computing capacity to serve the demand. However, power has become a major limiting factor prohibiting the growth in industry: it is often the case that no more servers can be added to datacenters without surpassing the capacity of the existing power infrastructure.},
	language = {en-US},
	urldate = {2018-04-27},
	journal = {Facebook Research},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\FHJZ7I3R\\smoothoperator-reducing-power-fragmentation-and-improving-power-utilization-in-large-scale-data.html:text/html}
}

@misc{noauthor_netchain:_nodate,
	title = {{NetChain}: {Scale}-{Free} {Sub}-{RTT} {Coordination} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/nsdi18/presentation/jin},
	urldate = {2018-04-30},
	file = {NetChain\: Scale-Free Sub-RTT Coordination | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\HTPGR6VF\\jin.html:text/html}
}

@misc{noauthor_andromeda:_nodate,
	title = {Andromeda: {Performance}, {Isolation}, and {Velocity} at {Scale} in {Cloud} {Network} {Virtualization} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/nsdi18/presentation/dalton},
	urldate = {2018-05-02},
	file = {Andromeda\: Performance, Isolation, and Velocity at Scale in Cloud Network Virtualization | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\628FIQDK\\dalton.html:text/html}
}

@misc{noauthor_stateless_nodate,
	title = {Stateless {Datacenter} {Load}-balancing with {Beamer} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/nsdi18/presentation/olteanu},
	urldate = {2018-05-03},
	file = {Stateless Datacenter Load-balancing with Beamer | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\MAV8V77X\\olteanu.html:text/html}
}

@misc{noauthor_performance_nodate,
	title = {Performance {Analysis} of {Cloud} {Applications} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/nsdi18/presentation/ardelean},
	urldate = {2018-05-04},
	file = {Performance Analysis of Cloud Applications | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\MVTD43PG\\ardelean.html:text/html}
}

@article{hardt_equality_2016,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.},
	urldate = {2018-05-07},
	journal = {arXiv:1610.02413 [cs]},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.02413},
	keywords = {Computer Science - Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IE49TN55\\1610.html:text/html;Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CGUT984Z\\Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf}
}

@misc{noauthor_file_nodate,
	title = {File {System} {Improvements} to the {Windows} {Subsystem} for {Linux} – {Windows} {Subsystem} for {Linux}},
	url = {https://blogs.msdn.microsoft.com/wsl/2017/04/18/file-system-improvements-to-the-windows-subsystem-for-linux/},
	urldate = {2018-05-08},
	file = {File System Improvements to the Windows Subsystem for Linux – Windows Subsystem for Linux:C\:\\Users\\Anna\\Zotero\\storage\\9GDU4XAY\\file-system-improvements-to-the-windows-subsystem-for-linux.html:text/html}
}

@article{ledig_photo-realistic_2016,
	title = {Photo-{Realistic} {Single} {Image} {Super}-{Resolution} {Using} a {Generative} {Adversarial} {Network}},
	url = {http://arxiv.org/abs/1609.04802},
	abstract = {Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.},
	urldate = {2018-05-09},
	journal = {arXiv:1609.04802 [cs, stat]},
	author = {Ledig, Christian and Theis, Lucas and Huszar, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.04802},
	keywords = {Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1609.04802 PDF:C\:\\Users\\Anna\\Zotero\\storage\\JXXG5R6M\\Ledig et al. - 2016 - Photo-Realistic Single Image Super-Resolution Usin.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\P8ZE425E\\1609.html:text/html}
}

@misc{noauthor_sketchnotes:_nodate,
	title = {Sketchnotes: {A} {Guide} to {Visual} {Note}-{Taking} - {JetPens}.com},
	url = {https://www.jetpens.com/blog/sketchnotes-a-guide-to-visual-note-taking/pt/892},
	urldate = {2018-05-11},
	file = {Sketchnotes\: A Guide to Visual Note-Taking - JetPens.com:C\:\\Users\\Anna\\Zotero\\storage\\8ASYS6P5\\892.html:text/html}
}

@misc{conner_principles_nodate,
	title = {Principles {Of} {Persuasion}: {Bill} {McGowan}'s 7 {Secrets} {For} {Saying} {The} {Right} {Words}, {Every} {Time}},
	shorttitle = {Principles {Of} {Persuasion}},
	url = {https://www.forbes.com/sites/cherylsnappconner/2014/02/22/principles-of-persuasion-bill-mcgowans-7-secrets-for-saying-the-right-words-every-time/},
	abstract = {These days I receive a great number of books for prospective review. Very few make a major impact, but the book I received this week—Pitch Perfect: How To Say It Right The First Time, Every Time had my attention from the word “go.” Due April 1, Pitch Perfect is the [...]},
	language = {en},
	urldate = {2018-05-12},
	journal = {Forbes},
	author = {Conner, Cheryl},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EEZVSUFT\\principles-of-persuasion-bill-mcgowans-7-secrets-for-saying-the-right-words-every-time.html:text/html}
}

@misc{noauthor_7_nodate,
	title = {The 7 {Habits} of {Highly} {Effective} {People} {Summary} {\textbar} {Stephen} {R}. {Covey}},
	url = {https://www.getabstract.com/en/summary/career-and-self-development/the-7-habits-of-highly-effective-people/3515},
	abstract = {In this getAbstract summary, you will learn: Which seven approaches effective people take to attain fulfillment and How to build your character and shape your life more deliberately.},
	language = {en},
	urldate = {2018-05-12},
	journal = {getAbstract}
}

@misc{noauthor_pitch_nodate,
	title = {Pitch {Perfect} {Summary} {\textbar} {Bill} {McGowan} and {Alisa} {Bowman}},
	url = {https://www.getabstract.com/en/summary/career-and-self-development/pitch-perfect/21643},
	abstract = {In this getAbstract summary, you will learn: How you can significantly improve your verbal communications skills in various business and personal situations,; What the Seven Principles of Persuasion are, and How to gauge the importance of verbal and nonverbal communications.},
	language = {en},
	urldate = {2018-05-12},
	journal = {getAbstract},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\YS45RNN9\\21643.html:text/html}
}

@misc{noauthor_pitch_nodate-1,
	title = {Pitch {Anything} {Summary} {\textbar} {Oren} {Klaff} {\textbar} {PDF} {Download}},
	url = {https://www.getabstract.com/en/summary/sales-and-marketing/pitch-anything/17415},
	abstract = {In this getAbstract summary, you will learn: Why you must speak to each listener’s “croc brain” while making a pitch,; How to use the “STRONG” pitching process and Why “frame control” and high perceived status are essential to a successful pitch.},
	language = {en},
	urldate = {2018-05-12},
	journal = {getAbstract},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\XJCLSL9B\\Download.html:text/html}
}

@misc{noauthor_one_nodate,
	title = {One {Perfect} {Pitch} {Summary} {\textbar} {Marie} {Perruchet} {\textbar} {PDF} {Download}},
	url = {https://www.getabstract.com/en/summary/career-and-self-development/one-perfect-pitch/27224},
	abstract = {In this getAbstract summary, you will learn: Why your pitch for venture funding should include storytelling,; What story elements work well in a pitch,; What a “one-minute” pitch must accomplish and What rules you should follow to solicit funds from tech venture capitalists.},
	language = {en},
	urldate = {2018-05-12},
	journal = {getAbstract},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RT8M5R23\\27224.html:text/html}
}

@misc{alison_targetjobs_interview_2012,
	type = {Text},
	title = {Interview introductions: how to perfect your personal pitch},
	shorttitle = {Interview introductions},
	url = {https://targetjobs.co.uk/careers-advice/networking/273687-interview-introductions-how-to-perfect-your-personal-pitch},
	abstract = {A personal pitch is basically a succinct introduction to yourself and your background. Having an outline pitch ready is a great confidence-booster for graduate interviews, networking events and careers fairs. The process of creating one also helps you to focus on what employers want and helps you specifically demonstrate how you meet their requirements.},
	language = {en},
	urldate = {2018-05-13},
	journal = {TARGETjobs},
	author = {Alison\_TARGETjobs},
	month = jun,
	year = {2012},
	keywords = {software campus},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\42HTDRC2\\273687-interview-introductions-how-to-perfect-your-personal-pitch.html:text/html}
}

@misc{noauthor_4_2015,
	title = {4 {Messages} {You} {Need} to {Know} (and {Nail}) to {Pitch} {Yourself}},
	url = {https://www.themuse.com/advice/4-messages-you-need-to-know-and-nail-to-pitch-yourself},
	abstract = {How to Pitch Yourself to Anyone - The Muse: Need to talk about how awesome you are? Here's ...},
	language = {en},
	urldate = {2018-05-13},
	month = jun,
	year = {2015},
	keywords = {software campus},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\AR7AKVFD\\4-messages-you-need-to-know-and-nail-to-pitch-yourself.html:text/html}
}

@article{silen_acid-base_1975,
	title = {Acid-base balance in amphibian gastric mucosa},
	volume = {229},
	issn = {0002-9513},
	doi = {10.1152/ajplegacy.1975.229.3.721},
	abstract = {It has been established that H+ secretion can be maintained in frog stomach in the absence of exogenous CO2 by using a nutrient bathing fluid containing 25 mM H2PO4 (pH approximately equal to 4.5) or by lowering the pH of a nonbuffered nutrient solution to about 3.0-3.6. Exogenous CO2 in the presence of these nutrient solutions uniformly caused a marked decrease in H+ secretion, PD, adn short-circuit current (Isc) and an increase in transmucosal resistance (R). Elevation of nutrient [k+] to 83 mM reduced R significantly but transiently without change in H+ when nutrient pH less than 5.0, whereas R returned to base line and H+ increased when nutrient pH greater than 5.0. Acidification of the nutrient medium in the presence of exogenous CO2 results in inhibition of the secretory pump, probably by decreasing intracellular pH, and also interferes with conductance at the nutrient membrane. Removal of exogenous CO2 from standard bicarbonate nutrient solution reduced by 50\% the H+, PD, and Isc without change in R; K+-free nutrient solutions reverse these changes in Isc and PD but not in H+. The dropping PD and rising R induced by K+-free nutrient solutions in 5\% CO2 - 95\% O2 are returned toward normal by 100\% O2. Our findings support an important role for exogenous CO2 in maintaining normal acid-base balance in frog mucosa by acting as an acidifying agent.},
	language = {eng},
	number = {3},
	journal = {The American Journal of Physiology},
	author = {Silen, W. and Machen, T. E. and Forte, J. G.},
	month = sep,
	year = {1975},
	pmid = {2015},
	keywords = {Acid-Base Equilibrium, Animals, Anura, Bicarbonates, Carbon Dioxide, Electrophysiology, Gastric Mucosa, Hydrogen-Ion Concentration, Phosphates, Potassium, Rana catesbeiana, Solutions},
	pages = {721--730}
}

@article{hendrickson_atomic_1975,
	title = {Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin},
	volume = {66},
	issn = {1090-2104},
	language = {eng},
	number = {4},
	journal = {Biochemical and Biophysical Research Communications},
	author = {Hendrickson, W. A. and Ward, K. B.},
	month = oct,
	year = {1975},
	pmid = {5},
	keywords = {Animals, Cnidaria, Computers, Hemerythrin, Metalloproteins, Models, Molecular, Muscle Proteins, Protein Conformation, Species Specificity},
	pages = {1349--1356}
}

@article{moroi_comparison_1975,
	title = {Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase},
	volume = {24},
	issn = {1873-2968},
	language = {eng},
	number = {16},
	journal = {Biochemical Pharmacology},
	author = {Moroi, K. and Sato, T.},
	month = aug,
	year = {1975},
	pmid = {8},
	keywords = {Animals, Hydrogen-Ion Concentration, Amidohydrolases, Esterases, In Vitro Techniques, Isocarboxazid, Kinetics, Male, Metals, Microsomes, Liver, Phospholipids, Procaine, Proteins, Rats, Subcellular Fractions, Temperature},
	pages = {1517--1521}
}

@misc{smith_get_2018,
	title = {Get {An} {Elevator} {Pitch} {That} {Sounds} {Like} {You} {AND} {Gets} {You} {The} {Job}},
	url = {https://skillcrush.com/2015/05/08/elevator-pitch-proud-of/},
	language = {Englisch},
	journal = {The Hard Refresh},
	author = {Smith, Kelli},
	month = may,
	year = {2018},
	keywords = {software campus}
}

@misc{giang_how_nodate,
	title = {How {To} {Sell} {Yourself} {In} 30 {Seconds} {And} {Leave} {People} {Wanting} {More}},
	url = {http://www.businessinsider.com/how-to-tell-your-story-in-30-seconds-2013-11},
	abstract = {How do you sell yourself in 30 seconds? Paul McDonald, senior executive director at Robert Half, gives us eight steps to crafting the perfect elevator pitch.},
	urldate = {2018-05-13},
	journal = {Business Insider},
	author = {Giang, Vivian},
	keywords = {software campus},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\Q9G4VMI7\\how-to-tell-your-story-in-30-seconds-2013-11.html:text/html}
}

@misc{noauthor_high_nodate,
	title = {High {Potentials}: 7 {Merkmale}, wie man eine {Führungskraft} erkennt},
	shorttitle = {High {Potentials}},
	url = {https://www.cio.de/a/7-merkmale-wie-man-eine-fuehrungskraft-erkennt,2974022},
	abstract = {Anhand von sieben überprüfbaren Faktoren können Unternehmen feststellen, ob jemand das Zeug zur Führungskraft hat. Das versprechen zumindest die Analysten von Korn Ferry.},
	language = {de},
	urldate = {2018-05-13},
	keywords = {software campus},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EWGKG6BI\\7-merkmale-wie-man-eine-fuehrungskraft-erkennt,2974022.html:text/html}
}

@inproceedings{tietz_digital_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {Digital {Zombies} - the {Reanimation} of {Our} {Digital} {Selves}},
	isbn = {978-1-4503-5640-4},
	url = {https://doi.org/10.1145/3184558.3191606},
	doi = {10.1145/3184558.3191606},
	abstract = {What happens to our social media profiles when we die The episode "Be Right Back" as part of Netflix's series "Black Mirror" provides a possible scenario. A digital avatar is created to communicate with close relatives which learns from past social media activities of the deceased user. While the users entrust their social media content to one or more companies, even after their death, it may be reasonable to ask: What will the company really do with a deceased user's data: sell it to manipulate users or create advertisements In this paper we tackle the issues of ownership, ethics, and transparency of post mortem user data.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-14},
	booktitle = {Companion {Proceedings} of the {The} {Web} {Conference} 2018},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Tietz, Tabea and Pichierri, Francesca and Koutraki, Maria and Hallinan, Dara and Boehm, Franziska and Sack, Harald},
	year = {2018},
	keywords = {privacy, artificial intelligence, black mirror, ethics, law, social media, transparency},
	pages = {1535--1539},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\EEPLZIBL\\Tietz et al. - 2018 - Digital Zombies - the Reanimation of Our Digital S.pdf:application/pdf}
}

@inproceedings{mensio_rise_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {The {Rise} of {Emotion}-aware {Conversational} {Agents}: {Threats} in {Digital} {Emotions}},
	isbn = {978-1-4503-5640-4},
	shorttitle = {The {Rise} of {Emotion}-aware {Conversational} {Agents}},
	url = {https://doi.org/10.1145/3184558.3191607},
	doi = {10.1145/3184558.3191607},
	abstract = {A future where the conversation with machines can potentially involve mutual emotions between the parties may be not so far in time. Inspired by the episode of Black Mirror "Be Right Back'' and Replika, a futuristic app that promises to be "your best friend'', in this work we are considering the positive and negative points of including an automated learning conversational agent inside the personal world of feelings and emotions. These systems can impact both single individuals and society, worsening an already critical situation. Our conclusion is that a regulation on the artificial emotional content should be considered before actually going beyond some one-way-only limits.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-14},
	booktitle = {Companion {Proceedings} of the {The} {Web} {Conference} 2018},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Mensio, Martino and Rizzo, Giuseppe and Morisio, Maurizio},
	year = {2018},
	keywords = {affective computing, conversational agents, psychological implications, social implications},
	pages = {1541--1544},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\5MV672TL\\Mensio et al. - 2018 - The Rise of Emotion-aware Conversational Agents T.pdf:application/pdf}
}

@misc{noauthor_seven_nodate,
	title = {Seven signposts: {The} unmistakable markers of high-potential leaders.},
	shorttitle = {Seven signposts},
	url = {https://www.kornferry.com/institute/694-seven-signposts-the-unmistakable-markers-that-identify-high-potential-leaders},
	abstract = {October 09, 2013 - Learn the seven signs that make identifying high potential employees easy.},
	language = {en},
	urldate = {2018-05-14},
	journal = {Korn Ferry},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\B938X95R\\694-seven-signposts-the-unmistakable-markers-that-identify-high-potential-leaders.html:text/html}
}

@article{palomba_how_2018,
	title = {How {Do} {Community} {Smells} {Influence} {Code} {Smells}?},
	abstract = {Code smells reflect sub-optimal patterns of code that often lead to
critical software flaws or failure. In the same way, community smells
reflect sub-optimal organisational and socio-technical patterns in
the organisational structure of the software community.
To understand the relation between the community smells and
code smells we start by surveying 162 developers of nine open-
source systems. Then we look deeper into this connection by con-
ducting an empirical study of 117 releases from these systems.
Our results indicate that community-related factors are intu-
itively perceived by most developers as causes of the persistence of
code smells. Inspired by this observation we design a community-
aware prediction model for code smells and show that it outper-
forms a model that does not consider community factors},
	author = {Palomba, Fabio and Tamburri, Damian A. and Serebrenik, Alexander and Zaidman, Andy and Fontana, Francesca Arcelli and Oliveto, Rocco},
	year = {2018},
	keywords = {to read}
}

@misc{noauthor_detecting_nodate,
	title = {Detecting third-party libraries in {Android} applications with high precision and recall - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/document/8330204/},
	urldate = {2018-05-22},
	file = {Detecting third-party libraries in Android applications with high precision and recall - IEEE Conference Publication:C\:\\Users\\Anna\\Zotero\\storage\\S2LIJF6S\\8330204.html:text/html}
}

@inproceedings{zhang_detecting_2018,
	title = {Detecting third-party libraries in {Android} applications with high precision and recall},
	doi = {10.1109/SANER.2018.8330204},
	abstract = {Third-party libraries are widely used in Android applications to ease development and enhance functionalities. However, the incorporated libraries also bring new security \& privacy issues to the host application, and blur the accounting between application code and library code. Under this situation, a precise and reliable library detector is highly desirable. In fact, library code may be customized by developers during integration and dead library code may be eliminated by code obfuscators during application build process. However, existing research on library detection has not gracefully handled these problems, thus facing severe limitations in practice. In this paper, we propose LibPecker, an obfuscation-resilient, highly precise and reliable library detector for Android applications. LibPecker adopts signature matching to give a similarity score between a given library and an application. By fully utilizing the internal class dependencies inside a library, LibPecker generates a strict signature for each class. To tolerate library code customization and elimination as much as possible, LibPecker introduces adaptive class similarity threshold and weighted class similarity score when calculating library similarity. To quantitatively evaluate the precision and the recall of LibPecker, we perform the first such experiment (to the best of our knowledge) with a large number of libraries and applications. Results show that LibPecker significantly outperforms the state-of-the-art tools in both recall and precision (91\% and 98.1\% respectively).},
	booktitle = {2018 {IEEE} 25th {International} {Conference} on {Software} {Analysis}, {Evolution} and {Reengineering} ({SANER})},
	author = {Zhang, Y. and Dai, J. and Zhang, X. and Huang, S. and Yang, Z. and Yang, M. and Chen, H.},
	month = mar,
	year = {2018},
	keywords = {Libraries, data privacy, software libraries, Android (operating system), Androids, Humanoid robots, mobile computing, Tools, Feature extraction, adaptive class similarity threshold, Android applications, application code, code obfuscators, Code Similarity, dead library code, Detectors, host application, LibPecker, library code customization, library detection, Library Detection, library similarity calculation, Obfuscation Resilience, precise library detector, privacy issues, Reliability, reliable library detector, third-party libraries detection, weighted class similarity score},
	pages = {141--152},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\QI9ZEMMA\\8330204.html:text/html;Zhang et al. - 2018 - Detecting third-party libraries in Android applica.pdf:C\:\\Users\\Anna\\Zotero\\storage\\RA6Y79N7\\Zhang et al. - 2018 - Detecting third-party libraries in Android applica.pdf:application/pdf}
}

@inproceedings{saied_mining_2015,
	title = {Mining {Multi}-level {API} {Usage} {Patterns}},
	doi = {10.1109/SANER.2015.7081812},
	abstract = {Software developers need to cope with complexity of Application Programming Interfaces (APIs) of external libraries or frameworks. However, typical APIs provide several thousands of methods to their client programs, and such large APIs are difficult to learn and use. An API method is generally used within client programs along with other methods of the API of interest. Despite this, co-usage relationships between API methods are often not documented. We propose a technique for mining Multi-Level API Usage Patterns (MLUP) to exhibit the co-usage relationships between methods of the API of interest across interfering usage scenarios. We detect multi-level usage patterns as distinct groups of API methods, where each group is uniformly used across variable client programs, independently of usage contexts. We evaluated our technique through the usage of four APIs having up to 22 client programs per API. For all the studied APIs, our technique was able to detect usage patterns that are, almost all, highly consistent and highly cohesive across a considerable variability of client programs.},
	booktitle = {2015 {IEEE} 22nd {International} {Conference} on {Software} {Analysis}, {Evolution}, and {Reengineering} ({SANER})},
	author = {Saied, M. A. and Benomar, O. and Abdeen, H. and Sahraoui, H.},
	month = mar,
	year = {2015},
	keywords = {Security, Java, software libraries, Context, data mining, application program interfaces, to read, application programming interface, Documentation, API Documentation, API Usage, Clustering algorithms, Graphical user interfaces, Layout, MLUP, multilevel API usage pattern mining, Software Clustering, Usage Pattern, apimisuse},
	pages = {23--32},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\J2NZXG47\\7081812.html:text/html;Saied et al. - 2015 - Mining Multi-level API Usage Patterns.pdf:C\:\\Users\\Anna\\Zotero\\storage\\DPZWSCIN\\Saied et al. - 2015 - Mining Multi-level API Usage Patterns.pdf:application/pdf}
}

@inproceedings{krawiecka_safekeeper:_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {{SafeKeeper}: {Protecting} {Web} {Passwords} {Using} {Trusted} {Execution} {Environments}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {{SafeKeeper}},
	url = {https://doi.org/10.1145/3178876.3186101},
	doi = {10.1145/3178876.3186101},
	abstract = {Passwords are by far the most widely-used mechanism for authenticating users on the web, out-performing all competing solutions in terms of deployability (e.g. cost and compatibility). However, two critical security concerns are phishing and theft of password databases. These are exacerbated by users» tendency to reuse passwords across different services. Current solutions typically address only one of the two concerns, and do not protect passwords against rogue servers. Furthermore, they do not provide any verifiable evidence of their (server-side) adoption to users, and they face deployability challenges in terms of ease-of-use for end users, and/or costs for service providers. We present SafeKeeper, a novel and comprehensive solution to ensure secrecy of passwords in web authentication systems. Unlike previous approaches, SafeKeeper protects users» passwords against very strong adversaries, including external phishers as well as corrupted (rogue) servers. It is relatively inexpensive to deploy as it (i) uses widely available hardware-based trusted execution environments like Intel SGX, (ii) requires only minimal changes for integration into popular web platforms like WordPress, and (iii) imposes negligible performance overhead. We discuss several challenges in designing and implementing such a system, and how we overcome them. Via an 86-participant user study, systematic analysis and experiments, we show the usability, security and deployability of SafeKeeper, which is available as open-source.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-22},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Krawiecka, Klaudia and Kurnikov, Arseny and Paverd, Andrew and Mannan, Mohammad and Asokan, N.},
	year = {2018},
	keywords = {intel sgx, passwords, phishing, trusted execution environment},
	pages = {349--358},
	file = {Krawiecka et al. - 2018 - SafeKeeper Protecting Web Passwords Using Trusted.pdf:C\:\\Users\\Anna\\Zotero\\storage\\WT6T7FXR\\Krawiecka et al. - 2018 - SafeKeeper Protecting Web Passwords Using Trusted.pdf:application/pdf}
}

@misc{noauthor_pixie_nodate,
	title = {Pixie},
	url = {https://dl.acm.org/citation.cfm?id=3186183},
	urldate = {2018-05-23},
	file = {Pixie:C\:\\Users\\Anna\\Zotero\\storage\\G93RL9GL\\citation.html:text/html}
}

@inproceedings{eksombatchai_pixie:_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {Pixie: {A} {System} for {Recommending} 3+ {Billion} {Items} to 200+ {Million} {Users} in {Real}-{Time}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Pixie},
	url = {https://doi.org/10.1145/3178876.3186183},
	doi = {10.1145/3178876.3186183},
	abstract = {User experience in modern content discovery applications critically depends on high-quality personalized recommendations. However, building systems that provide such recommendations presents a major challenge due to a massive pool of items, a large number of users, and requirements for recommendations to be responsive to user actions and generated on demand in real-time. Here we present Pixie, a scalable graph-based real-time recommender system that we developed and deployed at Pinterest. Given a set of user-specific pins as a query, Pixie selects in real-time from billions of possible pins those that are most related to the query. To generate recommendations, we develop Pixie Random Walk algorithm that utilizes the Pinterest object graph of 3 billion nodes and 17 billion edges. Experiments show that recommendations provided by Pixie lead up to 50\% higher user engagement when compared to the previous Hadoop-based production system. Furthermore, we develop a graph pruning strategy at that leads to an additional 58\% improvement in recommendations. Last, we discuss system aspects of Pixie, where a single server executes 1,200 recommendation requests per second with 60 millisecond latency. Today, systems backed by Pixie contribute to more than 80\% of all user engagement on Pinterest.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-23},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Eksombatchai, Chantat and Jindal, Pranav and Liu, Jerry Zitao and Liu, Yuchen and Sharma, Rahul and Sugnet, Charles and Ulrich, Mark and Leskovec, Jure},
	year = {2018},
	pages = {1775--1784},
	file = {Eksombatchai et al. - 2018 - Pixie A System for Recommending 3+ Billion Items .pdf:C\:\\Users\\Anna\\Zotero\\storage\\2EUWDQ29\\Eksombatchai et al. - 2018 - Pixie A System for Recommending 3+ Billion Items .pdf:application/pdf}
}

@misc{noauthor_eigener_nodate,
	title = {In eigener {Sache}: {Wer} kennt sich mit {Luhmanns} {Zettelkasten} aus? › {ToolBlog}},
	shorttitle = {In eigener {Sache}},
	url = {https://toolblog.de/2017/09/04/in-eigener-sache-wer-kennt-sich-mit-luhmanns-zettelkasten-aus/},
	abstract = {Dieser Tage habe ich das Buch von Sönke Arens Das Zettelkasten-Prinzip mit großem Gewinn gelesen. Der Autor beschreibt darin, warum ...},
	language = {de-DE},
	urldate = {2018-05-24},
	keywords = {Zettelkasten},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\7Y4CSSB3\\in-eigener-sache-wer-kennt-sich-mit-luhmanns-zettelkasten-aus.html:text/html}
}

@misc{daniel_vom_2011,
	title = {Vom {Zettel} zum {Text}},
	url = {https://strengejacke.wordpress.com/2011/06/15/vom-zettel-zum-text/},
	abstract = {Gelegentlich wird der Zettelkasten als Literaturverwaltung beschrieben. Das ist eigentlich genau nicht der Fall, denn vernünftig Literatur verwalten wie bspw. mit BibDesk oder JabRef geht mit dem Z…},
	language = {de-DE},
	urldate = {2018-05-24},
	journal = {Strenge Jacke!},
	author = {{Daniel}},
	month = jun,
	year = {2011},
	keywords = {Zettelkasten}
}

@misc{noauthor_zettelkasten_nodate,
	title = {Zettelkasten knowledge and info management • {Zettelkasten} {Method}},
	url = {https://zettelkasten.de/},
	urldate = {2018-05-24},
	keywords = {Zettelkasten},
	file = {Zettelkasten knowledge and info management • Zettelkasten Method:C\:\\Users\\Anna\\Zotero\\storage\\EBQGDUFB\\zettelkasten.de.html:text/html}
}

@misc{noauthor_how_nodate-1,
	title = {How {I} {Stopped} {Worrying} and {Learned} to {Love} {Design} {Thinking}},
	url = {https://medium.com/@cwodtke/how-i-stopped-worrying-and-learned-to-love-design-thinking-f1142bab60e8},
	urldate = {2018-05-24},
	keywords = {to read, Zettelkasten},
	file = {How I Stopped Worrying and Learned to Love Design Thinking:C\:\\Users\\Anna\\Zotero\\storage\\8QANDJ2A\\how-i-stopped-worrying-and-learned-to-love-design-thinking-f1142bab60e8.html:text/html}
}

@misc{x28_magic_2016,
	title = {Magic of {Zettelkasten}},
	url = {https://x28newblog.wordpress.com/2016/12/01/magic-of-zettelkasten/},
	abstract = {My tool is now able to import from/ export to tools that are inspired by Luhmann’s famous Zettelkasten. The magic of this was that he allowed for arbitrary branching at every point in his hie…},
	language = {en},
	urldate = {2018-05-24},
	journal = {x28's new Blog},
	author = {{x28}},
	month = dec,
	year = {2016},
	keywords = {to read, Zettelkasten},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JUWWFKP9\\magic-of-zettelkasten.html:text/html}
}

@misc{ludecke_introduction_nodate,
	title = {Introduction to  {Luhmann}’s {Zettelkasten} - thinking and its technical implementation},
	url = {https://strengejacke.files.wordpress.com/2015/10/introduction-into-luhmanns-zettelkasten-thinking.pdf},
	author = {Lüdecke, Daniel}
}

@misc{technik_johannes_2016,
	title = {Johannes {Schmidt}:  {Der} {Zettelkasten} als {Zweitged}\&auml;chtnis {Niklas} {Luhmanns}},
	shorttitle = {Johannes {Schmidt}},
	url = {https://vimeo.com/173128404},
	abstract = {Niklas Luhmann (1927-1998) z\&auml;hlt zu den bedeutendsten Soziologen des 20. Jahrhunderts. Im Laufe seiner 25j\&auml;hrigen Forschungs- und Lehrt\&auml;tigkeit an\&hellip;},
	urldate = {2018-05-24},
	author = {Technik, Labor f\&uuml;r Kunst und},
	month = jul,
	year = {2016},
	keywords = {Zettelkasten, Archivierung, Johannes Schmidt, Kunstverein Hannover, Luhmann, Niklas Luhmann, Systemtheorie, Wissensordnungen},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\SNPGT4JI\\173128404.html:text/html}
}

@misc{noauthor_morning_nodate-7,
	title = {The {Morning} {Paper}: {Algorithmic} glass ceiling in social networks - the effects of social recommendations on network diversity},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/wuk1nrbpx1?e=6b9727817f},
	urldate = {2018-05-24},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WGITWZBY\\wuk1nrbpx1.html:text/html}
}

@inproceedings{stoica_algorithmic_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {Algorithmic {Glass} {Ceiling} in {Social} {Networks}: {The} {Effects} of {Social} {Recommendations} on {Network} {Diversity}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Algorithmic {Glass} {Ceiling} in {Social} {Networks}},
	url = {https://doi.org/10.1145/3178876.3186140},
	doi = {10.1145/3178876.3186140},
	abstract = {As social recommendations such as friend suggestions and people to follow become increasingly popular and influential on the growth of social media, we find that prominent social recommendation algorithms can exacerbate the under-representation of certain demographic groups at the top of the social hierarchy. To study this imbalance in online equal opportunities, we leverage new Instagram data and offer for the first time an analysis that studies the effect of gender, homophily and growth dynamics under social recommendations. Our mathematical analysis demonstrates the existence of an algorithmic glass ceiling that exhibits all the properties of the metaphorical social barrier that hinders groups like women or people of color from attaining equal representation. What raises concern is that our proof shows that under fixed minority and homophily parameters the algorithmic effect is systematically larger than the glass ceiling generated by the spontaneous growth of social networks. We discuss ways to address this concern in future design.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-24},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Stoica, Ana-Andreea and Riederer, Christopher and Chaintreau, Augustin},
	year = {2018},
	keywords = {fairness, homophily, random walks, social recommender},
	pages = {923--932},
	file = {Stoica et al. - 2018 - Algorithmic Glass Ceiling in Social Networks The .pdf:C\:\\Users\\Anna\\Zotero\\storage\\MJICFM7Z\\Stoica et al. - 2018 - Algorithmic Glass Ceiling in Social Networks The .pdf:application/pdf}
}

@misc{shepperd_replication_2018,
	title = {Replication studies considered harmful!},
	url = {https://empiricalsoftwareengineering.wordpress.com/2018/05/23/replication-studies-considered-harmful/},
	abstract = {On June 1st I will be presenting a paper at the 2018 40th International Conference on Software Engineering (\#ICSE18) in Gothenburg as part of the New Ideas and Emerging Results track [8].  As the t…},
	language = {en},
	urldate = {2018-05-24},
	journal = {Thoughts  on Empirical Software Engineering},
	author = {Shepperd, Martin},
	month = may,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZPI2RNWZ\\replication-studies-considered-harmful.html:text/html}
}

@inproceedings{xu_unsupervised_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {Unsupervised {Anomaly} {Detection} via {Variational} {Auto}-{Encoder} for {Seasonal} {KPIs} in {Web} {Applications}},
	isbn = {978-1-4503-5639-8},
	url = {https://doi.org/10.1145/3178876.3185996},
	doi = {10.1145/3178876.3185996},
	abstract = {To ensure undisrupted business, large Internet companies need to closely monitor various KPIs (e.g., Page Views, number of online users, and number of orders) of its Web applications, to accurately detect anomalies and trigger timely troubleshooting/mitigation. However, anomaly detection for these seasonal KPIs with various patterns and data quality has been a great challenge, especially without labels. In this paper, we proposed Donut, an unsupervised anomaly detection algorithm based on VAE. Thanks to a few of our key techniques, Donut greatly outperforms a state-of-arts supervised ensemble approach and a baseline VAE approach, and its best F-scores range from 0.75 to 0.9 for the studied KPIs from a top global Internet company. We come up with a novel KDE interpretation of reconstruction for Donut, making it the first VAE-based anomaly detection algorithm with solid theoretical explanation.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-25},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Xu, Haowen and Chen, Wenxiao and Zhao, Nengwen and Li, Zeyan and Bu, Jiahao and Li, Zhihan and Liu, Ying and Zhao, Youjian and Pei, Dan and Feng, Yang and Chen, Jie and Wang, Zhaogang and Qiao, Honglin},
	year = {2018},
	keywords = {anomaly detection, seasonal KPI, variational auto-encoder},
	pages = {187--196},
	file = {Xu et al. - 2018 - Unsupervised Anomaly Detection via Variational Aut.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JJUHQ7SN\\Xu et al. - 2018 - Unsupervised Anomaly Detection via Variational Aut.pdf:application/pdf}
}

@misc{noauthor_*_nodate,
	title = {* {ICSE} 2018 * {Technical} {Papers} - * {ICSE} 2018 *},
	url = {https://www.icse2018.org/track/icse-2018-Technical-Papers#event-overview},
	urldate = {2018-05-25}
}

@misc{noauthor_was_nodate,
	title = {"{Was} my contribution fairly reviewed?" {A} framework and an empirical study of fairness in {Modern} {Code} {Reviews} - * {ICSE} 2018 *},
	url = {https://www.icse2018.org/event/icse-2018-technical-papers-was-my-contribution-fairly-reviewed-a-framework-and-an-empirical-study-of-fairness-in-modern-code-reviews},
	urldate = {2018-05-25},
	file = {"Was my contribution fairly reviewed?" A framework and an empirical study of fairness in Modern Code Reviews - * ICSE 2018 *:C\:\\Users\\Anna\\Zotero\\storage\\IUT7JWD5\\icse-2018-technical-papers-was-my-contribution-fairly-reviewed-a-framework-and-an-empirical-stu.html:text/html}
}

@inproceedings{arshad_large-scale_2018,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '18},
	title = {Large-{Scale} {Analysis} of {Style} {Injection} by {Relative} {Path} {Overwrite}},
	isbn = {978-1-4503-5639-8},
	url = {https://doi.org/10.1145/3178876.3186090},
	doi = {10.1145/3178876.3186090},
	abstract = {Relative Path Overwrite (RPO) is a recent technique to inject style directives into sites even when no style sink or markup injection vulnerability is present. It exploits differences in how browsers and web servers interpret relative paths (i.e., path confusion) to make a HTML page reference itself as a stylesheet; a simple text injection vulnerability along with browsers» leniency in parsing CSS resources results in an attacker»s ability to inject style directives that will be interpreted by the browser. Even though style injection may appear less serious a threat than script injection, it has been shown that it enables a range of attacks, including secret exfiltration. In this paper, we present the first large-scale study of the Web to measure the prevalence and significance of style injection using RPO. Our work shows that around 9\% of the sites in the Alexa Top 10,000 contain at least one vulnerable page, out of which more than one third can be exploited. We analyze in detail various impediments to successful exploitation, and make recommendations for remediation. In contrast to script injection, relatively simple countermeasures exist to mitigate style injection. However, there appears to be little awareness of this attack vector as evidenced by a range of popular Content Management Systems (CMSes) that we found to be exploitable.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-05-28},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Arshad, Sajjad and Mirheidari, Seyed Ali and Lauinger, Tobias and Crispo, Bruno and Kirda, Engin and Robertson, William},
	year = {2018},
	keywords = {relative path overwrite, scriptless attack, style injection},
	pages = {237--246},
	file = {Arshad et al. - 2018 - Large-Scale Analysis of Style Injection by Relativ.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HCG72Z5Z\\Arshad et al. - 2018 - Large-Scale Analysis of Style Injection by Relativ.pdf:application/pdf}
}

@article{chen_mining_2018,
	title = {Mining balanced {API} protocols},
	volume = {16},
	issn = {1742-7185},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJCSE.2018.091764},
	doi = {10.1504/IJCSE.2018.091764},
	abstract = {API protocols can be used in many aspects of software engineering, such as software testing, program validation, software documentation, etc. Mining API protocols based on probabilistic models is proved to be an effective approach to achieve protocols automatically. However, it always achieves unbalanced protocols, that is, protocols described using probabilistic models have unexpected extremely high and low probabilities. In this paper, we discuss the unbalanced probability problem and propose to address it by preprocessing method call sequences used for training. Our method first finds tandem arrays in method call sequences based on the suffix tree. Then, it substitutes each tandem array with a tandem repeat. Since repeated sub method call sequences are eliminated, balanced API protocols may be achieved. In order to investigate the feasibility and effectiveness of our approach, we implemented it in our previous prototype tool ISpecMiner and used the tool to perform a comparison test based on several real-world applications. Experimental results show that our approach can achieve more balanced API protocols than existing approaches, which is essential for mining valid and precise API protocols.},
	number = {3},
	urldate = {2018-05-29},
	journal = {International Journal of Computational Science and Engineering},
	author = {Chen, Deng and Zhang, Yanduo and Wei, Wei and Wang, Rongcun and Zhou, Huabing and Li, Xun and Qu, Binbin},
	month = jan,
	year = {2018},
	keywords = {mira},
	pages = {289--302},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2QHKESAG\\IJCSE.2018.html:text/html}
}

@misc{noauthor_morning_nodate-8,
	title = {The {Morning} {Paper}: {Measuring} the tendency of {CNNs} to learn surface statistical regularities},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/c4bc02eedz?e=6b9727817f},
	urldate = {2018-05-29},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MAUJ6GYW\\c4bc02eedz.html:text/html}
}

@article{jo_measuring_2017,
	title = {Measuring the tendency of {CNNs} to {Learn} {Surface} {Statistical} {Regularities}},
	url = {http://arxiv.org/abs/1711.11561},
	abstract = {Deep CNNs are known to exhibit the following peculiarity: on the one hand they generalize extremely well to a test set, while on the other hand they are extremely sensitive to so-called adversarial perturbations. The extreme sensitivity of high performance CNNs to adversarial examples casts serious doubt that these networks are learning high level abstractions in the dataset. We are concerned with the following question: How can a deep CNN that does not learn any high level semantics of the dataset manage to generalize so well? The goal of this article is to measure the tendency of CNNs to learn surface statistical regularities of the dataset. To this end, we use Fourier filtering to construct datasets which share the exact same high level abstractions but exhibit qualitatively different surface statistical regularities. For the SVHN and CIFAR-10 datasets, we present two Fourier filtered variants: a low frequency variant and a randomly filtered variant. Each of the Fourier filtering schemes is tuned to preserve the recognizability of the objects. Our main finding is that CNNs exhibit a tendency to latch onto the Fourier image statistics of the training dataset, sometimes exhibiting up to a 28\% generalization gap across the various test sets. Moreover, we observe that significantly increasing the depth of a network has a very marginal impact on closing the aforementioned generalization gap. Thus we provide quantitative evidence supporting the hypothesis that deep CNNs tend to learn surface statistical regularities in the dataset rather than higher-level abstract concepts.},
	urldate = {2018-05-29},
	journal = {arXiv:1711.11561 [cs, stat]},
	author = {Jo, Jason and Bengio, Yoshua},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.11561},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\QCDN7YQJ\\1711.html:text/html;Jo und Bengio - 2017 - Measuring the tendency of CNNs to Learn Surface St.pdf:C\:\\Users\\Anna\\Zotero\\storage\\BPYZQFNC\\Jo und Bengio - 2017 - Measuring the tendency of CNNs to Learn Surface St.pdf:application/pdf}
}

@inproceedings{li_effective_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Effective {Soundness}-{Guided} {Reflection} {Analysis}},
	isbn = {978-3-662-48287-2 978-3-662-48288-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-662-48288-9_10},
	doi = {10.1007/978-3-662-48288-9_10},
	abstract = {We introduce Solar, the first reflection analysis that allows its soundness to be reasoned about when some assumptions are met and produces significantly improved under-approximations otherwise. In both settings, Solar has three novel aspects: (1) lazy heap modeling for reflective allocation sites, (2) collective inference for improving the inferences on related reflective calls, and (3) automatic identification of “problematic” reflective calls that may threaten its soundness, precision and scalability, thereby enabling their improvement via lightweight annotations. We evaluate Solar against two state-of-the-art solutions, Doop and Elf, with the three treated as under-approximate reflection analyses, using 11 large Java benchmarks and applications. Solar is significantly more sound while achieving nearly the same precision and running only several-fold more slowly, subject to only 7 annotations in 3 programs.},
	language = {en},
	urldate = {2018-05-29},
	booktitle = {Static {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Li, Yue and Tan, Tian and Xue, Jingling},
	month = sep,
	year = {2015},
	pages = {162--180},
	file = {Li et al. - 2015 - Effective Soundness-Guided Reflection Analysis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Y6K8ZTTG\\Li et al. - 2015 - Effective Soundness-Guided Reflection Analysis.pdf:application/pdf}
}

@misc{gross_emotional_2018,
	type = {Tweet},
	title = {The emotional journey of creating anything great requires crossing the dark swamp of despair.. {Outsiders} almost never see the crazy belief and persistence required to cross that chasm..pic.twitter.com/{iyZBKw}5zE8},
	url = {https://twitter.com/Bill_Gross/status/1000211381109469184},
	language = {en},
	urldate = {2018-05-29},
	journal = {@Bill\_Gross},
	author = {Gross, Bill},
	month = may,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\EKTAP44P\\1000211381109469184.html:text/html}
}

@article{wijayarathna_why_2018,
	title = {Why {Johnny} {Can}'t {Store} {Passwords} {Securely}? {A} {Usability} {Evaluation} of {Bouncycastle} {Password} {Hashing}},
	shorttitle = {Why {Johnny} {Can}'t {Store} {Passwords} {Securely}?},
	url = {https://128.84.21.199/abs/1805.09487},
	language = {en},
	urldate = {2018-05-29},
	author = {Wijayarathna, Chamila and Arachchilage, Nalin Asanka Gamagedara},
	month = may,
	year = {2018},
	keywords = {user study},
	file = {Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\AJGZFT6W\\Wijayarathna und Arachchilage - 2018 - Why Johnny Can't Store Passwords Securely A Usabi.pdf:application/pdf;Wijayarathna und Arachchilage - 2018 - Why Johnny Can't Store Passwords Securely A Usabi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\WI9LYQI6\\Wijayarathna und Arachchilage - 2018 - Why Johnny Can't Store Passwords Securely A Usabi.pdf:application/pdf}
}

@article{senarath_why_2018,
	title = {Why developers cannot embed privacy into software systems? {An} empirical investigation},
	shorttitle = {Why developers cannot embed privacy into software systems?},
	url = {https://128.84.21.199/abs/1805.09485},
	language = {en},
	urldate = {2018-05-29},
	author = {Senarath, Awanthika and Arachchilage, Nalin Asanka Gamagedara},
	month = may,
	year = {2018},
	keywords = {to read, user stduy},
	file = {Senarath und Arachchilage - 2018 - Why developers cannot embed privacy into software .pdf:C\:\\Users\\Anna\\Zotero\\storage\\CEJ6FRKX\\Senarath und Arachchilage - 2018 - Why developers cannot embed privacy into software .pdf:application/pdf}
}

@inproceedings{androulaki_hyperledger_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Hyperledger {Fabric}: {A} {Distributed} {Operating} {System} for {Permissioned} {Blockchains}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {Hyperledger {Fabric}},
	url = {http://doi.acm.org/10.1145/3190508.3190538},
	doi = {10.1145/3190508.3190538},
	abstract = {Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org). Fabric is the first truly extensible blockchain system for running distributed applications. It supports modular consensus protocols, which allows the system to be tailored to particular use cases and trust models. Fabric is also the first blockchain system that runs distributed applications written in standard, general-purpose programming languages, without systemic dependency on a native cryptocurrency. This stands in sharp contrast to existing block-chain platforms that require "smart-contracts" to be written in domain-specific languages or rely on a cryptocurrency. Fabric realizes the permissioned model using a portable notion of membership, which may be integrated with industry-standard identity management. To support such flexibility, Fabric introduces an entirely novel blockchain design and revamps the way blockchains cope with non-determinism, resource exhaustion, and performance attacks. This paper describes Fabric, its architecture, the rationale behind various design decisions, its most prominent implementation aspects, as well as its distributed application programming model. We further evaluate Fabric by implementing and benchmarking a Bitcoin-inspired digital currency. We show that Fabric achieves end-to-end throughput of more than 3500 transactions per second in certain popular deployment configurations, with sub-second latency, scaling well to over 100 peers.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-04},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Androulaki, Elli and Barger, Artem and Bortnikov, Vita and Cachin, Christian and Christidis, Konstantinos and De Caro, Angelo and Enyeart, David and Ferris, Christopher and Laventman, Gennady and Manevich, Yacov and Muralidharan, Srinivasan and Murthy, Chet and Nguyen, Binh and Sethi, Manish and Singh, Gari and Smith, Keith and Sorniotti, Alessandro and Stathakopoulou, Chrysoula and Vukolić, Marko and Cocco, Sharon Weed and Yellick, Jason},
	year = {2018},
	pages = {30:1--30:15},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\Y75LYK2H\\Androulaki et al. - 2018 - Hyperledger Fabric A Distributed Operating System.pdf:application/pdf}
}

@inproceedings{yu_dynamic_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Dynamic {Control} {Flow} in {Large}-scale {Machine} {Learning}},
	isbn = {978-1-4503-5584-1},
	url = {http://doi.acm.org/10.1145/3190508.3190551},
	doi = {10.1145/3190508.3190551},
	abstract = {Many recent machine learning models rely on fine-grained dynamic control flow for training and inference. In particular, models based on recurrent neural networks and on reinforcement learning depend on recurrence relations, data-dependent conditional execution, and other features that call for dynamic control flow. These applications benefit from the ability to make rapid control-flow decisions across a set of computing devices in a distributed system. For performance, scalability, and expressiveness, a machine learning system must support dynamic control flow in distributed and heterogeneous environments. This paper presents a programming model for distributed machine learning that supports dynamic control flow. We describe the design of the programming model, and its implementation in TensorFlow, a distributed machine learning system. Our approach extends the use of dataflow graphs to represent machine learning models, offering several distinctive features. First, the branches of conditionals and bodies of loops can be partitioned across many machines to run on a set of heterogeneous devices, including CPUs, GPUs, and custom ASICs. Second, programs written in our model support automatic differentiation and distributed gradient computations, which are necessary for training machine learning models that use control flow. Third, our choice of non-strict semantics enables multiple loop iterations to execute in parallel across machines, and to overlap compute and I/O operations. We have done our work in the context of TensorFlow, and it has been used extensively in research and production. We evaluate it using several real-world applications, and demonstrate its performance and scalability.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-08},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Yu, Yuan and Abadi, Martín and Barham, Paul and Brevdo, Eugene and Burrows, Mike and Davis, Andy and Dean, Jeff and Ghemawat, Sanjay and Harley, Tim and Hawkins, Peter and Isard, Michael and Kudlur, Manjunath and Monga, Rajat and Murray, Derek and Zheng, Xiaoqiang},
	year = {2018},
	pages = {18:1--18:15},
	file = {Yu et al. - 2018 - Dynamic Control Flow in Large-scale Machine Learni.pdf:C\:\\Users\\Anna\\Zotero\\storage\\S4YZZ24N\\Yu et al. - 2018 - Dynamic Control Flow in Large-scale Machine Learni.pdf:application/pdf}
}

@inproceedings{zhang_bds:_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {{BDS}: {A} {Centralized} {Near}-optimal {Overlay} {Network} for {Inter}-datacenter {Data} {Replication}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {{BDS}},
	url = {http://doi.acm.org/10.1145/3190508.3190519},
	doi = {10.1145/3190508.3190519},
	abstract = {Many important cloud services require replicating massive data from one datacenter (DC) to multiple DCs. While the performance of pair-wise inter-DC data transfers has been much improved, prior solutions are insufficient to optimize bulk-data multicast, as they fail to explore the capability of servers to store-and-forward data, as well as the rich inter-DC overlay paths that exist in geo-distributed DCs. To take advantage of these opportunities, we present BDS, an application-level multicast overlay network for large-scale inter-DC data replication. At the core of BDS is a fully centralized architecture, allowing a central controller to maintain an up-to-date global view of data delivery status of intermediate servers, in order to fully utilize the available overlay paths. To quickly react to network dynamics and workload churns, BDS speeds up the control algorithm by decoupling it into selection of overlay paths and scheduling of data transfers, each can be optimized efficiently. This enables BDS to update overlay routing decisions in near realtime (e.g., every other second) at the scale of multicasting hundreds of TB data over tens of thousands of overlay paths. A pilot deployment in one of the largest online service providers shows that BDS can achieve 3-5 x speedup over the provider's existing system and several well-known overlay routing baselines.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-08},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Zhang, Yuchao and Jiang, Junchen and Xu, Ke and Nie, Xiaohui and Reed, Martin J. and Wang, Haiyang and Yao, Guang and Zhang, Miao and Chen, Kai},
	year = {2018},
	pages = {10:1--10:14},
	file = {Zhang et al. - 2018 - BDS A Centralized Near-optimal Overlay Network fo.pdf:C\:\\Users\\Anna\\Zotero\\storage\\L2YAUFVQ\\Zhang et al. - 2018 - BDS A Centralized Near-optimal Overlay Network fo.pdf:application/pdf}
}

@inproceedings{van_der_linden_safe_2018,
	title = {Safe {Cryptography} for {All}: {Towards} {Visual} {Metaphor} {Driven} {Cryptography} {Building} {Blocks}},
	shorttitle = {Safe {Cryptography} for {All}},
	doi = {10.1145/3194707.3194709},
	abstract = {In this vision paper, we focus on a key aspect of the modern software developer's potential to write secure software: their (lack of) success in securely using cryptography APIs. In particular, we note that most ongoing research tends to focus on identifying concrete problems software developers experience, and providing workable solutions, but that such solutions still require developers to identify the appropriate API calls to make and, worse, to be familiar with and configure sometimes obscure parameters of such calls. In contrast, we envision identifying and employing targeted visual metaphors to allow developers to simply select the most appropriate cryptographic functionality they need.},
	author = {van der Linden, Dirk and Rashid, Awais and Williams, Emma and Warinschi, Bogdan},
	month = may,
	year = {2018},
	file = {van der Linden et al. - 2018 - Safe Cryptography for All Towards Visual Metaphor.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7FUSADCI\\van der Linden et al. - 2018 - Safe Cryptography for All Towards Visual Metaphor.pdf:application/pdf}
}

@inproceedings{jeong_improving_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Improving the {Expressiveness} of {Deep} {Learning} {Frameworks} with {Recursion}},
	isbn = {978-1-4503-5584-1},
	url = {http://doi.acm.org/10.1145/3190508.3190530},
	doi = {10.1145/3190508.3190530},
	abstract = {Recursive neural networks have widely been used by researchers to handle applications with recursively or hierarchically structured data. However, embedded control flow deep learning frameworks such as TensorFlow, Theano, Caffe2, and MXNet fail to efficiently represent and execute such neural networks, due to lack of support for recursion. In this paper, we add recursion to the programming model of existing frameworks by complementing their design with recursive execution of dataflow graphs as well as additional APIs for recursive definitions. Unlike iterative implementations, which can only understand the topological index of each node in recursive data structures, our recursive implementation is able to exploit the recursive relationships between nodes for efficient execution based on parallel computation. We present an implementation on TensorFlow and evaluation results with various recursive neural network models, showing that our recursive implementation not only conveys the recursive nature of recursive neural networks better than other implementations, but also uses given resources more effectively to reduce training and inference time.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-11},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Jeong, Eunji and Jeong, Joo Seong and Kim, Soojeong and Yu, Gyeong-In and Chun, Byung-Gon},
	year = {2018},
	keywords = {automatic differentiation, data flow graph, deep learning framework, programmability, recursive neural network},
	pages = {19:1--19:13},
	file = {Jeong et al. - 2018 - Improving the Expressiveness of Deep Learning Fram.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KDIKMUXU\\Jeong et al. - 2018 - Improving the Expressiveness of Deep Learning Fram.pdf:application/pdf}
}

@inproceedings{peng_optimus:_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Optimus: {An} {Efficient} {Dynamic} {Resource} {Scheduler} for {Deep} {Learning} {Clusters}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {Optimus},
	url = {http://doi.acm.org/10.1145/3190508.3190517},
	doi = {10.1145/3190508.3190517},
	abstract = {Deep learning workloads are common in today's production clusters due to the proliferation of deep learning driven AI services (e.g., speech recognition, machine translation). A deep learning training job is resource-intensive and time-consuming. Efficient resource scheduling is the key to the maximal performance of a deep learning cluster. Existing cluster schedulers are largely not tailored to deep learning jobs, and typically specifying a fixed amount of resources for each job, prohibiting high resource efficiency and job performance. This paper proposes Optimus, a customized job scheduler for deep learning clusters, which minimizes job training time based on online resource-performance models. Optimus uses online fitting to predict model convergence during training, and sets up performance models to accurately estimate training speed as a function of allocated resources in each job. Based on the models, a simple yet effective method is designed and used for dynamically allocating resources and placing deep learning tasks to minimize job completion time. We implement Optimus on top of Kubernetes, a cluster manager for container orchestration, and experiment on a deep learning cluster with 7 CPU servers and 6 GPU servers, running 9 training jobs using the MXNet framework. Results show that Optimus outperforms representative cluster schedulers by about 139\% and 63\% in terms of job completion time and makespan, respectively.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-12},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Peng, Yanghua and Bao, Yixin and Chen, Yangrui and Wu, Chuan and Guo, Chuanxiong},
	year = {2018},
	keywords = {deep learning, resource management},
	pages = {3:1--3:14},
	file = {Peng et al. - 2018 - Optimus An Efficient Dynamic Resource Scheduler f.pdf:C\:\\Users\\Anna\\Zotero\\storage\\H6ZHWQH4\\Peng et al. - 2018 - Optimus An Efficient Dynamic Resource Scheduler f.pdf:application/pdf}
}

@inproceedings{garefalakis_medea:_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Medea: {Scheduling} of {Long} {Running} {Applications} in {Shared} {Production} {Clusters}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {Medea},
	url = {http://doi.acm.org/10.1145/3190508.3190549},
	doi = {10.1145/3190508.3190549},
	abstract = {The rise in popularity of machine learning, streaming, and latency-sensitive online applications in shared production clusters has raised new challenges for cluster schedulers. To optimize their performance and resilience, these applications require precise control of their placements, by means of complex constraints, e.g., to collocate or separate their long-running containers across groups of nodes. In the presence of these applications, the cluster scheduler must attain global optimization objectives, such as maximizing the number of deployed applications or minimizing the violated constraints and the resource fragmentation, but without affecting the scheduling latency of short-running containers. We present Medea, a new cluster scheduler designed for the placement of long- and short-running containers. Medea introduces powerful placement constraints with formal semantics to capture interactions among containers within and across applications. It follows a novel two-scheduler design: (i) for long-running containers, it applies an optimization-based approach that accounts for constraints and global objectives; (ii) for short-running containers, it uses a traditional task-based scheduler for low placement latency. Evaluated on a 400-node cluster, our implementation of Medea on Apache Hadoop YARN achieves placement of long-running applications with significant performance and resilience benefits compared to state-of-the-art schedulers.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-14},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Garefalakis, Panagiotis and Karanasos, Konstantinos and Pietzuch, Peter and Suresh, Arun and Rao, Sriram},
	year = {2018},
	pages = {4:1--4:13},
	file = {Garefalakis et al. - 2018 - Medea Scheduling of Long Running Applications in .pdf:C\:\\Users\\Anna\\Zotero\\storage\\KSX9RFM5\\Garefalakis et al. - 2018 - Medea Scheduling of Long Running Applications in .pdf:application/pdf}
}

@inproceedings{psaroudakis_analytics_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Analytics with {Smart} {Arrays}: {Adaptive} and {Efficient} {Language}-independent {Data}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {Analytics with {Smart} {Arrays}},
	url = {http://doi.acm.org/10.1145/3190508.3190514},
	doi = {10.1145/3190508.3190514},
	abstract = {This paper introduces smart arrays, an abstraction for providing adaptive and efficient language-independent data storage. Their smart functionalities include NUMA-aware data placement across sockets and bit compression. We show how our single C++ implementation can be used efficiently from both native C++ and compiled Java code. We experimentally evaluate smart arrays on a diverse set of C++ and Java analytics workloads. Further, we show how their smart functionalities affect performance and lead to differences in hardware resource demands on multicore machines, motivating the need for adaptivity. We observe that smart arrays can significantly decrease the memory space requirements of analytics workloads, and improve their performance by up to 4x. Smart arrays are the first step towards general smart collections with various smart functionalities that enable the consumption of hardware resources to be traded-off against one another.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-14},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Psaroudakis, Iraklis and Kaestle, Stefan and Grimmer, Matthias and Goodman, Daniel and Lozi, Jean-Pierre and Harris, Tim},
	year = {2018},
	keywords = {adaptivity, compression, data structures, graph analytics, language interoperability, multicore, NUMA, resource trade-offs},
	pages = {17:1--17:15},
	file = {Psaroudakis et al. - 2018 - Analytics with Smart Arrays Adaptive and Efficien.pdf:C\:\\Users\\Anna\\Zotero\\storage\\MEXAT3SF\\Psaroudakis et al. - 2018 - Analytics with Smart Arrays Adaptive and Efficien.pdf:application/pdf}
}

@misc{noauthor_peter_nodate,
	title = {Peter {Bourgon} · {Go} for {Industrial} {Programming}},
	url = {https://peter.bourgon.org/go-for-industrial-programming/},
	urldate = {2018-06-14},
	keywords = {to read},
	file = {Peter Bourgon · Go for Industrial Programming:C\:\\Users\\Anna\\Zotero\\storage\\LWZMVBBU\\go-for-industrial-programming.html:text/html}
}

@misc{noauthor_how_nodate-2,
	title = {How to write bulletproof code in {Go}: a workflow for servers that can’t fail},
	url = {https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22},
	urldate = {2018-06-14},
	keywords = {to read},
	file = {How to write bulletproof code in Go\: a workflow for servers that can’t fail:C\:\\Users\\Anna\\Zotero\\storage\\AH7JPD8F\\how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22.html:text/html}
}

@misc{golangci_golangci-lint:_2018,
	title = {golangci-lint: {Linters} {Runner} for {Go}. 5x faster than gometalinter. {Nice} colored output. {Can} report only new issues. {Fewer} false-positives. {Yaml}/toml config},
	copyright = {AGPL-3.0},
	shorttitle = {golangci-lint},
	url = {https://github.com/golangci/golangci-lint},
	urldate = {2018-06-14},
	author = {golangci},
	month = jun,
	year = {2018},
	note = {original-date: 2018-05-04T13:41:15Z},
	keywords = {go, to read, ci, golang, linter}
}

@article{tian_deeptest:_2017,
	title = {{DeepTest}: {Automated} {Testing} of {Deep}-{Neural}-{Network}-driven {Autonomous} {Cars}},
	shorttitle = {{DeepTest}},
	url = {http://arxiv.org/abs/1708.08559},
	abstract = {Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explores different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.},
	urldate = {2018-06-18},
	journal = {arXiv:1708.08559 [cs]},
	author = {Tian, Yuchi and Pei, Kexin and Jana, Suman and Ray, Baishakhi},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.08559},
	keywords = {Computer Science - Software Engineering, Computer Science - Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JQZ34XIK\\1708.html:text/html;Tian et al. - 2017 - DeepTest Automated Testing of Deep-Neural-Network.pdf:C\:\\Users\\Anna\\Zotero\\storage\\PPU853XW\\Tian et al. - 2017 - DeepTest Automated Testing of Deep-Neural-Network.pdf:application/pdf}
}

@inproceedings{xu_debugging_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Debugging with {Intelligence} via {Probabilistic} {Inference}},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3180237},
	doi = {10.1145/3180155.3180237},
	abstract = {We aim to debug a single failing execution without the assistance from other passing/failing runs. In our context, debugging is a process with substantial uncertainty - lots of decisions have to be made such as what variables shall be inspected first. To deal with such uncertainty, we propose to equip machines with human-like intelligence. Specifically, we develop a highly automated debugging technique that aims to couple human-like reasoning (e.g., dealing with uncertainty and fusing knowledge) with program semantics based analysis, to achieve benefits from the two and mitigate their limitations. We model debugging as a probabilistic inference problem, in which the likelihood of each executed statement instance and variable being correct/faulty is modeled by a random variable. Human knowledge, human-like reasoning rules and program semantics are modeled as conditional probability distributions, also called probabilistic constraints. Solving these constraints identifies the most likely faulty statements. Our results show that the technique is highly effective. It can precisely identify root causes for a set of real-world bugs in a very small number of interactions with developers, much smaller than a recent proposal that does not encode human intelligence. Our user study also confirms that it substantially improves human productivity.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-06-19},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Xu, Zhaogui and Ma, Shiqing and Zhang, Xiangyu and Zhu, Shuofei and Xu, Baowen},
	year = {2018},
	keywords = {debugging, probabilistic inference, Python},
	pages = {1171--1181},
	file = {Xu et al. - 2018 - Debugging with Intelligence via Probabilistic Infe.pdf:C\:\\Users\\Anna\\Zotero\\storage\\9XUCX4CB\\Xu et al. - 2018 - Debugging with Intelligence via Probabilistic Infe.pdf:application/pdf}
}

@book{noauthor_icse_2018,
	address = {New York, NY, USA},
	title = {{ICSE} '18: {Proceedings} of the 40th {International} {Conference} on {Software} {Engineering}},
	isbn = {978-1-4503-5638-1},
	shorttitle = {{ICSE} '18},
	publisher = {ACM},
	year = {2018}
}

@inproceedings{oliveira_api_nodate,
	address = {Baltimore, Maryland 2018},
	title = {{API} {Blindspots}: {Why} {Experienced} {Developers} {Write} {Vulnerable} {Code}},
	abstract = {Despite the best efforts of the security community, security vulnerabilities in software are still prevalent, with new vulnerabilities reported daily and older ones stubbornly repeating themselves. One potential source of these vulnerabilities is shortcomings in the used language and library APIs. Developers tend to trust APIs, but can misunderstand or misuse them, introducing vulnerabilities. We call the causes of such misuse blindspots. In this paper, we study API blindspots from the developers’ perspective to: (1) determine the extent to which developers can detect API blindspots in code and (2) examine the extent to which developer characteristics (i.e., perception of code correctness, familiarity with code, confidence, professional experience, cognitive function, and personality) affect this capability. We conducted a study with 109 developers from four countries solving programming puzzles that involve Java APIs known to contain blindspots. We find that (1) The presence of blindspots correlated negatively with the developers’ accuracy in answering implicit security questions and the developers’ ability to identify potential security concerns in the code. This effect was more pronounced for I/O-related APIs and for puzzles with higher cyclomatic complexity. (2) Higher cognitive functioning and more programming experience did not predict better ability to detect API blindspots. (3) Developers exhibiting greater openness as a personality trait were more likely to detect API blindspots. This study has the potential to advance API security in (1) design, implementation, and testing of new APIs; (2) addressing blindspots in legacy APIs; (3) development of novel methods for developer recruitment and training based on cognitive and personality assessments; and (4) improvement of software development processes (e.g., establishment of security and functionality teams).},
	author = {Oliveira and Akefirad and Ellis and Perez and Bobhate and DeLong and Cappos and Brun and Ebner and Lin and Rahman},
	keywords = {to read, incomplete},
	file = {et al. - API Blindspots Why Experienced Developers Write V.pdf:C\:\\Users\\Anna\\Documents\\55_Paper\\ et al. - API Blindspots Why Experienced Developers Write V.pdf:application/pdf}
}

@article{mindermann_how_2018,
	title = {How {Usable} are {Rust} {Cryptography} {APIs}?},
	url = {http://arxiv.org/abs/1806.04929},
	abstract = {Context: Poor usability of cryptographic APIs is a severe source of vulnerabilities. Aim: We wanted to ﬁnd out what kind of cryptographic libraries are present in Rust and how usable they are. Method: We explored Rust’s cryptographic libraries through a systematic search, conducted an exploratory study on the major libraries and a controlled experiment on two of these libraries with 28 student participants. Results: Only half of the major libraries explicitly focus on usability and misuse resistance, which is reﬂected in their current APIs. We found that participants were more successful using rustcrypto which we considered less usable than ring before the experiment. Conclusion: We discuss API design insights and make recommendations for the design of crypto libraries in Rust regarding the detail and structure of the documentation, higher-level APIs as wrappers for the existing low-level libraries, and selected, good-quality example code to improve the emerging cryptographic libraries of Rust.},
	language = {en},
	urldate = {2018-06-19},
	journal = {arXiv:1806.04929 [cs]},
	author = {Mindermann, Kai and Keck, Philipp and Wagner, Stefan},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.04929},
	keywords = {Computer Science - Software Engineering, Computer Science - Cryptography and Security, to read, Computer Science - Programming Languages},
	file = {Mindermann et al. - 2018 - How Usable are Rust Cryptography APIs.pdf:C\:\\Users\\Anna\\Zotero\\storage\\GNFXT7E2\\Mindermann et al. - 2018 - How Usable are Rust Cryptography APIs.pdf:application/pdf}
}

@misc{noauthor_security_nodate,
	title = {Security {Code} {Review} with {Static} {Analysis} {Techniques} for the {Detection} and {Remediation} of {Security} {Vulnerabilities} - {ProQuest}},
	url = {https://search.proquest.com/openview/db08141efb09bc6bccf243ee9907807c/1?pq-origsite=gscholar&cbl=18750&diss=y},
	language = {de},
	urldate = {2018-06-19},
	keywords = {to read}
}

@article{oliveira_api_nodate-1,
	title = {{API} {Blindspots}: {Why} {Experienced} {Developers} {Write} {Vulnerable} {Code}},
	abstract = {Despite the best efforts of the security community, security vulnerabilities in software are still prevalent, with new vulnerabilities reported daily and older ones stubbornly repeating themselves. One potential source of these vulnerabilities is shortcomings in the used language and library APIs. Developers tend to trust APIs, but can misunderstand or misuse them, introducing vulnerabilities. We call the causes of such misuse blindspots. In this paper, we study API blindspots from the developers’ perspective to: (1) determine the extent to which developers can detect API blindspots in code and (2) examine the extent to which developer characteristics (i.e., perception of code correctness, familiarity with code, conﬁdence, professional experience, cognitive function, and personality) affect this capability. We conducted a study with 109 developers from four countries solving programming puzzles that involve Java APIs known to contain blindspots. We ﬁnd that (1) The presence of blindspots correlated negatively with the developers’ accuracy in answering implicit security questions and the developers’ ability to identify potential security concerns in the code. This effect was more pronounced for I/O-related APIs and for puzzles with higher cyclomatic complexity. (2) Higher cognitive functioning and more programming experience did not predict better ability to detect API blindspots. (3) Developers exhibiting greater openness as a personality trait were more likely to detect API blindspots. This study has the potential to advance API security in (1) design, implementation, and testing of new APIs; (2) addressing blindspots in legacy APIs; (3) development of novel methods for developer recruitment and training based on cognitive and personality assessments; and (4) improvement of software development processes (e.g., establishment of security and functionality teams).},
	language = {en},
	author = {Oliveira, Daniela S and Lin, Tian and Rahman, Muhammad Sajidur and Akeﬁrad, Rad and Ellis, Donovan and Perez, Eliany and Bobhate, Rahul and DeLong, Lois A and Cappos, Justin and Brun, Yuriy and Ebner, Natalie C},
	keywords = {to read},
	pages = {14},
	file = {Oliveira et al. - API Blindspots Why Experienced Developers Write V.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5NRYPNW8\\Oliveira et al. - API Blindspots Why Experienced Developers Write V.pdf:application/pdf;Oliveira et al. - API Blindspots Why Experienced Developers Write V.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5PMDL83I\\Oliveira et al. - API Blindspots Why Experienced Developers Write V.pdf:application/pdf}
}

@inproceedings{patra_conflictjs:_2018,
	title = {{ConflictJS}: finding and understanding conflicts between {JavaScript} libraries},
	isbn = {978-1-4503-5638-1},
	shorttitle = {{ConflictJS}},
	url = {http://dl.acm.org/citation.cfm?doid=3180155.3180184},
	doi = {10.1145/3180155.3180184},
	language = {en},
	urldate = {2018-06-20},
	publisher = {ACM Press},
	author = {Patra, Jibesh and Dixit, Pooja N. and Pradel, Michael},
	year = {2018},
	keywords = {to read, icse18},
	pages = {741--751},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DZ26L7AU\\Patra et al. - 2018 - ConflictJS Finding and Understanding Conflicts Be.pdf:application/pdf;Patra et al. - 2018 - ConflictJS finding and understanding conflicts be.pdf:C\:\\Users\\Anna\\Zotero\\storage\\ETE6YXRJ\\Patra et al. - 2018 - ConflictJS finding and understanding conflicts be.pdf:application/pdf}
}

@inproceedings{wu_automatically_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Automatically {Answering} {API}-related {Questions}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194965},
	doi = {10.1145/3183440.3194965},
	abstract = {Automatically recommending API-related tutorial fragments or Q\&A pairs from Stack Overflow (SO) is very helpful for developers, especially when they need to use unfamiliar APIs to complete programming tasks. However, in practice developers are more likely to express the API-related questions using natural language when they do not know the exact name of an unfamiliar API. In this paper, we propose an approach, called SOTU, to automatically find answers for API-related natural language questions (NLQs) from tutorials and SO. We first identify relevant API-related tutorial fragments and extract API-related Q\&A pairs from SO. We then construct an API-Answer corpus by combining these two sources of information. For an API-related NLQ given by the developer, we parse it into several potential APIs and then retrieve potential answers from the API-Answer corpus. Finally, we return a list of potential results ranked by their relevancy. Experiments on API-Answer corpus demonstrate the effectiveness of SOTU.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Wu, Di and Jing, Xiao-Yuan and Chen, Haowen and Zhu, Xiaoke and Zhang, Hongyu and Zuo, Mei and Zi, Lu and Zhu, Chen},
	year = {2018},
	keywords = {stack overflow, to read, application programming interface, natural language question, tutorials, icse18},
	pages = {270--271},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\Q7V67NBN\\Wu et al. - 2018 - Automatically Answering API-related Questions.pdf:application/pdf}
}

@inproceedings{hempel_deuce:_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Deuce: {A} {Lightweight} {User} {Interface} for {Structured} {Editing}},
	isbn = {978-1-4503-5638-1},
	shorttitle = {Deuce},
	url = {http://doi.acm.org/10.1145/3180155.3180165},
	doi = {10.1145/3180155.3180165},
	abstract = {We present a structure-aware code editor, called Deuce, that is equipped with direct manipulation capabilities for invoking automated program transformations. Compared to traditional refactoring environments, DEUCE employs a direct manipulation interface that is tightly integrated within a text-based editing workflow. In particular, Deuce draws (i) clickable widgets atop the source code that allow the user to structurally select the unstructured text for subexpressions and other relevant features, and (ii) a lightweight, interactive menu of potential transformations based on the current selections. We implement and evaluate our design with mostly standard transformations in the context of a small functional programming language. A controlled user study with 21 participants demonstrates that structural selection is preferred to a more traditional text-selection interface and may be faster overall once users gain experience with the tool. These results accord with Deuce's aim to provide human-friendly structural interactions on top of familiar text-based editing.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Hempel, Brian and Lubin, Justin and Lu, Grace and Chugh, Ravi},
	year = {2018},
	keywords = {to read, direct manipulation, refactoring, structured editing},
	pages = {654--664},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\WHXQ3MHE\\Hempel et al. - 2018 - Deuce A Lightweight User Interface for Structured.pdf:application/pdf}
}

@inproceedings{svajlenko_fast_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Fast, {Scalable} and {User}-guided {Clone} {Detection}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3195005},
	doi = {10.1145/3183440.3195005},
	abstract = {Despite the great number of clone detection approaches proposed in the literature, few have the scalability and speed to analyze large inter-project source datasets, where clone detection has many potential applications. Furthermore, because of the many uses of clone detection, an approach is needed that can adapt to the needs of the user to detect any kind of clone. We propose a clone detection approach designed for user-guided clone detection by exploiting the power of source transformation in a plugin based source processing pipeline. Clones are detected using a simple Jaccard-based clone similarity metric, and users customize the representation of their source code as sets of terms to target particular types or kinds of clones. Fast and scalable clone detection is achieved with indexing, sub-block filtering and input partitioning.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Svajlenko, Jeffrey and Roy, Chanchai K.},
	year = {2018},
	keywords = {clone detection, to read, fast, large-scale, scalable, user guided, icse18},
	pages = {352--353},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\WJBYWB8U\\Svajlenko und Roy - 2018 - Fast, Scalable and User-guided Clone Detection.pdf:application/pdf}
}

@inproceedings{stratis_reordering_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Reordering {Tests} for {Faster} {Test} {Suite} {Execution}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3195048},
	doi = {10.1145/3183440.3195048},
	abstract = {As software takes on more responsibility, it gets increasingly complex, requiring an extremely large number of tests for effective validation [1, 6]. Executing these large test suites is expensive, both in terms of time and energy. Cache misses are a significant contributing factor to execution time of software. In this paper, we propose an approach that helps order test executions in a test suite in such a way that instruction cache misses are reduced, and thereby execution time.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Stratis, Panagiotis and Rajan, Ajitha},
	year = {2018},
	keywords = {to read, icse18},
	pages = {442--443},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\X33X9S7F\\Stratis und Rajan - 2018 - Reordering Tests for Faster Test Suite Execution.pdf:application/pdf}
}

@inproceedings{huang_synthesizing_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Synthesizing {Qualitative} {Research} in {Software} {Engineering}: {A} {Critical} {Review}},
	isbn = {978-1-4503-5638-1},
	shorttitle = {Synthesizing {Qualitative} {Research} in {Software} {Engineering}},
	url = {http://doi.acm.org/10.1145/3180155.3180235},
	doi = {10.1145/3180155.3180235},
	abstract = {Synthesizing data extracted from primary studies is an integral component of the methodologies in support of Evidence Based Software Engineering (EBSE) such as System Literature Review (SLR). Since a large and increasing number of studies in Software Engineering (SE) incorporate qualitative data, it is important to systematically review and understand different aspects of the Qualitative Research Synthesis (QRS) being used in SE. We have reviewed the use of QRS methods in 328 SLRs published between 2005 and 2015. We also inquired the authors of 274 SLRs to confirm whether or not any QRS methods were used in their respective reviews. 116 of them provided the responses, which were included in our analysis. We found eight QRS methods applied in SE research, two of which, narrative synthesis and thematic synthesis, have been predominantly adopted by SE researchers for synthesizing qualitative data. Our study determines that a significant amount of missing knowledge and incomplete understanding of the defined QRS methods in the community. Our effort also identifies an initial set factors that may influence the selection and use of appropriate QRS methods in SE.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Huang, Xin and Zhang, He and Zhou, Xin and Babar, Muhammad Ali and Yang, Song},
	year = {2018},
	keywords = {to read, evidence-based software engineering, qualitative (synthesis) methods, research synthesis, systematic (literature) review, icse18},
	pages = {1207--1218},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\FZHII4EG\\Huang et al. - 2018 - Synthesizing Qualitative Research in Software Engi.pdf:application/pdf}
}

@inproceedings{liu_reguard:_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {{ReGuard}: {Finding} {Reentrancy} {Bugs} in {Smart} {Contracts}},
	isbn = {978-1-4503-5663-3},
	shorttitle = {{ReGuard}},
	url = {http://doi.acm.org/10.1145/3183440.3183495},
	doi = {10.1145/3183440.3183495},
	abstract = {Smart contracts enabled a new way to perform cryptocurrency transactions over blockchains. While this emerging technique introduces free-of-conflicts and transparency, smart contract itself is vulnerable. As a special form of computer program, smart contract can hardly get rid of bugs. Even worse, an exploitable security bug can lead to catastrophic consequences, e.g., loss of cryptocurrency/money. In this demo paper, we focus on the most common type of security bugs in smart contracts, i.e., reentrancy bug, which caused the famous DAO attack with a loss of 60 million US dollars. We presented ReGuard, an fuzzing-based analyzer to automatically detect reentrancy bugs in Ethereum smart contracts. Specifically, ReGuard performs fuzz testing on smart contracts by iteratively generating random but diverse transactions. Based on the runtime traces, ReGuard further dynamically identifies reentrancy vulnerabilities. In the preliminary evaluation, we have analyzed 5 existing Ethereum contracts. ReGuard automatically flagged 7 previously unreported reentrancy bugs. A demo video of ReGuard is at https://youtu.be/XxJ3\_-cmUiY.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Liu, Chao and Liu, Han and Cao, Zhao and Chen, Zhong and Chen, Bangdao and Roscoe, Bill},
	year = {2018},
	keywords = {to read, dynamic analysis, reentrancy bug, smart contract, icse18},
	pages = {65--68},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\6XA8RRNU\\Liu et al. - 2018 - ReGuard Finding Reentrancy Bugs in Smart Contract.pdf:application/pdf}
}

@inproceedings{sadeghi_temporal_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {A {Temporal} {Permission} {Analysis} and {Enforcement} {Framework} for {Android}},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3180172},
	doi = {10.1145/3180155.3180172},
	abstract = {Permission-induced attacks, i.e., security breaches enabled by permission misuse, are among the most critical and frequent issues threatening the security of Android devices. By ignoring the temporal aspects of an attack during the analysis and enforcement, the state-of-the-art approaches aimed at protecting the users against such attacks are prone to have low-coverage in detection and high-disruption in prevention of permission-induced attacks. To address this shortcomings, we present Terminator, a temporal permission analysis and enforcement framework for Android. Leveraging temporal logic model checking,Terminator's analyzer identifies permission-induced threats with respect to dynamic permission states of the apps. At runtime, Terminator's enforcer selectively leases (i.e., temporarily grants) permissions to apps when the system is in a safe state, and revokes the permissions when the system moves to an unsafe state realizing the identified threats. The results of our experiments, conducted over thousands of apps, indicate that Terminator is able to provide an effective, yet non-disruptive defense against permission-induced attacks. We also show that our approach, which does not require modification to the Android framework or apps' implementation logic, is highly reliable and widely applicable.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Sadeghi, Alireza and Jabbarvand, Reyhaneh and Ghorbani, Negar and Bagheri, Hamid and Malek, Sam},
	year = {2018},
	keywords = {Android, to read, access control (permission), temporal logic, icse18},
	pages = {846--857},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\A5JU9CX2\\Sadeghi et al. - 2018 - A Temporal Permission Analysis and Enforcement Fra.pdf:application/pdf}
}

@inproceedings{hora_assessing_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Assessing the {Threat} of {Untracked} {Changes} in {Software} {Evolution}},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3180212},
	doi = {10.1145/3180155.3180212},
	abstract = {While refactoring is extensively performed by practitioners, many Mining Software Repositories (MSR) approaches do not detect nor keep track of refactorings when performing source code evolution analysis. In the best case, keeping track of refactorings could be unnecessary work; in the worst case, these untracked changes could significantly affect the performance of MSR approaches. Since the extent of the threat is unknown, the goal of this paper is to assess whether it is significant. Based on an extensive empirical study, we answer positively: we found that between 10 and 21\% of changes at the method level in 15 large Java systems are untracked. This results in a large proportion (25\%) of entities that may have their histories split by these changes, and a measurable effect on at least two MSR approaches. We conclude that handling untracked changes should be systematically considered by MSR studies.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Hora, Andre and Silva, Danilo and Valente, Marco Tulio and Robbes, Romain},
	year = {2018},
	keywords = {to read, mining software repositories, software evolution, refactoring, icse18},
	pages = {1102--1113},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\ZQIZDA49\\Hora et al. - 2018 - Assessing the Threat of Untracked Changes in Softw.pdf:application/pdf}
}

@inproceedings{zhang_grafter:_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Grafter: {Transplantation} and {Differential} {Testing} for {Clones}},
	isbn = {978-1-4503-5663-3},
	shorttitle = {Grafter},
	url = {http://doi.acm.org/10.1145/3183440.3195038},
	doi = {10.1145/3183440.3195038},
	abstract = {Code clones are common in software. When applying similar edits to clones, developers often find it difficult to examine the runtime behavior of clones. The problem is exacerbated when some clones are tested, while their counterparts are not. To reuse tests for similar but not identical clones, Grafter transplants one clone to its counterpart by (1) identifying variations in identifier names, types, and method call targets, (2) resolving compilation errors caused by such variations through code transformation, and (3) inserting stub code to transfer input data and intermediate output values for examination. To help developers examine behavioral differences between clones, Grafter supports fine-grained differential testing at both the test outcome level and the internal program state level. Our evaluation shows that Grafter can successfully reuse tests and detect behavioral differences. The tool is available for download at http://web.cs.ucla.edu/{\textasciitilde}tianyi.zhang/grafter.html and the demo video is available at https://youtu.be/liqAeuM8s3U.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Zhang, Tianyi and Kim, Miryung},
	year = {2018},
	keywords = {to read, code clones, differential testing, software transplantation, icse18},
	pages = {422--423},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\QXIQFU2X\\Zhang und Kim - 2018 - Grafter Transplantation and Differential Testing .pdf:application/pdf}
}

@inproceedings{peitek_neuro-cognitive_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {A {Neuro}-cognitive {Perspective} of {Program} {Comprehension}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3183442},
	doi = {10.1145/3183440.3183442},
	abstract = {Program comprehension is the cognitive process of understanding code. Researchers have proposed several models to describe program comprehension. However, because program comprehension is an internal process and difficult to measure, the accuracy of the existing models are limited. Neuro-imaging methods, such as functional magnetic resonance imaging (fMRI), provide a novel neuro-cognitive perspective to program-comprehension research. With my thesis work, we aim at establishing fMRI as a new tool for program-comprehension and software-engineering studies. Furthermore, we seek to refine our existing framework for conducting fMRI studies by extending it with eye tracking and improved control conditions. We describe how we will apply our upgraded framework to extend our understanding of program comprehension. In the long-run, we would like to contribute insights from our fMRI studies into software-engineering practices by providing code-styling guidelines and programming tools, which reduce the required cognitive effort to comprehend code.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Peitek, Norman},
	year = {2018},
	keywords = {to read, program comprehension, eye tracking, functional magnetic resonance imaging, top-down comprehension, icse18},
	pages = {496--499},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\8CKNAPSL\\Peitek - 2018 - A Neuro-cognitive Perspective of Program Comprehen.pdf:application/pdf}
}

@inproceedings{kalliamvakou_what_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {What {Makes} a {Great} {Manager} of {Software} {Engineers}?},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3182525},
	doi = {10.1145/3180155.3182525},
	abstract = {Having great managers is as critical to success as having a good team or organization. A great manager is seen as fuelling the team they manage, enabling it to use its full potential. Though software engineering research studies factors that may affect the performance and productivity of software engineers and teams (like tools and skill), it has overlooked the software engineering manager. On the one hand, experts are questioning how the abundant work in management applies to software engineering. On the other hand, practitioners are looking to researchers for evidence-based guidance on how to manage software teams. We conducted a mixed methods empirical study to investigate what manager attributes developers and engineering managers perceive important and why. We present a conceptual framework of manager attributes, and find that technical skills are not the sign of greatness for an engineering manager. Through statistical analysis we identify how engineers and managers relate in their views, and how software engineering differs from other knowledge work groups.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Kalliamvakou, Eirini and Bird, Christian and Zimmermann, Thomas and Begel, Andrew and DeLine, Robert and German, Daniel M.},
	year = {2018},
	keywords = {software engineering, to read, empirical study, conceptual framework, knowledge work, manager, manager attributes, technical skills, icse18},
	pages = {701--701},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\WF7VDSUV\\Kalliamvakou et al. - 2018 - What Makes a Great Manager of Software Engineers.pdf:application/pdf}
}

@inproceedings{braude_incremental_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Incremental {UML} for {Agile} {Development} with {PREXEL}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194985},
	doi = {10.1145/3183440.3194985},
	abstract = {UML creates useful visualizations but they become monolithic, complex, and expensive to maintain. In agile development, documentation is secondary, which discourages the use of UML even further. We introduce an in-code, just-in-time, maintainable approach to UML, supported by a tool called PREXEL. PREXEL minimizes interruptions in coding by allowing concise in-line specifications which automatically synthesize in-code graphical ASCII class models, class and method skeletons, and class relationships.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Braude, Eric and Van Schooneveld, Jason},
	year = {2018},
	keywords = {to read, agile modelling, agile UML, embedded UML, incremental UML, inline UML, icse18},
	pages = {310--312},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DS7ZIX5N\\Braude und Van Schooneveld - 2018 - Incremental UML for Agile Development with PREXEL.pdf:application/pdf}
}

@inproceedings{defreez_path-based_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Path-based {Function} {Embeddings}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3195042},
	doi = {10.1145/3183440.3195042},
	abstract = {Identifying relationships among program elements, such as functions, is useful for program understanding, debugging, and analysis. We present func2vec, an algorithm that uses static traces to embed functions in a vector space such that related functions are close together, even if they are semantically and syntactically dissimilar. We present applications of func2vec that aid program comprehension.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {DeFreez, Daniel and Thakur, Aditya V. and Rubio-González, Cindy},
	year = {2018},
	keywords = {to read, program comprehension, embeddings, systems software, icse18},
	pages = {430--431},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\II2MMFDJ\\DeFreez et al. - 2018 - Path-based Function Embeddings.pdf:application/pdf}
}

@inproceedings{gao_vulnerability_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {On {Vulnerability} {Evolution} in {Android} {Apps}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194968},
	doi = {10.1145/3183440.3194968},
	abstract = {In this work, we reconstruct a set of Android app lineages which each of them represents a sequence of app versions that are historically released for the same app. Then, based on these lineages, we empirically investigate the evolution of app vulnerabilities, which are revealed by well-known vulnerability scanners, and subsequently summarise various interesting findings that constitute a tangible knowledge to the community.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Gao, Jun and Li, Li and Kong, Pingfan and Bissyandé, Tegawendé F. and Klein, Jacques},
	year = {2018},
	keywords = {incomplete, icse18},
	pages = {276--277},
	file = {Gao et al. - 2018 - On Vulnerability Evolution in Android Apps.pdf:C\:\\Users\\Anna\\Zotero\\storage\\P9E5Q6NE\\Gao et al. - 2018 - On Vulnerability Evolution in Android Apps.pdf:application/pdf}
}

@inproceedings{tian_accelerating_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Accelerating {Counterexample} {Detection} in {Software} {Model} {Checking}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194955},
	doi = {10.1145/3183440.3194955},
	abstract = {Model checking is an automatic approach in enhancing correctness of systems. However, when it is applied to discover flaws in software systems, most of the respective verification tools lack scalability due to the state-space explosion problem. Abstraction technique is useful in reducing the state space of systems. It maps a concrete set of states to a smaller set of states that is actually an approximation of the system with respect to the property of interest. Predicate abstraction [3] is one of the most often used methods for attaining a finite abstract model from a concrete program which is often even an infinite state system. With predicate abstraction, a finite set of predicates, which determines the precision of the abstraction, is selected to keep track of certain facts about the program variables. The model obtained via predicate abstraction is an over-approximation of the original program. Thus, spurious paths may exist when an insufficient set of predicates are considered.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Tian, Cong and Duan, Zhao and Duan, Zhenhua},
	year = {2018},
	keywords = {to read, icse18},
	pages = {250--251},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\HBHQ9KEV\\Tian et al. - 2018 - Accelerating Counterexample Detection in Software .pdf:application/pdf}
}

@inproceedings{decker_taxonomy_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {A {Taxonomy} of {How} {Method} {Stereotypes} {Change}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194998},
	doi = {10.1145/3183440.3194998},
	abstract = {The role of a well-designed method should not change frequently or significantly over its lifetime. As such, changes to the role of a method can be an indicator of design improvement or degradation. To measure this, we use method stereotypes. Method stereotypes provide a high-level description of a method's behavior and role; giving insight into how a method interacts with its environment and carries out tasks. When a method's stereotype changes, so has its role. This work presents a taxonomy of how method stereotypes change and why the categories of changes are significant.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Decker, Michael John and Newman, Christian D. and Dragan, Natalia and Collard, Michael L. and Maletic, Jonathan I. and Kraft, Nicholas A.},
	year = {2018},
	keywords = {to read, software change, software evolution, method stereotypes, icse18},
	pages = {337--338},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\7XNECY2W\\Decker et al. - 2018 - A Taxonomy of How Method Stereotypes Change.pdf:application/pdf}
}

@inproceedings{hannebauer_does_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Does {Syntax} {Highlighting} {Help} {Programming} {Novices}?},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3182554},
	doi = {10.1145/3180155.3182554},
	abstract = {Program comprehension is an important skill for programmers - extending and debugging existing source code is part of the daily routine. Syntax highlighting is one of the most common tools used to support developers in understanding algorithms. However, most research on code highlighting is more than 20 years old, when programmers used a completely different tool chain. Newer results on the effect of syntax highlighting as used in modern Integrated Development Environments (IDEs) are inconclusive.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Hannebauer, Christoph and Hesenius, Marc and Gruhn, Volker},
	year = {2018},
	keywords = {to read, program comprehension, IDE interface, source code typography code colouring, syntax highlighting, icse18},
	pages = {704--704},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\5SL6PSQU\\Hannebauer et al. - 2018 - Does Syntax Highlighting Help Programming Novices.pdf:application/pdf}
}

@inproceedings{mendez_open_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Open {Source} {Barriers} to {Entry}, {Revisited}: {A} {Sociotechnical} {Perspective}},
	isbn = {978-1-4503-5638-1},
	shorttitle = {Open {Source} {Barriers} to {Entry}, {Revisited}},
	url = {http://doi.acm.org/10.1145/3180155.3180241},
	doi = {10.1145/3180155.3180241},
	abstract = {Research has revealed that significant barriers exist when entering Open-Source Software (OSS) communities and that women disproportionately experience such barriers. However, this research has focused mainly on social/cultural factors, ignoring the environment itself --- the tools and infrastructure. To shed some light onto how tools and infrastructure might somehow factor into OSS barriers to entry, we conducted a field study with five teams of software professionals, who worked through five use-cases to analyze the tools and infrastructure used in their OSS projects. These software professionals found tool/infrastructure barriers in 7\% to 71\% of the use-case steps that they analyzed, most of which are tied to newcomer barriers that have been established in the literature. Further, over 80\% of the barrier types they found include attributes that are biased against women.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Mendez, Christopher and Padala, Hema Susmita and Steine-Hanson, Zoe and Hilderbrand, Claudia and Horvath, Amber and Hill, Charles and Simpson, Logan and Patil, Nupoor and Sarma, Anita and Burnett, Margaret},
	year = {2018},
	keywords = {to read, gender, newcomer, open source software, icse18},
	pages = {1004--1015},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\JV4UYR8N\\Mendez et al. - 2018 - Open Source Barriers to Entry, Revisited A Sociot.pdf:application/pdf}
}

@inproceedings{nguyen_recommending_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Recommending {Exception} {Handling} {Patterns} with {ExAssist}},
	isbn = {978-1-4503-5663-3},
	url = {http://doi.acm.org/10.1145/3183440.3194971},
	doi = {10.1145/3183440.3194971},
	abstract = {Exception handling is an advanced programming technique to prevent run-time errors or crashes for modern software systems. However, inexperienced programmers might fail to write proper exception handling code in their programs. In this paper, we introduce ExAssist, a code recommendation tool for exception handling. Ex-Assist can predict what types of exception could occur in a given piece of code and recommend proper exception handling code for such an exception. Preliminary evaluation of ExAssist suggests that it provides highly accurate recommendations.},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {ACM},
	author = {Nguyen, Tam The and Vu, Phong Minh and Pham, Hung Viet and Nguyen, Tung Thanh},
	year = {2018},
	keywords = {to read, icse18},
	pages = {282--283},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\DKG8FFQ2\\Nguyen et al. - 2018 - Recommending Exception Handling Patterns with ExAs.pdf:application/pdf}
}

@article{aldakheel_deadlock_2018,
	title = {Deadlock detector and solver ({DDS})},
	url = {http://dl.acm.org/citation.cfm?doid=3183440.3190331},
	doi = {10.1145/3183440.3190331},
	urldate = {2018-06-21},
	author = {Aldakheel, Eman},
	year = {2018},
	keywords = {to read},
	pages = {512--514}
}

@inproceedings{barbosa_global-aware_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Global-aware {Recommendations} for {Repairing} {Violations} in {Exception} {Handling}},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3182539},
	doi = {10.1145/3180155.3182539},
	urldate = {2018-06-21},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Barbosa, Eiji Adachi and Garcia, Alessandro},
	year = {2018},
	keywords = {software maintenance, to read, recommender system, exception handling},
	pages = {858--858},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\7T58HQMY\\Barbosa und Garcia - 2018 - Global-aware Recommendations for Repairing Violati.pdf:application/pdf}
}

@article{loncaric_generalized_2018,
	title = {Generalized {Data} {Structure} {Synthesis}},
	abstract = {Data structure synthesis is the task of generating data structure implementations from high-level specifications. Recent work in this area has shown potential to save programmer time and reduce the risk of defects. Existing techniques focus on data structures for manipulating subsets of a single collection, but real-world programs often track multiple related collections and aggregate properties such as sums, counts, minimums, and maximums.},
	language = {en},
	author = {Loncaric, Calvin and Ernst, Michael D and Torlak, Emina},
	year = {2018},
	pages = {11},
	file = {Loncaric et al. - 2018 - Generalized Data Structure Synthesis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NGQ2QH44\\Loncaric et al. - 2018 - Generalized Data Structure Synthesis.pdf:application/pdf}
}

@misc{noauthor_how_nodate-3,
	title = {How powerful are {Graph} {Convolutional} {Networks}?},
	url = {http://tkipf.github.io/graph-convolutional-networks/},
	abstract = {Many important real-world datasets come in the form of graphs or networks: social networks, knowledge graphs, protein-interaction networks, the World Wide Web, etc. (just to name a few). Yet, until recently, very little attention has been devoted to the generalization of neural...},
	urldate = {2018-06-21},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\QACVXHPP\\graph-convolutional-networks.html:text/html}
}

@misc{noauthor_how_2016,
	title = {How powerful are {Graph} {Convolutions}? (review of {Kipf} \& {Welling}, 2016)},
	shorttitle = {How powerful are {Graph} {Convolutions}?},
	url = {http://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/},
	abstract = {This post is about a paper that has just come out recently on practical generalizations of convolutional layers to graphs: Thomas N. Kipf and Max Welling (2016) Semi-Supervised Classification with Graph Convolutional Networks Along the way I found this earlier, related paper: Defferrard, Bresson and Vandergheynst (NIPS 2016) Convolutional Neural},
	language = {en},
	urldate = {2018-06-21},
	journal = {inFERENCe},
	month = sep,
	year = {2016},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\Y7WI5LRV\\how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2.html:text/html}
}

@article{ren_automated_2018,
	title = {Automated {Localization} for {Unreproducible} {Builds}},
	url = {http://arxiv.org/abs/1803.06766},
	abstract = {Reproducibility is the ability of recreating identical binaries under pre-defined build environments. Due to the need of quality assurance and the benefit of better detecting attacks against build environments, the practice of reproducible builds has gained popularity in many open-source software repositories such as Debian and Bitcoin. However, identifying the unreproducible issues remains a labour intensive and time consuming challenge, because of the lacking of information to guide the search and the diversity of the causes that may lead to the unreproducible binaries. In this paper we propose an automated framework called RepLoc to localize the problematic files for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs, and a heuristic rule-based filtering component that narrows the search scope. By integrating the two components with a weighted file ranking module, RepLoc is able to automatically produce a ranked list of files that are helpful in locating the problematic files for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four different categories. By considering the topmost ranked file only, RepLoc achieves an accuracy rate of 47.09\%. If we expand our examination to the top ten ranked files in the list produced by RepLoc, the accuracy rate becomes 79.28\%. Considering that there are hundreds of source code, scripts, Makefiles, etc., in a package, RepLoc significantly reduces the scope of localizing problematic files. Moreover, with the help of RepLoc, we successfully identified and fixed six new unreproducible packages from Debian and Guix.},
	urldate = {2018-06-25},
	journal = {arXiv:1803.06766 [cs]},
	author = {Ren, Zhilei and Jiang, He and Xuan, Jifeng and Yang, Zijiang},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.06766},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WAH7ILCU\\1803.html:text/html;Ren et al. - 2018 - Automated Localization for Unreproducible Builds.pdf:C\:\\Users\\Anna\\Zotero\\storage\\DNYCJ36C\\Ren et al. - 2018 - Automated Localization for Unreproducible Builds.pdf:application/pdf}
}

@article{vendome_distribute_2018,
	title = {To {Distribute} or {Not} to {Distribute}? {Why} {Licensing} {Bugs} {Matter}},
	abstract = {Software licenses dictate how source code or binaries can be modified, reused, and redistributed. In the case of open source projects, software licenses generally fit into two main categories, permissive and restrictive, depending on the degree to which they allow redistribution or modification under licenses different from the original one(s). Developers and organizations can also modify existing licenses, creating custom licenses with specific permissive/restrictive terms. Having such a variety of software licenses can create confusion among software developers, and can easily result in the introduction of licensing bugs, not necessarily limited to well-known license incompatibilities. In this work, we report a study aimed at characterizing licensing bugs by (i) building a catalog categorizing the types of licensing bugs developers and other stakeholders face, and (ii) understanding the implications licensing bugs have on the software projects they affect. The presented study is the result of the manual analysis of 1,200 discussions related to licensing bugs carried out in issue trackers and in five legal mailing lists of open source communities. Our findings uncover new types of licensing bugs not addressed in prior literature, and a detailed assessment of their implications.},
	language = {en},
	author = {Vendome, Christopher and German, Daniel M and Penta, Massimiliano Di and Bavota, Gabriele and Linares-Vásquez, Mario and Poshyvanyk, Denys},
	year = {2018},
	pages = {12},
	file = {Vendome et al. - 2018 - To Distribute or Not to Distribute Why Licensing .pdf:C\:\\Users\\Anna\\Zotero\\storage\\2IYMRK87\\Vendome et al. - 2018 - To Distribute or Not to Distribute Why Licensing .pdf:application/pdf}
}

@inproceedings{caseau_efficient_1993,
	address = {New York, NY, USA},
	series = {{OOPSLA} '93},
	title = {Efficient {Handling} of {Multiple} {Inheritance} {Hierarchies}},
	isbn = {978-0-89791-587-8},
	url = {http://doi.acm.org/10.1145/165854.165905},
	doi = {10.1145/165854.165905},
	urldate = {2018-06-25},
	booktitle = {Proceedings of the {Eighth} {Annual} {Conference} on {Object}-oriented {Programming} {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Caseau, Yves},
	year = {1993},
	pages = {271--287},
	file = {Caseau - 1993 - Efficient Handling of Multiple Inheritance Hierarc.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XU7EYT6N\\Caseau - 1993 - Efficient Handling of Multiple Inheritance Hierarc.pdf:application/pdf}
}

@inproceedings{gu_deep_2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {Deep {Code} {Search}},
	isbn = {978-1-4503-5638-1},
	url = {http://doi.acm.org/10.1145/3180155.3180167},
	doi = {10.1145/3180155.3180167},
	abstract = {To implement a program functionality, developers can reuse previously written code snippets by searching through a large-scale codebase. Over the years, many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the textual similarity between source code and natural language query. They lack a deep understanding of the semantics of queries and source code. In this paper, we propose a novel deep neural network named CODEnn (Code-Description Embedding Neural Network). Instead of matching text similarity, CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space, in such a way that code snippet and its corresponding description have similar vectors. Using the unified vector representation, code snippets related to a natural language query can be retrieved according to their vectors. Semantically related words can also be recognized and irrelevant/noisy keywords in queries can be handled. As a proof-of-concept application, we implement a code search tool named DeepCS using the proposed CODEnn model. We empirically evaluate DeepCS on a large scale codebase collected from GitHub. The experimental results show that our approach can effectively retrieve relevant code snippets and outperforms previous techniques.},
	urldate = {2018-06-26},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Gu, Xiaodong and Zhang, Hongyu and Kim, Sunghun},
	year = {2018},
	keywords = {to read, code search, deep learning, joint embedding},
	pages = {933--944},
	file = {Gu et al. - 2018 - Deep Code Search.pdf:C\:\\Users\\Anna\\Zotero\\storage\\R2AJ5B37\\Gu et al. - 2018 - Deep Code Search.pdf:application/pdf}
}

@inproceedings{paletov_inferring_2018,
	address = {New York, NY, USA},
	series = {{PLDI} 2018},
	title = {Inferring {Crypto} {API} {Rules} from {Code} {Changes}},
	isbn = {978-1-4503-5698-5},
	url = {http://doi.acm.org/10.1145/3192366.3192403},
	doi = {10.1145/3192366.3192403},
	abstract = {Creating and maintaining an up-to-date set of security rules that match misuses of crypto APIs is challenging, as crypto APIs constantly evolve over time with new cryptographic primitives and settings, making existing ones obsolete.   To address this challenge, we present a new approach to extract security fixes from thousands of code changes. Our approach consists of: (i) identifying code changes, which often capture security fixes, (ii) an abstraction that filters irrelevant code changes (such as refactorings), and (iii) a clustering analysis that reveals commonalities between semantic code changes and helps in eliciting security rules.   We applied our approach to the Java Crypto API and showed that it is effective: (i) our abstraction effectively filters non-semantic code changes (over 99\% of all changes) without removing security fixes, and (ii) over 80\% of the code changes are security fixes identifying security rules. Based on our results, we identified 13 rules, including new ones not supported by existing security checkers.},
	urldate = {2018-06-26},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Paletov, Rumen and Tsankov, Petar and Raychev, Veselin and Vechev, Martin},
	year = {2018},
	keywords = {Security, Learning, Misuse of Cryptography, important},
	pages = {450--464},
	file = {Paletov et al. - 2018 - Inferring Crypto API Rules from Code Changes.pdf:C\:\\Users\\Anna\\Zotero\\storage\\I745SCRK\\Paletov et al. - 2018 - Inferring Crypto API Rules from Code Changes.pdf:application/pdf}
}

@inproceedings{meng_secure_2017,
	title = {Secure {Coding} {Practices} in {Java}: {Challenges} and {Vulnerabilities}},
	shorttitle = {Secure {Coding} {Practices} in {Java}},
	url = {http://arxiv.org/abs/1709.09970},
	abstract = {Java platform and third-party libraries provide various security features to facilitate secure coding. However, misusing these features can cost tremendous time and effort of developers or cause security vulnerabilities in software. Prior research was focused on the misuse of cryptography and SSL APIs, but did not explore the key fundamental research question: what are the biggest challenges and vulnerabilities in secure coding practices? In this paper, we conducted a comprehensive empirical study on StackOverflow posts to understand developers' concerns on Java secure coding, their programming obstacles, and potential vulnerabilities in their code. We observed that developers have shifted their effort to the usage of authentication and authorization features provided by Spring security--a third-party framework designed to secure enterprise applications. Multiple programming challenges are related to APIs or libraries, including the complicated cross-language data handling of cryptography APIs, and the complex Java-based or XML-based approaches to configure Spring security. More interestingly, we identified security vulnerabilities in the suggested code of accepted answers. The vulnerabilities included using insecure hash functions such as MD5, breaking SSL/TLS security through bypassing certificate validation, and insecurely disabling the default protection against Cross Site Request Forgery (CSRF) attacks. Our findings reveal the insufficiency of secure coding assistance and education, and the gap between security theory and coding practices.},
	urldate = {2018-06-27},
	booktitle = {{arXiv}:1709.09970 [cs]},
	author = {Meng, Na and Nagy, Stefan and Yao, Daphne and Zhuang, Wenjie and Argoty, Gustavo Arango},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.09970},
	keywords = {authorization, cryptography, secure coding, Computer Science - Cryptography and Security, to read, incomplete, authentication, certificate validation, cryptographic hash functions, CSRF, spring security, SSL/TLS, stackOverflow},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\NTN45FL3\\Meng et al. - 2018 - Secure Coding Practices in Java Challenges and Vu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JSA9CLEI\\1709.html:text/html;Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\EMZ46JFZ\\Meng et al. - 2018 - Secure coding practices in Java challenges and vu.pdf:application/pdf;Meng et al. - 2017 - Secure Coding Practices in Java Challenges and Vu.pdf:C\:\\Users\\Anna\\Zotero\\storage\\979V5QDN\\Meng et al. - 2017 - Secure Coding Practices in Java Challenges and Vu.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\TCK2QPNA\\citation.html:text/html}
}

@misc{noauthor_survival_nodate,
	title = {A {Survival} {Guide} to a {PhD}},
	url = {http://karpathy.github.io/2016/09/07/phd/},
	urldate = {2018-06-27},
	keywords = {to read}
}

@misc{noauthor_using_0100,
	title = {Using .gitignore the {Right} {Way}},
	url = {/development/git/2017/02/22/gitignore.html},
	abstract = {Have you ever wondered what kind of patterns .gitignore allows? Was it **/*/target, target/* or *target*?? Read on and find out!},
	language = {en},
	urldate = {2018-06-28},
	journal = {Consol Labs},
	year = {0100},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\JMZI3SMD\\gitignore.html:text/html}
}

@inproceedings{yang_how_2018,
	title = {How \textit{not} to structure your database-backed web applications: a study of performance bugs in the wild},
	isbn = {978-1-4503-5638-1},
	shorttitle = {How \textit{not} to structure your database-backed web applications},
	url = {http://dl.acm.org/citation.cfm?doid=3180155.3180194},
	doi = {10.1145/3180155.3180194},
	abstract = {Many web applications use databases for persistent data storage, and using Object Relational Mapping (ORM) frameworks is a common way to develop such database-backed web applications. Unfortunately, developing efficient ORM applications is challenging, as the ORM framework hides the underlying database query generation and execution. This problem is becoming more severe as these applications need to process an increasingly large amount of persistent data. Recent research has targeted specific aspects of performance problems in ORM applications. However, there has not been any systematic study to identify common performance antipatterns in real-world such applications, how they affect resulting application performance, and remedies for them. In this paper, we try to answer these questions through a comprehensive study of 12 representative real-world ORM applications. We generalize 9 ORM performance anti-patterns from more than 200 performance issues that we obtain by studying their bug-tracking systems and profiling their latest versions. To prove our point, we manually fix 64 performance issues in their latest versions and obtain a median speedup of 2× (and up to 39× max) with fewer than 5 lines of code change in most cases. Many of the issues we found have been confirmed by developers, and we have implemented ways to identify other code fragments with similar issues as well.},
	language = {en},
	urldate = {2018-07-02},
	publisher = {ACM Press},
	author = {Yang, Junwen and Subramaniam, Pranav and Lu, Shan and Yan, Cong and Cheung, Alvin},
	year = {2018},
	keywords = {API misuse},
	pages = {800--810},
	file = {Yang et al. - 2018 - How inoti to structure your database-backed w.pdf:C\:\\Users\\Anna\\Zotero\\storage\\3G2B6UAP\\Yang et al. - 2018 - How inoti to structure your database-backed w.pdf:application/pdf}
}

@misc{noauthor_debugging_2018,
	title = {Debugging data flows in reactive programs},
	url = {https://blog.acolyer.org/2018/06/29/debugging-data-flows-in-reactive-programs/},
	abstract = {Debugging data flows in reactive programs Banken et al., ICSE’18 To round off our look at papers from ICSE, here’s a really interesting look at the challenges of debugging reactive applicatio…},
	language = {en},
	urldate = {2018-07-02},
	journal = {the morning paper},
	month = jun,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BRX8S7AB\\debugging-data-flows-in-reactive-programs.html:text/html}
}

@article{oltrogge_rise_nodate,
	title = {The {Rise} of the {Citizen} {Developer}: {Assessing} the {Security} {Impact} of {Online} {App} {Generators}},
	abstract = {Mobile apps are increasingly created using online application generators (OAGs) that automate app development, distribution, and maintenance. These tools signiﬁcantly lower the level of technical skill that is required for app development, which makes them particularly appealing to citizen developers, i.e., developers with little or no software engineering background. However, as the pervasiveness of these tools increases, so does their overall inﬂuence on the mobile ecosystem’s security, as security lapses by such generators affect thousands of generated apps. The security of such generated apps, as well as their impact on the security of the overall app ecosystem, has not yet been investigated.},
	language = {en},
	author = {Oltrogge, Marten and Derr, Erik and Stranksy, Christian and Acar, Yasemin and Fahl, Sascha and Rossow, Christian and Pellegrino, Giancarlo and Bugiel, Sven and Backes, Michael},
	pages = {14},
	file = {Oltrogge et al. - The Rise of the Citizen Developer Assessing the S.pdf:C\:\\Users\\Anna\\Zotero\\storage\\US27YZQK\\Oltrogge et al. - The Rise of the Citizen Developer Assessing the S.pdf:application/pdf}
}

@inproceedings{allen_combining_2015,
	address = {New York, NY, USA},
	series = {{SOAP} 2015},
	title = {Combining {Type}-analysis with {Points}-to {Analysis} for {Analyzing} {Java} {Library} {Source}-code},
	isbn = {978-1-4503-3585-0},
	url = {http://doi.acm.org/10.1145/2771284.2771287},
	doi = {10.1145/2771284.2771287},
	abstract = {The predominant work in static program analysis is focused on whole program analysis assuming that the whole program is present at analysis time and the only unknowns are program inputs. However, for library designers it is of paramount importance to perform semantic checks via static program analysis tools without the presence of an application. The literature offers only little research on partial program analysis for object-oriented programming languages including Java. Analyzing libraries statically requires novel abstractions for all possible applications that are not known a-priori. In this work, we present a static program analysis technique that reasons about the state of the library by approximating the behaviour of all possible applications. The key contribution is (1) the combination of type-analysis with points-to analysis and (2) the development of a most-general application (MGA) as a type, which represents the interaction of the library with all possible applications.},
	urldate = {2018-07-03},
	booktitle = {Proceedings of the 4th {ACM} {SIGPLAN} {International} {Workshop} on {State} {Of} the {Art} in {Program} {Analysis}},
	publisher = {ACM},
	author = {Allen, Nicholas and Krishnan, Padmanabhan and Scholz, Bernhard},
	year = {2015},
	keywords = {Libraries, Static Analysis, Type-based abstraction},
	pages = {13--18},
	file = {Allen et al. - 2015 - Combining Type-analysis with Points-to Analysis fo.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NG3EIIJM\\Allen et al. - 2015 - Combining Type-analysis with Points-to Analysis fo.pdf:application/pdf}
}

@misc{noauthor_privacy_2018,
	title = {Privacy risks with {Facebook}’s {PII}-based targeting: auditing a data broker’s advertising interface},
	shorttitle = {Privacy risks with {Facebook}’s {PII}-based targeting},
	url = {https://blog.acolyer.org/2018/07/03/privacy-risks-with-facebooks-pii-based-targeting-auditing-a-data-brokers-advertising-interface/},
	abstract = {Privacy risks with Facebook’s PII-based targeting: auditing a data broker’s advertising interface Venkatadri et al., IEEE Security and Privacy 2018 This is one of those jaw-hits-the-floor, can’t qu…},
	language = {en},
	urldate = {2018-07-03},
	journal = {the morning paper},
	month = jul,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\GPNUL7TW\\privacy-risks-with-facebooks-pii-based-targeting-auditing-a-data-brokers-advertising-interface.html:text/html}
}

@inproceedings{weisenburger_multitier_2016,
	title = {Multitier reactive abstractions},
	isbn = {978-1-4503-4437-1},
	url = {http://dl.acm.org/citation.cfm?doid=2984043.2984051},
	doi = {10.1145/2984043.2984051},
	abstract = {Distributed applications are traditionally developed using separate modules for each component in the distributed system, which can even be written in different programming languages. Those modules react on events such as user input, which are produced by other modules, and may in turn produce new events to be handled by different modules. Thus, most distributed applications are reactive in nature. Distributed event-based data ﬂow makes it is hard to reason about the system and therefore makes the development of distributed systems challenging.},
	language = {en},
	urldate = {2018-07-03},
	publisher = {ACM Press},
	author = {Weisenburger, Pascal},
	year = {2016},
	keywords = {example},
	pages = {18--20},
	file = {Weisenburger - 2016 - Multitier reactive abstractions.pdf:C\:\\Users\\Anna\\Zotero\\storage\\WQZINBJM\\Weisenburger - 2016 - Multitier reactive abstractions.pdf:application/pdf}
}

@inproceedings{grewe_veritas:_2016,
	title = {{VeriTaS}: verification of type system specifications: mechanizing domain knowledge about progress and preservation proofs},
	isbn = {978-1-4503-4437-1},
	shorttitle = {{VeriTaS}},
	url = {http://dl.acm.org/citation.cfm?doid=2984043.2984046},
	doi = {10.1145/2984043.2984046},
	abstract = {Developing a type system with a soundness proof is hard. The VeriTaS project aims at simplifying the development of sound type systems through automation of soundness proofs and through automated derivation of efﬁcient type checkers from sound type system speciﬁcations.},
	language = {en},
	urldate = {2018-07-03},
	publisher = {ACM Press},
	author = {Grewe, Sylvia},
	year = {2016},
	keywords = {example},
	pages = {12--14},
	file = {Grewe - 2016 - VeriTaS verification of type system specification.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XBC4TDHS\\Grewe - 2016 - VeriTaS verification of type system specification.pdf:application/pdf}
}

@misc{noauthor_how_nodate-4,
	title = {How to write a great research paper},
	url = {https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/},
	abstract = {Related links How to write a great research proposal How to give a great research talk Contact Simon Peyton Jones: simonpj@microsoft.com},
	language = {en-US},
	urldate = {2018-07-04},
	journal = {Microsoft Research},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\4U8U7XW8\\write-great-research-paper.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\2X8BVAUJ\\write-great-research-paper.html:text/html}
}

@misc{noauthor_github_nodate,
	title = {{GitHub} {Sourced} query for security sensitive information},
	url = {https://twitter.com/vadimlearning/status/1014442076853932032}
}

@article{frigo_grand_nodate,
	title = {Grand {Pwning} {Unit}: {Accelerating} {Microarchitectural} {Attacks} with the {GPU}},
	abstract = {Dark silicon is pushing processor vendors to add more specialized units such as accelerators to commodity processor chips. Unfortunately this is done without enough care to security. In this paper we look at the security implications of integrated Graphical Processor Units (GPUs) found in almost all mobile processors. We demonstrate that GPUs, already widely employed to accelerate a variety of benign applications such as image rendering, can also be used to “accelerate” microarchitectural attacks (i.e., making them more effective) on commodity platforms. In particular, we show that an attacker can build all the necessary primitives for performing effective GPU-based microarchitectural attacks and that these primitives are all exposed to the web through standardized browser extensions, allowing side-channel and Rowhammer attacks from JavaScript. These attacks bypass state-of-the-art mitigations and advance existing CPU-based attacks: we show the ﬁrst end-toend microarchitectural compromise of a browser running on a mobile phone in under two minutes by orchestrating our GPU primitives. While powerful, these GPU primitives are not easy to implement due to undocumented hardware features. We describe novel reverse engineering techniques for peeking into the previously unknown cache architecture and replacement policy of the Adreno 330, an integrated GPU found in many common mobile platforms. This information is necessary when building shader programs implementing our GPU primitives. We conclude by discussing mitigations against GPU-enabled attackers.},
	language = {en},
	author = {Frigo, Pietro and Giuffrida, Cristiano and Bos, Herbert and Razavi, Kaveh},
	pages = {16},
	file = {Frigo et al. - Grand Pwning Unit Accelerating Microarchitectural.pdf:C\:\\Users\\Anna\\Zotero\\storage\\KFK73Q45\\Frigo et al. - Grand Pwning Unit Accelerating Microarchitectural.pdf:application/pdf}
}

@misc{noauthor_enclavedb:_2018,
	title = {{EnclaveDB}: a secure database using {SGX}},
	shorttitle = {{EnclaveDB}},
	url = {https://blog.acolyer.org/2018/07/05/enclavedb-a-secure-database-using-sgx/},
	abstract = {EnclaveDB: A secure database using SGX Priebe et al., IEEE Security \& Privacy 2018 This is a really interesting paper (if you’re into this kind of thing I guess!) bringing together the security…},
	language = {en},
	urldate = {2018-07-05},
	journal = {the morning paper},
	month = jul,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\MWYVHPJ4\\enclavedb-a-secure-database-using-sgx.html:text/html}
}

@inproceedings{pratyush_oblix:_2018,
	title = {Oblix: {An} {Efficient} {Oblivious} {Search} {Index}},
	abstract = {Search indices are fundamental building blocks of many systems, and there is great interest in running them on encrypted data. Unfortunately, many known schemes that enable search queries on encrypted data achieve efficiency at the expense of security, as they reveal access patterns to the encrypted data.

In this paper we present Oblix, a search index for encrypted data that is oblivious (provably hides access patterns), is dynamic (supports inserts and deletes), and has good efficiency.

Oblix relies on a combination of novel oblivious-access techniques and recent hardware enclave platforms (e.g., Intel SGX). In particular, a key technical contribution is the design and implementation of doubly-oblivious data structures, in which the client's accesses to its internal memory are oblivious, in addition to accesses to its external memory at the server. These algorithms are motivated by hardware enclaves like SGX, which leak access patterns to both internal and external memory.

We demonstrate the usefulness of Oblix in several applications: private contact discovery for Signal, private retrieval of public keys for Key Transparency, and searchable encryption that hides access patterns and result sizes.},
	author = {Pratyush, Mishra and Rishabh, Poddar and Chen, Jerry and Chiesa, Alessandro and Popa, Raluca Ada},
	month = may,
	year = {2018}
}

@misc{noauthor_cryptoanalysis:_2018,
	title = {{CryptoAnalysis}: {CogniCrypt}\_SAST: {CrySL}-to-{Static} {Analysis} {Compiler}},
	shorttitle = {{CryptoAnalysis}},
	url = {https://github.com/CROSSINGTUD/CryptoAnalysis},
	urldate = {2018-07-06},
	publisher = {CROSSING},
	month = jul,
	year = {2018},
	note = {original-date: 2017-05-23T13:22:50Z}
}

@article{kruger_1_2018,
	title = {1 {CrySL}: {An} {Extensible} {Approach} to {Validating} the 2 {Correct} {Usage} of {Cryptographic} {APIs}},
	abstract = {19 Various studies have empirically shown that the majority of Java and Android apps misuse 20 cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such 21 misuses early in the development process. To detect cryptography misuses, one must ﬁrst deﬁne 22 secure uses, a process mastered primarily by cryptography experts, and not by developers.},
	language = {en},
	author = {Krüger, Stefan},
	year = {2018},
	pages = {28},
	file = {Krüger - 2018 - 1 CrySL An Extensible Approach to Validating the .pdf:C\:\\Users\\Anna\\Zotero\\storage\\NWRV5B4J\\Krüger - 2018 - 1 CrySL An Extensible Approach to Validating the .pdf:application/pdf}
}

@article{grunweg_mercedes_2018,
	chapter = {Mobilität},
	title = {Mercedes {C}-{Klasse}: {Das} {Auto}, das {Rempler} verpetzt},
	shorttitle = {Mercedes {C}-{Klasse}},
	url = {http://www.spiegel.de/auto/fahrberichte/mercedes-c-klasse-im-test-die-macht-alarm-a-1214357.html},
	abstract = {Nach vier Jahren Laufzeit gönnt Mercedes der C-Klasse eine Überarbeitung. Mehr als die Hälfte aller Bauteile wurden verändert. Aber die größte Innovation kommt hoffentlich nie zum Einsatz.},
	urldate = {2018-07-10},
	journal = {Spiegel Online},
	author = {Grünweg, Tom},
	month = jul,
	year = {2018},
	keywords = {Autotests, Limousine, Mercedes-Benz-Modelle},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\BFFZ9U7M\\mercedes-c-klasse-im-test-die-macht-alarm-a-1214357.html:text/html}
}

@article{smaragdakis_defensive_2018,
	title = {Defensive {Points}-{To} {Analysis}: {Eﬀective} {Soundness} via {Laziness}},
	abstract = {We present a defensive may-point-to analysis approach, which oﬀers soundness even in the presence of arbitrary opaque code: all non-empty points-to sets computed are guaranteed to be over-approximations of the sets of values arising at run time. A key design tenet of the analysis is laziness: the analysis computes points-to relationships only for variables or objects that are guaranteed to never escape into opaque code. This means that the analysis misses some valid inferences, yet it also never wastes work to compute sets of values that are not “complete”, i.e., that may be missing elements due to opaque code. Laziness enables great eﬃciency, allowing a highly precise points-to analysis (such as a 5-call-site-sensitive, ﬂow-sensitive analysis).},
	language = {en},
	author = {Smaragdakis, Yannis and Kastrinis, George},
	year = {2018},
	pages = {28}
}

@article{barker_transitioning_nodate,
	title = {Transitioning the {Use} of {Cryptographic} {Algorithms} and {Key} {Lengths}},
	abstract = {The National Institute of Standards and Technology (NIST) provides cryptographic key management guidance for defining and implementing appropriate key management procedures, using algorithms that adequately protect sensitive information, and planning ahead for possible changes in the use of cryptography because of algorithm breaks or the availability of more powerful computing techniques. NIST Special Publication (SP) 80057, Part 1 includes a general approach for transitioning from one algorithm or key length to another. This Recommendation (SP 800-131A) provides more specific guidance for transitions to the use of stronger cryptographic keys and more robust algorithms.},
	language = {en},
	author = {Barker, Elaine and Roginsky, Allen},
	pages = {29},
	file = {Barker und Roginsky - Transitioning the Use of Cryptographic Algorithms .pdf:C\:\\Users\\Anna\\Zotero\\storage\\ZTC4K9N6\\Barker und Roginsky - Transitioning the Use of Cryptographic Algorithms .pdf:application/pdf}
}

@misc{noauthor_bouncycastle.org_nodate,
	title = {bouncycastle.org},
	url = {https://bouncycastle.org/},
	urldate = {2018-07-21},
	file = {bouncycastle.org:C\:\\Users\\Anna\\Zotero\\storage\\BVJMYI7S\\bouncycastle.org.html:text/html}
}

@misc{java_cryptographic_architecture_java_2018,
	title = {Java {Cryptography} {Architecture} ({JCA}) {Reference} {Guide}},
	copyright = {Copyright © 1993, 2017, Oracle and/or its affiliates. All rights reserved.},
	url = {https://docs.oracle.com/javase/9/security/java-cryptography-architecture-jca-reference-guide.htm},
	language = {en-US},
	urldate = {2018-07-21},
	journal = {Oacle JDK 9 Documentation},
	author = {Java Cryptographic Architecture},
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\P3U8TJS9\\java-cryptography-architecture-jca-reference-guide.html:text/html}
}

@misc{go_authors_package_2018,
	title = {Package crypto},
	url = {https://golang.org/pkg/crypto/},
	urldate = {2018-07-21},
	journal = {The Go Programming Language},
	author = {Go Authors},
	year = {2018},
	file = {crypto - The Go Programming Language:C\:\\Users\\Anna\\Zotero\\storage\\3EQFECXR\\crypto.html:text/html}
}

@misc{legion_of_the_bouncy_castle_inc._bouncy_2018,
	title = {Bouncy {Castle} {Documentation}},
	url = {https://bouncycastle.org/documentation.html},
	abstract = {Legion of the Bouncy Castle Inc. BouncyCastle, 2018. https://www.bouncycastle. org/java.html},
	urldate = {2018-07-21},
	author = {Legion of the Bouncy Castle Inc.},
	year = {2018},
	file = {bouncycastle.org:C\:\\Users\\Anna\\Zotero\\storage\\MPMWEL8X\\documentation.html:text/html}
}

@misc{crazycontini_top_2017,
	title = {Top 10 {Developer} {Crypto} {Mistakes}},
	url = {https://littlemaninmyhead.wordpress.com/2017/04/22/top-10-developer-crypto-mistakes/},
	abstract = {After doing hundreds of security code reviews for companies ranging from small start-ups to large banks and telcos, and after reading hundreds of stack overflow posts on security, I have composed a…},
	language = {en},
	urldate = {2018-07-30},
	author = {{crazycontini}},
	month = apr,
	year = {2017},
	keywords = {to read}
}

@inproceedings{sidiroglou-douskos_codecarboncopy_2017,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2017},
	title = {{CodeCarbonCopy}},
	isbn = {978-1-4503-5105-8},
	url = {http://doi.acm.org/10.1145/3106237.3106269},
	doi = {10.1145/3106237.3106269},
	abstract = {We present CodeCarbonCopy (CCC), a system for transferring code from a donor application into a recipient application. CCC starts with functionality identified by the developer to transfer into an insertion point (again identified by the developer) in the recipient. CCC uses paired executions of the donor and recipient on the same input file to obtain a translation between the data representation and name space of the recipient and the data representation and name space of the donor. It also implements a static analysis that identifies and removes irrelevant functionality useful in the donor but not in the recipient. We evaluate CCC on eight transfers between six applications. Our results show that CCC can successfully transfer donor functionality into recipient applications.},
	urldate = {2018-07-31},
	booktitle = {Proceedings of the 2017 11th {Joint} {Meeting} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Sidiroglou-Douskos, Stelios and Lahtinen, Eric and Eden, Anthony and Long, Fan and Rinard, Martin},
	year = {2017},
	keywords = {Automatic, Code, Transfer},
	pages = {95--105},
	file = {Sidiroglou-Douskos et al. - 2017 - CodeCarbonCopy.pdf:C\:\\Users\\Anna\\Zotero\\storage\\3HPWDFLH\\Sidiroglou-Douskos et al. - 2017 - CodeCarbonCopy.pdf:application/pdf}
}

@inproceedings{landman_challenges_2017,
	title = {Challenges for {Static} {Analysis} of {Java} {Reflection} - {Literature} {Review} and {Empirical} {Study}},
	doi = {10.1109/ICSE.2017.53},
	abstract = {The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-the-art static analysis. Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available. We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78\% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code.},
	booktitle = {2017 {IEEE}/{ACM} 39th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Landman, D. and Serebrenik, A. and Vinju, J. J.},
	month = may,
	year = {2017},
	keywords = {program diagnostics, public domain software, Software, source code (software), software tools, Grammar, Java, static analysis tool, Tools, application program interfaces, source code, Empirical Study, Semantics, Static Analysis, abstract syntax trees, Bibliographies, code idioms, collected descriptive statistics, collections semantics, computational linguistics, dynamic proxies, Java projects, Java Reflection API, Java systems, literature review, nonexceptional exceptions, programmatic filtering meta objects, real-world Java code analysis, Reflection, reflection code analysis, reflective Java code, software behavior, Systematic Literature Review, Systematics, trees (mathematics)},
	pages = {507--518},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\ASRDXTLW\\7985689.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\IC6XQZVJ\\7985689.html:text/html;Landman et al. - 2017 - Challenges for Static Analysis of Java Reflection .pdf:C\:\\Users\\Anna\\Documents\\55_Paper\\Landman et al. - 2017 - Challenges for Static Analysis of Java Reflection .pdf:application/pdf}
}

@misc{noauthor_replication-diversity_software_engineering:_2017,
	title = {replication-diversity\_software\_engineering: {Replication} {Package} for "{Diversity} in software engineering research"},
	shorttitle = {replication-diversity\_software\_engineering},
	url = {https://github.com/SAILResearch/replication-diversity_software_engineering},
	urldate = {2018-08-07},
	publisher = {SAILResearch},
	month = nov,
	year = {2017},
	note = {original-date: 2017-11-17T19:55:34Z}
}

@inproceedings{wohlin_guidelines_2014,
	address = {New York, NY, USA},
	series = {{EASE} '14},
	title = {Guidelines for {Snowballing} in {Systematic} {Literature} {Studies} and a {Replication} in {Software} {Engineering}},
	isbn = {978-1-4503-2476-2},
	url = {http://doi.acm.org/10.1145/2601248.2601268},
	doi = {10.1145/2601248.2601268},
	abstract = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches. Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
	urldate = {2018-08-07},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {ACM},
	author = {Wohlin, Claes},
	year = {2014},
	keywords = {to read, replication, snowball search, snowballing, systematic literature review, systematic mapping studies},
	pages = {38:1--38:10},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\CG8358H5\\Wohlin - 2014 - Guidelines for Snowballing in Systematic Literatur.pdf:application/pdf}
}

@article{jane_webster_analyzing_2002,
	title = {Analyzing the {Past} to {Prepare} for the {Future}: {Writing} a {Literature} {Review}},
	volume = {26},
	url = {http://www.jstor.org/stable/4132319},
	language = {en},
	number = {2},
	journal = {MIS Quarterly},
	author = {Jane Webster and Richard T. Watson},
	year = {2002},
	keywords = {to read},
	pages = {xiii--xxiii},
	file = {Jane Webster und Richard T. Watson - 2002 - Analyzing the Past to Prepare for the Future Writ.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VEJEKSGR\\Jane Webster und Richard T. Watson - 2002 - Analyzing the Past to Prepare for the Future Writ.pdf:application/pdf}
}

@techreport{kitchenham_guidelines_2007,
	title = {Guidelines for performing {Systematic} {Literature} {Reviews} in {Software} {Engineering}},
	abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology.
The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research.
The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis},
	number = {2.3},
	institution = {Keele University and Durham University},
	author = {Kitchenham, Barbara and Charters, Stuart},
	month = jul,
	year = {2007},
	keywords = {to read},
	pages = {65}
}

@book{fink_conducting_2014,
	address = {Thousand Oaks, California},
	edition = {Fourth edition},
	title = {Conducting research literature reviews: from the internet to paper},
	isbn = {978-1-4522-5949-9},
	shorttitle = {Conducting research literature reviews},
	publisher = {SAGE},
	author = {Fink, Arlene},
	year = {2014},
	keywords = {to read, Evaluation, Bibliography, Methodology, Research}
}

@misc{noauthor_delayed_2018,
	title = {Delayed impact of fair machine learning},
	url = {https://blog.acolyer.org/2018/08/13/delayed-impact-of-fair-machine-learning/},
	abstract = {Delayed impact of fair machine learning Liu et al., ICML’18 “Delayed impact of fair machine learning” won a best paper award at ICML this year. It’s not an easy read (at least it …},
	language = {en},
	urldate = {2018-08-13},
	journal = {the morning paper},
	month = aug,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\I5RYYM5N\\delayed-impact-of-fair-machine-learning.html:text/html}
}

@misc{noauthor_obfuscated_2018,
	title = {Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples},
	shorttitle = {Obfuscated gradients give a false sense of security},
	url = {https://blog.acolyer.org/2018/08/15/obfuscated-gradients-give-a-false-sense-of-security-circumventing-defenses-to-adversarial-examples/},
	abstract = {Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples Athalye et al., ICML’18 There has been a lot of back and forth in the research community on…},
	language = {en},
	urldate = {2018-08-15},
	journal = {the morning paper},
	month = aug,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\DSJNWWUT\\obfuscated-gradients-give-a-false-sense-of-security-circumventing-defenses-to-adversarial-examp.html:text/html}
}

@misc{noauthor_filter_2018,
	title = {Filter before you parse: faster analytics on raw data with {Sparser}},
	shorttitle = {Filter before you parse},
	url = {https://blog.acolyer.org/2018/08/20/filter-before-you-parse-faster-analytics-on-raw-data-with-sparser/},
	abstract = {Filter before you parse: faster analytics on raw data with Sparser Palkar et al., VLDB’18 We’ve been parsing JSON for over 15 years. So it’s surprising and wonderful that with a fresh look at…},
	language = {en},
	urldate = {2018-08-20},
	journal = {the morning paper},
	month = aug,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\H254I7IU\\filter-before-you-parse-faster-analytics-on-raw-data-with-sparser.html:text/html}
}

@misc{noauthor_filter_nodate,
	title = {Filter {Before} {You} {Parse}: {Faster} {Analytics} on {Raw} {Data} with {Sparser} · {Stanford} {DAWN}},
	url = {https://dawn.cs.stanford.edu/2018/08/07/sparser/},
	urldate = {2018-08-20},
	file = {Filter Before You Parse\: Faster Analytics on Raw Data with Sparser · Stanford DAWN:C\:\\Users\\Anna\\Zotero\\storage\\X85UX95X\\sparser.html:text/html}
}

@article{kruger_crysl:_2018-2,
	title = {{CrySL}: {An} {Extensible} {Approach} to {Validating} the {Correct} {Usage} of {Cryptographic} {APIs}},
	abstract = {Various studies have empirically shown that the majority of Java and Android apps misuse cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such misuses early in the development process. To detect cryptography misuses, one must ﬁrst deﬁne secure uses, a process mastered primarily by cryptography experts, and not by developers.},
	language = {en},
	author = {Krüger, Stefan and Späth, Johannes and Ali, Karim and Bodden, Eric and Mezini, Mira},
	year = {2018},
	keywords = {important},
	pages = {27},
	file = {Krüger et al. - 2018 - CrySL An Extensible Approach to Validating the Co.pdf:C\:\\Users\\Anna\\Zotero\\storage\\5DFI5K9F\\Krüger et al. - 2018 - CrySL An Extensible Approach to Validating the Co.pdf:application/pdf}
}

@article{ratner_snorkel:_2017,
	title = {Snorkel: {Rapid} {Training} {Data} {Creation} with {Weak} {Supervision}},
	volume = {11},
	issn = {21508097},
	shorttitle = {Snorkel},
	url = {http://arxiv.org/abs/1711.10160},
	doi = {10.14778/3157794.3157797},
	abstract = {Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a first-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research labs. In a user study, subject matter experts build models 2.8x faster and increase predictive performance an average 45.5\% versus seven hours of hand labeling. We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 1.8x speedup per pipeline execution. In two collaborations, with the U.S. Department of Veterans Affairs and the U.S. Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132\% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60\% of the predictive performance of large hand-curated training sets.},
	number = {3},
	urldate = {2018-08-23},
	journal = {Proceedings of the VLDB Endowment},
	author = {Ratner, Alexander and Bach, Stephen H. and Ehrenberg, Henry and Fries, Jason and Wu, Sen and Ré, Christopher},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10160},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	pages = {269--282},
	file = {arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IK8CAY8Z\\1711.html:text/html;Ratner et al. - 2017 - Snorkel Rapid Training Data Creation with Weak Su.pdf:C\:\\Users\\Anna\\Zotero\\storage\\BDCXEQC9\\Ratner et al. - 2017 - Snorkel Rapid Training Data Creation with Weak Su.pdf:application/pdf}
}

@inproceedings{xu_sttr:_2018,
	address = {Hamilton, New Zealand},
	title = {{STTR}: {A} {System} for {Tracking} {All} {Vehicles} {All} the {Time} {At} the {Edge} of the {Network}},
	isbn = {978-1-4503-5782-1},
	shorttitle = {{STTR}},
	url = {http://dl.acm.org/citation.cfm?doid=3210284.3210291},
	doi = {10.1145/3210284.3210291},
	abstract = {To fully exploit the capabilities of sensors in real life, especially cameras, smart camera surveillance requires the cooperation from both domain experts in computer vision and systems. Existing alert-based smart surveillance is only capable of tracking a limited number of suspicious objects, while in most real-life applications, we often do not know the perpetrator ahead of time for tracking their activities in advance. In this work, we propose a radically different approach to smart surveillance for vehicle tracking. Specifically, we explore a smart camera surveillance system aimed at tracking all vehicles in real time. The insight is not to store the raw videos, but to store the space-time trajectories of the vehicles. Since vehicle tracking is a continuous and geo-distributed task, we assume a geo-distributed Fog computing infrastructure as the execution platform for our system. To bound the storage space for storing the trajectories on each Fog node (serving the computational needs of a camera), we focus on the activities of vehicles in the vicinity of a given camera in a specific geographic region instead of the time dimension, and the fact that every vehicle has a “finite” lifetime. To bound the computational and network communication requirements for detection, re-identification, and inter-node communication, we propose novel techniques, namely, forward and backward propagation that reduces the latency for the operations and the communication overhead. STTR is a system for smart surveillance that we have built embodying these ideas. For evaluation, we develop a toolkit upon SUMO to emulate camera detections from traffic flow and adopt MaxiNet to emulate the fog computing infrastructure on Microsoft Azure.},
	language = {en},
	urldate = {2018-08-30},
	booktitle = {Proceedings of the 12th {ACM} {International} {Conference} on {Distributed} and {Event}-based {Systems}  - {DEBS} '18},
	publisher = {ACM Press},
	author = {Xu, Zhuangdi and Gupta, Harshit and Ramachandran, Umakishore},
	year = {2018},
	pages = {124--135},
	file = {Xu et al. - 2018 - STTR A System for Tracking All Vehicles All the T.pdf:C\:\\Users\\Anna\\Zotero\\storage\\VJP2FZP7\\Xu et al. - 2018 - STTR A System for Tracking All Vehicles All the T.pdf:application/pdf}
}

@article{gorski_developers_nodate,
	title = {Developers {Deserve} {Security} {Warnings}, {Too}},
	abstract = {Cryptographic API misuse is responsible for a large number of software vulnerabilities. In many cases developers are overburdened by the complex set of programming choices and their security implications. Past studies have identiﬁed signiﬁcant challenges when using cryptographic APIs that lack a certain set of usability features (e. g. easy-to-use documentation or meaningful warning and error messages) leading to an especially high likelihood of writing functionally correct but insecure code.},
	language = {en},
	author = {Gorski, Peter Leo and Iacono, Luigi Lo and Wermke, Dominik and Stransky, Christian and Moeller, Sebastian and Acar, Yasemin and Fahl, Sascha},
	keywords = {to read},
	pages = {17},
	file = {Gorski et al. - Developers Deserve Security Warnings, Too.pdf:C\:\\Users\\Anna\\Zotero\\storage\\W52YPYCS\\Gorski et al. - Developers Deserve Security Warnings, Too.pdf:application/pdf}
}

@misc{noauthor_cryptographically_2017,
	title = {Cryptographically {Secure} {Pseudo}-{Random} {Number} {Generator} ({CSPRNG})},
	url = {https://www.veracode.com/blog/research/cryptographically-secure-pseudo-random-number-generator-csprng},
	abstract = {Skip to the tl;dr},
	urldate = {2018-09-03},
	journal = {CA Veracode},
	month = mar,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\SYT4ANLL\\cryptographically-secure-pseudo-random-number-generator-csprng.html:text/html}
}

@misc{noauthor_fear_nodate,
	title = {Fear the {Reaper}: {Characterization} and {Fast} {Detection} of {Card} {Skimmers} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/usenixsecurity18/presentation/scaife},
	urldate = {2018-09-05},
	file = {Fear the Reaper\: Characterization and Fast Detection of Card Skimmers | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\QP3VTNVV\\scaife.html:text/html}
}

@misc{noauthor_empirical_nodate,
	title = {An {Empirical} {Analysis} of {Anonymity} in {Zcash} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/usenixsecurity18/presentation/kappos},
	urldate = {2018-09-14},
	file = {An Empirical Analysis of Anonymity in Zcash | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\6IU783CM\\kappos.html:text/html}
}

@article{wang_understanding_2018,
	title = {Understanding the factors for fast answers in technical {Q}\&{A} websites: {An} empirical study of four stack exchange websites},
	volume = {23},
	issn = {1382-3256, 1573-7616},
	shorttitle = {Understanding the factors for fast answers in technical {Q}\&{A} websites},
	url = {http://link.springer.com/10.1007/s10664-017-9558-5},
	doi = {10.1007/s10664-017-9558-5},
	language = {en},
	number = {3},
	urldate = {2018-09-14},
	journal = {Empirical Software Engineering},
	author = {Wang, Shaowei and Chen, Tse-Hsun and Hassan, Ahmed E.},
	month = jun,
	year = {2018},
	pages = {1552--1593}
}

@article{battaglia_relational_2018,
	title = {Relational inductive biases, deep learning, and graph networks},
	url = {http://arxiv.org/abs/1806.01261},
	abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning.},
	urldate = {2018-09-19},
	journal = {arXiv:1806.01261 [cs, stat]},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.01261},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv\:1806.01261 PDF:C\:\\Users\\Anna\\Zotero\\storage\\D4XUCQBC\\Battaglia et al. - 2018 - Relational inductive biases, deep learning, and gr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\RYF6JJTP\\1806.html:text/html}
}

@article{ricci_same-different_2018,
	title = {Same-different problems strain convolutional neural networks},
	url = {http://arxiv.org/abs/1802.03390},
	abstract = {The robust and efficient recognition of visual relations in images is a hallmark of biological vision. We argue that, despite recent progress in visual recognition, modern machine vision algorithms are severely limited in their ability to learn visual relations. Through controlled experiments, we demonstrate that visual-relation problems strain convolutional neural networks (CNNs). The networks eventually break altogether when rote memorization becomes impossible, as when intra-class variability exceeds network capacity. Motivated by the comparable success of biological vision, we argue that feedback mechanisms including attention and perceptual grouping may be the key computational components underlying abstract visual reasoning.{\textbackslash}},
	urldate = {2018-09-21},
	journal = {arXiv:1802.03390 [cs, q-bio]},
	author = {Ricci, Matthew and Kim, Junkyung and Serre, Thomas},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.03390},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition},
	file = {arXiv\:1802.03390 PDF:C\:\\Users\\Anna\\Zotero\\storage\\XKCB4EY7\\Ricci et al. - 2018 - Same-different problems strain convolutional neura.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\LTH27UNA\\1802.html:text/html}
}

@misc{noauthor_online_nodate,
	title = {Online {Parameter} {Selection} for {Web}-based {Ranking} {Problems}},
	url = {http://www.kdd.org/kdd2018/accepted-papers/view/online-parameter-selection-for-web-based-ranking-problems},
	language = {en},
	urldate = {2018-10-10},
	journal = {SIGKDD - KDD 2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WK2QAIFV\\online-parameter-selection-for-web-based-ranking-problems.html:text/html}
}

@misc{noauthor_grammarly_nodate,
	title = {Grammarly},
	url = {https://app.grammarly.com/docs/new},
	urldate = {2018-10-10},
	file = {Grammarly:C\:\\Users\\Anna\\Zotero\\storage\\IGPUCF79\\new.html:text/html}
}

@misc{noauthor_rept:_nodate,
	title = {{REPT}: {Reverse} {Debugging} of {Failures} in {Deployed} {Software} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/osdi18/presentation/weidong},
	urldate = {2018-10-17},
	file = {REPT\: Reverse Debugging of Failures in Deployed Software | USENIX:C\:\\Users\\Anna\\Zotero\\storage\\ZFH6DDX8\\weidong.html:text/html}
}

@misc{noauthor_state_nodate,
	title = {The {State} of {Software} {Security} {Today}},
	url = {https://www.veracode.com/sites/default/files/pdf/resources/ipapers/soss-2017/index.html?mkt_tok=eyJpIjoiTnpGaE9EazROemxoT0dNeSIsInQiOiJuRGNYTjBZUysrSHBqUkdOOXVXQ0Y0XC9oZlV5Yk1jdzJ5N2xBTkNuanNWM2JBOXlyaUZPck4zQXRPMlloN2NJZHJLRGRGZ3hndXRLK3JBYmQrdUFxYU9VbzhPMlNEeSt1UEhuclFPSVVpU3BBbTFTUlhhd25wSlpKZGNZTThhY0kifQ%3D%3D},
	abstract = {Veracode presents the eight volume of the State of Software Security (SOSS) report, the application security industry’s most comprehensive review of application testing data.},
	urldate = {2018-10-18},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\WZ2ZHPAI\\index.html:text/html}
}

@misc{noauthor_dont_2017,
	title = {Don't {Get} {Zapped} by the {Struts}-{Shock} {Vulnerability} {Affecting} {Apache} {Struts} 2},
	url = {https://www.veracode.com/blog/security-news/struts-shock-vulnerability-affecting-apache-struts-2},
	abstract = {If you haven't heard of it by now, you should sit up and pay attention to "Struts-Shock." That's what CA Veracode is calling a critical vulnerability just identified in the Apache Struts 2 library, which attackers are actively exploiting.},
	urldate = {2018-10-18},
	journal = {CA Veracode},
	month = mar,
	year = {2017},
	keywords = {real-world attack}
}

@misc{noauthor_hackers_nodate,
	title = {Hackers steal identity info of 72,000 at {U} of {Delaware}},
	url = {https://www.usatoday.com/story/tech/2013/07/31/identity-theft-university-of-delaware/2602229/},
	language = {en},
	urldate = {2018-10-18},
	journal = {usatoday},
	keywords = {real-world attack},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\SFFYTLUJ\\2602229.html:text/html;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\IZHJF3IT\\2602229.html:text/html}
}

@misc{noauthor_dont_nodate,
	title = {Don't {Get} {Zapped} by the {Struts}-{Shock} {Vulnerability} {Affecting} {Apache} {Struts} 2 {\textbar} {Veracode} {Blog}},
	url = {https://www.veracode.com/blog/security-news/struts-shock-vulnerability-affecting-apache-struts-2},
	urldate = {2018-10-18},
	keywords = {real-world attack},
	file = {Don't Get Zapped by the Struts-Shock Vulnerability Affecting Apache Struts 2 | Veracode Blog:C\:\\Users\\Anna\\Zotero\\storage\\78FXZCEM\\struts-shock-vulnerability-affecting-apache-struts-2.html:text/html}
}

@misc{biasini_content-type:_nodate,
	title = {Content-{Type}: {Malicious} - {New} {Apache} {Struts}2 0-day {Under} {Attack}},
	shorttitle = {Content-{Type}},
	url = {http://blog.talosintelligence.com/2017/03/apache-0-day-exploited.html},
	abstract = {A blog from the world class Intelligence Group, Talos, Cisco's Intelligence Group},
	urldate = {2018-10-18},
	author = {Biasini, Nick},
	keywords = {real-world attack},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\UEC6ZEBD\\apache-0-day-exploited.html:text/html}
}

@misc{noauthor_canadian_2017,
	title = {Canadian agency breached as hackers exploit {CVE}-2017-5638 flaw in {Apache} {Struts} 2},
	url = {https://securityaffairs.co/wordpress/57130/hacking/cra-apache-struts-hack.html},
	abstract = {Canada Revenue Agency confirmed it shut down its website for filing federal taxes due to a cyber attack leveraging the CVE-2017-5638 flaw in Apache Struts 2},
	language = {en-US},
	urldate = {2018-10-18},
	journal = {Security Affairs},
	month = mar,
	year = {2017},
	keywords = {real-world attack},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\CTDQUMCB\\cra-apache-struts-hack.html:text/html}
}

@misc{noauthor_cve_nodate,
	title = {{CVE} - {CVE}-2017-5638},
	url = {https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5638},
	urldate = {2018-10-18},
	keywords = {real-world attack},
	file = {CVE - CVE-2017-5638:C\:\\Users\\Anna\\Zotero\\storage\\V755E6NF\\cvename.html:text/html}
}

@misc{noauthor_san_nodate,
	title = {San {Francisco} {Rail} {System} {Hacker} {Hacked} — {Krebs} on {Security}},
	url = {https://krebsonsecurity.com/2016/11/san-francisco-rail-system-hacker-hacked/},
	language = {en-US},
	urldate = {2018-10-18},
	keywords = {real-world attack},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\ZVIYVKWF\\san-francisco-rail-system-hacker-hacked.html:text/html}
}

@inproceedings{james_stephen_program_2014,
	address = {New York, NY, USA},
	series = {{ASE} '14},
	title = {Program {Analysis} for {Secure} {Big} {Data} {Processing}},
	isbn = {978-1-4503-3013-8},
	url = {http://doi.acm.org/10.1145/2642937.2643006},
	doi = {10.1145/2642937.2643006},
	abstract = {The ubiquitous nature of computers is driving a massive increase in the amount of data generated by humans and machines. Two natural consequences of this are the increased efforts to (a) derive meaningful information from accumulated data and (b) ensure that data is not used for unintended purposes. In the direction of analyzing massive amounts of data (a.), tools like MapReduce, Spark, Dryad and higher level scripting languages like Pig Latin and DryadLINQ have significantly improved corresponding tasks for software developers. The second, but equally important aspect of ensuring confidentiality (b.), has seen little support emerge for programmers: while advances in cryptographic techniques allow us to process directly on encrypted data, programmer-friendly and efficient ways of programming such data analysis jobs are still missing. This paper presents novel data flow analyses and program transformations for Pig Latin, that automatically enable the execution of corresponding scripts on encrypted data. We avoid fully homomorphic encryption because of its prohibitively high cost; instead, in some cases, we rely on a minimal set of operations performed by the client. We present the algorithms used for this translation, and empirically demonstrate the practical performance of our approach as well as improvements for programmers in terms of the effort required to preserve data confidentiality.},
	urldate = {2018-11-27},
	booktitle = {Proceedings of the 29th {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {ACM},
	author = {James Stephen, Julian and Savvides, Savvas and Seidel, Russell and Eugster, Patrick},
	year = {2014},
	keywords = {privacy, big data, cloud computing},
	pages = {277--288},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\I9ACAU9Z\\James Stephen et al. - 2014 - Program Analysis for Secure Big Data Processing.pdf:application/pdf}
}

@inproceedings{cui_mining_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mining {Function} {Call} {Sequence} {Patterns} {Across} {Different} {Versions} of the {Project} for {Defect} {Detection}},
	isbn = {978-3-030-04272-1},
	abstract = {Large scale programs usually imply many programming rules, which are missing from specification documents. However, if programmers violate these rules in the process of programming, they may introduce software defects. Mining programming rules for detecting defect is an effective way to alleviate this problem. However, previous works suffer from a large number of candidate rules and suspicious defects which need manual validation. This issue affects the applicability and scalability of these previously proposed approaches. This paper proposes a novel approach to detect defects based on programming rules mined from different versions of a project. Firstly, it mines function call sequence patterns from the version under analysis and a previous stable version; secondly, it filters useful function call sequence patterns based on the patterns contained in the previous version; thirdly, the programs are automatically checked against filtered patterns for detecting suspicious defects. Experiments are carried out on three open source projects varies from 12k to 142k LOC to evaluate the effectiveness of our proposed approach. The experiment results show that the approach can improve the efficiency of defect detection by reducing 55\% suspicious defects for the three projects without comprising the defect detection capability.},
	language = {en},
	booktitle = {Software {Analysis}, {Testing}, and {Evolution}},
	publisher = {Springer International Publishing},
	author = {Cui, Zhanqi and Chen, Xiang and Mu, Yongmin and Zhang, Zhihua and Ma, Xu},
	editor = {Bu, Lei and Xiong, Yingfei},
	year = {2018},
	keywords = {Defect detection, Programming rules, Version history},
	pages = {154--169},
	file = {Cui et al. - 2018 - Mining Function Call Sequence Patterns Across Diff.pdf:C\:\\Users\\Anna\\Zotero\\storage\\XFGVPUVX\\Cui et al. - 2018 - Mining Function Call Sequence Patterns Across Diff.pdf:application/pdf;Springer Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\GGZNSMGL\\Cui et al. - 2018 - Mining Function Call Sequence Patterns Across Diff.pdf:application/pdf}
}

@book{noauthor_software_2019,
	address = {New York, NY},
	title = {Software analysis, testing, and evolution},
	isbn = {978-3-030-04271-4},
	language = {en},
	publisher = {Springer Berlin Heidelberg},
	year = {2019},
	file = {2019 - Software analysis, testing, and evolution.pdf:C\:\\Users\\Anna\\Zotero\\storage\\E2WJLB37\\2019 - Software analysis, testing, and evolution.pdf:application/pdf}
}

@article{spath_boomerang:_2016-1,
	title = {Boomerang: {Demand}-{Driven} {Flow}- and {Context}-{Sensitive} {Pointer} {Analysis} for {Java}},
	abstract = {Many current program analyses require highly precise pointer information about small, targeted parts of a given program. This motivates the need for demand-driven pointer analyses that compute information only where required. Pointer analyses generally compute points-to sets of program variables or answer boolean alias queries. However, many client analyses require richer pointer information. For example, taint and typestate analyses often need to know the set of all aliases of a given variable under a certain calling context. With most current pointer analyses, clients must compute such information through repeated points-to or alias queries, increasing complexity and computation time for them. This paper presents Boomerang, a demand-driven, ﬂow-, ﬁeld-, and context-sensitive pointer analysis for Java programs. Boomerang computes rich results that include both the possible allocation sites of a given pointer (points-to information) and all pointers that can point to those allocation sites (alias information). For increased precision and scalability, clients can query Boomerang with respect to particular calling contexts of interest.},
	language = {en},
	author = {Späth, Johannes and Do, Lisa Nguyen Quang and Ali, Karim and Bodden, Eric},
	year = {2016},
	pages = {26},
	file = {Späth et al. - 2016 - Boomerang Demand-Driven Flow- and Context-Sensiti.pdf:C\:\\Users\\Anna\\Zotero\\storage\\AXFF7IYG\\Späth et al. - 2016 - Boomerang Demand-Driven Flow- and Context-Sensiti.pdf:application/pdf}
}

@misc{noauthor_morning_nodate-9,
	title = {The {Morning} {Paper}: {Identifying} impactful service system problems via log analysis},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/zyskc2wsi2?e=6b9727817f},
	urldate = {2018-12-19},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\V3TEIQZB\\zyskc2wsi2.html:text/html}
}

@article{bousquet_tradeoffs_nodate,
	title = {The {Tradeoffs} of {Large} {Scale} {Learning}},
	abstract = {This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation–estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.},
	language = {en},
	author = {Bousquet, Olivier and Bottou, Léon},
	keywords = {machine learning},
	pages = {8},
	file = {Bousquet und Bottou - The Tradeoffs of Large Scale Learning.pdf:C\:\\Users\\Anna\\Zotero\\storage\\E55WNZE9\\Bousquet und Bottou - The Tradeoffs of Large Scale Learning.pdf:application/pdf}
}

@misc{noauthor_contribute_2018,
	title = {Contribute to {M}-{Cosmetics}/cafre development by creating an account on {GitHub}},
	url = {https://github.com/M-Cosmetics/cafre},
	urldate = {2019-01-10},
	publisher = {M-Cosmetics},
	month = aug,
	year = {2018},
	note = {original-date: 2018-02-06T07:05:05Z}
}

@misc{noauthor_crypto_nodate,
	title = {Crypto misuses from {Mattis}' thesis by salsolatragus · {Pull} {Request} \#156 · stg-tud/{MUBench}},
	url = {https://github.com/stg-tud/MUBench/pull/156},
	language = {en},
	urldate = {2019-01-15},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\KGX2N39T\\156.html:text/html}
}

@inproceedings{ma_cdrep:_2016,
	address = {Xi'an, China},
	title = {{CDRep}: {Automatic} {Repair} of {Cryptographic} {Misuses} in {Android} {Applications}},
	isbn = {978-1-4503-4233-9},
	shorttitle = {{CDRep}},
	url = {http://dl.acm.org/citation.cfm?doid=2897845.2897896},
	doi = {10.1145/2897845.2897896},
	abstract = {Cryptography is increasingly being used in mobile applications to provide various security services; from user authentication, data privacy, to secure communications. However, there are plenty of mistakes that developers could accidentally make when using cryptography in their mobile apps and such mistakes can lead to a false sense of security. Recent research e↵orts indeed show that a signiﬁcant portion of mobile apps in both Android and iOS platforms misused cryptographic APIs. In this paper, we present CDRep, a tool for automatically repairing cryptographic misuse defects in Android apps. We classify such defects into seven types and manually assemble the corresponding ﬁx patterns based on the best practices in cryptographic implementations. CDRep consists of two phases, a detection phase which identiﬁes defect locations in a mobile app and a repair phase which repairs the vulnerable app automatically. In our validation, CDRep is able to successfully repair 94.5\% of 1,262 vulnerable apps. Furthermore, CDRep is lightweight, the average runtime to generate a patch is merely 19.3 seconds and the size of a repaired app increases by only 0.667\% on average.},
	language = {en},
	urldate = {2019-01-16},
	booktitle = {Proceedings of the 11th {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security} - {ASIA} {CCS} '16},
	publisher = {ACM Press},
	author = {Ma, Siqi and Lo, David and Li, Teng and Deng, Robert H.},
	year = {2016},
	keywords = {to read, automated program repair, cryptographic misuse, vulnerability detection},
	pages = {711--722},
	file = {Ma et al. - 2016 - CDRep Automatic Repair of Cryptographic Misuses i.pdf:C\:\\Users\\Anna\\Zotero\\storage\\CYCC38ZE\\Ma et al. - 2016 - CDRep Automatic Repair of Cryptographic Misuses i.pdf:application/pdf;Ma et al. - 2016 - CDRep Automatic Repair of Cryptographic Misuses i.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IPWIQ5EN\\Ma et al. - 2016 - CDRep Automatic Repair of Cryptographic Misuses i.pdf:application/pdf}
}

@article{pradel_deepbugs:_2018,
	title = {{DeepBugs}: {A} {Learning} {Approach} to {Name}-based {Bug} {Detection}},
	volume = {2},
	issn = {2475-1421},
	shorttitle = {{DeepBugs}},
	url = {http://doi.acm.org/10.1145/3276517},
	doi = {10.1145/3276517},
	abstract = {Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a semantic representation and which automatically learns bug detectors instead of manually writing them. We formulate bug detection as a binary classification problem and train a classifier that distinguishes correct from incorrect code. To address the challenge that effectively learning a bug detector requires examples of both correct and incorrect code, we create likely incorrect code examples from an existing corpus of code through simple code transformations. A novel insight learned from our work is that learning from artificially seeded bugs yields bug detectors that are effective at finding bugs in real-world code. We implement our idea into a framework for learning-based and name-based bug detection. Three bug detectors built on top of the framework detect accidentally swapped function arguments, incorrect binary operators, and incorrect operands in binary operations. Applying the approach to a corpus of 150,000 JavaScript files yields bug detectors that have a high accuracy (between 89\% and 95\%), are very efficient (less than 20 milliseconds per analyzed file), and reveal 102 programming mistakes (with 68\% true positive rate) in real-world code.},
	number = {OOPSLA},
	urldate = {2019-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Pradel, Michael and Sen, Koushik},
	month = oct,
	year = {2018},
	keywords = {JavaScript, Bug detection, Machine learning, Name-based program analysis, Natural language},
	pages = {147:1--147:25},
	file = {Pradel und Sen - 2018 - DeepBugs A Learning Approach to Name-based Bug De.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HT8QUKBH\\Pradel und Sen - 2018 - DeepBugs A Learning Approach to Name-based Bug De.pdf:application/pdf}
}

@misc{amann_contribute_2019,
	title = {Contribute to stg-tud/{MUBench} development by creating an account on {GitHub}},
	url = {https://github.com/stg-tud/MUBench},
	urldate = {2019-01-29},
	publisher = {Software Technology Group},
	author = {Amann, Sven and Schlitzer, Jonas},
	month = jan,
	year = {2019},
	note = {original-date: 2016-02-12T15:26:49Z}
}

@misc{amann_mubench_2019,
	title = {{MUBench} - {GitHub} repository},
	copyright = {View license},
	url = {https://github.com/stg-tud/MUBench},
	urldate = {2019-02-06},
	author = {Amann, Sven},
	month = jan,
	year = {2019},
	note = {original-date: 2016-02-12T15:26:49Z}
}

@inproceedings{gkortzis_vulinoss:_2018,
	address = {Gothenburg, Sweden},
	title = {{VulinOSS}: a dataset of security vulnerabilities in open-source systems},
	isbn = {978-1-4503-5716-6},
	shorttitle = {{VulinOSS}},
	url = {http://dl.acm.org/citation.cfm?doid=3196398.3196454},
	doi = {10.1145/3196398.3196454},
	abstract = {Examining the different characteristics of open-source software in relation to security vulnerabilities, can provide the research community with findings that can lead to the development of more secure systems. We present a dataset where the reported vulnerabilities of 8694 open-source project versions, can be correlated with the corresponding source code and a number of software metrics. The metrics were obtained by analyzing the project’s source code via well-established tools. Apart from commonly used metrics (e.g. loc), we also provide data related to modern development trends such as continuous integration and testing. We outline motivational examples based on the dataset we describe.},
	language = {en},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Mining} {Software} {Repositories}  - {MSR} '18},
	publisher = {ACM Press},
	author = {Gkortzis, Antonios and Mitropoulos, Dimitris and Spinellis, Diomidis},
	year = {2018},
	pages = {18--21},
	file = {Gkortzis et al. - 2018 - VulinOSS a dataset of security vulnerabilities in.pdf:C\:\\Users\\Anna\\Zotero\\storage\\4FFABUTE\\Gkortzis et al. - 2018 - VulinOSS a dataset of security vulnerabilities in.pdf:application/pdf}
}

@inproceedings{massacci_after-life_2011,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {After-{Life} {Vulnerabilities}: {A} {Study} on {Firefox} {Evolution}, {Its} {Vulnerabilities}, and {Fixes}},
	isbn = {978-3-642-19125-1},
	shorttitle = {After-{Life} {Vulnerabilities}},
	abstract = {We study the interplay in the evolution of Firefox source code and known vulnerabilities in Firefox over six major versions (v1.0, v1.5, v2.0, v3.0, v3.5, and v3.6) spanning almost ten years of development, and integrating a numbers of sources (NVD, CVE, MFSA, Firefox CVS). We conclude that a large fraction of vulnerabilities apply to code that is no longer maintained in older versions. We call these after-life vulnerabilities. This complements the Milk-or-Wine study of Ozment and Schechter—which we also partly confirm—as we look at vulnerabilities in the reference frame of the source code, revealing a vulnerabilitiy’s future, while they looked at its past history. Through an analysis of that code’s market share, we also conclude that vulnerable code is still very much in use both in terms of instances and as global codebase: CVS evidence suggests that Firefox evolves relatively slowly.This is empirical evidence that the software-evolution-as-security solution—patching software and automatic updates—might not work, and that vulnerabilities will have to be mitigated by other means.},
	language = {en},
	booktitle = {Engineering {Secure} {Software} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Massacci, Fabio and Neuhaus, Stephan and Nguyen, Viet Hung},
	editor = {Erlingsson, Úlfar and Wieringa, Roel and Zannone, Nicola},
	year = {2011},
	keywords = {Local Vulnerability, Software Instance, Software Security, Software Vendor, Total Vulnerability},
	pages = {195--208},
	file = {Massacci et al. - 2011 - After-Life Vulnerabilities A Study on Firefox Evo.pdf:C\:\\Users\\Anna\\Zotero\\storage\\HSZX7I6I\\Massacci et al. - 2011 - After-Life Vulnerabilities A Study on Firefox Evo.pdf:application/pdf}
}

@inproceedings{mitropoulos_bug_2014,
	address = {New York, NY, USA},
	series = {{MSR} 2014},
	title = {The {Bug} {Catalog} of the {Maven} {Ecosystem}},
	isbn = {978-1-4503-2863-0},
	url = {http://doi.acm.org/10.1145/2597073.2597123},
	doi = {10.1145/2597073.2597123},
	abstract = {Examining software ecosystems can provide the research community with data regarding artifacts, processes, and communities. We present a dataset obtained from the Maven central repository ecosystem (approximately 265GB of data) by statically analyzing the repository to detect potential software bugs. For our analysis we used FindBugs, a tool that examines Java bytecode to detect numerous types of bugs. The dataset contains the metrics results that FindBugs reports for every project version (a JAR) included in the ecosystem. For every version we also stored specific metadata such as the JAR's size, its dependencies and others. Our dataset can be used to produce interesting research results, as we show in specific examples.},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the 11th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Mitropoulos, Dimitris and Karakoidas, Vassilios and Louridas, Panos and Gousios, Georgios and Spinellis, Diomidis},
	year = {2014},
	note = {event-place: Hyderabad, India},
	keywords = {FindBugs, Maven Repository, Software Bugs},
	pages = {372--375},
	file = {Mitropoulos et al. - 2014 - The Bug Catalog of the Maven Ecosystem.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JGLABPTK\\Mitropoulos et al. - 2014 - The Bug Catalog of the Maven Ecosystem.pdf:application/pdf}
}

@misc{oracle_java_nodate,
	title = {Java {Cryptography} {Architecture} ({JCA}) {Reference} {Guide}},
	url = {https://docs.oracle.com/javase/8/docs/technotes/guides/security/crypto/CryptoSpec.html},
	urldate = {2019-02-06},
	author = {Oracle},
	file = {Java Cryptography Architecture (JCA) Reference Guide:C\:\\Users\\Anna\\Zotero\\storage\\NPCMUMZV\\CryptoSpec.html:text/html}
}

@misc{anam_dodhy_stg-tud/github-query-script:_2019,
	title = {stg-tud/github-query-script: {MSR}19 {Alpha}},
	shorttitle = {stg-tud/github-query-script},
	url = {https://zenodo.org/record/2558580},
	abstract = {Two independent scripts to collect GitHub repositories which uses the Java cryptographic library {\textless}em{\textgreater}javax.crypto. {\textless}/em{\textgreater}},
	urldate = {2019-02-06},
	publisher = {Zenodo},
	author = {{Anam Dodhy} and {Anna-Katharina Wickert}},
	month = feb,
	year = {2019},
	doi = {10.5281/zenodo.2558580}
}

@misc{noauthor_stg-tud/github-query-script:_nodate,
	title = {stg-tud/github-query-script: {MSR}19 {Alpha} {\textbar} {Zenodo}},
	url = {https://zenodo.org/record/2558580},
	urldate = {2019-02-06},
	file = {stg-tud/github-query-script\: MSR19 Alpha | Zenodo:C\:\\Users\\Anna\\Zotero\\storage\\AA5YQKF6\\2558580.html:text/html}
}

@misc{wickert_stg-tud/github-query-script:_2019,
	title = {stg-tud/github-query-script: {MSR}19 {Alpha}},
	shorttitle = {stg-tud/github-query-script},
	url = {https://zenodo.org/record/2558580},
	abstract = {Two independent scripts to collect GitHub repositories which uses the Java cryptographic library {\textless}em{\textgreater}javax.crypto. {\textless}/em{\textgreater}},
	urldate = {2019-02-06},
	publisher = {Zenodo},
	author = {Wickert, Anna-Katharina and {Dodhy, Anam}},
	month = feb,
	year = {2019},
	doi = {10.5281/zenodo.2558580}
}

@misc{oracle_javax.crypto_nodate,
	title = {javax.crypto ({Java} {Platform} {SE} 8 )},
	url = {https://docs.oracle.com/javase/8/docs/api/javax/crypto/package-summary.html},
	urldate = {2019-02-07},
	author = {Oracle},
	file = {javax.crypto (Java Platform SE 8 ):C\:\\Users\\Anna\\Zotero\\storage\\GKDIPD2C\\package-summary.html:text/html}
}

@techreport{german_federal_office_for_information_security_bsi_cryptographic_2018,
	title = {Cryptographic mechanisms: {Recommendations} and key lengths},
	author = {German Federal Office for Information Security (BSI)},
	month = may,
	year = {2018}
}

@article{gad-elrab_exfakt:_2019,
	title = {{ExFaKT}: {A} {Framework} for {Explaining} {Facts}  over {Knowledge} {Graphs} and {Text}},
	abstract = {Fact checking is a crucial task for accurately populating, updating and curating knowledge graphs. Manually validating candidate facts is time-consuming. Prior work on automating this task focuses on estimating truthfulness using numerical scores which are not human-interpretable. Others extract explicit mentions of the candidate fact in the text as an evidence for the candidate fact, which can be hard to directly spot. In our work, we introduce ExFaKT, a framework focused on generating human-comprehensible explanations for candidate facts. ExFaKT uses background knowledge encoded in the form of Horn clauses to rewrite the fact in question into a set of other easier-to-spot facts. The final output of our framework is a set of semantic traces for the candidate fact from both text and knowledge graphs. The experiments demonstrate that our rewritings significantly increase the recall of fact spotting while preserving high precision. Moreover, we show that the explanations effectively help humans to perform fact-checking and can also perform well when used for automated fact-checking.},
	language = {en},
	author = {Gad-Elrab, Mohamed and Stepanova, Daria and Urbani, Jacopo and Weikum, Gerhard},
	year = {2019},
	pages = {10},
	file = {Gad-Elrab et al. - 2019 - ExFaKT A Framework for Explaining Facts  over Kno.pdf:C\:\\Users\\Anna\\Zotero\\storage\\QF388Z7G\\Gad-Elrab et al. - 2019 - ExFaKT A Framework for Explaining Facts  over Kno.pdf:application/pdf}
}

@inproceedings{ognawala_automatically_2018,
	address = {New York, NY, USA},
	series = {{MASES} 2018},
	title = {Automatically {Assessing} {Vulnerabilities} {Discovered} by {Compositional} {Analysis}},
	isbn = {978-1-4503-5972-6},
	url = {http://doi.acm.org/10.1145/3243127.3243130},
	doi = {10.1145/3243127.3243130},
	abstract = {Testing is the most widely employed method to find vulnerabilities in real-world software programs. Compositional analysis, based on symbolic execution, is an automated testing method to find vulnerabilities in medium- to large-scale programs consisting of many interacting components. However, existing compositional analysis frameworks do not assess the severity of reported vulnerabilities. In this paper, we present a framework to analyze vulnerabilities discovered by an existing compositional analysis tool and assign CVSS3 (Common Vulnerability Scoring System v3.0) scores to them, based on various heuristics such as interaction with related components, ease of reachability, complexity of design and likelihood of accepting unsanitized input. By analyzing vulnerabilities reported with CVSS3 scores in the past, we train simple machine learning models. By presenting our interactive framework to developers of popular open-source software and other security experts, we gather feedback on our trained models and further improve the features to increase the accuracy of our predictions. By providing qualitative (based on community feedback) and quantitative (based on prediction accuracy) evidence from 21 open-source programs, we show that our severity prediction framework can effectively assist developers with assessing vulnerabilities.},
	urldate = {2019-02-12},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Machine} {Learning} and {Software} {Engineering} in {Symbiosis}},
	publisher = {ACM},
	author = {Ognawala, Saahil and Amato, Ricardo Nales and Pretschner, Alexander and Kulkarni, Pooja},
	year = {2018},
	note = {event-place: Montpellier, France},
	keywords = {compositional analysis, machine learning, software testing, symbolic execution, vulnerability assessment},
	pages = {16--25},
	file = {Ognawala et al. - 2018 - Automatically Assessing Vulnerabilities Discovered.pdf:C\:\\Users\\Anna\\Zotero\\storage\\Y98RDBL5\\Ognawala et al. - 2018 - Automatically Assessing Vulnerabilities Discovered.pdf:application/pdf}
}

@article{allamanis_adverse_2018,
	title = {The {Adverse} {Effects} of {Code} {Duplication} in {Machine} {Learning} {Models} of {Code}},
	url = {http://arxiv.org/abs/1812.06469},
	abstract = {The field of big code relies on mining large corpora of code to perform some learning task. A significant threat to this approach has been recently identified by Lopes et al. (2017) who found a large amount of near-duplicate code on GitHub. However, the impact of code duplication has not been noticed by researchers devising machine learning models for source code. In this article, we study the effect of code duplication to machine learning models showing that reported metrics are sometimes inflated by up to 100\% when testing on duplicated code corpora compared to the performance on de-duplicated corpora which more accurately represent how machine learning models of code are used by software engineers. We present an "errata" for widely used datasets, list best practices for collecting code corpora and evaluating machine learning models on them, and release tools to help the community avoid this problem in future research.},
	urldate = {2019-02-12},
	journal = {arXiv:1812.06469 [cs]},
	author = {Allamanis, Miltiadis},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.06469},
	keywords = {Computer Science - Software Engineering, machine learning, Computer Science - Machine Learning, code duplication},
	file = {Allamanis - 2018 - The Adverse Effects of Code Duplication in Machine.pdf:C\:\\Users\\Anna\\Zotero\\storage\\PDPKK6HD\\Allamanis - 2018 - The Adverse Effects of Code Duplication in Machine.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\HJDMKZDG\\1812.html:text/html}
}

@misc{noauthor_beyond_2019,
	title = {Beyond news contents: the role of social context for fake news detection},
	shorttitle = {Beyond news contents},
	url = {https://blog.acolyer.org/2019/02/13/beyond-news-contents-the-role-of-social-context-for-fake-news-detection/},
	abstract = {Beyond news contents: the role of social context for fake news detection Shu et al., WSDM’19 Today we’re looking at a more general fake news problem: detecting fake news that is being spread …},
	language = {en},
	urldate = {2019-02-13},
	journal = {the morning paper},
	month = feb,
	year = {2019},
	keywords = {fake news detection, fake news, think-off},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\K36VVYVG\\beyond-news-contents-the-role-of-social-context-for-fake-news-detection.html:text/html}
}

@inproceedings{dietrich_driver_2018,
	title = {Driver {Generation} for {Java} {EE} {Web} {Applications}},
	doi = {10.1109/ASWEC.2018.00024},
	abstract = {Program analyses typically need to identify a single entry method that triggers program executions. However, many modern applications do not have such a single entry point. Instead, they have to be deployed in a container that interacts with them through an application programming interface (API). We present a tool that generates a driver that supplies such an entry method for Java EE web applications. The generated driver simulates an arbitrary client interacting with the web application through the container. We describe the modular design of the driver generator, and existing support for features like Java server pages, servlets, filters and listeners. We report on our experience of using the driver generator for large real-world web applications.},
	booktitle = {2018 25th {Australasian} {Software} {Engineering} {Conference} ({ASWEC})},
	author = {Dietrich, J. and Gauthier, F. and Krishnan, P.},
	month = nov,
	year = {2018},
	keywords = {Testing, Libraries, Internet, Java, Servers, Tools, application program interfaces, application programming interface, Bug Detection, Static Analysis, arbitrary client interacting, Containers, Driver, driver generation, driver generator, driver simulation, Generators, Java EE Web applications, Java server pages, JEE, modern applications, program analyses, program executions, real-world Web applications, single entry method, single entry point, Static analysis, Vulnerability Detection},
	pages = {121--125},
	file = {Dietrich et al. - 2018 - Driver Generation for Java EE Web Applications.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7LHMM8ZF\\Dietrich et al. - 2018 - Driver Generation for Java EE Web Applications.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\6EWI4E79\\8587295.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\Anna\\Zotero\\storage\\575CYD4I\\8587295.html:text/html}
}

@article{ritzinger_survey_2016,
	title = {A survey on dynamic and stochastic vehicle routing problems},
	volume = {54},
	issn = {0020-7543, 1366-588X},
	url = {http://www.tandfonline.com/doi/full/10.1080/00207543.2015.1043403},
	doi = {10.1080/00207543.2015.1043403},
	language = {en},
	number = {1},
	urldate = {2019-02-15},
	journal = {International Journal of Production Research},
	author = {Ritzinger, Ulrike and Puchinger, Jakob and Hartl, Richard F.},
	month = jan,
	year = {2016},
	pages = {215--231}
}

@article{cvitkovic_open_2018,
	title = {Open {Vocabulary} {Learning} on {Source} {Code} with a {Graph}-{Structured} {Cache}},
	url = {http://arxiv.org/abs/1810.08305},
	abstract = {Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names. Reasoning over such a vocabulary is not something for which most NLP methods are designed. We introduce a Graph–Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code. We ﬁnd that combining this graph–structured cache strategy with recent Graph–Neural–Network–based models for supervised learning on code improves the models’ performance on a code completion task and a variable naming task — with over 100\% relative improvement on the latter — at the cost of a moderate increase in computation time.},
	language = {en},
	urldate = {2019-02-28},
	journal = {arXiv:1810.08305 [cs, stat]},
	author = {Cvitkovic, Milan and Singh, Badal and Anandkumar, Anima},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.08305},
	keywords = {machine learning, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {Cvitkovic et al. - 2018 - Open Vocabulary Learning on Source Code with a Gra.pdf:C\:\\Users\\Anna\\Zotero\\storage\\86J3YDVN\\Cvitkovic et al. - 2018 - Open Vocabulary Learning on Source Code with a Gra.pdf:application/pdf}
}

@misc{noauthor_2019-01-25_nodate,
	title = {2019-01-25 {Sorting} and {Transforming} {Program} {Repair} {Ingredients} via {Deep} {Learning} {Code} {Similarities}.pdf},
	url = {https://drive.google.com/file/d/1MTXvBeQl6ITmMd11F6kYUg2mNixmBPFE/view?usp=embed_facebook},
	urldate = {2019-02-28},
	journal = {Google Docs},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\4JC7X3GN\\view.html:text/html}
}

@article{white_sorting_2017,
	title = {Sorting and {Transforming} {Program} {Repair} {Ingredients} via {Deep} {Learning} {Code} {Similarities}},
	url = {http://arxiv.org/abs/1707.04742},
	abstract = {In the field of automated program repair, the redundancy assumption claims large programs contain the seeds of their own repair. However, most redundancy-based program repair techniques do not reason about the repair ingredients---the code that is reused to craft a patch. We aim to reason about the repair ingredients by using code similarities to prioritize and transform statements in a codebase for patch generation. Our approach, DeepRepair, relies on deep learning to reason about code similarities. Code fragments at well-defined levels of granularity in a codebase can be sorted according to their similarity to suspicious elements (i.e., code elements that contain suspicious statements) and statements can be transformed by mapping out-of-scope identifiers to similar identifiers in scope. We examined these new search strategies for patch generation with respect to effectiveness from the viewpoint of a software maintainer. Our comparative experiments were executed on six open-source Java projects including 374 buggy program revisions and consisted of 19,949 trials spanning 2,616 days of computation time. DeepRepair's search strategy using code similarities generally found compilable ingredients faster than the baseline, jGenProg, but this improvement neither yielded test-adequate patches in fewer attempts (on average) nor found significantly more patches than the baseline. Although the patch counts were not statistically different, there were notable differences between the nature of DeepRepair patches and baseline patches. The results demonstrate that our learning-based approach finds patches that cannot be found by existing redundancy-based repair techniques.},
	urldate = {2019-02-28},
	journal = {arXiv:1707.04742 [cs]},
	author = {White, Martin and Tufano, Michele and Martinez, Matias and Monperrus, Martin and Poshyvanyk, Denys},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.04742},
	keywords = {Computer Science - Software Engineering, to read},
	file = {arXiv\:1707.04742 PDF:C\:\\Users\\Anna\\Zotero\\storage\\HTD6TEY2\\White et al. - 2017 - Sorting and Transforming Program Repair Ingredient.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\PYXNRHMA\\1707.html:text/html}
}

@misc{noauthor_morning_nodate-10,
	title = {The {Morning} {Paper}: {Efficient} large-scale fleet management via multi-agent deep reinforcement learning},
	shorttitle = {The {Morning} {Paper}},
	url = {https://mailchi.mp/onelanday/k398sgiho5?e=6b9727817f},
	urldate = {2019-03-04},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\J9ZVL39Y\\k398sgiho5.html:text/html}
}

@inproceedings{he_identifying_2018,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2018},
	title = {Identifying {Impactful} {Service} {System} {Problems} via {Log} {Analysis}},
	isbn = {978-1-4503-5573-5},
	url = {http://doi.acm.org/10.1145/3236024.3236083},
	doi = {10.1145/3236024.3236083},
	abstract = {Logs are often used for troubleshooting in large-scale software systems. For a cloud-based online system that provides 24/7 service, a huge number of logs could be generated every day. However, these logs are highly imbalanced in general, because most logs indicate normal system operations, and only a small percentage of logs reveal impactful problems. Problems that lead to the decline of system KPIs (Key Performance Indicators) are impactful and should be fixed by engineers with a high priority. Furthermore, there are various types of system problems, which are hard to be distinguished manually. In this paper, we propose Log3C, a novel clustering-based approach to promptly and precisely identify impactful system problems, by utilizing both log sequences (a sequence of log events) and system KPIs. More specifically, we design a novel cascading clustering algorithm, which can greatly save the clustering time while keeping high accuracy by iteratively sampling, clustering, and matching log sequences. We then identify the impactful problems by correlating the clusters of log sequences with system KPIs. Log3C is evaluated on real-world log data collected from an online service system at Microsoft, and the results confirm its effectiveness and efficiency. Furthermore, our approach has been successfully applied in industrial practice.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2019-03-04},
	booktitle = {Proceedings of the 2018 26th {ACM} {Joint} {Meeting} on {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {He, Shilin and Lin, Qingwei and Lou, Jian-Guang and Zhang, Hongyu and Lyu, Michael R. and Zhang, Dongmei},
	year = {2018},
	note = {event-place: Lake Buena Vista, FL, USA},
	keywords = {Clustering, Log Analysis, Problem Identification, Service Systems},
	pages = {60--70},
	file = {He et al. - 2018 - Identifying Impactful Service System Problems via .pdf:C\:\\Users\\Anna\\Zotero\\storage\\7CE3NJM2\\He et al. - 2018 - Identifying Impactful Service System Problems via .pdf:application/pdf}
}

@inproceedings{papi_practical_2008,
	address = {New York, NY, USA},
	series = {{ISSTA} '08},
	title = {Practical {Pluggable} {Types} for {Java}},
	isbn = {978-1-60558-050-0},
	url = {http://doi.acm.org/10.1145/1390630.1390656},
	doi = {10.1145/1390630.1390656},
	abstract = {This paper introduces the Checker Framework, which supports adding pluggable type systems to the Java language in a backward-compatible way. A type system designer defines type qualifiers and their semantics, and a compiler plug-in enforces the semantics. Programmers can write the type qualifiers in their programs and use the plug-in to detect or prevent errors. The Checker Framework is useful both to programmers who wish to write error-free code, and to type system designers who wish to evaluate and deploy their type systems. The Checker Framework includes new Java syntax for expressing type qualifiers; declarative and procedural mechanisms for writing type-checking rules; and support for flow-sensitive local type qualifier inference and for polymorphism over types and qualifiers. The Checker Framework is well-integrated with the Java language and toolset. We have evaluated the Checker Framework by writing 5 checkers and running them on over 600K lines of existing code. The checkers found real errors, then confirmed the absence of further errors in the fixed code. The case studies also shed light on the type systems themselves.},
	urldate = {2019-03-05},
	booktitle = {Proceedings of the 2008 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Papi, Matthew M. and Ali, Mahmood and Correa, Jr., Telmo Luis and Perkins, Jeff H. and Ernst, Michael D.},
	year = {2008},
	note = {event-place: Seattle, WA, USA},
	keywords = {case study, verification, polymorphism, annotation, bug finding, compiler, flow sensitivity, igj, immutable, intern, java, javac, javari, nonnull, pluggable type, readonly, type qualifier, type system},
	pages = {201--212},
	file = {Papi et al. - 2008 - Practical Pluggable Types for Java.pdf:C\:\\Users\\Anna\\Zotero\\storage\\29LIWA5F\\Papi et al. - 2008 - Practical Pluggable Types for Java.pdf:application/pdf}
}

@article{hellerstein_declarative_2010,
	title = {The declarative imperative: experiences and conjectures in distributed logic},
	volume = {39},
	issn = {01635808},
	shorttitle = {The declarative imperative},
	url = {http://portal.acm.org/citation.cfm?doid=1860702.1860704},
	doi = {10.1145/1860702.1860704},
	abstract = {The rise of multicore processors and cloud computing is putting enormous pressure on the software community to ﬁnd solutions to the difﬁculty of parallel and distributed programming. At the same time, there is more—and more varied—interest in data-centric programming languages than at any time in computing history, in part because these languages parallelize naturally. This juxtaposition raises the possibility that the theory of declarative database query languages can provide a foundation for the next generation of parallel and distributed programming languages.},
	language = {en},
	number = {1},
	urldate = {2019-03-06},
	journal = {ACM SIGMOD Record},
	author = {Hellerstein, Joseph M.},
	month = sep,
	year = {2010},
	pages = {5},
	file = {Hellerstein - 2010 - The declarative imperative experiences and conjec.pdf:C\:\\Users\\Anna\\Zotero\\storage\\SYZD8UKT\\Hellerstein - 2010 - The declarative imperative experiences and conjec.pdf:application/pdf}
}

@misc{philippe_find_nodate,
	title = {Find {Security} {Bugs}},
	url = {https://find-sec-bugs.github.io/},
	urldate = {2019-03-11},
	author = {Philippe, Arteau},
	file = {Find Security Bugs:C\:\\Users\\Anna\\Zotero\\storage\\ETI5E7PN\\find-sec-bugs.github.io.html:text/html}
}

@misc{legion_of_the_bouncy_castle_inc_bouncy_nodate,
	title = {Bouncy {Castle}},
	url = {http://bouncycastle.org/},
	urldate = {2019-03-11},
	author = {\{Legion of the Bouncy Castle Inc\}},
	file = {bouncycastle.org:C\:\\Users\\Anna\\Zotero\\storage\\2ZLBA96R\\bouncycastle.org.html:text/html}
}

@misc{noauthor_mining_nodate-2,
	title = {Mining {Function} {Call} {Sequence} {Patterns} {Across} {Different} {Versions} of the {Project} for {Defect} {Detection} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-04272-1_10},
	urldate = {2019-03-12},
	file = {Mining Function Call Sequence Patterns Across Different Versions of the Project for Defect Detection | SpringerLink:C\:\\Users\\Anna\\Zotero\\storage\\6T7LKGPU\\978-3-030-04272-1_10.html:text/html}
}

@misc{noauthor_how_2018,
	title = {How {Bad} {Can} {It} {Git}? {Characterizing} {Secret} {Leakage} in {Public} {GitHub} {Repositories}},
	shorttitle = {How {Bad} {Can} {It} {Git}?},
	url = {https://www.ndss-symposium.org/ndss-paper/how-bad-can-it-git-characterizing-secret-leakage-in-public-github-repositories/},
	abstract = {Visit the post for more.},
	language = {en-US},
	urldate = {2019-04-10},
	journal = {NDSS Symposium},
	month = dec,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\6QZZ6TIR\\how-bad-can-it-git-characterizing-secret-leakage-in-public-github-repositories.html:text/html}
}

@article{barros_static_nodate,
	title = {Static {Analysis} of {Implicit} {Control} {Flow}: {Resolving} {Java} {Reﬂection} and {Android} {Intents}},
	abstract = {Implicit or indirect control ﬂow is a transfer of control between procedures using some mechanism other than an explicit procedure call. Implicit control ﬂow is a staple design pattern that adds ﬂexibility to system design. However, it is challenging for a static analysis to compute or verify properties about a system that uses implicit control ﬂow.},
	language = {en},
	author = {Barros, Paulo and Just, René and Millstein, Suzanne and Vines, Paul and Dietl, Werner},
	pages = {11},
	file = {Barros et al. - Static Analysis of Implicit Control Flow Resolvin.pdf:C\:\\Users\\Anna\\Zotero\\storage\\NY3JAYF5\\Barros et al. - Static Analysis of Implicit Control Flow Resolvin.pdf:application/pdf}
}

@inproceedings{livshits_reflection_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Reflection {Analysis} for {Java}},
	isbn = {978-3-540-32247-4},
	abstract = {Reflection has always been a thorn in the side of Java static analysis tools. Without a full treatment of reflection, static analysis tools are both incomplete because some parts of the program may not be included in the application call graph, and unsound because the static analysis does not take into account reflective features of Java that allow writes to object fields and method invocations. However, accurately analyzing reflection has always been difficult, leading to most static analysis tools treating reflection in an unsound manner or just ignoring it entirely. This is unsatisfactory as many modern Java applications make significant use of reflection.In this paper we propose a static analysis algorithm that uses points-to information to approximate the targets of reflective calls as part of call graph construction. Because reflective calls may rely on input to the application, in addition to performing reflection resolution, our algorithm also discovers all places in the program where user-provided specifications are necessary to fully resolve reflective targets. As an alternative to user-provided specifications, we also propose a reflection resolution approach based on type cast information that reduces the need for user input, but typically results in a less precise call graph.We have implemented the reflection resolution algorithms described in this paper and applied them to a set of six large, widely-used benchmark applications consisting of more than 600,000 lines of code combined. Experiments show that our technique is effective for resolving most reflective calls without any user input. Certain reflective calls, however, cannot be resolved at compile time precisely. Relying on a user-provided specification to obtain a conservative call graph results in graphs that contain 1.43 to 6.58 times more methods that the original. In one case, a conservative call graph has 7,047 more methods than a call graph that does not interpret reflective calls. In contrast, ignoring reflection leads to missing substantial portions of the application call graph.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Livshits, Benjamin and Whaley, John and Lam, Monica S.},
	editor = {Yi, Kwangkeun},
	year = {2005},
	keywords = {to read, Reflection, Call Graph, Call Site, Cast Operation, Method Invocation, Static Analysis Tool},
	pages = {139--160},
	file = {Livshits et al. - 2005 - Reflection Analysis for Java.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IKRQR5F7\\Livshits et al. - 2005 - Reflection Analysis for Java.pdf:application/pdf}
}

@inproceedings{bodden_taming_2011,
	address = {New York, NY, USA},
	series = {{ICSE} '11},
	title = {Taming {Reflection}: {Aiding} {Static} {Analysis} in the {Presence} of {Reflection} and {Custom} {Class} {Loaders}},
	isbn = {978-1-4503-0445-0},
	shorttitle = {Taming {Reflection}},
	url = {http://doi.acm.org/10.1145/1985793.1985827},
	doi = {10.1145/1985793.1985827},
	abstract = {Static program analyses and transformations for Java face many problems when analyzing programs that use reflection or custom class loaders: How can a static analysis know which reflective calls the program will execute? How can it get hold of classes that the program loads from remote locations or even generates on the fly? And if the analysis transforms classes, how can these classes be re-inserted into a program that uses custom class loaders? In this paper, we present TamiFlex, a tool chain that offers a partial but often effective solution to these problems. With TamiFlex, programmers can use existing static-analysis tools to produce results that are sound at least with respect to a set of recorded program runs. TamiFlex inserts runtime checks into the program that warn the user in case the program executes reflective calls that the analysis did not take into account. TamiFlex further allows programmers to re-insert offline-transformed classes into a program. We evaluate TamiFlex in two scenarios: benchmarking with the DaCapo benchmark suite and analysing large-scale interactive applications. For the latter, TamiFlex significantly improves code coverage of the static analyses, while for the former our approach even appears complete: the inserted runtime checks issue no warning. Hence, for the first time, TamiFlex enables sound static whole-program analyses on DaCapo. During this process, TamiFlex usually incurs less than 10\% runtime overhead.},
	urldate = {2019-04-16},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Bodden, Eric and Sewe, Andreas and Sinschek, Jan and Oueslati, Hela and Mezini, Mira},
	year = {2011},
	note = {event-place: Waikiki, Honolulu, HI, USA},
	keywords = {static analysis, to read, dynamic class loaders, dynamic class loading, native code, reflection, tracing},
	pages = {241--250},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\W7UYG37W\\Bodden et al. - 2011 - Taming Reflection Aiding Static Analysis in the P.pdf:application/pdf}
}

@inproceedings{ernst_collaborative_2014,
	address = {New York, NY, USA},
	series = {{CCS} '14},
	title = {Collaborative {Verification} of {Information} {Flow} for a {High}-{Assurance} {App} {Store}},
	isbn = {978-1-4503-2957-6},
	url = {http://doi.acm.org/10.1145/2660267.2660343},
	doi = {10.1145/2660267.2660343},
	abstract = {Current app stores distribute some malware to unsuspecting users, even though the app approval process may be costly and time-consuming. High-integrity app stores must provide stronger guarantees that their apps are not malicious. We propose a verification model for use in such app stores to guarantee that the apps are free of malicious information flows. In our model, the software vendor and the app store auditor collaborate -- each does tasks that are easy for her/him, reducing overall verification cost. The software vendor provides a behavioral specification of information flow (at a finer granularity than used by current app stores) and source code annotated with information-flow type qualifiers. A flow-sensitive, context-sensitive information-flow type system checks the information flow type qualifiers in the source code and proves that only information flows in the specification can occur at run time. The app store auditor uses the vendor-provided source code to manually verify declassifications. We have implemented the information-flow type system for Android apps written in Java, and we evaluated both its effectiveness at detecting information-flow violations and its usability in practice. In an adversarial Red Team evaluation, we analyzed 72 apps (576,000 LOC) for malware. The 57 Trojans among these had been written specifically to defeat a malware analysis such as ours. Nonetheless, our information-flow type system was effective: it detected 96\% of malware whose malicious behavior was related to information flow and 82\% of all malware. In addition to the adversarial evaluation, we evaluated the practicality of using the collaborative model. The programmer annotation burden is low: 6 annotations per 100 LOC. Every sound analysis requires a human to review potential false alarms, and in our experiments, this took 30 minutes per 1,000 LOC for an auditor unfamiliar with the app.},
	urldate = {2019-04-16},
	booktitle = {Proceedings of the 2014 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Ernst, Michael D. and Just, René and Millstein, Suzanne and Dietl, Werner and Pernsteiner, Stuart and Roesner, Franziska and Koscher, Karl and Barros, Paulo Barros and Bhoraskar, Ravi and Han, Seungyeop and Vines, Paul and Wu, Edward X.},
	year = {2014},
	note = {event-place: Scottsdale, Arizona, USA},
	keywords = {static analysis, to read, information flow, reflection, android security, collaborative verification},
	pages = {1092--1104},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\9MHHVQAK\\Ernst et al. - 2014 - Collaborative Verification of Information Flow for.pdf:application/pdf}
}

@article{fischer_stack_nodate,
	title = {Stack {Overﬂow} {Considered} {Helpful}! {Deep} {Learning} {Security} {Nudges} {Towards} {Stronger} {Cryptography}},
	abstract = {Stack Overﬂow is the most popular discussion platform for software developers. However, recent research identiﬁed a large amount of insecure encryption code in production systems that has been inspired by examples given on Stack Overﬂow. By copying and pasting functional code, developers introduced exploitable software vulnerabilities into security-sensitive high-proﬁle applications installed by millions of users every day.},
	language = {en},
	author = {Fischer, Felix and Xiao, Huang and Kao, Ching-Yu and Stachelscheid, Yannick and Johnson, Benjamin and Raza, Danial and Fawkesley, Paul and Buckley, Nat and Bottinger, Konstantin and Muntean, Paul and Grossklags, Jens},
	pages = {18},
	file = {Fischer et al. - Stack Overﬂow Considered Helpful! Deep Learning Se.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IFAJXB9P\\Fischer et al. - Stack Overﬂow Considered Helpful! Deep Learning Se.pdf:application/pdf;Fischer et al. - Stack Overﬂow Considered Helpful! Deep Learning Se.pdf:C\:\\Users\\Anna\\Zotero\\storage\\43G5N824\\Fischer et al. - Stack Overﬂow Considered Helpful! Deep Learning Se.pdf:application/pdf}
}

@article{chen_how_2019,
	title = {How {Reliable} is the {Crowdsourced} {Knowledge} of {Security} {Implementation}?},
	journal = {arXiv preprint arXiv:1901.01327},
	author = {Chen, Mengsu and Fischer, Felix and Meng, Na and Wang, Xiaoyin and Grossklags, Jens},
	year = {2019},
	file = {Chen et al. - 2019 - How Reliable is the Crowdsourced Knowledge of Secu.pdf:C\:\\Users\\Anna\\Zotero\\storage\\IM8CLPKE\\Chen et al. - 2019 - How Reliable is the Crowdsourced Knowledge of Secu.pdf:application/pdf;Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\TKIL89EK\\1901.html:text/html}
}

@misc{noauthor_informatik_nodate,
	title = {Informatik 24 - {Lehrstuhl} für {Cyber} {Trust}: {Usable} {Security} \& {Privacy}},
	url = {https://www.cybertrust.in.tum.de/index.php?id=172},
	urldate = {2019-04-23},
	file = {Informatik 24 - Lehrstuhl für Cyber Trust\: Usable Security & Privacy:C\:\\Users\\Anna\\Zotero\\storage\\4B6QBZMM\\index.html:text/html}
}

@inproceedings{mohnen_graphfree_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Graph}—{Free} {Approach} to {Data}—{Flow} {Analysis}},
	isbn = {978-3-540-45937-8},
	abstract = {For decades, data—flow analysis (DFA) has been done using an iterative algorithm based on graph representations of programs. For a given data—flow problem, this algorithm computes the maximum fixed point (MFP) solution. The edge structure of the graph represents possible control flows in the program. In this paper, we present a new, graph-free algorithm for computing the MFP solution. The experimental implementation of the algorithm was applied to a large set of samples. The experiments clearly show that the memory usage of our algorithm is much better: Our algorithm always reduces the amount of memory and reached improvements upto less than a tenth. In the average case, the reduction is about a third of the memory usage of the classical algorithm. In addition, the experiments showed that the runtimes are almost the same: The average speedup of the classical algorithm is only marginally greater than one.},
	language = {en},
	booktitle = {Compiler {Construction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Mohnen, Markus},
	editor = {Horspool, R. Nigel},
	year = {2002},
	keywords = {Abstract Interpretation, Basic Block, Classical Algorithm, Java Virtual Machine, Memory Usage},
	pages = {46--61},
	file = {Mohnen - 2002 - A Graph—Free Approach to Data—Flow Analysis.pdf:C\:\\Users\\Anna\\Zotero\\storage\\2BIBHRKS\\Mohnen - 2002 - A Graph—Free Approach to Data—Flow Analysis.pdf:application/pdf}
}

@article{prokopec_renaissance:_2019,
	title = {Renaissance: {Benchmarking} {Suite} for {Parallel} {Applications} on the {JVM}},
	language = {en},
	author = {Prokopec, Aleksandar and Rosà, Andrea and Leopoldseder, David and Duboscq, Gilles and Tůma, Petr and Studener, Martin and Bulej, Lubomír and Zheng, Yudi and Villazón, Alex and Simon, Doug and Würthinger, Thomas and Binder, Walter},
	year = {2019},
	pages = {17},
	file = {Prokopec et al. - 2019 - Renaissance Benchmarking Suite for Parallel Appli.pdf:C\:\\Users\\Anna\\Zotero\\storage\\7LCZXD86\\Prokopec et al. - 2019 - Renaissance Benchmarking Suite for Parallel Appli.pdf:application/pdf}
}

@inproceedings{gan_open-source_2019,
	address = {Providence, RI, USA},
	title = {An {Open}-{Source} {Benchmark} {Suite} for {Microservices} and {Their} {Hardware}-{Software} {Implications} for {Cloud} \& {Edge} {Systems}},
	isbn = {978-1-4503-6240-5},
	url = {http://dl.acm.org/citation.cfm?doid=3297858.3304013},
	doi = {10.1145/3297858.3304013},
	language = {en},
	urldate = {2019-05-13},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}  - {ASPLOS} '19},
	publisher = {ACM Press},
	author = {Gan, Yu and Jackson, Brendon and Hu, Kelvin and Pancholi, Meghna and He, Yuan and Clancy, Brett and Colen, Chris and Wen, Fukang and Leung, Catherine and Wang, Siyuan and Zaruvinsky, Leon and Zhang, Yanqi and Espinosa, Mateo and Lin, Rick and Liu, Zhongling and Padilla, Jake and Delimitrou, Christina and Cheng, Dailun and Shetty, Ankitha and Rathi, Priyal and Katarki, Nayan and Bruno, Ariana and Hu, Justin and Ritchken, Brian},
	year = {2019},
	keywords = {to read},
	pages = {3--18},
	file = {Gan et al. - 2019 - An Open-Source Benchmark Suite for Microservices a.pdf:C\:\\Users\\Anna\\Zotero\\storage\\JWLWRJHT\\Gan et al. - 2019 - An Open-Source Benchmark Suite for Microservices a.pdf:application/pdf}
}

@inproceedings{li_large-scale_2017,
	address = {Dallas, Texas, USA},
	title = {A {Large}-{Scale} {Empirical} {Study} of {Security} {Patches}},
	isbn = {978-1-4503-4946-8},
	url = {http://dl.acm.org/citation.cfm?doid=3133956.3134072},
	doi = {10.1145/3133956.3134072},
	abstract = {Given how the “patching treadmill” plays a central role for enabling sites to counter emergent security concerns, it behooves the security community to understand the patch development process and characteristics of the resulting fixes. Illumination of the nature of security patch development can inform us of shortcomings in existing remediation processes and provide insights for improving current practices. In this work we conduct a large-scale empirical study of security patches, investigating more than 4,000 bug fixes for over 3,000 vulnerabilities that affected a diverse set of 682 open-source software projects. For our analysis we draw upon the National Vulnerability Database, information scraped from relevant external references, affected software repositories, and their associated security fixes. Leveraging this diverse set of information, we conduct an analysis of various aspects of the patch development life cycle, including investigation into the duration of impact a vulnerability has on a code base, the timeliness of patch development, and the degree to which developers produce safe and reliable fixes. We then characterize the nature of security fixes in comparison to other non-security bug fixes, exploring the complexity of different types of patches and their impact on code bases.},
	language = {en},
	urldate = {2019-05-14},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}  - {CCS} '17},
	publisher = {ACM Press},
	author = {Li, Frank and Paxson, Vern},
	year = {2017},
	pages = {2201--2215},
	file = {Li und Paxson - 2017 - A Large-Scale Empirical Study of Security Patches.pdf:C\:\\Users\\Anna\\Zotero\\storage\\968MPHV2\\Li und Paxson - 2017 - A Large-Scale Empirical Study of Security Patches.pdf:application/pdf}
}

@inproceedings{derr_keep_2017-1,
	address = {New York, NY, USA},
	series = {{CCS} '17},
	title = {Keep {Me} {Updated}: {An} {Empirical} {Study} of {Third}-{Party} {Library} {Updatability} on {Android}},
	isbn = {978-1-4503-4946-8},
	shorttitle = {Keep {Me} {Updated}},
	url = {http://doi.acm.org/10.1145/3133956.3134059},
	doi = {10.1145/3133956.3134059},
	abstract = {Third-party libraries in Android apps have repeatedly been shown to be hazards to the users' privacy and an amplification of their host apps' attack surface. A particularly aggravating factor to this situation is that the libraries' version included in apps are very often outdated. This paper makes the first contribution towards solving the problem of library outdatedness on Android. First, we conduct a survey with 203 app developers from Google Play to retrieve first-hand information about their usage of libraries and requirements for more effective library updates. With a subsequent study of library providers' semantic versioning practices, we uncover that those providers are likely a contributing factor to the app developers' abstinence from library updates in order to avoid ostensible re-integration efforts and version incompatibilities. Further, we conduct a large-scale library updatability analysis of 1,264,118 apps to show that, based on the library API usage, 85.6\% of the libraries could be upgraded by at least one version without modifying the app code, 48.2\% even to the latest version. Particularly alarming are our findings that 97.8\% out of 16,837 actively used library versions with a known security vulnerability could be easily fixed through a drop-in replacement of the vulnerable library with the fixed version. Based on these results, we conclude with a thorough discussion of solutions and actionable items for different actors in the app ecosystem to effectively remedy this situation.},
	urldate = {2019-05-14},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Derr, Erik and Bugiel, Sven and Fahl, Sascha and Acar, Yasemin and Backes, Michael},
	year = {2017},
	note = {event-place: Dallas, Texas, USA},
	keywords = {android, to read, api, app security, third-party library, updatability},
	pages = {2187--2200},
	file = {ACM Full Text PDF:C\:\\Users\\Anna\\Zotero\\storage\\WCNYIXBC\\Derr et al. - 2017 - Keep Me Updated An Empirical Study of Third-Party.pdf:application/pdf}
}

@inproceedings{gan_seer:_2019,
	address = {Providence, RI, USA},
	title = {Seer: {Leveraging} {Big} {Data} to {Navigate} the {Complexity} of {Performance} {Debugging} in {Cloud} {Microservices}},
	isbn = {978-1-4503-6240-5},
	shorttitle = {Seer},
	url = {http://dl.acm.org/citation.cfm?doid=3297858.3304004},
	doi = {10.1145/3297858.3304004},
	abstract = {Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether. We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91\% of the time, and avoids the QoS violation to begin with in 84\% of cases. Finally, we show that Seer can identify applicationlevel design bugs, and provide insights on how to better architect microservices to achieve predictable performance.},
	language = {en},
	urldate = {2019-05-15},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}  - {ASPLOS} '19},
	publisher = {ACM Press},
	author = {Gan, Yu and Zhang, Yanqi and Hu, Kelvin and Cheng, Dailun and He, Yuan and Pancholi, Meghna and Delimitrou, Christina},
	year = {2019},
	pages = {19--33},
	file = {Gan et al. - 2019 - Seer Leveraging Big Data to Navigate the Complexi.pdf:C\:\\Users\\Anna\\Zotero\\storage\\AI6JU2MZ\\Gan et al. - 2019 - Seer Leveraging Big Data to Navigate the Complexi.pdf:application/pdf}
}

@article{ranganath_new_2007,
	title = {A {New} {Foundation} for {Control} {Dependence} and {Slicing} for {Modern} {Program} {Structures}},
	volume = {29},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1275497.1275502},
	doi = {10.1145/1275497.1275502},
	abstract = {The notion of control dependence underlies many program analysis and transformation techniques. Despite being widely used, existing definitions and approaches to calculating control dependence are difficult to apply directly to modern program structures because these make substantial use of exception processing and increasingly support reactive systems designed to run indefinitely. This article revisits foundational issues surrounding control dependence, and develops definitions and algorithms for computing several variations of control dependence that can be directly applied to modern program structures. To provide a foundation for slicing reactive systems, the article proposes a notion of slicing correctness based on weak bisimulation, and proves that some of these new definitions of control dependence generate slices that conform to this notion of correctness. This new framework of control dependence definitions, with corresponding correctness results, is even able to support programs with irreducible control flow graphs. Finally, a variety of properties show that the new definitions conservatively extend classic definitions. These new definitions and algorithms form the basis of the Indus Java slicer, a publicly available program slicer that has been implemented for full Java.},
	number = {5},
	urldate = {2019-05-16},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Ranganath, Venkatesh Prasad and Amtoft, Torben and Banerjee, Anindya and Hatcliff, John and Dwyer, Matthew B.},
	month = aug,
	year = {2007},
	keywords = {bisimulation, control dependence, Indus, Nontermination, order dependence, program slicing},
	file = {Ranganath et al. - 2007 - A New Foundation for Control Dependence and Slicin.pdf:C\:\\Users\\Anna\\Zotero\\storage\\QWWUJZNH\\Ranganath et al. - 2007 - A New Foundation for Control Dependence and Slicin.pdf:application/pdf}
}

@misc{noauthor_understanding_2019,
	title = {Understanding real-world concurrency bugs in {Go}},
	url = {https://blog.acolyer.org/2019/05/17/understanding-real-world-concurrency-bugs-in-go/},
	abstract = {Understanding real-world concurrency bugs in Go Tu, Liu et al., ASPLOS’19 The design of a programming (or data) model not only makes certain problems easier (or harder) to solve, but also mak…},
	language = {en},
	urldate = {2019-05-17},
	journal = {the morning paper},
	month = may,
	year = {2019},
	file = {Snapshot:C\:\\Users\\Anna\\Zotero\\storage\\399TC4M7\\understanding-real-world-concurrency-bugs-in-go.html:text/html}
}

@inproceedings{tu_understanding_2019,
	address = {Providence, RI, USA},
	title = {Understanding {Real}-{World} {Concurrency} {Bugs} in {Go}},
	isbn = {978-1-4503-6240-5},
	url = {http://dl.acm.org/citation.cfm?doid=3297858.3304069},
	doi = {10.1145/3297858.3304069},
	abstract = {Go is a statically-typed programming language that aims to provide a simple, efficient, and safe way to build multithreaded software. Since its creation in 2009, Go has matured and gained significant adoption in production and open-source software. Go advocates for the usage of message passing as the means of inter-thread communication and provides several new concurrency mechanisms and libraries to ease multi-threading programming. It is important to understand the implication of these new proposals and the comparison of message passing and shared memory synchronization in terms of program errors, or bugs. Unfortunately, as far as we know, there has been no study on Go’s concurrency bugs.},
	language = {en},
	urldate = {2019-05-17},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}  - {ASPLOS} '19},
	publisher = {ACM Press},
	author = {Tu, Tengfei and Liu, Xiaoyu and Song, Linhai and Zhang, Yiying},
	year = {2019},
	pages = {865--878},
	file = {Tu et al. - 2019 - Understanding Real-World Concurrency Bugs in Go.pdf:C\:\\Users\\Anna\\Zotero\\storage\\T5DNGNU3\\Tu et al. - 2019 - Understanding Real-World Concurrency Bugs in Go.pdf:application/pdf}
}

@inproceedings{derr_keep_2017-2,
	address = {Dallas, Texas, USA},
	title = {Keep me {Updated}: {An} {Empirical} {Study} of {Third}-{Party} {Library} {Updatability} on {Android}},
	isbn = {978-1-4503-4946-8},
	shorttitle = {Keep me {Updated}},
	url = {http://dl.acm.org/citation.cfm?doid=3133956.3134059},
	doi = {10.1145/3133956.3134059},
	abstract = {Third-party libraries in Android apps have repeatedly been shown to be hazards to the users’ privacy and an amplification of their host apps’ attack surface. A particularly aggravating factor to this situation is that the libraries’ version included in apps are very often outdated.},
	language = {en},
	urldate = {2019-05-20},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}  - {CCS} '17},
	publisher = {ACM Press},
	author = {Derr, Erik and Bugiel, Sven and Fahl, Sascha and Acar, Yasemin and Backes, Michael},
	year = {2017},
	keywords = {to read},
	pages = {2187--2200},
	file = {p2187-derr.pdf:C\:\\Users\\Anna\\Zotero\\storage\\AUZPQJ5D\\p2187-derr.pdf:application/pdf}
}

@inproceedings{li_large-scale_2017-1,
	address = {New York, NY, USA},
	series = {{CCS} '17},
	title = {A {Large}-{Scale} {Empirical} {Study} of {Security} {Patches}},
	isbn = {978-1-4503-4946-8},
	url = {http://doi.acm.org/10.1145/3133956.3134072},
	doi = {10.1145/3133956.3134072},
	abstract = {Given how the "patching treadmill" plays a central role for enabling sites to counter emergent security concerns, it behooves the security community to understand the patch development process and characteristics of the resulting fixes. Illumination of the nature of security patch development can inform us of shortcomings in existing remediation processes and provide insights for improving current practices. In this work we conduct a large-scale empirical study of security patches, investigating more than 4,000 bug fixes for over 3,000 vulnerabilities that affected a diverse set of 682 open-source software projects. For our analysis we draw upon the National Vulnerability Database, information scraped from relevant external references, affected software repositories, and their associated security fixes. Leveraging this diverse set of information, we conduct an analysis of various aspects of the patch development life cycle, including investigation into the duration of impact a vulnerability has on a code base, the timeliness of patch development, and the degree to which developers produce safe and reliable fixes. We then characterize the nature of security fixes in comparison to other non-security bug fixes, exploring the complexity of different types of patches and their impact on code bases. Among our findings we identify that: security patches have a lower footprint in code bases than non-security bug patches; a third of all security issues were introduced more than 3 years prior to remediation; attackers who monitor open-source repositories can often get a jump of weeks to months on targeting not-yet-patched systems prior to any public disclosure and patch distribution; nearly 5\% of security fixes negatively impacted the associated software; and 7\% failed to completely remedy the security hole they targeted.},
	urldate = {2019-05-20},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Li, Frank and Paxson, Vern},
	year = {2017},
	note = {event-place: Dallas, Texas, USA},
	keywords = {vulnerabilities, to read, empirical study, patch complexity, security patches},
	pages = {2201--2215},
	file = {Li und Paxson - 2017 - A Large-Scale Empirical Study of Security Patches.pdf:C\:\\Users\\Anna\\Zotero\\storage\\AGDG4J66\\Li und Paxson - 2017 - A Large-Scale Empirical Study of Security Patches.pdf:application/pdf}
}

@article{gao_negative_nodate,
	title = {Negative {Results} on {Mining} {Crypto}-{API} {Usage} {Rules} in {Android} {Apps}},
	abstract = {Android app developers recurrently use crypto-APIs to provide data security to app users. Unfortunately, misuse of APIs only creates an illusion of security and even exposes apps to systematic attacks. It is thus necessary to provide developers with a statically-enforceable list of speciﬁcations of crypto-API usage rules. On the one hand, such rules cannot be manually written as the process does not scale to all available APIs. On the other hand, a classical mining approach based on common usage patterns is not relevant in Android, given that a large share of usages include mistakes. In this work, building on the assumption that “developers update API usage instances to ﬁx misuses”, we propose to mine a large dataset of updates within about 40 000 real-world app lineages to infer API usage rules. Eventually, our investigations yield negative results on our assumption that API usage updates tend to correct misuses. Actually, it appears that updates that ﬁx misuses may be unintentional: the same misuses patterns are quickly re-introduced by subsequent updates.},
	language = {en},
	author = {Gao, Jun and Kong, Pingfan and Li, Li and Bissyande, Tegawende F and Klein, Jacques},
	keywords = {to read},
	pages = {11},
	file = {Gao et al. - Negative Results on Mining Crypto-API Usage Rules .pdf:C\:\\Users\\Anna\\Zotero\\storage\\AV4DI7QE\\Gao et al. - Negative Results on Mining Crypto-API Usage Rules .pdf:application/pdf}
}

@article{noauthor_notitle_nodate-1
}

@inproceedings{wickert_dataset_2019,
	title = {A {Dataset} of {Parametric} {Cryptographic} {Misuses}},
	copyright = {All rights reserved},
	url = {http://tubiblio.ulb.tu-darmstadt.de/112142/},
	booktitle = {2019 {IEEE}/{ACM} 16th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	publisher = {IEEE},
	author = {Wickert, Anna-Katharina and Reif, Michael and Eichberg, Michael and Dodhy, Anam and Mezini, Mira},
	month = mar,
	year = {2019},
	keywords = {E1, Engineering}
}